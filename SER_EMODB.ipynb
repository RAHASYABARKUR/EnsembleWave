{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SER_EMODB.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fKYweTIypSK0"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLR9sECNmvum",
        "outputId": "e56c0108-5a16-4e15-d072-1df268b9b48f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqYdFLgmnN2h",
        "outputId": "78d74fe0-d38a-4ae1-cf8b-c0fe1fe9a193"
      },
      "source": [
        "%cd '/content/drive/My Drive/AudioProcessing/Emotion_Recognition'\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/AudioProcessing/Emotion_Recognition\n",
            " \u001b[0m\u001b[01;34mCREMA\u001b[0m/     kaggle.json            \u001b[01;34mRAVDESS_copied\u001b[0m/                     \u001b[01;34mtry\u001b[0m/\n",
            " \u001b[01;34mEMODB\u001b[0m/     model.png              \u001b[01;34mSAVEE\u001b[0m/\n",
            " \u001b[01;34mEMO_DB\u001b[0m/   \u001b[01;36m'Papers & Materials'\u001b[0m@   speech-emotion-recognition-en.zip\n",
            " \u001b[01;34mIEMOCAP\u001b[0m/   \u001b[01;34mRAVDESS\u001b[0m/               \u001b[01;34mTESS\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xg4aijrnU-R"
      },
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.callbacks import ModelCheckpoint, Callback\n",
        "from sklearn.preprocessing import  StandardScaler\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn import feature_selection\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy52NUf_YE3M"
      },
      "source": [
        "# DataSet Splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5EQtaP08Es1",
        "outputId": "4e0d1537-e90b-431b-ff0f-133f0f081469"
      },
      "source": [
        "def decompose_emodb():\n",
        "\n",
        "        EMODB_PATH = 'EMO_DB/'\n",
        "        emotion = []\n",
        "        path = []\n",
        "        for dirname, _, filenames in os.walk('EMO_DB/wav'):\n",
        "          for name in filenames[1:]:\n",
        "            #print(name,len(name))\n",
        "\n",
        "                if name[0:2] in '0310111215':  # MALE\n",
        "                    if name[5] == 'W':  # Ärger (Wut) -> Angry\n",
        "                        emotion.append('m_angry')\n",
        "                    elif name[5] == 'L':  # Langeweile -> Boredom\n",
        "                        emotion.append('m_bored')\n",
        "                    elif name[5] == 'E':  # Ekel -> Disgusted\n",
        "                        emotion.append('m_disgust')\n",
        "                    elif name[5] == 'A':  # Angst -> Fear\n",
        "                        emotion.append('m_fear')\n",
        "                    elif name[5] == 'F':  # Freude -> Happiness\n",
        "                        emotion.append('m_happy')\n",
        "                    elif name[5] == 'T':  # Trauer -> Sadness\n",
        "                        emotion.append('m_sad')\n",
        "                    else:\n",
        "                        #print(name)\n",
        "                        emotion.append('m_neutral')\n",
        "                else:\n",
        "                    if name[5] == 'W':  # Ärger (Wut) -> Angry\n",
        "                        emotion.append('f_angry')\n",
        "                    elif name[5] == 'L':  # Langeweile -> Boredom\n",
        "                        emotion.append('f_bored')\n",
        "                    elif name[5] == 'E':  # Ekel -> Disgusted\n",
        "                        emotion.append('f_disgust')\n",
        "                    elif name[5] == 'A':  # Angst -> Fear\n",
        "                        emotion.append('f_fear')\n",
        "                    elif name[5] == 'F':  # Freude -> Happiness\n",
        "                        emotion.append('f_happy')\n",
        "                    elif name[5] == 'T':  # Trauer -> Sadness\n",
        "                        emotion.append('f_sad')\n",
        "                    else:\n",
        "                        emotion.append('f_neutral')\n",
        "\n",
        "                path.append(os.path.join(EMODB_PATH+'wav', name))\n",
        "\n",
        "        print(len(path),len(emotion))\n",
        "        emodb_df = pd.DataFrame(emotion, columns=['labels'])\n",
        "        #emodb_df['source'] = 'EMODB'\n",
        "        emodb_df = pd.concat([emodb_df, pd.DataFrame(path, columns=['path'])], axis=1)\n",
        "        \n",
        "        return emodb_df\n",
        "\n",
        "df = decompose_emodb()\n",
        "print(df.shape)\n",
        "df.to_csv('EMO_DB/EMODB_details.csv',index=False,index_label=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "534 534\n",
            "(534, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGsVzCiKpk8W",
        "outputId": "1ee64252-0160-490f-e7de-0eb2e1442d53"
      },
      "source": [
        "#angry, happy, neutral, sad\n",
        "X = pd.read_csv('EMO_DB/EMODB_details.csv',usecols=['labels','path'])\n",
        "options = ['m_angry', 'm_happy','m_neutral','m_sad',\n",
        "           'f_angry', 'f_happy','f_neutral','f_sad'] \n",
        "  \n",
        "rslt_df = X[X['labels'].isin(options)] \n",
        "print(np.unique(rslt_df.labels))\n",
        "print(rslt_df.shape)\n",
        "rslt_df.head()\n",
        "\n",
        "test_val= rslt_df.sample(frac = 0.3)\n",
        "train = rslt_df.drop(test_val.index)\n",
        "\n",
        "test= test_val.sample(frac = 0.5)\n",
        "val = test_val.drop(test.index)\n",
        "\n",
        "print(val['labels'].unique())\n",
        "print(test['labels'].unique())\n",
        "print(train['labels'].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['f_angry' 'f_happy' 'f_neutral' 'f_sad' 'm_angry' 'm_happy' 'm_neutral'\n",
            " 'm_sad']\n",
            "(338, 2)\n",
            "['m_angry' 'f_neutral' 'f_happy' 'f_sad' 'f_angry' 'm_neutral' 'm_sad'\n",
            " 'm_happy']\n",
            "['f_angry' 'm_angry' 'f_sad' 'm_neutral' 'f_happy' 'f_neutral' 'm_sad'\n",
            " 'm_happy']\n",
            "['m_happy' 'm_angry' 'm_sad' 'm_neutral' 'f_happy' 'f_neutral' 'f_angry'\n",
            " 'f_sad']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0LUQh70tJ9m"
      },
      "source": [
        "train.to_csv(\"EMO_DB//train.csv\")\n",
        "test.to_csv(\"EMO_DB//test.csv\")\n",
        "val.to_csv(\"EMO_DB//val.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NHZlhyTtYiw"
      },
      "source": [
        "#angry, happy, neutral, sad\n",
        "import csv\n",
        "\n",
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "\n",
        "def extract_features(csvpath,path):\n",
        "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
        "    for i in range(1, 21):\n",
        "        header += f' mfcc{i}'\n",
        "    header += ' label'\n",
        "    header = header.split()\n",
        "    file = open(csvpath, 'w', newline='')\n",
        "    with file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow(header)\n",
        "    rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "        filename = row['path']\n",
        "        y, sr = librosa.load(row['path'], mono=True, duration=30)\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "        rmse = librosa.feature.rms(y=y)\n",
        "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "        to_append = f' {filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
        "        for e in mfcc:\n",
        "                    to_append += f' {np.mean(e)}'\n",
        "        onehot_label = label_to_onehot(row['labels'])\n",
        "        to_append += f' {np.argmax(onehot_label)}'\n",
        "        file = open(csvpath, 'a', newline='')\n",
        "        with file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow(to_append.split())\n",
        "\n",
        "train_csv = \"EMO_DB//train.csv\"\n",
        "test_csv = \"EMO_DB//test.csv\"\n",
        "val_csv = \"EMO_DB//val.csv\"\n",
        "csvpath = 'EMO_DB//hand_engineered_features_EMODB_train.csv'\n",
        "extract_features(csvpath,train_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_EMODB_test.csv'\n",
        "extract_features(csvpath,test_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_EMODB_val.csv'\n",
        "extract_features(csvpath,val_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEg_CAGopOYh"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mjUWpl9nYVi",
        "outputId": "e14ab6c7-65bf-447d-f63e-806bd77c3d8f"
      },
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (237, 64000, 1) (237, 4)\n",
            "Test Data (50, 64000, 1) (50, 4)\n",
            "Val Data (51, 64000, 1) (51, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8yKXyj7noth",
        "outputId": "2e83895f-3e01-4f7f-9c9c-aed587bd45e9"
      },
      "source": [
        "csvpath = 'EMO_DB/hand_engineered_features_EMODB_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB/hand_engineered_features_EMODB_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB/hand_engineered_features_EMODB_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 26) (237, 1)\n",
            "(50, 26) (50, 1)\n",
            "(51, 26) (51, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKYweTIypSK0"
      },
      "source": [
        "# Feature Importance Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "zLzS6YjEpHjP",
        "outputId": "68fca300-99d4-4e48-dbd5-5a3424d64e9a"
      },
      "source": [
        "importances = feature_selection.mutual_info_classif(X_train_features,Y_train_features)\n",
        "feat_importances = pd.Series(importances,data.columns[0:len(data.columns)-1])\n",
        "plt.figure(figsize = (10,10))\n",
        "feat_importances.plot(kind = 'barh',color = 'teal')\n",
        "plt.title(\"Features vs Importance\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCnxAlngpW1w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duBWGLjupeWc"
      },
      "source": [
        "# WaveNet Paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxCU9X94pgTJ",
        "outputId": "cbc141fe-72a6-4fe4-c87c-4b3cc7ea965c"
      },
      "source": [
        "# hyper-parameters\n",
        "n_filters = 32\n",
        "filter_width = 2\n",
        "dilation_rates = [2**i for i in range(4)] * 2 \n",
        "sr = 16000\n",
        "# define an input history series and pass it through a stack of dilated causal convolution blocks\n",
        "history_seq = Input(shape=(int(sr*time), 1))\n",
        "x = history_seq\n",
        "\n",
        "skips = []\n",
        "for dilation_rate in dilation_rates:\n",
        "    \n",
        "    # preprocessing - equivalent to time-distributed dense\n",
        "    x = Conv1D(16, 1, padding='same', activation='relu')(x) \n",
        "    \n",
        "    # filter\n",
        "    x_f = Conv1D(filters=n_filters,\n",
        "                 kernel_size=filter_width, \n",
        "                 padding='causal',\n",
        "                 dilation_rate=dilation_rate)(x)\n",
        "    \n",
        "    # gate\n",
        "    x_g = Conv1D(filters=n_filters,\n",
        "                 kernel_size=filter_width, \n",
        "                 padding='causal',\n",
        "                 dilation_rate=dilation_rate)(x)\n",
        "    \n",
        "    # combine filter and gating branches\n",
        "    z = Multiply()([Activation('tanh')(x_f),\n",
        "                    Activation('sigmoid')(x_g)])\n",
        "    \n",
        "    # postprocessing - equivalent to time-distributed dense\n",
        "    z = Conv1D(16, 1, padding='same', activation='relu')(z)\n",
        "    \n",
        "    # residual connection\n",
        "    x = Add()([x, z])    \n",
        "    \n",
        "    # collect skip connections\n",
        "    skips.append(z)\n",
        "\n",
        "# add all skip connection outputs \n",
        "out = Activation('relu')(Add()(skips))\n",
        "out = AveragePooling1D(sr*time)(out)\n",
        "out = Conv1D(8,1,activation='relu')(out)\n",
        "out = Conv1D(4,1,activation='softmax')(out)\n",
        "out = Reshape((4,1))(out)\n",
        "\n",
        "Wavenet_paper = Model(history_seq, out)\n",
        "Wavenet_paper.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           [(None, 64000, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_298 (Conv1D)             (None, 64000, 16)    32          input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_299 (Conv1D)             (None, 64000, 32)    1056        conv1d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_300 (Conv1D)             (None, 64000, 32)    1056        conv1d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 64000, 32)    0           conv1d_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 64000, 32)    0           conv1d_300[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_58 (Multiply)          (None, 64000, 32)    0           activation_127[0][0]             \n",
            "                                                                 activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_301 (Conv1D)             (None, 64000, 16)    528         multiply_58[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_75 (Add)                    (None, 64000, 16)    0           conv1d_298[0][0]                 \n",
            "                                                                 conv1d_301[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_302 (Conv1D)             (None, 64000, 16)    272         add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_303 (Conv1D)             (None, 64000, 32)    1056        conv1d_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_304 (Conv1D)             (None, 64000, 32)    1056        conv1d_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 64000, 32)    0           conv1d_303[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 64000, 32)    0           conv1d_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_59 (Multiply)          (None, 64000, 32)    0           activation_129[0][0]             \n",
            "                                                                 activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_305 (Conv1D)             (None, 64000, 16)    528         multiply_59[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_76 (Add)                    (None, 64000, 16)    0           conv1d_302[0][0]                 \n",
            "                                                                 conv1d_305[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_306 (Conv1D)             (None, 64000, 16)    272         add_76[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_307 (Conv1D)             (None, 64000, 32)    1056        conv1d_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_308 (Conv1D)             (None, 64000, 32)    1056        conv1d_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 64000, 32)    0           conv1d_307[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 64000, 32)    0           conv1d_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_60 (Multiply)          (None, 64000, 32)    0           activation_131[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_309 (Conv1D)             (None, 64000, 16)    528         multiply_60[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_77 (Add)                    (None, 64000, 16)    0           conv1d_306[0][0]                 \n",
            "                                                                 conv1d_309[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_310 (Conv1D)             (None, 64000, 16)    272         add_77[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_311 (Conv1D)             (None, 64000, 32)    1056        conv1d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_312 (Conv1D)             (None, 64000, 32)    1056        conv1d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 64000, 32)    0           conv1d_311[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 64000, 32)    0           conv1d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_61 (Multiply)          (None, 64000, 32)    0           activation_133[0][0]             \n",
            "                                                                 activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_313 (Conv1D)             (None, 64000, 16)    528         multiply_61[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_78 (Add)                    (None, 64000, 16)    0           conv1d_310[0][0]                 \n",
            "                                                                 conv1d_313[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_314 (Conv1D)             (None, 64000, 16)    272         add_78[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_315 (Conv1D)             (None, 64000, 32)    1056        conv1d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_316 (Conv1D)             (None, 64000, 32)    1056        conv1d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 64000, 32)    0           conv1d_315[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 64000, 32)    0           conv1d_316[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_62 (Multiply)          (None, 64000, 32)    0           activation_135[0][0]             \n",
            "                                                                 activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_317 (Conv1D)             (None, 64000, 16)    528         multiply_62[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_79 (Add)                    (None, 64000, 16)    0           conv1d_314[0][0]                 \n",
            "                                                                 conv1d_317[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_318 (Conv1D)             (None, 64000, 16)    272         add_79[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_319 (Conv1D)             (None, 64000, 32)    1056        conv1d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_320 (Conv1D)             (None, 64000, 32)    1056        conv1d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 64000, 32)    0           conv1d_319[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 64000, 32)    0           conv1d_320[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_63 (Multiply)          (None, 64000, 32)    0           activation_137[0][0]             \n",
            "                                                                 activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_321 (Conv1D)             (None, 64000, 16)    528         multiply_63[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_80 (Add)                    (None, 64000, 16)    0           conv1d_318[0][0]                 \n",
            "                                                                 conv1d_321[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_322 (Conv1D)             (None, 64000, 16)    272         add_80[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_323 (Conv1D)             (None, 64000, 32)    1056        conv1d_322[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_324 (Conv1D)             (None, 64000, 32)    1056        conv1d_322[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 64000, 32)    0           conv1d_323[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 64000, 32)    0           conv1d_324[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_64 (Multiply)          (None, 64000, 32)    0           activation_139[0][0]             \n",
            "                                                                 activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_325 (Conv1D)             (None, 64000, 16)    528         multiply_64[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_81 (Add)                    (None, 64000, 16)    0           conv1d_322[0][0]                 \n",
            "                                                                 conv1d_325[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_326 (Conv1D)             (None, 64000, 16)    272         add_81[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_327 (Conv1D)             (None, 64000, 32)    1056        conv1d_326[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_328 (Conv1D)             (None, 64000, 32)    1056        conv1d_326[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 64000, 32)    0           conv1d_327[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 64000, 32)    0           conv1d_328[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_65 (Multiply)          (None, 64000, 32)    0           activation_141[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_329 (Conv1D)             (None, 64000, 16)    528         multiply_65[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_83 (Add)                    (None, 64000, 16)    0           conv1d_301[0][0]                 \n",
            "                                                                 conv1d_305[0][0]                 \n",
            "                                                                 conv1d_309[0][0]                 \n",
            "                                                                 conv1d_313[0][0]                 \n",
            "                                                                 conv1d_317[0][0]                 \n",
            "                                                                 conv1d_321[0][0]                 \n",
            "                                                                 conv1d_325[0][0]                 \n",
            "                                                                 conv1d_329[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 64000, 16)    0           add_83[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_29 (AveragePo (None, 1, 16)        0           activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_330 (Conv1D)             (None, 1, 8)         136         average_pooling1d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_331 (Conv1D)             (None, 1, 4)         36          conv1d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_35 (Reshape)            (None, 4, 1)         0           conv1d_331[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 23,228\n",
            "Trainable params: 23,228\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Xc777sOpkul",
        "outputId": "7cb75a01-e26d-4a04-f9e4-1154eea26133"
      },
      "source": [
        "Wavenet_paper.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMO_DB//models//wavenet_paper_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMO_DB//models//wavenet_paper_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = Wavenet_paper.fit(X_train,Y_train, batch_size=20,validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 23s 2s/step - loss: 1.3864 - accuracy: 0.7500 - val_loss: 1.3861 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.38608, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.75000, saving model to EMO_DB//models/wavenet_paper_acc.h5\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.3816 - accuracy: 0.7500 - val_loss: 1.3859 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.38608 to 1.38588, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.75000\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.3756 - accuracy: 0.7500 - val_loss: 1.3859 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.38588 to 1.38585, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.75000\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.3726 - accuracy: 0.7500 - val_loss: 1.3844 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.38585 to 1.38436, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.75000\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.3580 - accuracy: 0.7500 - val_loss: 1.3769 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.38436 to 1.37692, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.75000\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.3451 - accuracy: 0.7500 - val_loss: 1.3690 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.37692 to 1.36899, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.75000\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.3114 - accuracy: 0.7500 - val_loss: 1.3488 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.36899 to 1.34877, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.75000\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.2737 - accuracy: 0.7500 - val_loss: 1.3964 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.34877\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.75000\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.2527 - accuracy: 0.7652 - val_loss: 1.3084 - val_accuracy: 0.7647\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.34877 to 1.30843, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.75000 to 0.76471, saving model to EMO_DB//models/wavenet_paper_acc.h5\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.1887 - accuracy: 0.7852 - val_loss: 1.2512 - val_accuracy: 0.7598\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.30843 to 1.25117, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.76471\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.1338 - accuracy: 0.7979 - val_loss: 1.2042 - val_accuracy: 0.7696\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.25117 to 1.20419, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.76471 to 0.76961, saving model to EMO_DB//models/wavenet_paper_acc.h5\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.0719 - accuracy: 0.7980 - val_loss: 1.1700 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.20419 to 1.16998, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.76961\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.9913 - accuracy: 0.8022 - val_loss: 1.1331 - val_accuracy: 0.7549\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.16998 to 1.13311, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.76961\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.0029 - accuracy: 0.8109 - val_loss: 1.1011 - val_accuracy: 0.7696\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.13311 to 1.10108, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.76961\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.9668 - accuracy: 0.7920 - val_loss: 1.2346 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.10108\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.76961\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.9765 - accuracy: 0.8036 - val_loss: 1.0647 - val_accuracy: 0.7745\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.10108 to 1.06471, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.76961 to 0.77451, saving model to EMO_DB//models/wavenet_paper_acc.h5\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.9086 - accuracy: 0.8115 - val_loss: 1.0076 - val_accuracy: 0.7794\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.06471 to 1.00755, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.77451 to 0.77941, saving model to EMO_DB//models/wavenet_paper_acc.h5\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.8704 - accuracy: 0.8171 - val_loss: 1.0030 - val_accuracy: 0.7745\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.00755 to 1.00301, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.77941\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.8607 - accuracy: 0.8212 - val_loss: 0.9710 - val_accuracy: 0.7794\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.00301 to 0.97103, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.77941\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.8494 - accuracy: 0.8313 - val_loss: 1.0628 - val_accuracy: 0.7745\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.97103\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.77941\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.8022 - accuracy: 0.8345 - val_loss: 0.9355 - val_accuracy: 0.7843\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.97103 to 0.93549, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.77941 to 0.78431, saving model to EMO_DB//models/wavenet_paper_acc.h5\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.8316 - accuracy: 0.8233 - val_loss: 0.9060 - val_accuracy: 0.7990\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.93549 to 0.90595, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.78431 to 0.79902, saving model to EMO_DB//models/wavenet_paper_acc.h5\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.7732 - accuracy: 0.8453 - val_loss: 0.8893 - val_accuracy: 0.8039\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.90595 to 0.88931, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.79902 to 0.80392, saving model to EMO_DB//models/wavenet_paper_acc.h5\n",
            "Epoch 24/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.7957 - accuracy: 0.8318 - val_loss: 0.8998 - val_accuracy: 0.8039\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.88931\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.80392\n",
            "Epoch 25/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.7644 - accuracy: 0.8500 - val_loss: 0.8725 - val_accuracy: 0.7941\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.88931 to 0.87248, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.80392\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.7814 - accuracy: 0.8303 - val_loss: 0.8367 - val_accuracy: 0.7990\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.87248 to 0.83673, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.80392\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.7250 - accuracy: 0.8601 - val_loss: 0.8303 - val_accuracy: 0.7990\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.83673 to 0.83032, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.80392\n",
            "Epoch 28/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.7216 - accuracy: 0.8360 - val_loss: 0.8195 - val_accuracy: 0.7990\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.83032 to 0.81952, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.80392\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.7599 - accuracy: 0.8408 - val_loss: 0.7992 - val_accuracy: 0.8137\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.81952 to 0.79921, saving model to EMO_DB//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.80392 to 0.81373, saving model to EMO_DB//models/wavenet_paper_acc.h5\n",
            "Epoch 30/30\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.6905 - accuracy: 0.8623 - val_loss: 0.8224 - val_accuracy: 0.7990\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.79921\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.81373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-XGhBZ-NH_b",
        "outputId": "e8973e43-16c7-441c-d70e-37397b807948"
      },
      "source": [
        "Wavenet_paper.evaluate(X_test,Y_test)\n",
        "Wavenet_paper.load_weights('EMO_DB//models//wavenet_paper_loss.h5')\n",
        "print(Wavenet_paper.evaluate(X_test,Y_test))\n",
        "Wavenet_paper.load_weights('EMO_DB//models//wavenet_paper_acc.h5')\n",
        "Wavenet_paper.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 2s 567ms/step - loss: 0.6163 - accuracy: 0.8650\n",
            "2/2 [==============================] - 1s 562ms/step - loss: 0.6061 - accuracy: 0.8550\n",
            "[0.6060598492622375, 0.8550000190734863]\n",
            "2/2 [==============================] - 1s 560ms/step - loss: 0.6061 - accuracy: 0.8550\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6060598492622375, 0.8550000190734863]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "qirrWUUQZqfa",
        "outputId": "c02d2c62-ece3-478a-c1d7-a0dcdd567207"
      },
      "source": [
        "Wavenet_paper.load_weights('EMO_DB//models//wavenet_paper_loss.h5')\n",
        "\n",
        "Wavenet_paper.evaluate(X_test,Y_test)\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(Wavenet_paper.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1)\n",
        "print(g.shape,p.shape)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(Y_test_features,np.argmax(Wavenet_paper.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 2s 576ms/step - loss: 0.6061 - accuracy: 0.8550\n",
            "(50,) (50,)\n",
            "F1 SCORE: 0.5922943722943723\n",
            "Kappa: 0.6370235934664248\n",
            "Accuracy: 0.76\n",
            "Jaccard Score: 0.49313186813186816\n",
            "Precision: 0.5600649350649352\n",
            "Recall: 0.6318181818181818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f61fa43ce90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J_6UhiTp23a"
      },
      "source": [
        "# Wavenet 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqYxqURqpzKa",
        "outputId": "369c7c1b-629c-4d56-c228-8639cf6dd5ef"
      },
      "source": [
        "# hyper-parameters\n",
        "\n",
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "n_filters = 64\n",
        "filter_width = 2\n",
        "dilation_rates = [2**i for i in range(3)]  \n",
        "sr = 16000\n",
        "\n",
        "history_seq = Input(shape=(int(sr*4), 1))\n",
        "x = history_seq\n",
        "\n",
        "\n",
        "x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "x = AveragePooling1D()(x)\n",
        "\n",
        "x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "x = AveragePooling1D()(x)\n",
        "\n",
        "x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "x = AveragePooling1D()(x)\n",
        "skips = []\n",
        "for dilation_rate in dilation_rates:\n",
        "    \n",
        "    \n",
        "    x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "    \n",
        "    # filter\n",
        "    x_f = Conv1D(filters=n_filters,\n",
        "                 kernel_size=filter_width, \n",
        "                 padding='causal',\n",
        "                 dilation_rate=dilation_rate)(x)\n",
        "    \n",
        "    # gate\n",
        "    x_g = Conv1D(filters=n_filters,\n",
        "                 kernel_size=filter_width, \n",
        "                 padding='causal',\n",
        "                 dilation_rate=dilation_rate)(x)\n",
        "    \n",
        "    # combine filter and gating branches\n",
        "    z = Multiply()([Activation('tanh')(x_f),\n",
        "                    Activation('sigmoid')(x_g)])\n",
        "    \n",
        "    # postprocessing - equivalent to time-distributed dense\n",
        "    z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "    \n",
        "    # residual connection\n",
        "    x = Add()([x, z])    \n",
        "    \n",
        "    \n",
        "    skips.append(z)\n",
        "\n",
        "\n",
        "out = Activation('relu')(Add()(skips))\n",
        "\n",
        "out = AveragePooling1D(8000)(out)\n",
        "out = self_attention(out)\n",
        "\n",
        "out = Conv1D(4,1,activation='softmax')(out)\n",
        "out = Reshape((4,1))(out)\n",
        "\n",
        "Wavenet5 = Model(history_seq, out)\n",
        "Wavenet5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_17 (InputLayer)           [(None, 64000, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_332 (Conv1D)             (None, 64000, 8)     48          input_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_44 (LeakyReLU)      (None, 64000, 8)     0           conv1d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_333 (Conv1D)             (None, 64000, 8)     328         leaky_re_lu_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_45 (LeakyReLU)      (None, 64000, 8)     0           conv1d_333[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_30 (AveragePo (None, 32000, 8)     0           leaky_re_lu_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_334 (Conv1D)             (None, 32000, 16)    656         average_pooling1d_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_46 (LeakyReLU)      (None, 32000, 16)    0           conv1d_334[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_335 (Conv1D)             (None, 32000, 16)    1296        leaky_re_lu_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_47 (LeakyReLU)      (None, 32000, 16)    0           conv1d_335[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_31 (AveragePo (None, 16000, 16)    0           leaky_re_lu_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_336 (Conv1D)             (None, 16000, 16)    1296        average_pooling1d_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_48 (LeakyReLU)      (None, 16000, 16)    0           conv1d_336[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_337 (Conv1D)             (None, 16000, 16)    1296        leaky_re_lu_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_49 (LeakyReLU)      (None, 16000, 16)    0           conv1d_337[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_32 (AveragePo (None, 8000, 16)     0           leaky_re_lu_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_338 (Conv1D)             (None, 8000, 32)     544         average_pooling1d_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_339 (Conv1D)             (None, 8000, 64)     4160        conv1d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_340 (Conv1D)             (None, 8000, 64)     4160        conv1d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 8000, 64)     0           conv1d_339[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 8000, 64)     0           conv1d_340[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_66 (Multiply)          (None, 8000, 64)     0           activation_144[0][0]             \n",
            "                                                                 activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_341 (Conv1D)             (None, 8000, 32)     2080        multiply_66[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_84 (Add)                    (None, 8000, 32)     0           conv1d_338[0][0]                 \n",
            "                                                                 conv1d_341[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_342 (Conv1D)             (None, 8000, 32)     1056        add_84[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_343 (Conv1D)             (None, 8000, 64)     4160        conv1d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_344 (Conv1D)             (None, 8000, 64)     4160        conv1d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 8000, 64)     0           conv1d_343[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 8000, 64)     0           conv1d_344[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_67 (Multiply)          (None, 8000, 64)     0           activation_146[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_345 (Conv1D)             (None, 8000, 32)     2080        multiply_67[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_85 (Add)                    (None, 8000, 32)     0           conv1d_342[0][0]                 \n",
            "                                                                 conv1d_345[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_346 (Conv1D)             (None, 8000, 32)     1056        add_85[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_347 (Conv1D)             (None, 8000, 64)     4160        conv1d_346[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_348 (Conv1D)             (None, 8000, 64)     4160        conv1d_346[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 8000, 64)     0           conv1d_347[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 8000, 64)     0           conv1d_348[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_68 (Multiply)          (None, 8000, 64)     0           activation_148[0][0]             \n",
            "                                                                 activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_349 (Conv1D)             (None, 8000, 32)     2080        multiply_68[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_87 (Add)                    (None, 8000, 32)     0           conv1d_341[0][0]                 \n",
            "                                                                 conv1d_345[0][0]                 \n",
            "                                                                 conv1d_349[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 8000, 32)     0           add_87[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_33 (AveragePo (None, 1, 32)        0           activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "permute_24 (Permute)            (None, 32, 1)        0           average_pooling1d_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_351 (Conv1D)             (None, 32, 1)        2           permute_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_350 (Conv1D)             (None, 32, 1)        2           permute_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_37 (Reshape)            (None, 1, 32)        0           conv1d_351[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_36 (Reshape)            (None, 32, 1)        0           conv1d_350[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "permute_25 (Permute)            (None, 32, 1)        0           reshape_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dot_12 (Dot)                    (None, 32, 32)       0           reshape_36[0][0]                 \n",
            "                                                                 permute_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 32, 32)       0           dot_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_352 (Conv1D)             (None, 32, 1)        2           permute_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "softmax_6 (Softmax)             (None, 32, 32)       0           lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_38 (Reshape)            (None, 1, 32)        0           conv1d_352[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "permute_26 (Permute)            (None, 32, 32)       0           softmax_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dot_13 (Dot)                    (None, 1, 32)        0           reshape_38[0][0]                 \n",
            "                                                                 permute_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_39 (Reshape)            (None, 32, 1)        0           dot_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_88 (Add)                    (None, 32, 1)        0           reshape_39[0][0]                 \n",
            "                                                                 permute_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "permute_27 (Permute)            (None, 1, 32)        0           add_88[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_353 (Conv1D)             (None, 1, 4)         132         permute_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_40 (Reshape)            (None, 4, 1)         0           conv1d_353[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 38,914\n",
            "Trainable params: 38,914\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loOWjYmpp9SU",
        "outputId": "8cb5f8dd-a04b-47bc-f762-95999ac1856d"
      },
      "source": [
        "Wavenet5.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMO_DB//models//wavenet5_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMO_DB//models//wavenet5_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = Wavenet5.fit(X_train,\n",
        "                        Y_train, \n",
        "                        batch_size=16,\n",
        "                        validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "15/15 [==============================] - 7s 311ms/step - loss: 1.3776 - accuracy: 0.7500 - val_loss: 1.4199 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.41988, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.75000, saving model to EMO_DB//models/wavenet5_acc.h5\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 1.3431 - accuracy: 0.7500 - val_loss: 1.4517 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.41988\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.75000\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 1.3652 - accuracy: 0.7500 - val_loss: 1.4565 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.41988\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.75000\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - 3s 224ms/step - loss: 1.3206 - accuracy: 0.7500 - val_loss: 1.4235 - val_accuracy: 0.7549\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.41988\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.75000 to 0.75490, saving model to EMO_DB//models/wavenet5_acc.h5\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 1.2850 - accuracy: 0.7492 - val_loss: 1.3332 - val_accuracy: 0.7549\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.41988 to 1.33318, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.75490\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 1.0792 - accuracy: 0.7939 - val_loss: 1.0227 - val_accuracy: 0.7843\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.33318 to 1.02268, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.75490 to 0.78431, saving model to EMO_DB//models/wavenet5_acc.h5\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.9135 - accuracy: 0.8176 - val_loss: 0.9482 - val_accuracy: 0.7892\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.02268 to 0.94825, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.78431 to 0.78922, saving model to EMO_DB//models/wavenet5_acc.h5\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.8473 - accuracy: 0.8164 - val_loss: 1.2639 - val_accuracy: 0.7353\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.94825\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.78922\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.9312 - accuracy: 0.7973 - val_loss: 1.0859 - val_accuracy: 0.7549\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.94825\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.78922\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.7871 - accuracy: 0.8315 - val_loss: 0.9206 - val_accuracy: 0.7941\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.94825 to 0.92057, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.78922 to 0.79412, saving model to EMO_DB//models/wavenet5_acc.h5\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.7710 - accuracy: 0.8323 - val_loss: 0.9176 - val_accuracy: 0.7941\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.92057 to 0.91763, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.79412\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.6890 - accuracy: 0.8490 - val_loss: 0.8305 - val_accuracy: 0.7892\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.91763 to 0.83047, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.79412\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.6914 - accuracy: 0.8238 - val_loss: 0.7628 - val_accuracy: 0.7941\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.83047 to 0.76283, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.79412\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.6750 - accuracy: 0.8499 - val_loss: 0.7403 - val_accuracy: 0.7941\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.76283 to 0.74029, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.79412\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.6755 - accuracy: 0.8613 - val_loss: 0.8168 - val_accuracy: 0.8088\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.74029\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.79412 to 0.80882, saving model to EMO_DB//models/wavenet5_acc.h5\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.6494 - accuracy: 0.8572 - val_loss: 0.7849 - val_accuracy: 0.7941\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.74029\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.80882\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.6194 - accuracy: 0.8708 - val_loss: 0.7223 - val_accuracy: 0.8284\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.74029 to 0.72235, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.80882 to 0.82843, saving model to EMO_DB//models/wavenet5_acc.h5\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.6174 - accuracy: 0.8651 - val_loss: 0.6757 - val_accuracy: 0.8137\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.72235 to 0.67573, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.82843\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.6043 - accuracy: 0.8733 - val_loss: 0.7002 - val_accuracy: 0.8186\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.67573\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.82843\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.6631 - accuracy: 0.8626 - val_loss: 0.6976 - val_accuracy: 0.8235\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.67573\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.82843\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - 3s 224ms/step - loss: 0.6497 - accuracy: 0.8488 - val_loss: 0.8108 - val_accuracy: 0.8137\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.67573\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.82843\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.5840 - accuracy: 0.8649 - val_loss: 0.8743 - val_accuracy: 0.8137\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.67573\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.82843\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.6079 - accuracy: 0.8647 - val_loss: 0.7167 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.67573\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.82843 to 0.84314, saving model to EMO_DB//models/wavenet5_acc.h5\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.5335 - accuracy: 0.9026 - val_loss: 0.6605 - val_accuracy: 0.8284\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.67573 to 0.66050, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.84314\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.6043 - accuracy: 0.8699 - val_loss: 0.6330 - val_accuracy: 0.8382\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.66050 to 0.63305, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.84314\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.5410 - accuracy: 0.8921 - val_loss: 0.5857 - val_accuracy: 0.8382\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.63305 to 0.58573, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.84314\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.5597 - accuracy: 0.8952 - val_loss: 0.8013 - val_accuracy: 0.8137\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.58573\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.84314\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.6243 - accuracy: 0.8686 - val_loss: 0.6294 - val_accuracy: 0.8284\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.58573\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.84314\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.5831 - accuracy: 0.8811 - val_loss: 0.6509 - val_accuracy: 0.8382\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.58573\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.84314\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.5981 - accuracy: 0.8634 - val_loss: 0.5777 - val_accuracy: 0.8529\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.58573 to 0.57773, saving model to EMO_DB//models/wavenet5_loss.h5\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.84314 to 0.85294, saving model to EMO_DB//models/wavenet5_acc.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo_GquhBvfHS",
        "outputId": "86792cb8-53ae-4b04-ed97-210f5497807e"
      },
      "source": [
        "Wavenet5.load_weights('EMO_DB//models//wavenet5_loss.h5')\n",
        "print(Wavenet5.evaluate(X_test,Y_test))\n",
        "Wavenet5.load_weights('EMO_DB//models//wavenet5_acc.h5')\n",
        "Wavenet5.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 124ms/step - loss: 0.4743 - accuracy: 0.9100\n",
            "[0.4743371307849884, 0.9100000262260437]\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 0.4743 - accuracy: 0.9100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4743371307849884, 0.9100000262260437]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "b0A0lnhhXApw",
        "outputId": "6b74ac3b-6dc1-451a-fa2f-9d77c4a1b934"
      },
      "source": [
        "Wavenet5.load_weights('EMO_DB//models//wavenet5_acc.h5')\n",
        "\n",
        "Wavenet5.evaluate(X_test,Y_test)\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(Wavenet5.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1)\n",
        "print(g.shape,p.shape)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(Y_test_features,np.argmax(Wavenet5.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 129ms/step - loss: 0.4743 - accuracy: 0.9100\n",
            "(50,) (50,)\n",
            "F1 SCORE: 0.7710227272727272\n",
            "Kappa: 0.7630331753554502\n",
            "Accuracy: 0.84\n",
            "Jaccard Score: 0.6698232323232324\n",
            "Precision: 0.826923076923077\n",
            "Recall: 0.7646103896103896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f61fa7b0410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD8CAYAAADUv3dIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgU1fX/8ffpYVBxQXYYwEAEo6IihoAmKhBliQbQn4qoJMElxCQYXKJx16CSRI2JJkbFPSZG0RgF5au4RuLGoiibyirMwr4ry0zP+f3RxdAgM1Mz093V03xePvVMV9Xt6tP3Gc9cbt17y9wdERHJjFjUAYiI7EmUdEVEMkhJV0Qkg5R0RUQySElXRCSDlHRFRDJISVdEpBJm9oiZrTCzWZWcNzO7x8zmm9knZnZMdddU0hURqdxjwIAqzv8A6BxsI4D7qrugkq6ISCXc/W1gTRVFBgN/94T3gQPNrE1V12yQygB3Z+u8dzXlLXBCr2uiDiFrfLhqftQhSBYq21Zkdb1G6aqFoXNOwxYH/4xEC3W7se4+tgYf1xZYmrRfGBwrqewNaU+6IiLZKkiwNUmydaakKyK5pTyeyU8rAton7bcLjlVKfboiklviZeG3uhsP/DgYxXAssN7dK+1aALV0RSTHuJen7Fpm9i+gN9DczAqBm4D8xOf4/cBE4BRgPvAVcH5111TSFZHcUp66pOvu51Rz3oFf1uSaSroikltS2NJNByVdEcktmb2RVmNKuiKSW9TSFRHJHE/NqIS0UdIVkdySwhtp6aCkKyK5Rd0LIiIZpBtpIiIZpJauiEgG6UaaiEgG6UaaiEjmuKtPV0Qkc9SnKyKSQepeEBHJILV0RUQyKF4adQRVUtIVkdyi7gURkQzK8u6Fev+MtP9Nn8nAn13DqT/9DQ8/89LXzhevWMVF197OGSNv4IKrf8+yVTseYX/0oAs465IbOeuSG7lk9N2ZDDstju3dg2cmP8G/3/knPx557tfOd+t5FH9/5UHeXfI63z+119fO77tfIyZMe4Zf3zYqE+FGqn+/3sye9TafzvkfV11Zo4X/c07O1UV5efgtAvW6pRuPlzPmvicYe+uvadWsKedcNprePY/m4IPaVpT548NPM/Ck7zL4pOP54OM53PP4s4y5IvGY+70aNuSZv4yOKvyUisViXDXmUkYOvYIVJSt5fOIDTH7lHRbN+6KizLKiFYy+9HcMu3jobq/xs6suZMYHn2Qq5MjEYjHuufs2BpxyDoWFJbz/3kQmvDiJuXPnRR1axuVkXWR590K9bunO+nwhB7VpSbvWLcnPb8CAE3vw5vsf7VRm4dJieh51GAA9jjrsa+dzRZduh1G4uIjiJSWUlZYx6YU3OLH/8TuVKSlcxvy5CynfzS/loUceQtMWTXj/v1MzFXJkenynGwsWLGbRoiWUlpYybtwLDBrYP+qwIpGLdeHx0tBbFEIlXTO7xMyapDuYmlq+ei2tWjSt2G/VvCkrVq/dqcwhHdvz2rvTAXj9vel8uXkL6zZsAmDbtlKGXvpbzrviFt5478PMBZ4GLVo3Z3nxior9FSUradGmeaj3mhmjbvoF94y+L13hZZWCtq1ZWlhcsV9YVEJBQesII4pOTtaFl4ffIhC2e6EVMNXMPgQeAV4JnoKZ9a644Gx+d/8/GP/6OxzT5RBaNmtCLJb4W/PyI3fSqnkTCpet4KJrb6dzh3a0b9My4ogz78zhp/HuGx+womRl1KGI1F2Wdy+ESrrufr2Z3QD0I/Fc97+a2TjgYXdfsGt5MxsBjAD46+iruGjo4BSGvEOrZk1YvnLHjbHlq9bQstnODfKWzZrwp+suAeCrzVt47d3pHLBfo8T7myfKtmvdku5HHsrcBV/U26S7ctkqWhXsiL1lmxasLFkV6r1HfrsLR/c8ijN+MphG++5Dg/x8Nn+5mXvHjE1XuJEqLlpG+3YFFfvt2rahuHhZhBFFJyfrIldGLwQt22XBVgY0AZ41s9t3U3asu3d39+7pSrgAXQ7pyBfFKyhctpLS0jJefnsKvXt226nM2vUbK/owH3rmJU7vewIAGzZ9ybbS0ooyM+bM4+CDCqiv5sz4lPYd21HQvjUN8hvQb/D3mTzpnVDvvXHkrQz6zhBO6zmUu0ffx8RnX8nZhAswddoMOnXqSIcO7cnPz2fIkMFMeHFS1GFFIifrIhdGL5jZKODHwCrgIeBKdy81sxgwD7gqfSFWrkFeHtdefB4/v/GPxMvLOa3vCXT6Rlvu/cd/OLxzB/r07MbUmZ9yz+PPYmYcc8QhXPfzHwGJG2yj//o4MYtR7uVccNapO416qG/i8Th3XPdn7nnyTmJ5MSY8NZGFny9mxJUXMPfjT5k86V0O63ootz98CwccuD8n9P0uI359PkP7DI869IyLx+OMuvR6Jr70JHmxGI89/jRz5nwedViRyMm6yPKWroXpmjWzm4FH3f2L3Zw7zN3nVvberfPerRd9v5lwQq9rog4ha3y4an7UIUgWKttWZHW9xuaX/hw65+xz6qV1/ryaqrZ7wczygKG7S7gAVSVcEZGMq++jF9w9bmafmdlB7r4kE0GJiNRaLoxeIHHTbLaZTQG+3H7Q3QelJSoRkdrK8j7dsEn3hrRGISKSKrnQ0nX3/6Y7EBGRlMiFlq6ZbQR2vSO4HpgGXOHuC1MdmIhIrZTlxiPY/wwUAk8CBgwFDga2TwvunY7gRERqLMtXKAibdAe5e9ek/bFmNsPdf2Nm16YjMBGRWsnyPt2w04C/MrMhZhYLtiHAluBcdv9ZEZE9S5ZPAw6bdM8DfgSsAJYHr4eZ2T7AyDTFJiJScymcHGFmA4J5CvPN7OrdnD/IzN40s4/M7BMzO6W6a4YdvbAQGFjJ6f+FuYaISEbE4ym5TDAb916gL4l7WlPNbLy7z0kqdj0wzt3vM7PDgYlAh6quG3b0Qgvgp8HFKt7j7hfU4DuIiKRf6roNegDzt4/OMrOngMFActJ14IDgdWOgmGqEvZH2AjAZeA1IzZ8REZF0qEHSTV77OzDW3beva9oWWJp0rhDoucslbgYmmdklwL7AydV9Ztik28jdfxOyrIhIdGowOSJIsHVZPPoc4DF3/6OZHQc8YWZHuFceRNgbaS+G6SAWEYmal3vorRpFQPuk/XbBsWQXAuMA3P09YG+gyocThk26o0gk3s1mtsHMNprZhpDvFRHJnNQNGZsKdDazjmbWkMSksPG7lFkCnASJtcVJJN0qHzYYdvTC/mbWFOgcXFREJDulaPSCu5eZ2UjgFSAPeMTdZ5vZaGCau48HrgAeNLPLSNxUG17dQ3vDjl64iERrtx0wAzgWeJcgw4uIZI0UTnpw94kkhoElH7sx6fUc4Hs1uWZNuhe+A3zh7n2AbiQWvBERyS5ZPiMt7OiFLe6+xcwws73c/VMz+1ZaIxMRqY0cWfCm0MwOBJ4HXjWztcBun5kmIhKpLF/wJuyNtNODlzeb2ZskZl68nLaoRERqq/qhYJEK29KtUNOnSAw/+faafkTO+l7DNlGHkDU+RI9glzRJ0eiFdKlx0hURyWaeC90LIiL1Rq51L4iIZLVceDCliEi9oZauiEgGlelGmohI5qh7QUQkg9S9ICKSORoyJiKSSWrpiohkkJKuiEgGaRqwiEjmhHj2WaSUdEUktyjpiohkkEYviIhkkFq6IiIZpKQrIpI5Hlf3gohI5qilKyKSORoyJiKSSUq6IiIZlN1dukq6IpJbvCy7s66SrojkluzOufU/6Xbt1Y0f33QRsbwYbz71KuPve26n86dcNIg+Q/tSXhZnw5oNPHDlX1hVtJLmbVtw+dirMYvRID+PVx57idf++UpE3yI1Du3VldNv/AmWF+ODp9/g9fvG73S+14WncOzQ71NeFmfTmo08ddX9rC1aBcAPrz6Xw/t0A2DSX55jxovvZTz+TOrfrzd33TWavFiMRx79F7ffcW/UIUUm1+pCN9LSyGIxzr/lZ4w57yZWL1vNbePvYPprUyiaV1hRZvHshVz3wyvYtmUbJw8bwLnX/IR7Rt7J2hVrufH031C2rYy9Gu3NHZPuYfqrU1i7Ym2E36j2LGacMfoC7h92G+uWreay8WOY9ep0ls8vqihTNGcxdw28ltIt2/jusL4MvOY8/j7ybg7v0412XTpw5ym/oUHDfH751I3MfWsGWzdtjvAbpU8sFuOeu29jwCnnUFhYwvvvTWTCi5OYO3de1KFlXE7WRZa3dGNRB1AXnY7uzLLFJaxYupx4aRnvTfgf3fv23KnMnPdmsW3LNgDmf/QZTds0AyBeWkbZtjIA8hvmYzHLbPApdtDRnVj1xTJWL11BvDTORxPe5Yh+3XcqM/+9OZQGdfHFR/M4sHVTAFp1bsuCKZ9SHi9n2+atFH+6hMN6dc34d8iUHt/pxoIFi1m0aAmlpaWMG/cCgwb2jzqsSORiXXi5h96iECrpmtklZtYk3cHUVJPWTVldsqpif3XJapoEiWR3ep99Mh+/9WHFftM2zfnDy3/mr+8/xPj7n6u3rVyAA1s1ZV3x6or99SVraNyq8rroOaQPc9+aAUDx3ESSzd+7Ifs22Z/Oxx3OgcEfp1xU0LY1SwuLK/YLi0ooKGgdYUTRycm6KK/BFoGwLd1WwFQzG2dmA8ysymahmY0ws2lmNm3+psV1DjIVjj+9F988shMTHvhPxbE1Jav4zYBLuezEiznxjD40bt44wggz59unHU/7o77JG2MnAPDZ5E+Y8+ZHjHpuND+65xIWfziP8ixfqUmkMl4WfotCqKTr7tcDnYGHgeHAPDMbY2YHV1J+rLt3d/funfbrkKpYv2btsjU0a9O8Yr9Zm2asXbbma+WO+N5RnDbyTO68aExFl8JO11mxlsLPl/CtHoenLdZ0W7d8DQcW7GidNm7TlPXLv14Xh3zvCPqOPJ2HL7qDeFJdvHbv89x5ytXc/6MxYMbKhSUZiTsKxUXLaN+uoGK/Xds2FBcvizCi6ORiXXh5+C0Koft03d2BZcFWBjQBnjWz29MUW7UWfDyP1h3b0KJ9S/LyG3DcwOOZ/uqUncp06NKRi373C+68cAwbVq+vON60dTPy92oIwL4H7Mu3uh9GyYJi6qulHy+gRYfWNG3Xgrz8PLoN/C6zX52+U5m2XTpw1pif8tBFd7Bp9YaK4xYzGh24HwBtDj2IgkMP4rPJn2Q0/kyaOm0GnTp1pEOH9uTn5zNkyGAmvDgp6rAikZN1kcLuheBf9p+Z2Xwzu7qSMkPMbI6ZzTazJ6u7ZqjRC2Y2CvgxsAp4CLjS3UvNLAbMA64Kc51UK4+X89iND3LN328ilpfHW+Neo3DeUs68/BwWfTKf6a9N5dxrh7N3o70Z9bdEiKuLV3LnRWNo26kdw64/H3fHzHhx7Ass/eyLKL5GSpTHy/n3jY/ys79fSywvxgfj3mTZvEIGXHYWS2cuZPZr0xl0zXns1Wgvhv/tUgDWFq3i4Z/eSV5+Ay555mYAtmzazD8u+yvlWb5SU13E43FGXXo9E196krxYjMcef5o5cz6POqxI5GJdpKoFa2Z5wL1AX6CQRBfreHefk1SmM3AN8D13X2tmLau9bqIBW+2H/xZ4xN2/lpXM7DB3n1vZe8/5xmnZPWgug1rb3lGHkDX+Ujw56hAkC5VtK6rzMKIVJ/UKnXNavv7fSj/PzI4Dbnb3/sH+NQDu/rukMrcDn7v7Q2E/M2yf7k1AMzP7VTCS4Zikc5UmXBGRTPO4hd6Sb/oH24ikS7UFlibtFwbHkh0CHGJm75jZ+2Y2oLr4wnYv3AAMAbZP93rUzJ5x91vDvF9EJFNq0r3g7mOBsXX4uAYkBhn0BtoBb5vZke6+rqo3hDEM6OruWwDM7PfADEBJV0SyipenbKJTEdA+ab9dcCxZIfCBu5cCi8zscxJJeGplFw07eqEYSO6Q3Gs3Hy4iErkUDhmbCnQ2s45m1hAYCozfpczzJFq5mFlzEt0NC6u6aNiW7npgtpm9CjiJu3lTzOweAHf/VcjriIiklXtqWrruXmZmI4FXgDwSgwlmm9loYJq7jw/O9TOzOUCcxMiu1ZVfNXzS/U+wbfdWTb+AiEgmpHLSg7tPBCbucuzGpNcOXB5soYRKuu7+eNC8PpRES/czd98W9kNERDKlPJ7di1eFHb1wCvAAsAAwoKOZ/czd/y+dwYmI1FQKb6SlRdjuhbuAPu4+HyBYc+ElQElXRLJKriTdjdsTbmAhsDEN8YiI1EmISbaRCpt0p5nZRGAciT7ds0jMQ/5/AO7+XFVvFhHJlFxp6e4NLAd6BfsrgX2AgSSSsJKuiGSFVA0ZS5ewoxfOT3cgIiKpEM+R0Qt7AxcCXUiamebuF6QpLhGRWsn2lm7YacBPAK2B/sB/ScxB1o00Eck6Xm6htyiETbqd3P0G4Et3fxw4FehZzXtERDLOPfwWhbA30kqDn+vM7AgSj+ypdoV0EZFMy5XRC2ODR7BfT2KVnf2AG9IWlYhILcXLQz/6MRJhk+4TwBlAB+Dx4FirdAQkIlIXuTI54gUSyztOB7amLxwRkbopz/LRC2GTbjt3r/bZPyIiUcuVIWPvmtmRaY1ERCQF6vXoBTObSWKabwPgfDNbSKJ7wUis33tUdR/wTEmljwqSPdjGRzWvZrsh13wUdQg5pb53L/wwI1GIiKRIvR694O5fZCoQEZFUyPLBC6FvpImI1Av1vXtBRKReyfbRC0q6IpJTUvgw4LRQ0hWRnOKopSsikjFl6l4QEckctXRFRDJIfboiIhmklq6ISAappSsikkFxtXRFRDIny5/Wo6QrIrmlXC1dEZHM0YI3IiIZpBtpIiIZVG7qXhARyZh41AFUI7uXWBcRqaFyC79Vx8wGmNlnZjbfzK6uotwZZuZm1r26a6qlKyI5JVWjF8wsD7gX6AsUAlPNbLy7z9ml3P7AKOCDMNdVS1dEcorXYKtGD2C+uy90923AU8Dg3ZS7BfgDsCVMfEq6IpJTatK9YGYjzGxa0jYi6VJtgaVJ+4XBsQpmdgzQ3t1fChtfzncv9O/Xm7vuGk1eLMYjj/6L2++4N+qQIrMn1cU780u4/ZUZlJc7p3fryAXHH7bT+ZL1X3LD81PYuLWU8nLnVycdxQmd2/DegmXc88ZMSuPl5OfFuOzko+jRsVVE3yL1jul1DD+9eQSxvBivPjWJZ//27E7nB190Gv3O6Ue8LM6GNRu4+9d/ZmXRyoiirZ2aDBlz97HA2Np8jpnFgLuA4TV5X063dGOxGPfcfRs/HDiMI7v24eyzT+OwwzpHHVYk9qS6iJeX87v/+5B7zz2B537Rn5dnL2HByvU7lXlw8lz6dWnP0yP68fszjmXMxOkANGm0F3cPPZ5nL+7PLYN7cN3zU6L4CmkRi8W4+Nafc/NPbuKXJ/2CEwf1on3n9juVWTh7AZefehm/6n8J77z0P86/9vyIoq29uIXfqlEEJFdQu+DYdvsDRwBvmdli4FhgfHU303I66fb4TjcWLFjMokVLKC0tZdy4Fxg0sH/UYUViT6qLWUVraN9kP9o12Y/8vDz6dzmItz4r3qmMAV9uLQVg05ZSWuy/DwCHtmlCy+D1wS0OYGtpnG1l2T4IKZzORx9CyeISli9ZTllpGW9PeJue/Y7dqczM92aydctWAD776DOatWkeRah1Ul6DrRpTgc5m1tHMGgJDgfHbT7r7endv7u4d3L0D8D4wyN2nVXXRnE66BW1bs7Rwx/9shUUlFBS0jjCi6OxJdbFi42ZaN25Usd/qgH1YsXHzTmUu7tWFl2Yuod+fJjDyX5O5ekC3r13ntbmFHNbmQBo2yEt7zJnQrHUzVhXv6CpYXbKKZq2aVVq+79n9mP7m9EyEllKpSrruXgaMBF4B5gLj3H22mY02s0G1ja/KPl0z28jub/JZIiY/oJL3jQBGAFheY2KxfWsbn0havDxrCYO6duDHx32Lj5eu4vrnp/Dsz/sTC2YzzV+xnrtf/4T7zusVcaTR6H16bzod1YlrhlQ6NDVrpfIRae4+EZi4y7EbKynbO8w1q2zpuvv+7n7Abrb9K0u4wfvGunt3d+8eZcItLlpG+3YFFfvt2rahuHhZZPFEaU+qi5b778Oy9V9V7C/fsLmiy2C7/8xYRL/DE911Xds3Z2tZnHVfbQ3Kf8Xl497hlsE9ad90v8wFnmarl62meUGLiv1mbZqzevnqr5XrenxXhow8m1svvIWybWWZDDElUti9kBY16l4ws5ZmdtD2LV1BpcrUaTPo1KkjHTq0Jz8/nyFDBjPhxUlRhxWJPakuurRtypI1myhau4nSeJxXZi+h1yEFO5Vpc0AjPli0HICFKzewrSxOk0Z7sWHLNi7512RGnXQU3Q6qf/2ZVZn38ecUdCygVftWNMhvwIkDT2TKqzuP5/9ml2/yy9+N5JYLb2H96vWVXCm7xWuwRSHUkLGg/+KPQAGwAvgGiT6OLukLre7i8TijLr2eiS89SV4sxmOPP82cOZ9HHVYk9qS6aBCLcfUPjuHn/3ybcncGH92RTi0b87c3Z3F4QRN6f6stl/fryugJ0/jnB58Dxm8H98DMeHrKfJas2cQDb8/hgbcTE4/uH3YiTffdO9ovlQLl8XLuv+F+fvvEaGJ5MV57+lWWfL6E8y4/j3kz5zHl1Smcf90F7N1ob66+L9GtsLJ4JbdeeEvEkddMti9ibu7Vz8sws4+B7wOvuXs3M+sDDHP3C6t7b4OGbbN9eUuJwMZHL4g6hKwx5JqPog4ha0xY8mKdU+afDhoWOudctuQfGU/RYbsXSt19NRAzs5i7vwlUu7CDiEimZXufbtgZaevMbD/gbeCfZrYC+DJ9YYmI1E62/9M6bEt3MPAVcBnwMrAAGJiuoEREaiuVSzumQ7Ut3WB5sxfdvQ+JFvnjaY9KRKSWsn3+YLVJ193jZlZuZo3dvX6OIRGRPUZ5lncwhO3T3QTMNLNXSerLdfdfpSUqEZFaypUHUz4XbMmy+8+JiOyRsj0xhU26B7r73ckHzGxUGuIREamTbG/phh298JPdHBuewjhERFKizDz0FoXqVhk7BzgX6Ghm45NO7Q+sSWdgIiK1Ud+7F94FSoDmJNZe2G4j8Em6ghIRqa1s716oMum6+xfAF8BxmQlHRKRucmLI2C6LmTcE8oEvq1pTV0QkCtmdckMmXXfff/trMzMS04KPrfwdIiLRyPbuhRo/I80Tngdy86mGIlKvxfHQWxTCdi/8v6TdGIllHbekJSIRkTrI9pZu2MkRySuKlQGLSXQxiIhkFc/yXt2wfbrnpzsQEZFUyPaWbqg+XTM7xMxeN7NZwf5RZnZ9ekMTEam5cjz0FoWwN9IeBK4BSgHc/RNgaLqCEhGpLa/BFoWwfbqN3H1KYrRYhbI0xCMiUidludCnC6wys4MJ/jiY2ZkkpgeLiGSVnLiRBvwSGAscamZFwCLgvLRFJTlv//MfiTqErLG5eHLUIeSUbL+RFjbpFgGPAm8CTYENJJZ7HJ2muEREaiVXWrovAOuAD4Hi9IUjIlI3udLSbefuA9IaiYhICsQ9u1u6YYeMvWtmR6Y1EhGRFMj2cbphW7rHA8PNbBGwFTASa98clbbIRERqIVf6dH+Q1ihERFIkJ/p0gydIiIhkvWx/ckSN19MVEclmXoP/qmNmA8zsMzObb2ZX7+b85WY2x8w+Cdan+UZ111TSFZGcEncPvVXFzPKAe0l0rx4OnGNmh+9S7COge3B/61ng9uriU9IVkZySwtELPYD57r7Q3bcBT7HLOuLu/qa7fxXsvg+0q+6iSroiklPKa7CZ2Qgzm5a0jUi6VFtgadJ+YXCsMhcC/1ddfGFHL4iI1As1GTLm7mNJrCtTJ2Y2jMRjzHpVV1ZJV0RySgpHLxQB7ZP22wXHdmJmJwPXAb3cfWt1F1XSFZGc4qmbBjwV6GxmHUkk26HAuckFzKwb8AAwwN1XhLmokq6I5JRUPVrd3cvMbCTwCpAHPOLus81sNDDN3ccDdwD7Ac8ED3lY4u6Dqrqukq6I5JRUTo5w94nAxF2O3Zj0+uSaXlNJV0RySgq7F9JCSVdEckq2TwNW0hWRnJIrq4yJiNQL2b6IuZKuiOQUdS+IiGRQtifdnF97oX+/3sye9TafzvkfV135y6jDiZTqYgfVRcL1Y+7ixFOHctqwi6MOJWXcPfQWhZxOurFYjHvuvo0fDhzGkV37cPbZp3HYYZ2jDisSqosdVBc7nHZKX+6/69aow0ipbH9GWk4n3R7f6caCBYtZtGgJpaWljBv3AoMG9o86rEioLnZQXezQ/egjaXzA/lGHkVKpXMQ8HXI66Ra0bc3SwuKK/cKiEgoKWkcYUXRUFzuoLnJb3MtDb1Go8kaamc2Eyv8c6GnAIpJt6vuMtB8GP7ffaXgi+HleVW8KFgIeAWB5jYnF9q11gHVRXLSM9u0KKvbbtW1DcfGySGKJmupiB9VFbqvXoxfc/YvgScB93f0qd58ZbFcD/ap431h37+7u3aNKuABTp82gU6eOdOjQnvz8fIYMGcyEFydFFk+UVBc7qC5yW7b36YYdp2tm9j13fyfY+S71oD84Ho8z6tLrmfjSk+TFYjz2+NPMmfN51GFFQnWxg+pihytv+j1TP/qEdes2cNJpw/jFhT/ijHp+U7E8y7sXLEz/h5l9G3gEaAwYsBa4wN0/rO69DRq2ze4aEInY5uLJUYeQNfKbf9Pqeo0urXqGzjmzl39Q58+rqVAtXXefDnQ1s8bB/vq0RiUiUktRjUoIK/Q0YDM7FegC7B2skI67j05TXCIitZLt3Quhkq6Z3Q80AvoADwFnAlPSGJeISK1k+9KOYW+GfdfdfwysdfffAscBh6QvLBGR2il3D71FIWz3wpbg51dmVgCsAdqkJyQRkdrL9pZu2KQ7wcwOJPHkyw9JzFJ7MG1RiYjUUtzjUYdQpbBJ91Mg7u7/NrPDgWOA59MXlohI7WT7NOCwfbo3uPtGMzse+D6Jm2n3pS8sEZHayZWlHbe3108FHnT3l4CG6QlJRKT2sn0R87DdC0Vm9gDQF/iDme1FPZgGLCJ7nmwfpxs2cQ4BXgH6u/s6oClwZdqiEhGppZxY8MbdvwKeS9ovARV1oUsAAAYzSURBVErSFZSISG3lzDRgEZH6INtHLyjpikhOyfY+XSVdEckpaumKiGRQtj+uR0lXRHKKWroiIhmk0QsiIhmkG2kiIhmU7d0LmsorIjkllTPSzGyAmX1mZvPN7OrdnN/LzJ4Ozn9gZh2qu6aSrojklFQteGNmecC9wA+Aw4FzgqVtk11I4ok6nYA/AX+oLj4lXRHJKSl8XE8PYL67L3T3bcBTwOBdygwGHg9ePwucZNuf3FuJtPfplm0ryvhz5XfHzEa4+9io48gGqosdVBc75Epd1CTnmNkIYETSobFJddAWWJp0rhDoucslKsq4e5mZrQeaAasq+8w9qaU7ovoiewzVxQ6qix32uLpw97Hu3j1pS/sfnT0p6YqI1EQR0D5pv11wbLdlzKwB0BhYXdVFlXRFRHZvKtDZzDqaWUNgKDB+lzLjgZ8Er88E3vBq7tDtSeN0631fVQqpLnZQXeygukgS9NGOJPEAhzzgEXefbWajgWnuPh54GHjCzOYDa0gk5ipZtg8kFhHJJepeEBHJICVdEZEMUtKtp8ysg5nNijqOXBDU5bm1fO+mVMeTTfR7lnpKulQM9ZA9Vwdgt0lXvxuSavUy6ZrZ82Y23cxmBzNKMLNNZnabmX1sZu+bWavg+MHB/kwzu3V7y8TMepvZZDMbD8wxs9FmdmnSZ9xmZqMi+YLh5ZnZg0E9TDKzfczsp2Y2NaiHf5tZIwAze8zM7jezaWb2uZn9MDg+3MxeMLO3zGyemd0UHM/6+ghaYXN3UwcHm9nLwe/IZDM7NCj/mJmdmfT+7a3U3wMnmNkMM7ssqJPxZvYG8LqZ7Wdmr5vZh8Hv0a5TQbOeme1rZi8FvxezzOxsM7sx+F2ZZWZjt09fNbNvB+U+Bn4Zcei5pyaLQ2TLBjQNfu4DzCIx7c6BgcHx24Hrg9cvAucEry8GNgWvewNfAh2D/Q7Ah8HrGLAAaBb1d62iDjoAZcDRwf44YFhyzMCtwCXB68eAl4Pv1pnElMa9geFASVCH2+uze32ojyrq4HWgc3CsJ4mxk9vr4Myk9yf/LryYdHx4UD/bf88aAAcEr5sD89kx8mdT1PUQsq7OAB5M2m+8/fsF+08k/f/zCXBi8PoOYFbU8efSVi9busCvgr/C75OYDdIZ2EYiwQJMJ/E/JMBxwDPB6yd3uc4Ud18E4O6LgdVm1g3oB3zk7lXOLMkCi9x9RvB6+3c+ImjdzQTOA7oklR/n7uXuPg9YCBwaHH/V3Ve7+2bgOeD4elQfu6uD7wLPmNkM4AGgTS2u+6q7rwleGzDGzD4BXiMx375VnaLOvJlAXzP7g5md4O7rgT7BcoQzge8DXczsQOBAd387eN8TUQWcq+pdf5WZ9QZOBo5z96/M7C0SLbZSD/40A3HCfbcvd9l/iEQrpzXwSCriTbOtSa/jJFqqjwGnufvHZjacRCtuu10HZXs1x+tDfexaB62Ade5+9G7KlhF0qZlZDGhYxXWTfzfOA1oA33b3UjNbTOJ3rt5w98/N7BjgFOBWM3udRNdBd3dfamY3U8++U31VH1u6jUmsX/lV0Fd3bDXl3yfxTyuofrbIf4ABwHdIzEKpj/YHSswsn0SySHaWmcXM7GDgm8BnwfG+ZtbUzPYBTgPeCY7Xx/rYACwys7MALKFrcG4x8O3g9SAgP3i9kUS9VaYxsCJIuH2Ab6Q86jQzswLgK3f/B4kug2OCU6vMbD8SU1hx93XAOjM7Pji/6++Q1FG9a+mS6Je82Mzmkkga71dT/lLgH2Z2XfDe9ZUVdPdtZvYmiZZSPFUBZ9gNwAfAyuBncjJZAkwBDgAudvctwb2TKcC/SSzo8Q93nwb1uj7OA+4zs+tJJNangI+BB4EXgq6pl9nRmv0EiAfHHwPW7nK9fwITgn+GTwM+Tfs3SL0jgTvMrBwoBX5O4g/sLGAZiXUGtjsfeMTMHJiU6UBzXc5PAw7u3m92dzezoSRuqu327nPwT84PgbOCfs+cYWaPkbhZ9Owux4eT+CfmyN28J2frQyQq9bF7oaa+DcwIboL8Arhid4Us8RiO+cDrSjCqD5F0yfmWrohINtkTWroiIllDSVdEJIOUdEVEMkhJV0Qkg5R0RUQy6P8Dn1jB7vM3/LIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVERX2ckrOYU"
      },
      "source": [
        "# ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4biHcdZC7u6h",
        "outputId": "fcc8b0f9-46ce-45f6-a080-564b4449e9a5"
      },
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "ann_model = Sequential(name='Input_Layer')\n",
        "ann_model.add(Dense(128,name='Dense_1'))\n",
        "ann_model.add(LeakyReLU(name='Leaky_Relu_Activation_1'))\n",
        "ann_model.add(Dense(32,name='Dense_2'))\n",
        "ann_model.add(LeakyReLU(name = 'LEaky_Relu_Activation_2'))\n",
        "ann_model.add(Dense(4, activation='softmax',name='Output_Layer'))\n",
        "\n",
        "ann_model.compile(optimizer='Adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "ann_model.build((1,26))\n",
        "ann_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Input_Layer\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Dense_1 (Dense)              (1, 128)                  3456      \n",
            "_________________________________________________________________\n",
            "Leaky_Relu_Activation_1 (Lea (1, 128)                  0         \n",
            "_________________________________________________________________\n",
            "Dense_2 (Dense)              (1, 32)                   4128      \n",
            "_________________________________________________________________\n",
            "LEaky_Relu_Activation_2 (Lea (1, 32)                   0         \n",
            "_________________________________________________________________\n",
            "Output_Layer (Dense)         (1, 4)                    132       \n",
            "=================================================================\n",
            "Total params: 7,716\n",
            "Trainable params: 7,716\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zinEOE2yrP1D",
        "outputId": "97830d17-c9ca-4745-8143-c1dcc34339d4"
      },
      "source": [
        "ann_model = Sequential(name='Input_Layer')\n",
        "ann_model.add(Dense(256,name='Dense_1'))\n",
        "ann_model.add(LeakyReLU(name='Leaky_Relu_Activation_1'))\n",
        "ann_model.add(Dense(64,name='Dense_2'))\n",
        "ann_model.add(LeakyReLU(name = 'LEaky_Relu_Activation_2'))\n",
        "ann_model.add(Dense(4, activation='softmax',name='Output_Layer'))\n",
        "\n",
        "ann_model.compile(optimizer='Adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_checkpoint1 = ModelCheckpoint('EMO_DB//models//ANN1.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMO_DB//models//ANN2.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "\n",
        "ann_model.fit(X_train_features,\n",
        "          Y_train_features,\n",
        "          epochs=30,\n",
        "          batch_size=20,\n",
        "          validation_data=(X_val_features, Y_val_features),callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 1.2072 - accuracy: 0.4333 - val_loss: 0.7218 - val_accuracy: 0.7451\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.72180, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.74510, saving model to EMO_DB//models/ANN2.h5\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5692 - accuracy: 0.8016 - val_loss: 0.5279 - val_accuracy: 0.7843\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.72180 to 0.52793, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.74510 to 0.78431, saving model to EMO_DB//models/ANN2.h5\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8522 - val_loss: 0.4869 - val_accuracy: 0.7647\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.52793 to 0.48692, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.78431\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3310 - accuracy: 0.9000 - val_loss: 0.4208 - val_accuracy: 0.8039\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.48692 to 0.42081, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.78431 to 0.80392, saving model to EMO_DB//models/ANN2.h5\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3176 - accuracy: 0.8811 - val_loss: 0.3862 - val_accuracy: 0.7843\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.42081 to 0.38619, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.80392\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2553 - accuracy: 0.8990 - val_loss: 0.3677 - val_accuracy: 0.8039\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.38619 to 0.36769, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.80392\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2467 - accuracy: 0.9351 - val_loss: 0.3607 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.36769 to 0.36069, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.80392 to 0.84314, saving model to EMO_DB//models/ANN2.h5\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2088 - accuracy: 0.9295 - val_loss: 0.3244 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.36069 to 0.32438, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.84314\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1664 - accuracy: 0.9688 - val_loss: 0.3188 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.32438 to 0.31876, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.84314\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1524 - accuracy: 0.9460 - val_loss: 0.3178 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.31876 to 0.31776, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.84314\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1976 - accuracy: 0.9376 - val_loss: 0.3084 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.31776 to 0.30840, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.84314\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1389 - accuracy: 0.9635 - val_loss: 0.2902 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.30840 to 0.29018, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.84314\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1595 - accuracy: 0.9466 - val_loss: 0.2933 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.29018\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.84314\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1047 - accuracy: 0.9757 - val_loss: 0.2851 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.29018 to 0.28508, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.84314 to 0.86275, saving model to EMO_DB//models/ANN2.h5\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1334 - accuracy: 0.9761 - val_loss: 0.2787 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.28508 to 0.27871, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.86275\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.9849 - val_loss: 0.2784 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.27871 to 0.27843, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.86275\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.9845 - val_loss: 0.2613 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.27843 to 0.26131, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.86275\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0771 - accuracy: 0.9923 - val_loss: 0.2500 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.26131 to 0.25004, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.86275\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9924 - val_loss: 0.2570 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.25004\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.86275\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0801 - accuracy: 0.9870 - val_loss: 0.2644 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.25004\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.86275\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0716 - accuracy: 0.9897 - val_loss: 0.2602 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.25004\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.86275\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0605 - accuracy: 0.9894 - val_loss: 0.2542 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.25004\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.86275\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0586 - accuracy: 0.9942 - val_loss: 0.2632 - val_accuracy: 0.8824\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.25004\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.86275 to 0.88235, saving model to EMO_DB//models/ANN2.h5\n",
            "Epoch 24/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0525 - accuracy: 0.9930 - val_loss: 0.2651 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.25004\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.88235\n",
            "Epoch 25/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0615 - accuracy: 0.9893 - val_loss: 0.2433 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.25004 to 0.24334, saving model to EMO_DB//models/ANN1.h5\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.88235\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0596 - accuracy: 0.9925 - val_loss: 0.2764 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.24334\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.88235\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0640 - accuracy: 0.9881 - val_loss: 0.2569 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.24334\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.88235\n",
            "Epoch 28/30\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0604 - accuracy: 0.9843 - val_loss: 0.2496 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.24334\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.88235\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0380 - accuracy: 0.9971 - val_loss: 0.2695 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.24334\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.88235\n",
            "Epoch 30/30\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9951 - val_loss: 0.2609 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.24334\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.88235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f61f2873710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWa7n4kxv8Kl",
        "outputId": "3a382025-2955-4dbd-9935-7dd4036079fc"
      },
      "source": [
        "ann_model.load_weights('EMO_DB//models//ANN2.h5')\n",
        "print(ann_model.evaluate(X_test_features,Y_test_features))\n",
        "ann_model.load_weights('EMO_DB//models//ANN1.h5')\n",
        "print(ann_model.evaluate(X_test_features,Y_test_features))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1766 - accuracy: 0.9400\n",
            "[0.176630899310112, 0.9399999976158142]\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1988 - accuracy: 0.9400\n",
            "[0.19882060587406158, 0.9399999976158142]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "ab7ifZBkT6FN",
        "outputId": "c125b7b3-7a9d-493a-9b84-0b0c7b8df93f"
      },
      "source": [
        "ann_model.load_weights('EMO_DB//models//ANN1.h5')\n",
        "print(ann_model.evaluate(X_test_features,Y_test_features))\n",
        "g = Y_test_features\n",
        "p = np.argmax(ann_model.predict(X_test_features),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(Y_test_features,np.argmax(ann_model.predict(X_test_features),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1988 - accuracy: 0.9400\n",
            "[0.19882060587406158, 0.9399999976158142]\n",
            "F1 SCORE: 0.9289082687338501\n",
            "Kappa: 0.9147242751563388\n",
            "Accuracy: 0.94\n",
            "Jaccard Score: 0.8689248251748252\n",
            "Precision: 0.9302884615384616\n",
            "Recall: 0.9386363636363637\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f61f6093410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bi1Ksb2-qeX"
      },
      "source": [
        "# Ensembled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74GKdT_wwBl-",
        "outputId": "917e6b4c-574b-4cf3-f0b6-754dd509ccb3"
      },
      "source": [
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*4), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "  #out = Conv1D(4,1,activation='softmax')(out)\n",
        "  #out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (26))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  #out2 = Dense(4)(layer2)\n",
        "  #out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out,layer3])\n",
        "  output_layer = Flatten()(output_layer)\n",
        "  output_layer = Dense(4,activation='softmax')(output_layer)\n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled = Wavenet()\n",
        "ensembled.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_18 (InputLayer)           [(None, 64000, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_354 (Conv1D)             (None, 64000, 8)     48          input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_50 (LeakyReLU)      (None, 64000, 8)     0           conv1d_354[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_355 (Conv1D)             (None, 64000, 8)     328         leaky_re_lu_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_51 (LeakyReLU)      (None, 64000, 8)     0           conv1d_355[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_34 (AveragePo (None, 32000, 8)     0           leaky_re_lu_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_356 (Conv1D)             (None, 32000, 16)    656         average_pooling1d_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_52 (LeakyReLU)      (None, 32000, 16)    0           conv1d_356[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_357 (Conv1D)             (None, 32000, 16)    1296        leaky_re_lu_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_53 (LeakyReLU)      (None, 32000, 16)    0           conv1d_357[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_35 (AveragePo (None, 16000, 16)    0           leaky_re_lu_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_358 (Conv1D)             (None, 16000, 16)    1296        average_pooling1d_35[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_54 (LeakyReLU)      (None, 16000, 16)    0           conv1d_358[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_359 (Conv1D)             (None, 16000, 16)    1296        leaky_re_lu_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_55 (LeakyReLU)      (None, 16000, 16)    0           conv1d_359[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_36 (AveragePo (None, 8000, 16)     0           leaky_re_lu_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_360 (Conv1D)             (None, 8000, 32)     544         average_pooling1d_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_361 (Conv1D)             (None, 8000, 64)     4160        conv1d_360[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_362 (Conv1D)             (None, 8000, 64)     4160        conv1d_360[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 8000, 64)     0           conv1d_361[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 8000, 64)     0           conv1d_362[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_69 (Multiply)          (None, 8000, 64)     0           activation_151[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_363 (Conv1D)             (None, 8000, 32)     2080        multiply_69[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_89 (Add)                    (None, 8000, 32)     0           conv1d_360[0][0]                 \n",
            "                                                                 conv1d_363[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_364 (Conv1D)             (None, 8000, 32)     1056        add_89[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_365 (Conv1D)             (None, 8000, 64)     4160        conv1d_364[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_366 (Conv1D)             (None, 8000, 64)     4160        conv1d_364[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 8000, 64)     0           conv1d_365[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 8000, 64)     0           conv1d_366[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_70 (Multiply)          (None, 8000, 64)     0           activation_153[0][0]             \n",
            "                                                                 activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_367 (Conv1D)             (None, 8000, 32)     2080        multiply_70[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_90 (Add)                    (None, 8000, 32)     0           conv1d_364[0][0]                 \n",
            "                                                                 conv1d_367[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_368 (Conv1D)             (None, 8000, 32)     1056        add_90[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_369 (Conv1D)             (None, 8000, 64)     4160        conv1d_368[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_370 (Conv1D)             (None, 8000, 64)     4160        conv1d_368[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 8000, 64)     0           conv1d_369[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 8000, 64)     0           conv1d_370[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_71 (Multiply)          (None, 8000, 64)     0           activation_155[0][0]             \n",
            "                                                                 activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_371 (Conv1D)             (None, 8000, 32)     2080        multiply_71[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_92 (Add)                    (None, 8000, 32)     0           conv1d_363[0][0]                 \n",
            "                                                                 conv1d_367[0][0]                 \n",
            "                                                                 conv1d_371[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 8000, 32)     0           add_92[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_37 (AveragePo (None, 1, 32)        0           activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "permute_28 (Permute)            (None, 32, 1)        0           average_pooling1d_37[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_373 (Conv1D)             (None, 32, 1)        2           permute_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_372 (Conv1D)             (None, 32, 1)        2           permute_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_42 (Reshape)            (None, 1, 32)        0           conv1d_373[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_41 (Reshape)            (None, 32, 1)        0           conv1d_372[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "permute_29 (Permute)            (None, 32, 1)        0           reshape_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dot_14 (Dot)                    (None, 32, 32)       0           reshape_41[0][0]                 \n",
            "                                                                 permute_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 32, 32)       0           dot_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_374 (Conv1D)             (None, 32, 1)        2           permute_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "softmax_7 (Softmax)             (None, 32, 32)       0           lambda_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_19 (InputLayer)           [(None, 26)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_43 (Reshape)            (None, 1, 32)        0           conv1d_374[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "permute_30 (Permute)            (None, 32, 32)       0           softmax_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 128)          3456        input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dot_15 (Dot)                    (None, 1, 32)        0           reshape_43[0][0]                 \n",
            "                                                                 permute_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_56 (LeakyReLU)      (None, 128)          0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_44 (Reshape)            (None, 32, 1)        0           dot_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 32)           4128        leaky_re_lu_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_93 (Add)                    (None, 32, 1)        0           reshape_44[0][0]                 \n",
            "                                                                 permute_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_57 (LeakyReLU)      (None, 32)           0           dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "permute_31 (Permute)            (None, 1, 32)        0           add_93[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "reshape_45 (Reshape)            (None, 1, 32)        0           leaky_re_lu_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_4 (Average)             (None, 1, 32)        0           permute_31[0][0]                 \n",
            "                                                                 reshape_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 32)           0           average_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 4)            132         flatten_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 46,498\n",
            "Trainable params: 46,498\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAeA5Hq4Bja5",
        "outputId": "643576a1-ddbb-4c8d-9549-44634a2a6ade"
      },
      "source": [
        "ensembled.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMO_DB//models//ensembled_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMO_DB//models//ensembled_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "ensembled.fit([X_train,X_train_features],Y_train, batch_size=16,\n",
        "                        validation_data=([X_val,X_val_features], Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "15/15 [==============================] - 7s 269ms/step - loss: 1.2436 - accuracy: 0.4890 - val_loss: 1.0460 - val_accuracy: 0.6078\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.04598, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.60784, saving model to EMO_DB//models/ensembled_acc.h5\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.8565 - accuracy: 0.7453 - val_loss: 0.8105 - val_accuracy: 0.7647\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.04598 to 0.81046, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.60784 to 0.76471, saving model to EMO_DB//models/ensembled_acc.h5\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.6613 - accuracy: 0.8290 - val_loss: 0.6720 - val_accuracy: 0.7843\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.81046 to 0.67199, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.76471 to 0.78431, saving model to EMO_DB//models/ensembled_acc.h5\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.5566 - accuracy: 0.8051 - val_loss: 0.5907 - val_accuracy: 0.7843\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.67199 to 0.59065, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.78431\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.4644 - accuracy: 0.8441 - val_loss: 0.5183 - val_accuracy: 0.8039\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.59065 to 0.51832, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.78431 to 0.80392, saving model to EMO_DB//models/ensembled_acc.h5\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.4229 - accuracy: 0.8605 - val_loss: 0.4684 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.51832 to 0.46839, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.80392 to 0.86275, saving model to EMO_DB//models/ensembled_acc.h5\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.3552 - accuracy: 0.9106 - val_loss: 0.4219 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.46839 to 0.42193, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.86275\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.3019 - accuracy: 0.9285 - val_loss: 0.4015 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.42193 to 0.40148, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.86275\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.3060 - accuracy: 0.9317 - val_loss: 0.3915 - val_accuracy: 0.8235\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.40148 to 0.39155, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.86275\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.3095 - accuracy: 0.9162 - val_loss: 0.3956 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.39155\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.86275\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.2465 - accuracy: 0.9228 - val_loss: 0.3344 - val_accuracy: 0.8235\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.39155 to 0.33437, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.86275\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.1839 - accuracy: 0.9492 - val_loss: 0.3640 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.33437\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.86275\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.1998 - accuracy: 0.9503 - val_loss: 0.3278 - val_accuracy: 0.8824\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.33437 to 0.32784, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.86275 to 0.88235, saving model to EMO_DB//models/ensembled_acc.h5\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - 3s 224ms/step - loss: 0.2288 - accuracy: 0.9162 - val_loss: 0.3008 - val_accuracy: 0.8824\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.32784 to 0.30080, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.88235\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.1672 - accuracy: 0.9687 - val_loss: 0.3566 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.30080\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.88235\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.1959 - accuracy: 0.9383 - val_loss: 0.2865 - val_accuracy: 0.8824\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.30080 to 0.28650, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.88235\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.1565 - accuracy: 0.9708 - val_loss: 0.2822 - val_accuracy: 0.8824\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.28650 to 0.28223, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.88235\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.1763 - accuracy: 0.9483 - val_loss: 0.3179 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.28223\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.88235\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.1238 - accuracy: 0.9572 - val_loss: 0.2664 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.28223 to 0.26638, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.88235\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.1476 - accuracy: 0.9738 - val_loss: 0.3024 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.26638\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.88235\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.1606 - accuracy: 0.9395 - val_loss: 0.2594 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.26638 to 0.25938, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.88235\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.1496 - accuracy: 0.9550 - val_loss: 0.2761 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.25938\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.88235\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.1337 - accuracy: 0.9613 - val_loss: 0.2674 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.25938\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.88235\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.1174 - accuracy: 0.9624 - val_loss: 0.2370 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.25938 to 0.23699, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.88235\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.1308 - accuracy: 0.9668 - val_loss: 0.2530 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.23699\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.88235\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.1004 - accuracy: 0.9821 - val_loss: 0.2782 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.23699\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.88235\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.1379 - accuracy: 0.9623 - val_loss: 0.2328 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.23699 to 0.23282, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.88235\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.1132 - accuracy: 0.9698 - val_loss: 0.2283 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.23282 to 0.22828, saving model to EMO_DB//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.88235\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.0865 - accuracy: 0.9805 - val_loss: 0.2423 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.22828\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.88235\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.0898 - accuracy: 0.9851 - val_loss: 0.2331 - val_accuracy: 0.8431\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.22828\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.88235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f62a0023c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mtunClsQ0Oz",
        "outputId": "c8c78510-5c69-43d7-e4a0-20f5c8fad791"
      },
      "source": [
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "ensembled.load_weights(\"EMO_DB//models/ensembled_loss.h5\")\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "\n",
        "ensembled.load_weights(\"EMO_DB//models/ensembled_acc.h5\")\n",
        "ensembled.evaluate([X_test,X_test_features],Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 124ms/step - loss: 0.1214 - accuracy: 0.9400\n",
            "[0.12144515663385391, 0.9399999976158142]\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.1313 - accuracy: 0.9800\n",
            "[0.13132430613040924, 0.9800000190734863]\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.2011 - accuracy: 0.9400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2010892629623413, 0.9399999976158142]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tkcf5lb5Bmur",
        "outputId": "49f6361f-68f6-45e1-b577-01ccbc962a8f"
      },
      "source": [
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "ensembled.load_weights(\"EMO_DB//models/ensembled2_loss.h5\")\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "\n",
        "ensembled.load_weights(\"EMO_DB//models/ensembled2_acc.h5\")\n",
        "ensembled.evaluate([X_test,X_test_features],Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 123ms/step - loss: 0.1241 - accuracy: 0.9600\n",
            "[0.1241101324558258, 0.9599999785423279]\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 0.1483 - accuracy: 0.9400\n",
            "[0.14827194809913635, 0.9399999976158142]\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.1437 - accuracy: 0.9600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14370474219322205, 0.9599999785423279]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "nx9B4pzXCCwg",
        "outputId": "ed4d99c4-2eb3-4b63-db51-602e98592fec"
      },
      "source": [
        "ensembled.load_weights(\"EMO_DB//models/ensembled_loss.h5\")\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 126ms/step - loss: 0.1313 - accuracy: 0.9800\n",
            "[0.13132430613040924, 0.9800000190734863]\n",
            "F1 SCORE: 0.9775193798449613\n",
            "Kappa: 0.9716070414537195\n",
            "Accuracy: 0.98\n",
            "Jaccard Score: 0.9573863636363636\n",
            "Precision: 0.96875\n",
            "Recall: 0.9886363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f61fefc5e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cIRa9rCBYZd"
      },
      "source": [
        "# Ensembled New"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNTKCUW4TLz2",
        "outputId": "9e8dab2b-1aac-4fe7-db02-56dee4cfb5ca"
      },
      "source": [
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*time), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "\n",
        "  out = Conv1D(4,1,activation='softmax')(out)\n",
        "  out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (26))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  out2 = Dense(4,activation = 'softmax')(layer3)\n",
        "  out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out1,out2])\n",
        "  \n",
        "  \n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled_new = Wavenet()\n",
        "ensembled_new.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 64000, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 64000, 8)     48          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 64000, 8)     0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 64000, 8)     328         leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 64000, 8)     0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d (AveragePooli (None, 32000, 8)     0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 32000, 16)    656         average_pooling1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 32000, 16)    0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 32000, 16)    1296        leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 32000, 16)    0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_1 (AveragePoo (None, 16000, 16)    0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 16000, 16)    1296        average_pooling1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 16000, 16)    0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 16000, 16)    1296        leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 16000, 16)    0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_2 (AveragePoo (None, 8000, 16)     0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 8000, 32)     544         average_pooling1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 8000, 64)     4160        conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 8000, 64)     4160        conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 8000, 64)     0           conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 8000, 64)     0           conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 8000, 64)     0           activation[0][0]                 \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 8000, 32)     2080        multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 8000, 32)     0           conv1d_6[0][0]                   \n",
            "                                                                 conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 8000, 32)     1056        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 8000, 64)     4160        conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 8000, 64)     4160        conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 8000, 64)     0           conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 8000, 64)     0           conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 8000, 64)     0           activation_2[0][0]               \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 8000, 32)     2080        multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 8000, 32)     0           conv1d_10[0][0]                  \n",
            "                                                                 conv1d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 8000, 32)     1056        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 8000, 64)     4160        conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 8000, 64)     4160        conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8000, 64)     0           conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8000, 64)     0           conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 8000, 64)     0           activation_4[0][0]               \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_17 (Conv1D)              (None, 8000, 32)     2080        multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 8000, 32)     0           conv1d_9[0][0]                   \n",
            "                                                                 conv1d_13[0][0]                  \n",
            "                                                                 conv1d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 8000, 32)     0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_3 (AveragePoo (None, 1, 32)        0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 32, 1)        0           average_pooling1d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_19 (Conv1D)              (None, 32, 1)        2           permute[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_18 (Conv1D)              (None, 32, 1)        2           permute[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 32)        0           conv1d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 32, 1)        0           conv1d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 32, 1)        0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 32, 32)       0           reshape[0][0]                    \n",
            "                                                                 permute_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 32, 32)       0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_20 (Conv1D)              (None, 32, 1)        2           permute[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 32, 32)       0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 26)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 1, 32)        0           conv1d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_2 (Permute)             (None, 32, 32)       0           softmax[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          3456        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 1, 32)        0           reshape_2[0][0]                  \n",
            "                                                                 permute_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 128)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 32, 1)        0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 32)           4128        leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 1)        0           reshape_3[0][0]                  \n",
            "                                                                 permute[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 32)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "permute_3 (Permute)             (None, 1, 32)        0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 1, 32)        0           leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_21 (Conv1D)              (None, 1, 4)         132         permute_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1, 4)         132         reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 4, 1)         0           conv1d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 4, 1)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average (Average)               (None, 4, 1)         0           reshape_4[0][0]                  \n",
            "                                                                 reshape_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 46,630\n",
            "Trainable params: 46,630\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLVfWELeBggO",
        "outputId": "6d3e45d7-0c81-4f60-e2f7-dc7d39784a1e"
      },
      "source": [
        "ensembled_new.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMODB//models//ensembled_new_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMODB//models//ensembled_new_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "ensembled_new.fit([X_train,X_train_features],Y_train, batch_size=16,validation_data=([X_val,X_val_features], Y_val),epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "15/15 [==============================] - 38s 192ms/step - loss: 1.2285 - accuracy: 0.7581 - val_loss: 0.9657 - val_accuracy: 0.7941\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.96566, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.79412, saving model to EMODB//models/ensembled_new_acc.h5\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - 2s 104ms/step - loss: 0.8673 - accuracy: 0.8377 - val_loss: 0.8556 - val_accuracy: 0.8039\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.96566 to 0.85564, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.79412 to 0.80392, saving model to EMODB//models/ensembled_new_acc.h5\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - 2s 103ms/step - loss: 0.7884 - accuracy: 0.8556 - val_loss: 0.8186 - val_accuracy: 0.8186\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.85564 to 0.81856, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.80392 to 0.81863, saving model to EMODB//models/ensembled_new_acc.h5\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - 2s 104ms/step - loss: 0.7315 - accuracy: 0.8690 - val_loss: 0.7911 - val_accuracy: 0.8284\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.81856 to 0.79106, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.81863 to 0.82843, saving model to EMODB//models/ensembled_new_acc.h5\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - 2s 103ms/step - loss: 0.6449 - accuracy: 0.8971 - val_loss: 0.7732 - val_accuracy: 0.8284\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.79106 to 0.77320, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.82843\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - 2s 104ms/step - loss: 0.6374 - accuracy: 0.8944 - val_loss: 0.7346 - val_accuracy: 0.8529\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.77320 to 0.73461, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.82843 to 0.85294, saving model to EMODB//models/ensembled_new_acc.h5\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - 2s 104ms/step - loss: 0.6057 - accuracy: 0.9075 - val_loss: 0.6963 - val_accuracy: 0.8480\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.73461 to 0.69633, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.85294\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - 2s 104ms/step - loss: 0.4960 - accuracy: 0.9110 - val_loss: 0.6156 - val_accuracy: 0.8824\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.69633 to 0.61558, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.85294 to 0.88235, saving model to EMODB//models/ensembled_new_acc.h5\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - 2s 104ms/step - loss: 0.4793 - accuracy: 0.9471 - val_loss: 0.5748 - val_accuracy: 0.8922\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.61558 to 0.57483, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.88235 to 0.89216, saving model to EMODB//models/ensembled_new_acc.h5\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - 2s 104ms/step - loss: 0.4194 - accuracy: 0.9483 - val_loss: 0.5699 - val_accuracy: 0.9020\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.57483 to 0.56990, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.89216 to 0.90196, saving model to EMODB//models/ensembled_new_acc.h5\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - 2s 105ms/step - loss: 0.3824 - accuracy: 0.9587 - val_loss: 0.5383 - val_accuracy: 0.8922\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.56990 to 0.53826, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.90196\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - 2s 104ms/step - loss: 0.3981 - accuracy: 0.9530 - val_loss: 0.5395 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.53826\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.90196 to 0.90686, saving model to EMODB//models/ensembled_new_acc.h5\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - 2s 104ms/step - loss: 0.3816 - accuracy: 0.9456 - val_loss: 0.5064 - val_accuracy: 0.9020\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.53826 to 0.50637, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.90686\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - 2s 104ms/step - loss: 0.3486 - accuracy: 0.9662 - val_loss: 0.5006 - val_accuracy: 0.9216\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.50637 to 0.50059, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.90686 to 0.92157, saving model to EMODB//models/ensembled_new_acc.h5\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - 2s 105ms/step - loss: 0.4110 - accuracy: 0.9428 - val_loss: 0.4996 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.50059 to 0.49962, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.92157\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - 2s 104ms/step - loss: 0.3371 - accuracy: 0.9659 - val_loss: 0.5290 - val_accuracy: 0.9020\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.49962\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.92157\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - 2s 105ms/step - loss: 0.3306 - accuracy: 0.9651 - val_loss: 0.5010 - val_accuracy: 0.9118\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.49962\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.92157\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - 2s 105ms/step - loss: 0.3160 - accuracy: 0.9694 - val_loss: 0.4870 - val_accuracy: 0.9167\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.49962 to 0.48703, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.92157\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - 2s 106ms/step - loss: 0.3325 - accuracy: 0.9618 - val_loss: 0.5119 - val_accuracy: 0.9265\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.48703\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.92157 to 0.92647, saving model to EMODB//models/ensembled_new_acc.h5\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - 2s 105ms/step - loss: 0.3239 - accuracy: 0.9729 - val_loss: 0.5068 - val_accuracy: 0.9118\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.48703\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.92647\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - 2s 106ms/step - loss: 0.3166 - accuracy: 0.9687 - val_loss: 0.4807 - val_accuracy: 0.9118\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.48703 to 0.48073, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.92647\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - 2s 105ms/step - loss: 0.3021 - accuracy: 0.9727 - val_loss: 0.5005 - val_accuracy: 0.9118\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.48073\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.92647\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - 2s 106ms/step - loss: 0.3195 - accuracy: 0.9790 - val_loss: 0.4665 - val_accuracy: 0.9118\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.48073 to 0.46649, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.92647\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - 2s 105ms/step - loss: 0.2892 - accuracy: 0.9797 - val_loss: 0.4953 - val_accuracy: 0.9020\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.46649\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.92647\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - 2s 105ms/step - loss: 0.2984 - accuracy: 0.9718 - val_loss: 0.4637 - val_accuracy: 0.9265\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.46649 to 0.46369, saving model to EMODB//models/ensembled_new_loss.h5\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.92647\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - 2s 105ms/step - loss: 0.2861 - accuracy: 0.9779 - val_loss: 0.4695 - val_accuracy: 0.9118\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.46369\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.92647\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - 2s 105ms/step - loss: 0.2805 - accuracy: 0.9754 - val_loss: 0.5027 - val_accuracy: 0.9020\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.46369\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.92647\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - 2s 106ms/step - loss: 0.3332 - accuracy: 0.9711 - val_loss: 0.4830 - val_accuracy: 0.9118\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.46369\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.92647\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - 2s 105ms/step - loss: 0.3231 - accuracy: 0.9658 - val_loss: 0.4734 - val_accuracy: 0.9020\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.46369\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.92647\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - 2s 106ms/step - loss: 0.2933 - accuracy: 0.9726 - val_loss: 0.4776 - val_accuracy: 0.9069\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.46369\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.92647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8ef00de750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFustAF-BqYF",
        "outputId": "432d669c-7128-42a5-f1fe-cb74fda1be5a"
      },
      "source": [
        "\n",
        "ensembled_new.load_weights(\"EMODB//models/ensembled_new_loss.h5\")\n",
        "print(ensembled_new.evaluate([X_test,X_test_features],Y_test))\n",
        "\n",
        "ensembled_new.load_weights(\"EMODB//models/ensembled_new_acc.h5\")\n",
        "ensembled_new.evaluate([X_test,X_test_features],Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 199ms/step - loss: 0.3105 - accuracy: 0.9650\n",
            "[0.31053170561790466, 0.9649999737739563]\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3168 - accuracy: 0.9800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.31680232286453247, 0.9800000190734863]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "wtmLN8aTCAtk",
        "outputId": "f352a64e-af87-4bd1-cbd5-c589959c800b"
      },
      "source": [
        "#test set\n",
        "print(ensembled_new.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_new.predict([X_test,X_test_features]).reshape(Y_test.shape),axis = -1)\n",
        "\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_new.predict([X_test,X_test_features]).reshape(Y_test.shape),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 59ms/step - loss: 0.3168 - accuracy: 0.9800\n",
            "[0.31680232286453247, 0.9800000190734863]\n",
            "F1 SCORE: 0.9511862152594419\n",
            "Kappa: 0.9421965317919075\n",
            "Accuracy: 0.96\n",
            "Jaccard Score: 0.9075828157349896\n",
            "Precision: 0.9682971014492754\n",
            "Recall: 0.9392857142857143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8eb351c610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28GSFNXiCP5u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpi38PE--I3k"
      },
      "source": [
        "# Spectogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxwc0F7x-KdU",
        "outputId": "066a79ec-d370-4982-f4c8-a3bef6da7800"
      },
      "source": [
        "def findmaxsize(rslt_df):\n",
        "\n",
        "    sizes = []\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "      filename = row['path']\n",
        "\n",
        "      y, sr = librosa.core.load(filename)\n",
        "          \n",
        "      # Computing the mel spectrograms\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        "      \n",
        "      # Adding the size to the list\n",
        "      sizes.append(spect.shape)\n",
        "    print(f'The sizes of all the mel spectrograms in our data set are equal: {len(set(sizes)) == 1}')\n",
        "\n",
        "    # Checking the max size\n",
        "    print(f'The maximum size is: {max(sizes)}')\n",
        "\n",
        "\n",
        "    return max(sizes)\n",
        "\n",
        "\n",
        "X = pd.read_csv('EMO_DB/EMODB_details.csv',usecols=['labels','path'])\n",
        "options = ['m_angry', 'm_happy','m_neutral','m_sad',\n",
        "           'f_angry', 'f_happy','f_neutral','f_sad']\n",
        "\n",
        "time = 4\n",
        "rslt_df = X[X['labels'].isin(options)]\n",
        "\n",
        "\n",
        "audio_files=[]\n",
        "labels=[]\n",
        "\n",
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "max_x,max_y = findmaxsize(rslt_df)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sizes of all the mel spectrograms in our data set are equal: False\n",
            "The maximum size is: (128, 194)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tevchhsjAgEZ",
        "outputId": "8c980198-63da-42ca-8937-dc7d0979bf65"
      },
      "source": [
        "def extract_mel_spectrogram(df,max_x,max_y):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path']\n",
        " \n",
        "      y, sr = librosa.core.load(filename)\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        " \n",
        "            # Adjusting the size to be 128 x 660\n",
        "      if spect.shape[1] != max_y:\n",
        "                #print('Sizes arent same')\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        " \n",
        "      mel_specs.append(spect)\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  mel_specs = np.array(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        " \n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv,max_x,max_y)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "X_train_spec = np.expand_dims(X_train_spec,axis=3)\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        " \n",
        " \n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv,max_x,max_y)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "X_test_spec = np.expand_dims(X_test_spec,axis=3)\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        " \n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv,max_x,max_y)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "X_val_spec = np.expand_dims(X_val_spec,axis=3)\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(237, 128, 194, 1) (237, 4)\n",
            "(50, 128, 194, 1) (50, 4)\n",
            "(51, 128, 194, 1) (51, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkNb3-3EEl3g",
        "outputId": "97f39212-a949-40aa-ffcc-2e89f4b63049"
      },
      "source": [
        "cnn_model = Sequential(name='Convolutional_Neural_Network')\n",
        "\n",
        "cnn_model.add(Conv2D(filters=16,\n",
        "                     kernel_size=(3,3),\n",
        "                     input_shape=(max_x,max_y,1),name = \"Input_Convolution_Layer\"))\n",
        "cnn_model.add(LeakyReLU( name = \"Leaky_Relu_Activation_1\"))\n",
        "# Adding max pooling layer\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2,4),name = 'Max_Pooling_1'))\n",
        "\n",
        "# Adding convolutional layer\n",
        "cnn_model.add(Conv2D(filters=32,\n",
        "                     kernel_size=(3,3),name = \"Convolution_Layer_2\"\n",
        "                     ))\n",
        "cnn_model.add(LeakyReLU(name = \"Leaky_Relu_Activation_2\"))\n",
        "# Adding max pooling layer\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2,4),name = 'Max_Pooling_2'))\n",
        "\n",
        "# Adding a flattened layer to input our image data\n",
        "cnn_model.add(Flatten(name = 'Flatten'))\n",
        "\n",
        "# Adding a dense layer with 64 neurons\n",
        "cnn_model.add(Dense(64,name = 'Dense_1' ))\n",
        "cnn_model.add(LeakyReLU())\n",
        "\n",
        "# Adding a dropout layer for regularization\n",
        "cnn_model.add(Dropout(0.25,name = 'Dropout'))\n",
        "\n",
        "# Adding an output layer\n",
        "cnn_model.add(Dense(4, activation='softmax',name = 'Output_Layer'))\n",
        "\n",
        "# Compiling our neural network\n",
        "cnn_model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "model_checkpoint = ModelCheckpoint(f'EMO_DB//models//CNN.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "# Fitting our neural network\n",
        "history = cnn_model.fit(X_train_spec,\n",
        "                        Y_train_spec, \n",
        "                        batch_size=16,\n",
        "                        validation_data=(X_val_spec, Y_val_spec),\n",
        "                        epochs=30,callbacks = model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 2.0511 - accuracy: 0.3598 - val_loss: 1.3086 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.30856, saving model to EMO_DB//models/CNN.h5\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.2433 - accuracy: 0.4095 - val_loss: 1.2119 - val_accuracy: 0.4510\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.30856 to 1.21185, saving model to EMO_DB//models/CNN.h5\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.1012 - accuracy: 0.5287 - val_loss: 1.0892 - val_accuracy: 0.5490\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.21185 to 1.08919, saving model to EMO_DB//models/CNN.h5\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9723 - accuracy: 0.5945 - val_loss: 1.0110 - val_accuracy: 0.6078\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.08919 to 1.01102, saving model to EMO_DB//models/CNN.h5\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8732 - accuracy: 0.6092 - val_loss: 0.9264 - val_accuracy: 0.6275\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.01102 to 0.92638, saving model to EMO_DB//models/CNN.h5\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6975 - accuracy: 0.6606 - val_loss: 0.9713 - val_accuracy: 0.6078\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.92638\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7642 - accuracy: 0.6889 - val_loss: 0.8971 - val_accuracy: 0.6275\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.92638 to 0.89706, saving model to EMO_DB//models/CNN.h5\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5978 - accuracy: 0.7646 - val_loss: 0.8338 - val_accuracy: 0.6078\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.89706 to 0.83376, saving model to EMO_DB//models/CNN.h5\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4548 - accuracy: 0.8666 - val_loss: 0.8116 - val_accuracy: 0.6471\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.83376 to 0.81157, saving model to EMO_DB//models/CNN.h5\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4652 - accuracy: 0.8685 - val_loss: 0.8223 - val_accuracy: 0.7059\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.81157\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3507 - accuracy: 0.8923 - val_loss: 0.9459 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.81157\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2647 - accuracy: 0.9119 - val_loss: 0.8739 - val_accuracy: 0.6275\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.81157\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3045 - accuracy: 0.9010 - val_loss: 0.7655 - val_accuracy: 0.6471\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.81157 to 0.76550, saving model to EMO_DB//models/CNN.h5\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2113 - accuracy: 0.9382 - val_loss: 1.0545 - val_accuracy: 0.6275\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.76550\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2762 - accuracy: 0.8700 - val_loss: 0.8656 - val_accuracy: 0.6471\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.76550\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1675 - accuracy: 0.9693 - val_loss: 0.8916 - val_accuracy: 0.6078\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.76550\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1680 - accuracy: 0.9561 - val_loss: 1.0657 - val_accuracy: 0.6863\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.76550\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1328 - accuracy: 0.9625 - val_loss: 0.8953 - val_accuracy: 0.6863\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.76550\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1238 - accuracy: 0.9746 - val_loss: 0.9356 - val_accuracy: 0.6078\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.76550\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0787 - accuracy: 0.9885 - val_loss: 0.8347 - val_accuracy: 0.6471\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.76550\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0679 - accuracy: 0.9957 - val_loss: 0.9703 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.76550\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0622 - accuracy: 0.9866 - val_loss: 1.2212 - val_accuracy: 0.5882\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.76550\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0873 - accuracy: 0.9902 - val_loss: 1.0430 - val_accuracy: 0.6863\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.76550\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 1.1021 - val_accuracy: 0.6863\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.76550\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0414 - accuracy: 0.9938 - val_loss: 1.0262 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.76550\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9956 - val_loss: 0.8544 - val_accuracy: 0.6471\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.76550\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0763 - accuracy: 0.9762 - val_loss: 0.9192 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.76550\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 0.9939 - val_loss: 1.2356 - val_accuracy: 0.6471\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.76550\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.0355 - accuracy: 0.9949 - val_loss: 1.1739 - val_accuracy: 0.6471\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.76550\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.0500 - val_accuracy: 0.6863\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.76550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DKdQL2rGFUC",
        "outputId": "805f0ba3-19ca-47af-d0cc-1ffe0d0e7efb"
      },
      "source": [
        "cnn_model.load_weights('EMO_DB//models//CNN.h5')\n",
        "cnn_model.evaluate(X_test_spec,Y_test_spec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 76ms/step - loss: 0.3502 - accuracy: 0.8600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3502076268196106, 0.8600000143051147]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "tESMd7EbGt2T",
        "outputId": "5df04119-e25f-48f1-d1bf-03ad34de70b5"
      },
      "source": [
        "#test set\n",
        "\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(cnn_model.predict(X_test_spec),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(cnn_model.predict(X_test_spec),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 SCORE: 0.8167249417249417\n",
            "Kappa: 0.7978047371461583\n",
            "Accuracy: 0.86\n",
            "Jaccard Score: 0.7074834887334888\n",
            "Precision: 0.8244729907773386\n",
            "Recall: 0.811038961038961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f90423b9610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q77jcjukLHkg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wctIIbixg5Q_"
      },
      "source": [
        "# Paper_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqt7I_xQg6Q1"
      },
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 8\n",
        "srk = 44100\n",
        "def label_to_onehot(l):\n",
        "    l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = srk)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hekS28b9hJ2u"
      },
      "source": [
        "def paper_model():\n",
        "  inp = Input((srk*time,1))\n",
        "  l1 = BatchNormalization()(Conv1D(32,21,activation='relu',padding = 'same')(inp))\n",
        "  m1 = MaxPool1D(2)(l1)\n",
        "\n",
        "  l2 = BatchNormalization()(Conv1D(64,19,activation='relu',padding = 'same')(m1))\n",
        "  m2 = MaxPool1D(2)(l2)\n",
        "\n",
        "  l3 = BatchNormalization()(Conv1D(128,17,activation='relu',padding = 'same')(m2))\n",
        "  m3 = MaxPool1D(2)(l3)\n",
        "\n",
        "\n",
        "  l4 = BatchNormalization()(Conv1D(256,15,activation='relu',padding = 'same')(m3))\n",
        "  m4 = MaxPool1D(2)(l4)\n",
        "\n",
        "  l5 = BatchNormalization()(Conv1D(512,13,activation='relu',padding = 'same')(m4))\n",
        "  m5 = MaxPool1D(2)(l5)\n",
        "\n",
        "  l6 = BatchNormalization()(Conv1D(1024,11,activation='relu',padding = 'same')(m5))\n",
        "  m6 = MaxPool1D(2)(l6)\n",
        "\n",
        "  l7 = BatchNormalization()(Conv1D(1024,9,activation='relu',padding = 'same')(m6))\n",
        "  m7 = GlobalMaxPool1D()(l7)\n",
        "\n",
        "  fl = Flatten()(m7)\n",
        "  d1 = Dense(128,activation='relu')(fl)\n",
        "  out = Dense(4,activation='softmax')(d1)\n",
        "\n",
        "  return Model(inputs = inp,outputs = out)\n",
        "\n",
        "m = paper_model()\n",
        "m.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 1"
      ],
      "metadata": {
        "id": "OTeKnXWIu34E"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwkrI5xtiTN6",
        "outputId": "689279c4-9f9a-4f93-ba67-e8f01e44445e"
      },
      "source": [
        "m.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMODB//models//paper_1_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMODB//models//paper_1_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = m.fit(X_train,Y_train, batch_size=8,validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "30/30 [==============================] - 154s 3s/step - loss: 13.2951 - accuracy: 0.3243 - val_loss: 4.5678 - val_accuracy: 0.1373\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.56778, saving model to EMODB//models/paper_1_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.13725, saving model to EMODB//models/paper_1_acc.h5\n",
            "Epoch 2/30\n",
            "30/30 [==============================] - 92s 3s/step - loss: 1.9484 - accuracy: 0.4970 - val_loss: 5.5771 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 4.56778\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.13725 to 0.25490, saving model to EMODB//models/paper_1_acc.h5\n",
            "Epoch 3/30\n",
            "30/30 [==============================] - 94s 3s/step - loss: 1.5728 - accuracy: 0.5744 - val_loss: 4.8159 - val_accuracy: 0.2157\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 4.56778\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.25490\n",
            "Epoch 4/30\n",
            "30/30 [==============================] - 94s 3s/step - loss: 0.9815 - accuracy: 0.5950 - val_loss: 4.1791 - val_accuracy: 0.2157\n",
            "\n",
            "Epoch 00004: val_loss improved from 4.56778 to 4.17907, saving model to EMODB//models/paper_1_loss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.25490\n",
            "Epoch 5/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 1.2259 - accuracy: 0.5849 - val_loss: 3.4971 - val_accuracy: 0.1373\n",
            "\n",
            "Epoch 00005: val_loss improved from 4.17907 to 3.49711, saving model to EMODB//models/paper_1_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.25490\n",
            "Epoch 6/30\n",
            "30/30 [==============================] - 94s 3s/step - loss: 1.4838 - accuracy: 0.6065 - val_loss: 1.6557 - val_accuracy: 0.4314\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.49711 to 1.65570, saving model to EMODB//models/paper_1_loss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.25490 to 0.43137, saving model to EMODB//models/paper_1_acc.h5\n",
            "Epoch 7/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.8956 - accuracy: 0.6391 - val_loss: 1.4348 - val_accuracy: 0.4314\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.65570 to 1.43484, saving model to EMODB//models/paper_1_loss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.43137\n",
            "Epoch 8/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.6122 - accuracy: 0.7093 - val_loss: 2.7891 - val_accuracy: 0.2353\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.43137\n",
            "Epoch 9/30\n",
            "30/30 [==============================] - 94s 3s/step - loss: 0.6991 - accuracy: 0.7131 - val_loss: 2.3755 - val_accuracy: 0.2353\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.43137\n",
            "Epoch 10/30\n",
            "30/30 [==============================] - 94s 3s/step - loss: 0.5452 - accuracy: 0.7548 - val_loss: 1.9147 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.43137\n",
            "Epoch 11/30\n",
            "30/30 [==============================] - 94s 3s/step - loss: 0.6204 - accuracy: 0.7375 - val_loss: 2.1241 - val_accuracy: 0.3137\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.43137\n",
            "Epoch 12/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.4885 - accuracy: 0.7630 - val_loss: 2.5987 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.43137\n",
            "Epoch 13/30\n",
            "30/30 [==============================] - 94s 3s/step - loss: 0.5802 - accuracy: 0.7624 - val_loss: 3.3115 - val_accuracy: 0.2745\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.43137\n",
            "Epoch 14/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.3488 - accuracy: 0.8350 - val_loss: 4.3385 - val_accuracy: 0.2745\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.43137\n",
            "Epoch 15/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.3420 - accuracy: 0.8416 - val_loss: 3.1334 - val_accuracy: 0.3137\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.43137\n",
            "Epoch 16/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.4931 - accuracy: 0.8146 - val_loss: 3.4152 - val_accuracy: 0.2941\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.43137\n",
            "Epoch 17/30\n",
            "30/30 [==============================] - 94s 3s/step - loss: 0.3186 - accuracy: 0.8715 - val_loss: 3.6019 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.43137\n",
            "Epoch 18/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.6913 - accuracy: 0.7612 - val_loss: 4.5731 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.43137\n",
            "Epoch 19/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.3646 - accuracy: 0.8731 - val_loss: 4.8882 - val_accuracy: 0.2353\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.43137\n",
            "Epoch 20/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.4624 - accuracy: 0.8286 - val_loss: 3.0455 - val_accuracy: 0.2745\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.43137\n",
            "Epoch 21/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.3386 - accuracy: 0.8396 - val_loss: 2.2401 - val_accuracy: 0.3725\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.43137\n",
            "Epoch 22/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.3976 - accuracy: 0.8658 - val_loss: 3.0851 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.43137\n",
            "Epoch 23/30\n",
            "30/30 [==============================] - 94s 3s/step - loss: 0.1752 - accuracy: 0.9267 - val_loss: 2.8482 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.43484\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.43137\n",
            "Epoch 24/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.2602 - accuracy: 0.8902 - val_loss: 0.6820 - val_accuracy: 0.7255\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.43484 to 0.68196, saving model to EMODB//models/paper_1_loss.h5\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.43137 to 0.72549, saving model to EMODB//models/paper_1_acc.h5\n",
            "Epoch 25/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.4201 - accuracy: 0.8131 - val_loss: 3.0135 - val_accuracy: 0.4118\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.68196\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.72549\n",
            "Epoch 26/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.1881 - accuracy: 0.9075 - val_loss: 1.0860 - val_accuracy: 0.6471\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.68196\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.72549\n",
            "Epoch 27/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.2989 - accuracy: 0.9202 - val_loss: 3.9546 - val_accuracy: 0.4118\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.68196\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.72549\n",
            "Epoch 28/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.3942 - accuracy: 0.8735 - val_loss: 2.5651 - val_accuracy: 0.4902\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.68196\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.72549\n",
            "Epoch 29/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.3478 - accuracy: 0.9014 - val_loss: 1.2619 - val_accuracy: 0.5294\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.68196\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.72549\n",
            "Epoch 30/30\n",
            "30/30 [==============================] - 95s 3s/step - loss: 0.1837 - accuracy: 0.9181 - val_loss: 0.7458 - val_accuracy: 0.7451\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.68196\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.72549 to 0.74510, saving model to EMODB//models/paper_1_acc.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY8iejGwiZyE",
        "outputId": "04063232-00e9-492f-d20f-346adfa95fae"
      },
      "source": [
        "m.load_weights('EMODB//models//paper_1_acc.h5')\n",
        "print(m.evaluate(X_test,Y_test))\n",
        "m.load_weights('EMODB//models//paper_1_loss.h5')\n",
        "m.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 29s 12s/step - loss: 0.4929 - accuracy: 0.8200\n",
            "[0.4929375946521759, 0.8199999928474426]\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.4995 - accuracy: 0.8200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49954158067703247, 0.8199999928474426]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "Wlcj6YNgtjvB",
        "outputId": "049dd9d5-b79a-4a7c-b998-1acf7880deb6"
      },
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(m.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(m.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 SCORE: 0.7703089244851258\n",
            "Kappa: 0.7382198952879581\n",
            "Accuracy: 0.82\n",
            "Jaccard Score: 0.6497668997668998\n",
            "Precision: 0.8006410256410257\n",
            "Recall: 0.7662337662337662\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87        22\n",
            "           1       0.60      0.43      0.50         7\n",
            "           2       1.00      0.73      0.84        11\n",
            "           3       0.77      1.00      0.87        10\n",
            "\n",
            "    accuracy                           0.82        50\n",
            "   macro avg       0.80      0.77      0.77        50\n",
            "weighted avg       0.82      0.82      0.81        50\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTzC0Q0Z6sek"
      },
      "source": [
        "# Paper_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VN4Mi2mttYq",
        "outputId": "e4fe8b03-1881-46e8-c4b1-7ef487d3bc79"
      },
      "source": [
        "def findmaxsize(rslt_df):\n",
        "\n",
        "    sizes = []\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "      filename = row['path']\n",
        "\n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      #print(y.shape)\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      \n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        "      #print(spect.shape)\n",
        "      \n",
        "      # Adding the size to the list\n",
        "      sizes.append(spect.shape)\n",
        "    print(f'The sizes of all the mel spectrograms in our data set are equal: {len(set(sizes)) == 1}')\n",
        "\n",
        "    # Checking the max size\n",
        "    print(f'The maximum size is: {max(sizes)}')\n",
        "\n",
        "\n",
        "    return max(sizes)\n",
        "\n",
        "\n",
        "X = pd.read_csv('EMO_DB/EMODB_details.csv',usecols=['labels','path'])\n",
        "options = ['m_angry', 'm_happy','m_neutral','m_sad',\n",
        "           'f_angry', 'f_happy','f_neutral','f_sad']\n",
        "\n",
        "time = 4\n",
        "rslt_df = X[X['labels'].isin(options)]\n",
        "\n",
        "\n",
        "audio_files=[]\n",
        "labels=[]\n",
        "max_x,max_y = findmaxsize(rslt_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sizes of all the mel spectrograms in our data set are equal: False\n",
            "The maximum size is: (64, 898)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UjJJTejWZNT",
        "outputId": "778613d6-69d1-4827-a812-35cc863a08b8"
      },
      "source": [
        "max_x = 64\n",
        "max_y = 898\n",
        "T = 80\n",
        "print(max_y,T,(int(max_y/T)+1)*T,int(max_y/T)+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "898 80 960 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr16obt376Vg",
        "outputId": "cf58c3ec-8210-4d94-ae11-a530352ecadd"
      },
      "source": [
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "def extract_mel_spectrogram(df,max_x = max_x,max_y = (int(max_y/T)+1)*T):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path']\n",
        " \n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      #print(y.shape)\n",
        "      # Computing the mel spectrograms\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      \n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        " \n",
        "            \n",
        "      \n",
        "      if spect.shape[1] != max_y:\n",
        "                #print('Sizes arent same')\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        "      s=[]\n",
        "      for i in range(int(max_y/T)):\n",
        "        #print(spect[:,i*64:(i+1)*64].shape)\n",
        "        q=spect[:,i*T:(i+1)*T]\n",
        "        delta = librosa.feature.delta(q).reshape((max_x,T,1))\n",
        "        d_delta = librosa.feature.delta(q,order = 2).reshape((max_x,T,1))\n",
        "        #print(q.shape,delta.shape,d_delta.shape)\n",
        "        q = q.reshape((max_x,T,1))\n",
        "\n",
        "        z = np.concatenate((q,delta,d_delta),axis = -1)\n",
        "        #print(z.shape)\n",
        "        s.append(z)\n",
        "      mel_specs.append(np.asarray(s))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  #print(len(mel_specs),mel_specs[0].shape)\n",
        "  mel_specs = np.asarray(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        " \n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "#X_train_spec = np.expand_dims(X_train_spec,axis=-1)\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        " \n",
        " \n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "#X_test_spec = np.expand_dims(X_test_spec,axis=-1)\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        " \n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "#X_val_spec = np.expand_dims(X_val_spec,axis=-1)\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(237, 12, 64, 80, 3) (237, 4)\n",
            "(50, 12, 64, 80, 3) (50, 4)\n",
            "(51, 12, 64, 80, 3) (51, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoE-xmAi_HCJ",
        "outputId": "89bd1c5e-e133-470a-8b5c-569a19f7a886"
      },
      "source": [
        "import keras\n",
        "def AlexNet(input_shape):\n",
        "    \n",
        "    X_input = Input(input_shape)\n",
        "    \n",
        "    X = Conv2D(96,(11,11),strides = 4,name=\"conv0\")(X_input)\n",
        "    X = BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
        "    \n",
        "    X = Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3 ,name='bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max2')(X)\n",
        "    \n",
        "    X = Reshape((36,256))(X)\n",
        "\n",
        "    X= LSTM(256,return_sequences=True)(X)\n",
        "    X= LSTM(256)(X)\n",
        "\n",
        "    \n",
        "    #X = Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
        "    \n",
        "    #X = Dense(4096, activation = 'relu', name = 'fc1')(X) \n",
        "    \n",
        "    \n",
        "\n",
        "    model = Model(inputs = X_input, outputs = X, name='AlexNet')\n",
        "\n",
        "    return model\n",
        "\n",
        "def paper_2():\n",
        "    input_layer = Input((int(max_y/T)+1,max_x,T,3))\n",
        "    alex = AlexNet((227,227,3))\n",
        "    \n",
        "    for i in range(int(max_y/T)+1):\n",
        "      #print(input_layer[:,0,:,:,:].shape)\n",
        "      inp = keras.layers.experimental.preprocessing.Resizing(227,227)(input_layer[:,i,:,:,:])\n",
        "      \n",
        "      cnn = alex(inp)\n",
        "\n",
        "      #cnn = Reshape((1,4096))(cnn)\n",
        "\n",
        "      if i == 0:\n",
        "        output_layers = cnn\n",
        "      else:\n",
        "        output_layers = Concatenate(axis = 1)([output_layers,cnn])\n",
        "      \n",
        "    \n",
        "    #print(len(output_layers))\n",
        "    #lstm = LSTM(256,return_sequences=True)(output_layers)\n",
        "    #lstm = LSTM(256,return_sequences=True)(lstm)\n",
        "    #lstm = LSTM(256)(lstm)\n",
        "    \n",
        "    out = Dense(4,activation='softmax')(output_layers)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return Model(inputs=input_layer,outputs=out)\n",
        "p2 = paper_2()\n",
        "p2.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 12, 64, 80,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici (None, 64, 80, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_1 (Sli (None, 64, 80, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing (Resizing)             (None, 227, 227, 3)  0           tf.__operators__.getitem[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_1 (Resizing)           (None, 227, 227, 3)  0           tf.__operators__.getitem_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_2 (Sli (None, 64, 80, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "AlexNet (Functional)            (None, 256)          4803328     resizing[0][0]                   \n",
            "                                                                 resizing_1[0][0]                 \n",
            "                                                                 resizing_2[0][0]                 \n",
            "                                                                 resizing_3[0][0]                 \n",
            "                                                                 resizing_4[0][0]                 \n",
            "                                                                 resizing_5[0][0]                 \n",
            "                                                                 resizing_6[0][0]                 \n",
            "                                                                 resizing_7[0][0]                 \n",
            "                                                                 resizing_8[0][0]                 \n",
            "                                                                 resizing_9[0][0]                 \n",
            "                                                                 resizing_10[0][0]                \n",
            "                                                                 resizing_11[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "resizing_2 (Resizing)           (None, 227, 227, 3)  0           tf.__operators__.getitem_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_3 (Sli (None, 64, 80, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 512)          0           AlexNet[0][0]                    \n",
            "                                                                 AlexNet[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_3 (Resizing)           (None, 227, 227, 3)  0           tf.__operators__.getitem_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_4 (Sli (None, 64, 80, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 768)          0           concatenate[0][0]                \n",
            "                                                                 AlexNet[2][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_4 (Resizing)           (None, 227, 227, 3)  0           tf.__operators__.getitem_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_5 (Sli (None, 64, 80, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1024)         0           concatenate_1[0][0]              \n",
            "                                                                 AlexNet[3][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_5 (Resizing)           (None, 227, 227, 3)  0           tf.__operators__.getitem_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_6 (Sli (None, 64, 80, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 1280)         0           concatenate_2[0][0]              \n",
            "                                                                 AlexNet[4][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_6 (Resizing)           (None, 227, 227, 3)  0           tf.__operators__.getitem_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_7 (Sli (None, 64, 80, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 1536)         0           concatenate_3[0][0]              \n",
            "                                                                 AlexNet[5][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_7 (Resizing)           (None, 227, 227, 3)  0           tf.__operators__.getitem_7[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_8 (Sli (None, 64, 80, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 1792)         0           concatenate_4[0][0]              \n",
            "                                                                 AlexNet[6][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_8 (Resizing)           (None, 227, 227, 3)  0           tf.__operators__.getitem_8[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_9 (Sli (None, 64, 80, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 2048)         0           concatenate_5[0][0]              \n",
            "                                                                 AlexNet[7][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_9 (Resizing)           (None, 227, 227, 3)  0           tf.__operators__.getitem_9[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_10 (Sl (None, 64, 80, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 2304)         0           concatenate_6[0][0]              \n",
            "                                                                 AlexNet[8][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_10 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_10[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_11 (Sl (None, 64, 80, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 2560)         0           concatenate_7[0][0]              \n",
            "                                                                 AlexNet[9][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_11 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_11[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 2816)         0           concatenate_8[0][0]              \n",
            "                                                                 AlexNet[10][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 3072)         0           concatenate_9[0][0]              \n",
            "                                                                 AlexNet[11][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            12292       concatenate_10[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 4,815,620\n",
            "Trainable params: 4,812,868\n",
            "Non-trainable params: 2,752\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLZHw0tFJKK9",
        "outputId": "a3fcefe5-ca75-49bb-8ce3-72bef8a63345"
      },
      "source": [
        "p2.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMODB//models//paper_2_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMODB//models//paper_2_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = p2.fit(X_train_spec,Y_train_spec, batch_size=8,validation_data=(X_val_spec, Y_val_spec),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "30/30 [==============================] - 100s 1s/step - loss: 1.4743 - accuracy: 0.2469 - val_loss: 1.3035 - val_accuracy: 0.3725\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.30351, saving model to EMODB//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.37255, saving model to EMODB//models/paper_2_acc.h5\n",
            "Epoch 2/30\n",
            "30/30 [==============================] - 22s 744ms/step - loss: 1.2786 - accuracy: 0.3911 - val_loss: 1.2956 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.30351 to 1.29555, saving model to EMODB//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.37255\n",
            "Epoch 3/30\n",
            "30/30 [==============================] - 22s 743ms/step - loss: 1.2599 - accuracy: 0.4450 - val_loss: 1.3521 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.29555\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.37255\n",
            "Epoch 4/30\n",
            "30/30 [==============================] - 22s 746ms/step - loss: 1.2901 - accuracy: 0.3929 - val_loss: 1.4040 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.29555\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.37255\n",
            "Epoch 5/30\n",
            "30/30 [==============================] - 22s 741ms/step - loss: 1.2317 - accuracy: 0.4270 - val_loss: 1.2152 - val_accuracy: 0.3922\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.29555 to 1.21515, saving model to EMODB//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.37255 to 0.39216, saving model to EMODB//models/paper_2_acc.h5\n",
            "Epoch 6/30\n",
            "30/30 [==============================] - 22s 741ms/step - loss: 1.3176 - accuracy: 0.4560 - val_loss: 1.4007 - val_accuracy: 0.2745\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.21515\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.39216\n",
            "Epoch 7/30\n",
            "30/30 [==============================] - 22s 742ms/step - loss: 1.3317 - accuracy: 0.3666 - val_loss: 1.3515 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.21515\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.39216\n",
            "Epoch 8/30\n",
            "30/30 [==============================] - 22s 741ms/step - loss: 1.3379 - accuracy: 0.3868 - val_loss: 1.2870 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.21515\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.39216\n",
            "Epoch 9/30\n",
            "30/30 [==============================] - 22s 741ms/step - loss: 1.1983 - accuracy: 0.3909 - val_loss: 1.4150 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.21515\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.39216\n",
            "Epoch 10/30\n",
            "30/30 [==============================] - 22s 740ms/step - loss: 1.2824 - accuracy: 0.4256 - val_loss: 1.3178 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.21515\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.39216\n",
            "Epoch 11/30\n",
            "30/30 [==============================] - 22s 742ms/step - loss: 1.2895 - accuracy: 0.3929 - val_loss: 1.6350 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.21515\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.39216\n",
            "Epoch 12/30\n",
            "30/30 [==============================] - 22s 743ms/step - loss: 1.2000 - accuracy: 0.4290 - val_loss: 1.3521 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.21515\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.39216\n",
            "Epoch 13/30\n",
            "30/30 [==============================] - 22s 744ms/step - loss: 1.2835 - accuracy: 0.4304 - val_loss: 1.2883 - val_accuracy: 0.3725\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.21515\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.39216\n",
            "Epoch 14/30\n",
            "30/30 [==============================] - 22s 744ms/step - loss: 1.1342 - accuracy: 0.5086 - val_loss: 1.2435 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.21515\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.39216\n",
            "Epoch 15/30\n",
            "30/30 [==============================] - 22s 744ms/step - loss: 1.1985 - accuracy: 0.4083 - val_loss: 1.2531 - val_accuracy: 0.3725\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.21515\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.39216\n",
            "Epoch 16/30\n",
            "30/30 [==============================] - 22s 742ms/step - loss: 1.2332 - accuracy: 0.3693 - val_loss: 1.3925 - val_accuracy: 0.2745\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.21515\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.39216\n",
            "Epoch 17/30\n",
            "30/30 [==============================] - 22s 744ms/step - loss: 1.1707 - accuracy: 0.4719 - val_loss: 1.8306 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.21515\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.39216\n",
            "Epoch 18/30\n",
            "30/30 [==============================] - 22s 742ms/step - loss: 1.1032 - accuracy: 0.5290 - val_loss: 1.5652 - val_accuracy: 0.2941\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.21515\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.39216\n",
            "Epoch 19/30\n",
            "30/30 [==============================] - 22s 743ms/step - loss: 1.1551 - accuracy: 0.5090 - val_loss: 1.2107 - val_accuracy: 0.5098\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.21515 to 1.21075, saving model to EMODB//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.39216 to 0.50980, saving model to EMODB//models/paper_2_acc.h5\n",
            "Epoch 20/30\n",
            "30/30 [==============================] - 22s 744ms/step - loss: 1.0040 - accuracy: 0.5719 - val_loss: 1.2672 - val_accuracy: 0.4118\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.21075\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.50980\n",
            "Epoch 21/30\n",
            "30/30 [==============================] - 22s 744ms/step - loss: 1.0651 - accuracy: 0.5343 - val_loss: 1.4001 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.21075\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.50980\n",
            "Epoch 22/30\n",
            "30/30 [==============================] - 22s 739ms/step - loss: 1.0465 - accuracy: 0.5735 - val_loss: 1.7185 - val_accuracy: 0.3922\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.21075\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.50980\n",
            "Epoch 23/30\n",
            "30/30 [==============================] - 22s 743ms/step - loss: 1.0183 - accuracy: 0.5258 - val_loss: 0.9932 - val_accuracy: 0.5490\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.21075 to 0.99324, saving model to EMODB//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.50980 to 0.54902, saving model to EMODB//models/paper_2_acc.h5\n",
            "Epoch 24/30\n",
            "30/30 [==============================] - 22s 740ms/step - loss: 1.0786 - accuracy: 0.5463 - val_loss: 1.1538 - val_accuracy: 0.4706\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.99324\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.54902\n",
            "Epoch 25/30\n",
            "30/30 [==============================] - 22s 740ms/step - loss: 0.9971 - accuracy: 0.5890 - val_loss: 0.9794 - val_accuracy: 0.5686\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.99324 to 0.97940, saving model to EMODB//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.54902 to 0.56863, saving model to EMODB//models/paper_2_acc.h5\n",
            "Epoch 26/30\n",
            "30/30 [==============================] - 22s 739ms/step - loss: 1.1427 - accuracy: 0.4826 - val_loss: 2.0085 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.97940\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.56863\n",
            "Epoch 27/30\n",
            "30/30 [==============================] - 22s 740ms/step - loss: 1.0072 - accuracy: 0.5632 - val_loss: 2.1346 - val_accuracy: 0.3725\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.97940\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.56863\n",
            "Epoch 28/30\n",
            "30/30 [==============================] - 22s 741ms/step - loss: 0.9909 - accuracy: 0.5927 - val_loss: 1.9355 - val_accuracy: 0.2745\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.97940\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.56863\n",
            "Epoch 29/30\n",
            "30/30 [==============================] - 22s 740ms/step - loss: 0.9031 - accuracy: 0.6277 - val_loss: 0.8598 - val_accuracy: 0.5490\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.97940 to 0.85985, saving model to EMODB//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.56863\n",
            "Epoch 30/30\n",
            "30/30 [==============================] - 22s 740ms/step - loss: 0.8092 - accuracy: 0.6136 - val_loss: 0.7146 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.85985 to 0.71465, saving model to EMODB//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.56863 to 0.66667, saving model to EMODB//models/paper_2_acc.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVxLMNYlUbGm",
        "outputId": "51ee6ca5-75b5-4832-df55-f8f2a48d4d77"
      },
      "source": [
        "p2.load_weights('EMODB//models//paper_2_acc.h5')\n",
        "print(p2.evaluate(X_test_spec,Y_test_spec))\n",
        "p2.load_weights('EMODB//models//paper_2_loss.h5')\n",
        "p2.evaluate(X_test_spec,Y_test_spec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 2s 869ms/step - loss: 0.9880 - accuracy: 0.6000\n",
            "[0.9880372881889343, 0.6000000238418579]\n",
            "2/2 [==============================] - 1s 385ms/step - loss: 0.9880 - accuracy: 0.6000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9880372881889343, 0.6000000238418579]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "oKqp7taFSH8i",
        "outputId": "6a0d6418-b89a-4e3c-ec54-0d74bd43d0d4"
      },
      "source": [
        "#test set\n",
        "\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p2.predict(X_test_spec),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p2.predict(X_test_spec),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 SCORE: 0.4220034351613299\n",
            "Kappa: 0.3638676844783715\n",
            "Accuracy: 0.6\n",
            "Jaccard Score: 0.30567226890756305\n",
            "Precision: 0.5207792207792208\n",
            "Recall: 0.43863636363636366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0d37fcf410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyOtWaokW6vk",
        "outputId": "f55a4b2b-8548-48f1-a000-6622b524ea98"
      },
      "source": [
        "0import keras\n",
        "def AlexNet(input_shape):\n",
        "    \n",
        "    X_input = Input(input_shape)\n",
        "    \n",
        "    X = Conv2D(96,(11,11),strides = 4,name=\"conv0\")(X_input)\n",
        "    X = BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
        "    \n",
        "    X = Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3 ,name='bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max2')(X)\n",
        "    \n",
        "    X = Flatten()(X)\n",
        "    \n",
        "    X = Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
        "    \n",
        "    X = Dense(4096, activation = 'relu', name = 'fc1')(X) \n",
        "    \n",
        "    \n",
        "    model = Model(inputs = X_input, outputs = X, name='AlexNet')\n",
        "\n",
        "    return model\n",
        "\n",
        "def paper_2():\n",
        "    input_layer = Input((int(max_y/T)+1,max_x,T,3))\n",
        "    alex = AlexNet((227,227,3))\n",
        "    \n",
        "    for i in range(int(max_y/T)+1):\n",
        "      #print(input_layer[:,0,:,:,:].shape)\n",
        "      inp = keras.layers.experimental.preprocessing.Resizing(227,227)(input_layer[:,i,:,:,:])\n",
        "      \n",
        "      cnn = alex(inp)\n",
        "      cnn = Reshape((1,4096))(cnn)\n",
        "      if i == 0:\n",
        "        output_layers = cnn\n",
        "      else:\n",
        "        output_layers = Concatenate(axis = 1)([output_layers,cnn])\n",
        "      \n",
        "    \n",
        "    #print(len(output_layers))\n",
        "    lstm = LSTM(512,return_sequences=True)(output_layers)\n",
        "    lstm = LSTM(512,return_sequences=True)(lstm)\n",
        "    lstm = LSTM(512)(lstm)\n",
        "    \n",
        "    out = Dense(4,activation='softmax')(lstm)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return Model(inputs=input_layer,outputs=out)\n",
        "p2 = paper_2()\n",
        "p2.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 12, 64, 80,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_39 (Sl (None, 64, 80, 3)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_40 (Sl (None, 64, 80, 3)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_39 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_39[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "resizing_40 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_40[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_41 (Sl (None, 64, 80, 3)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "AlexNet (Functional)            (None, 4096)         58286848    resizing_39[0][0]                \n",
            "                                                                 resizing_40[0][0]                \n",
            "                                                                 resizing_41[0][0]                \n",
            "                                                                 resizing_42[0][0]                \n",
            "                                                                 resizing_43[0][0]                \n",
            "                                                                 resizing_44[0][0]                \n",
            "                                                                 resizing_45[0][0]                \n",
            "                                                                 resizing_46[0][0]                \n",
            "                                                                 resizing_47[0][0]                \n",
            "                                                                 resizing_48[0][0]                \n",
            "                                                                 resizing_49[0][0]                \n",
            "                                                                 resizing_50[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "resizing_41 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_41[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_42 (Sl (None, 64, 80, 3)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_39 (Reshape)            (None, 1, 4096)      0           AlexNet[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_40 (Reshape)            (None, 1, 4096)      0           AlexNet[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_42 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_42[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_43 (Sl (None, 64, 80, 3)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 2, 4096)      0           reshape_39[0][0]                 \n",
            "                                                                 reshape_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_41 (Reshape)            (None, 1, 4096)      0           AlexNet[2][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_43 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_43[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_44 (Sl (None, 64, 80, 3)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 3, 4096)      0           concatenate_36[0][0]             \n",
            "                                                                 reshape_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_42 (Reshape)            (None, 1, 4096)      0           AlexNet[3][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_44 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_44[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_45 (Sl (None, 64, 80, 3)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 4, 4096)      0           concatenate_37[0][0]             \n",
            "                                                                 reshape_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_43 (Reshape)            (None, 1, 4096)      0           AlexNet[4][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_45 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_45[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_46 (Sl (None, 64, 80, 3)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 5, 4096)      0           concatenate_38[0][0]             \n",
            "                                                                 reshape_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_44 (Reshape)            (None, 1, 4096)      0           AlexNet[5][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_46 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_46[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_47 (Sl (None, 64, 80, 3)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 6, 4096)      0           concatenate_39[0][0]             \n",
            "                                                                 reshape_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_45 (Reshape)            (None, 1, 4096)      0           AlexNet[6][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_47 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_47[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_48 (Sl (None, 64, 80, 3)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 7, 4096)      0           concatenate_40[0][0]             \n",
            "                                                                 reshape_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_46 (Reshape)            (None, 1, 4096)      0           AlexNet[7][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_48 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_48[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_49 (Sl (None, 64, 80, 3)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 8, 4096)      0           concatenate_41[0][0]             \n",
            "                                                                 reshape_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_47 (Reshape)            (None, 1, 4096)      0           AlexNet[8][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_49 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_49[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_50 (Sl (None, 64, 80, 3)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 9, 4096)      0           concatenate_42[0][0]             \n",
            "                                                                 reshape_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_48 (Reshape)            (None, 1, 4096)      0           AlexNet[9][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_50 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_50[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 10, 4096)     0           concatenate_43[0][0]             \n",
            "                                                                 reshape_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_49 (Reshape)            (None, 1, 4096)      0           AlexNet[10][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 11, 4096)     0           concatenate_44[0][0]             \n",
            "                                                                 reshape_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_50 (Reshape)            (None, 1, 4096)      0           AlexNet[11][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 12, 4096)     0           concatenate_45[0][0]             \n",
            "                                                                 reshape_50[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   (None, 12, 512)      9439232     concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   (None, 12, 512)      2099200     lstm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 512)          2099200     lstm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4)            2052        lstm_7[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 71,926,532\n",
            "Trainable params: 71,923,780\n",
            "Non-trainable params: 2,752\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F47S50E5jr9E",
        "outputId": "e8037a44-8588-4844-d4bd-2e5e4f55c45c"
      },
      "source": [
        "p2.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMODB//models//paper_2_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMODB//models//paper_2_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = p2.fit(X_train_spec,Y_train_spec, batch_size=8,validation_data=(X_val_spec, Y_val_spec),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "30/30 [==============================] - 30s 672ms/step - loss: 1.8033 - accuracy: 0.2942 - val_loss: 1.4189 - val_accuracy: 0.2353\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.41886, saving model to EMODB//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.23529, saving model to EMODB//models/paper_2_acc.h5\n",
            "Epoch 2/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3838 - accuracy: 0.3058 - val_loss: 1.4771 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.23529 to 0.25490, saving model to EMODB//models/paper_2_acc.h5\n",
            "Epoch 3/30\n",
            "30/30 [==============================] - 18s 591ms/step - loss: 1.3811 - accuracy: 0.3681 - val_loss: 1.4774 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.25490\n",
            "Epoch 4/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3262 - accuracy: 0.4206 - val_loss: 1.4253 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.25490\n",
            "Epoch 5/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3419 - accuracy: 0.3857 - val_loss: 1.4489 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.25490\n",
            "Epoch 6/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3146 - accuracy: 0.4431 - val_loss: 1.4199 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.25490\n",
            "Epoch 7/30\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 1.3453 - accuracy: 0.3988 - val_loss: 1.4790 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.25490\n",
            "Epoch 8/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3333 - accuracy: 0.4156 - val_loss: 1.4282 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.25490\n",
            "Epoch 9/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3468 - accuracy: 0.3963 - val_loss: 1.4412 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.25490\n",
            "Epoch 10/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3554 - accuracy: 0.3544 - val_loss: 1.4600 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.25490\n",
            "Epoch 11/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3790 - accuracy: 0.3311 - val_loss: 1.4398 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.25490\n",
            "Epoch 12/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3065 - accuracy: 0.4541 - val_loss: 1.4333 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.25490\n",
            "Epoch 13/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3137 - accuracy: 0.4557 - val_loss: 1.4339 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.25490\n",
            "Epoch 14/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3531 - accuracy: 0.3577 - val_loss: 1.4434 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.25490\n",
            "Epoch 15/30\n",
            "30/30 [==============================] - 18s 588ms/step - loss: 1.3666 - accuracy: 0.3468 - val_loss: 1.4492 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.25490\n",
            "Epoch 16/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3075 - accuracy: 0.4276 - val_loss: 1.4331 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.25490\n",
            "Epoch 17/30\n",
            "30/30 [==============================] - 18s 590ms/step - loss: 1.3521 - accuracy: 0.3681 - val_loss: 1.4302 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.25490\n",
            "Epoch 18/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3418 - accuracy: 0.3772 - val_loss: 1.4623 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.25490\n",
            "Epoch 19/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3509 - accuracy: 0.3781 - val_loss: 1.4325 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.25490\n",
            "Epoch 20/30\n",
            "30/30 [==============================] - 18s 587ms/step - loss: 1.3145 - accuracy: 0.4085 - val_loss: 1.4450 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.41886\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.25490\n",
            "Epoch 21/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3177 - accuracy: 0.4534 - val_loss: 1.4129 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.41886 to 1.41295, saving model to EMODB//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.25490\n",
            "Epoch 22/30\n",
            "30/30 [==============================] - 18s 591ms/step - loss: 1.3295 - accuracy: 0.4157 - val_loss: 1.4465 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.41295\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.25490\n",
            "Epoch 23/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3619 - accuracy: 0.3707 - val_loss: 1.4422 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.41295\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.25490\n",
            "Epoch 24/30\n",
            "30/30 [==============================] - 18s 590ms/step - loss: 1.3193 - accuracy: 0.4351 - val_loss: 1.4431 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.41295\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.25490\n",
            "Epoch 25/30\n",
            "30/30 [==============================] - 18s 590ms/step - loss: 1.3529 - accuracy: 0.3469 - val_loss: 1.4366 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.41295\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.25490\n",
            "Epoch 26/30\n",
            "30/30 [==============================] - 18s 590ms/step - loss: 1.3533 - accuracy: 0.3705 - val_loss: 1.4456 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.41295\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.25490\n",
            "Epoch 27/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3134 - accuracy: 0.4093 - val_loss: 1.4393 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.41295\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.25490\n",
            "Epoch 28/30\n",
            "30/30 [==============================] - 18s 589ms/step - loss: 1.3294 - accuracy: 0.3908 - val_loss: 1.4417 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.41295\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.25490\n",
            "Epoch 29/30\n",
            "30/30 [==============================] - 18s 590ms/step - loss: 1.3282 - accuracy: 0.4047 - val_loss: 1.4376 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.41295\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.25490\n",
            "Epoch 30/30\n",
            "30/30 [==============================] - 18s 590ms/step - loss: 1.3453 - accuracy: 0.3726 - val_loss: 1.4404 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.41295\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.25490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX0jJuTE5iWa"
      },
      "source": [
        "# Paper 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS5MhTKtjuyT",
        "outputId": "57148c2a-58c3-4e04-deea-4f6b419b8df8"
      },
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data (237, 64000, 1) (237, 4)\n",
            "Test Data (50, 64000, 1) (50, 4)\n",
            "Val Data (51, 64000, 1) (51, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRZdCIrE5oUQ",
        "outputId": "c114e975-31c4-4244-81b2-bde0d5267132"
      },
      "source": [
        "def paper_3():\n",
        "  inp =  Input((time*16000,1))\n",
        "  l1 = Conv1D(64,80,strides = 4,padding = 'same')(inp)\n",
        "  m1 = MaxPooling1D(4)(l1)\n",
        "\n",
        "  l2 = Conv1D(128,3,strides = 1,padding = 'same')(m1)\n",
        "  l2 = Conv1D(128,3,strides = 1,padding = 'same')(l2)\n",
        "  m2 = MaxPooling1D(4)(l2)\n",
        "\n",
        "  l3 = Conv1D(256,3,strides = 1,padding = 'same')(m2)\n",
        "  l3 = Conv1D(256,3,strides = 1,padding = 'same')(l3)\n",
        "  m3 = MaxPooling1D(4)(l3)\n",
        "\n",
        "  l4 = Conv1D(512,3,strides = 1,padding = 'same')(m3)\n",
        "  l4 = Conv1D(512,3,strides = 1,padding = 'same')(l4)\n",
        "  m4 = GlobalAveragePooling1D()(l4)\n",
        "\n",
        "  f1 = Dense(1024)(m4)\n",
        "  f2 = Dense(4, activation='softmax')(f1)\n",
        "\n",
        "  return Model(inputs= inp,outputs=f2)\n",
        "\n",
        "p3 = paper_3()\n",
        "p3.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 64000, 1)]        0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 16000, 64)         5184      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 4000, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 4000, 128)         24704     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 4000, 128)         49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 1000, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 1000, 256)         98560     \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 1000, 256)         196864    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 250, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 250, 512)          393728    \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 250, 512)          786944    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 4100      \n",
            "=================================================================\n",
            "Total params: 2,084,676\n",
            "Trainable params: 2,084,676\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRHASkDF7F-Y",
        "outputId": "3f763a40-8e2d-4a11-9c14-d6faa15cf563"
      },
      "source": [
        "p3.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMODB//models//paper_3_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMODB//models//paper_3_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = p3.fit(X_train,Y_train, batch_size=8,validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "30/30 [==============================] - 34s 45ms/step - loss: 1.4008 - accuracy: 0.3656 - val_loss: 1.2707 - val_accuracy: 0.4118\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.27066, saving model to EMODB//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.41176, saving model to EMODB//models/paper_3_acc.h5\n",
            "Epoch 2/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.9869 - accuracy: 0.5252 - val_loss: 0.7496 - val_accuracy: 0.5490\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.27066 to 0.74961, saving model to EMODB//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.41176 to 0.54902, saving model to EMODB//models/paper_3_acc.h5\n",
            "Epoch 3/30\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.6952 - accuracy: 0.6893 - val_loss: 0.7737 - val_accuracy: 0.5882\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.74961\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.54902 to 0.58824, saving model to EMODB//models/paper_3_acc.h5\n",
            "Epoch 4/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.8114 - accuracy: 0.5762 - val_loss: 0.6890 - val_accuracy: 0.5882\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.74961 to 0.68897, saving model to EMODB//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.58824\n",
            "Epoch 5/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.7541 - accuracy: 0.6216 - val_loss: 0.8107 - val_accuracy: 0.6078\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.68897\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.58824 to 0.60784, saving model to EMODB//models/paper_3_acc.h5\n",
            "Epoch 6/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.8511 - accuracy: 0.4987 - val_loss: 1.2596 - val_accuracy: 0.4902\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.68897\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.60784\n",
            "Epoch 7/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.7818 - accuracy: 0.6890 - val_loss: 0.7605 - val_accuracy: 0.6078\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.68897\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.60784\n",
            "Epoch 8/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.6384 - accuracy: 0.7456 - val_loss: 0.5922 - val_accuracy: 0.6471\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.68897 to 0.59215, saving model to EMODB//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.60784 to 0.64706, saving model to EMODB//models/paper_3_acc.h5\n",
            "Epoch 9/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.6130 - accuracy: 0.7143 - val_loss: 0.7077 - val_accuracy: 0.6078\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.59215\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.64706\n",
            "Epoch 10/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.6304 - accuracy: 0.7057 - val_loss: 0.7981 - val_accuracy: 0.5686\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.59215\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.64706\n",
            "Epoch 11/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.6217 - accuracy: 0.6664 - val_loss: 0.6089 - val_accuracy: 0.7647\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.59215\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.64706 to 0.76471, saving model to EMODB//models/paper_3_acc.h5\n",
            "Epoch 12/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.5958 - accuracy: 0.7606 - val_loss: 0.7735 - val_accuracy: 0.6078\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.59215\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.76471\n",
            "Epoch 13/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.9302 - accuracy: 0.5456 - val_loss: 1.2334 - val_accuracy: 0.4902\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.59215\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.76471\n",
            "Epoch 14/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.8911 - accuracy: 0.6672 - val_loss: 2.2814 - val_accuracy: 0.4902\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.59215\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.76471\n",
            "Epoch 15/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.9493 - accuracy: 0.6218 - val_loss: 0.6631 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.59215\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.76471\n",
            "Epoch 16/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.5857 - accuracy: 0.7212 - val_loss: 0.5852 - val_accuracy: 0.6471\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.59215 to 0.58522, saving model to EMODB//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.76471\n",
            "Epoch 17/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.5855 - accuracy: 0.7076 - val_loss: 0.5351 - val_accuracy: 0.7255\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.58522 to 0.53505, saving model to EMODB//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.76471\n",
            "Epoch 18/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.5620 - accuracy: 0.7780 - val_loss: 0.7755 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.53505\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.76471\n",
            "Epoch 19/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.7071 - accuracy: 0.6672 - val_loss: 0.6425 - val_accuracy: 0.6275\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.53505\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.76471\n",
            "Epoch 20/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.5395 - accuracy: 0.7511 - val_loss: 0.6191 - val_accuracy: 0.6863\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.53505\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.76471\n",
            "Epoch 21/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.5432 - accuracy: 0.7685 - val_loss: 0.5853 - val_accuracy: 0.7255\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.53505\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.76471\n",
            "Epoch 22/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.6621 - accuracy: 0.6450 - val_loss: 0.6176 - val_accuracy: 0.6471\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.53505\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.76471\n",
            "Epoch 23/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.5662 - accuracy: 0.7222 - val_loss: 0.6064 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.53505\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.76471\n",
            "Epoch 24/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.5077 - accuracy: 0.7764 - val_loss: 0.5905 - val_accuracy: 0.6863\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.53505\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.76471\n",
            "Epoch 25/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.6573 - accuracy: 0.6946 - val_loss: 0.5805 - val_accuracy: 0.7255\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.53505\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.76471\n",
            "Epoch 26/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.5411 - accuracy: 0.7359 - val_loss: 0.5634 - val_accuracy: 0.6863\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.53505\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.76471\n",
            "Epoch 27/30\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.6177 - accuracy: 0.6901 - val_loss: 1.0460 - val_accuracy: 0.5490\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.53505\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.76471\n",
            "Epoch 28/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.7455 - accuracy: 0.6029 - val_loss: 0.6228 - val_accuracy: 0.6863\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.53505\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.76471\n",
            "Epoch 29/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.5880 - accuracy: 0.6708 - val_loss: 0.7481 - val_accuracy: 0.5882\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.53505\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.76471\n",
            "Epoch 30/30\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.7691 - accuracy: 0.6557 - val_loss: 1.2200 - val_accuracy: 0.4902\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.53505\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.76471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZkRM_F37xVp",
        "outputId": "910ae845-bd08-4034-a247-a6e29ac44f11"
      },
      "source": [
        "p3.load_weights('EMODB//models//paper_3_loss.h5')\n",
        "print(p3.evaluate(X_test,Y_test))\n",
        "p3.load_weights('EMODB//models//paper_3_loss.h5')\n",
        "p3.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 165ms/step - loss: 0.5084 - accuracy: 0.8200\n",
            "[0.5083817839622498, 0.8199999928474426]\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5084 - accuracy: 0.8200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5083817839622498, 0.8199999928474426]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "ZnSwJteq7afA",
        "outputId": "fd317c52-fa02-47e1-dbd1-bdb260542566"
      },
      "source": [
        "\n",
        "\n",
        "p3.evaluate(X_test,Y_test)\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(p3.predict(X_test).reshape(Y_test.shape[0],4),axis = -1)\n",
        "print(g.shape,p.shape)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(p3.predict(X_test).reshape(Y_test.shape[0],4),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5084 - accuracy: 0.8200\n",
            "(50,) (50,)\n",
            "F1 SCORE: 0.7866838539035335\n",
            "Kappa: 0.7421203438395416\n",
            "Accuracy: 0.82\n",
            "Jaccard Score: 0.6641258741258742\n",
            "Precision: 0.7893217893217893\n",
            "Recall: 0.7860389610389611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f579018c450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipEdzkKS_BQQ"
      },
      "source": [
        "# Paper_4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peviIzX70VWW",
        "outputId": "49b9b59b-ea3a-43ac-b4b7-3b97f02d5988"
      },
      "source": [
        "!pip install Signal_Analysis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Signal_Analysis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/77/f395f3d5a70394de295889b70551497852787e19f4cf5940fa9709151497/Signal_Analysis-0.1.26.tar.gz (378kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from Signal_Analysis) (1.19.5)\n",
            "Collecting peakutils\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/11/6416c8aebba4d5f73e23e1f070a419a8944f3ba17eed9efdf9cdc95f0411/PeakUtils-1.3.3-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from peakutils->Signal_Analysis) (1.4.1)\n",
            "Building wheels for collected packages: Signal-Analysis\n",
            "  Building wheel for Signal-Analysis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Signal-Analysis: filename=Signal_Analysis-0.1.26-cp37-none-any.whl size=14538 sha256=7566079332a7bddd40555b6c2eed8c6d5cee5bd2356718e428a81ff99e8177c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/06/bb/04aa9ef50b93b5961b9817600ca1ff379f7091e63e09831655\n",
            "Successfully built Signal-Analysis\n",
            "Installing collected packages: peakutils, Signal-Analysis\n",
            "Successfully installed Signal-Analysis-0.1.26 peakutils-1.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viP5GxeAOMln"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import ast\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "# Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Sound Processing\n",
        "import librosa\n",
        "from Signal_Analysis.features.signal import get_F_0, get_HNR\n",
        "\n",
        "# Training Data Preparation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from kapre.utils import Normalization2D\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import IPython.display as ipd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZtldtoW4TZV"
      },
      "source": [
        "NUM_EMOTIONS = 4\n",
        "N_FFT = 4096\n",
        "HOP_LENGTH = 1024\n",
        "EMOTIONS = ['ang', 'hap', 'neu', 'sad']\n",
        "SR = 16000\n",
        "\n",
        "\n",
        "def extract_HSF(lld):\n",
        "    mean_val = lld.mean()\n",
        "    min_val = lld.min()\n",
        "    max_val = lld.max()\n",
        "    var_val = lld.var()\n",
        "    range_val = np.subtract(max_val, min_val)\n",
        "    q25_val = np.quantile(lld, 0.25)\n",
        "    q50_val = np.quantile(lld, 0.5)\n",
        "    q75_val = np.quantile(lld, 0.75)\n",
        "    return np.asarray([\n",
        "        mean_val,\n",
        "        min_val,\n",
        "        max_val,\n",
        "        var_val,\n",
        "        range_val,\n",
        "        q25_val,\n",
        "        q50_val,\n",
        "        q75_val,\n",
        "    ])\n",
        "\n",
        "def extract_LLD_from_subaudio(subaudio, fs):\n",
        "    # Frame-wise energy\n",
        "    energy_val = np.sum(np.square(subaudio)) / (subaudio.shape[0] / fs + 0.00000000000001)\n",
        "    \n",
        "    # Frame-wise Zero Crossing Rate\n",
        "    zcr_val = np.sum((subaudio[:-1] * subaudio[1:]) < 0)\n",
        "    \n",
        "    return np.asarray([\n",
        "        energy_val,\n",
        "        zcr_val,\n",
        "    ])\n",
        "\n",
        "def extract_LLD_from_audio(audio, fs):\n",
        "    # MFCC\n",
        "    mfcc = librosa.feature.mfcc(audio, fs, n_fft = N_FFT, hop_length = HOP_LENGTH, center = False).transpose()\n",
        "    mfcc_hsf = extract_HSF(mfcc)\n",
        "    \n",
        "    # LPC\n",
        "    lpc = librosa.lpc(audio, 16)\n",
        "    \n",
        "    # Mel-Spectrogram\n",
        "    spect = librosa.feature.melspectrogram(y = audio, sr = fs, n_fft = N_FFT, hop_length = HOP_LENGTH, center = False)\n",
        "    spect = librosa.power_to_db(spect, ref = np.max).transpose()\n",
        "    spect_hsf = extract_HSF(spect)\n",
        "    \n",
        "    # Other features\n",
        "    f0 = get_F_0(audio, fs)[0]\n",
        "    hnr = get_HNR(audio, fs)\n",
        "    \n",
        "    return np.asarray(mfcc), np.asarray(mfcc_hsf), np.asarray(lpc), np.asarray(spect), np.asarray(spect_hsf), np.asarray([f0, hnr])\n",
        "\n",
        "def extract_LLD(audio, fs):\n",
        "    #print(audio.shape)\n",
        "    #print(int((audio.shape[0] - N_FFT) // HOP_LENGTH) + 1)\n",
        "    num_windows = int((audio.shape[0] - N_FFT) // HOP_LENGTH) + 1\n",
        "    framewise_lld = np.zeros((num_windows, 2))\n",
        "    for idx in range(num_windows):\n",
        "        subaudio = audio[int(idx * HOP_LENGTH): int(idx * HOP_LENGTH + N_FFT)]\n",
        "        framewise_lld[idx, :] = extract_LLD_from_subaudio(subaudio, fs)\n",
        "    framewise_lld_hsf = extract_HSF(framewise_lld)\n",
        "    \n",
        "    mfcc, mfcc_hsf, lpc, spect, spect_hsf, others = extract_LLD_from_audio(audio, fs)\n",
        "    \n",
        "    assert(framewise_lld.shape[0] == mfcc.shape[0])\n",
        "    assert(mfcc.shape[0] == spect.shape[0])\n",
        "\n",
        "    rnn_feats = np.concatenate((framewise_lld, mfcc, spect), axis = 1)\n",
        "    dense_feats = np.concatenate((framewise_lld_hsf, mfcc_hsf, lpc, spect_hsf, others))\n",
        "    return rnn_feats, dense_feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-Eo4siY4cXG",
        "outputId": "d04a65a6-58b8-430d-d4d7-cada2ffb1bde"
      },
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "  X = []\n",
        "  Y = []\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "    y = librosa.load(row['path'], mono=True, duration = 30,sr = SR)[0]\n",
        "    y = librosa.util.fix_length(y,4*SR)\n",
        "    rnn_feats, dense_feats = extract_LLD(y, SR)\n",
        "    X.append(rnn_feats)\n",
        "    Y.append(label_to_onehot(row['labels']))\n",
        "    #print(rnn_feats.shape)\n",
        "\n",
        "  X = np.reshape(np.array(X),(len(Y),X[0].shape[0],X[0].shape[1]))\n",
        "  Y = np.reshape(np.array(Y),(X.shape[0],4))\n",
        "\n",
        "  return X,Y\n",
        "\n",
        "\n",
        "\n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Train Data (237, 59, 150) (237, 4)\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Test Data (50, 59, 150) (50, 4)\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Val Data (51, 59, 150) (51, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0roJeirNRcW"
      },
      "source": [
        "X_train = np.expand_dims(X_train,axis = -1)\n",
        "X_test = np.expand_dims(X_test,axis = -1)\n",
        "X_val = np.expand_dims(X_val,axis = -1)\n",
        "\n",
        "X_train = (X_train - X_train.mean())/X_train.std()\n",
        "X_test = (X_test - X_test.mean())/X_test.std()\n",
        "X_val = (X_val - X_val.mean())/X_val.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWkiHpAOCUkI",
        "outputId": "47e822cd-f5ad-42d4-bc8c-531e98ceedbb"
      },
      "source": [
        "\n",
        "def RNNSpeechModel(no_of_classes, input_size):\n",
        "  \n",
        "  # x = tf.keras.layers.Input((input_len,))\n",
        "  # x = tf.keras.layers.Reshape((1,-1))(x)\n",
        "  # m = Melspectrogram(n_dft=1024, n_hop=128, input_shape=(1, input_len),\n",
        "  #                      padding='same', sr=sr, n_mels=80,\n",
        "  #                      fmin=40.0, fmax=sr / 2, power_melgram=1.0,\n",
        "  #                      return_decibel_melgram=True, trainable_fb=False,\n",
        "  #                      trainable_kernel=False,\n",
        "  #                      name='mel_stft')\n",
        "  # m.trainable = False\n",
        "  # x = m(x)\n",
        "  #x = Normalization2D(int_axis=0)(x)\n",
        "  #x = tf.keras.layers.Permute((2,1,3))(x)\n",
        "\n",
        "  input = tf.keras.layers.Input((input_size))\n",
        "  #Bidirectional RNN\n",
        "  x = tf.keras.layers.Conv2D(10,(5,1),activation='relu',padding = 'same')(input)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2D(1,(5,1),activation='relu', padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Lambda(lambda q: K.squeeze(q, -1))(x)\n",
        "  x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences = 'true'))(x)\n",
        "  #x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences = 'true'))(x)\n",
        "\n",
        "  #Attention unit\n",
        "  xFirst = tf.keras.layers.Lambda(lambda q: q[:,-1])(x)\n",
        "  query = tf.keras.layers.Dense(128)(xFirst)\n",
        "  att_score = tf.keras.layers.Dot(axes=[1,2])([query,x])\n",
        "  att_score = tf.keras.layers.Softmax()(att_score)\n",
        "\n",
        "  #weighted pooling\n",
        "  att_vector = tf.keras.layers.Dot(axes=[1,1])([att_score,x])\n",
        "  #x = tf.keras.layers.Dense(64,activation='relu')(att_vector)\n",
        "  #x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "  output = tf.keras.layers.Dense(no_of_classes,activation='softmax')(att_vector)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs = input,outputs = output)\n",
        "  return model\n",
        "  \n",
        "no_of_classes = 4\n",
        "input_size = X_train[0].shape\n",
        "p4 = RNNSpeechModel(no_of_classes,input_size)\n",
        "p4.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
        "p4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 59, 150, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 59, 150, 10)  60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 59, 150, 10)  40          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 59, 150, 1)   51          batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 59, 150, 1)   4           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 59, 150)      0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 59, 128)      110080      lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          16512       lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dot_2 (Dot)                     (None, 59)           0           dense_2[0][0]                    \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "softmax_1 (Softmax)             (None, 59)           0           dot_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dot_3 (Dot)                     (None, 128)          0           softmax_1[0][0]                  \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 4)            516         dot_3[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 127,263\n",
            "Trainable params: 127,241\n",
            "Non-trainable params: 22\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec9NrpWrTpiD",
        "outputId": "d671388e-2b82-4364-a8dd-753e0865f86c"
      },
      "source": [
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMODB//models//paper_4i_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMODB//models//paper_4i_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "p4.fit(X_train,Y_train, batch_size=8,validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "30/30 [==============================] - 35s 78ms/step - loss: 1.3408 - acc: 0.4099 - val_loss: 1.2944 - val_acc: 0.5882\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.29437, saving model to EMODB//models/paper_4i_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 2/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 1.0564 - acc: 0.5998 - val_loss: 1.1465 - val_acc: 0.4314\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.29437 to 1.14651, saving model to EMODB//models/paper_4i_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 3/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.9206 - acc: 0.6288 - val_loss: 0.9712 - val_acc: 0.6078\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.14651 to 0.97123, saving model to EMODB//models/paper_4i_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 4/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.7359 - acc: 0.7063 - val_loss: 0.8242 - val_acc: 0.6275\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.97123 to 0.82421, saving model to EMODB//models/paper_4i_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 5/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.7235 - acc: 0.7045 - val_loss: 0.8194 - val_acc: 0.6078\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.82421 to 0.81943, saving model to EMODB//models/paper_4i_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 6/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.6705 - acc: 0.7116 - val_loss: 0.7809 - val_acc: 0.6863\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.81943 to 0.78093, saving model to EMODB//models/paper_4i_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 7/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.6254 - acc: 0.7470 - val_loss: 0.8527 - val_acc: 0.5882\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.78093\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 8/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.5919 - acc: 0.7644 - val_loss: 0.8526 - val_acc: 0.6078\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.78093\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 9/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.6069 - acc: 0.7293 - val_loss: 0.9275 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.78093\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 10/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.4351 - acc: 0.8266 - val_loss: 0.9390 - val_acc: 0.6078\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.78093\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 11/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.5103 - acc: 0.7783 - val_loss: 0.8462 - val_acc: 0.6471\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.78093\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 12/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.4682 - acc: 0.8366 - val_loss: 0.8375 - val_acc: 0.6471\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.78093\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 13/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.4873 - acc: 0.7824 - val_loss: 0.7751 - val_acc: 0.7059\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.78093 to 0.77507, saving model to EMODB//models/paper_4i_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 14/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.4165 - acc: 0.8242 - val_loss: 0.8967 - val_acc: 0.5882\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 15/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.3512 - acc: 0.8838 - val_loss: 0.8877 - val_acc: 0.6275\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 16/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.3122 - acc: 0.8962 - val_loss: 0.9449 - val_acc: 0.6078\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 17/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.3086 - acc: 0.8998 - val_loss: 1.0127 - val_acc: 0.6471\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 18/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.2590 - acc: 0.9237 - val_loss: 0.9075 - val_acc: 0.6078\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 19/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.3220 - acc: 0.8610 - val_loss: 0.8016 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 20/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.3062 - acc: 0.9292 - val_loss: 1.0090 - val_acc: 0.7059\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 21/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.2003 - acc: 0.9546 - val_loss: 0.9246 - val_acc: 0.7255\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 22/30\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1579 - acc: 0.9691 - val_loss: 1.2678 - val_acc: 0.6471\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 23/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.3957 - acc: 0.8324 - val_loss: 1.1333 - val_acc: 0.6471\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 24/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.2283 - acc: 0.8833 - val_loss: 0.9736 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 25/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.1332 - acc: 0.9815 - val_loss: 0.8778 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 26/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.0818 - acc: 0.9983 - val_loss: 0.8306 - val_acc: 0.7255\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 27/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.1287 - acc: 0.9446 - val_loss: 0.7992 - val_acc: 0.7255\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 28/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.0680 - acc: 0.9894 - val_loss: 0.8863 - val_acc: 0.7255\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 29/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.0733 - acc: 0.9942 - val_loss: 1.0911 - val_acc: 0.7059\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 30/30\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.0561 - acc: 0.9903 - val_loss: 0.9415 - val_acc: 0.6863\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.77507\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc409572810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3QV7-guUAhs",
        "outputId": "683d3fc0-bf70-4a5c-8b8c-4016f6643fb6"
      },
      "source": [
        "p4.load_weights('EMODB//models//paper_4i_loss.h5')\n",
        "p4.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 63ms/step - loss: 0.6044 - acc: 0.7400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6043654084205627, 0.7400000095367432]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "W-ZPX7pIPRlf",
        "outputId": "b5826a91-1ada-480f-8e88-fc8f547511ed"
      },
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(p4.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(p4.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 SCORE: 0.7020133053221289\n",
            "Kappa: 0.6333897349125774\n",
            "Accuracy: 0.74\n",
            "Jaccard Score: 0.5693589743589744\n",
            "Precision: 0.7244047619047619\n",
            "Recall: 0.7025974025974027\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.77      0.81        22\n",
            "           1       0.33      0.43      0.38         7\n",
            "           2       0.71      0.91      0.80        11\n",
            "           3       1.00      0.70      0.82        10\n",
            "\n",
            "    accuracy                           0.74        50\n",
            "   macro avg       0.72      0.70      0.70        50\n",
            "weighted avg       0.78      0.74      0.75        50\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KtJa_P3yqqh"
      },
      "source": [
        "# paper_5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjILnUgmbgrL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337f8950-6d20-4277-d967-df94a652938c"
      },
      "source": [
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "def extract_mel_spectrogram(df,max_x = 64,max_y = 898):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path']\n",
        " \n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      #print(y.shape)\n",
        "      # Computing the mel spectrograms\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      \n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        " \n",
        "            \n",
        "      \n",
        "      if spect.shape[1] != max_y:\n",
        "                #print('Sizes arent same')\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        "      s=[]\n",
        "      for i in range(0,int((max_y-64)/30),1):\n",
        "        #print(spect[:,i*64:(i+1)*64].shape)\n",
        "        q=spect[:,i*30:64 +i*30]\n",
        "        delta = librosa.feature.delta(q).reshape((max_x,64,1))\n",
        "        d_delta = librosa.feature.delta(q,order = 2).reshape((max_x,64,1))\n",
        "        #print(q.shape,delta.shape,d_delta.shape)\n",
        "        q = q.reshape((max_x,64,1))\n",
        "        z = np.concatenate((q,delta,d_delta),axis = -1)\n",
        "        s.append(z)\n",
        "\n",
        "      mel_specs.append(np.asarray(s))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  #print(len(mel_specs),mel_specs[0].shape)\n",
        "  mel_specs = np.asarray(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        " \n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        " \n",
        " \n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        " \n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(237, 27, 64, 64, 3) (237, 4)\n",
            "(50, 27, 64, 64, 3) (50, 4)\n",
            "(51, 27, 64, 64, 3) (51, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81cNxIXNzJMs",
        "outputId": "43bb8c4b-bd6e-4d18-b1d2-416f2b348db3"
      },
      "source": [
        "import keras\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "def div_L0(num):\n",
        "    [a, b] = div_L1(num)\n",
        "    [c, d, e, f] = div_L2(num)\n",
        "\n",
        "    return [a, b], [c, d, e, f]\n",
        "\n",
        "    \n",
        "def div_L1(num):\n",
        "    a = num // 2\n",
        "    b = num - a\n",
        "    return [a, b]\n",
        "\n",
        "\n",
        "def div_L2(num):\n",
        "    [a, b] = div_L1(num)\n",
        "    [c, d] = div_L1(a)\n",
        "    [e, f] = div_L1(b)\n",
        "\n",
        "    return [c, d, e, f]\n",
        "\n",
        "def lpnorm_pooling(features_Ln):\n",
        "    '''\n",
        "    :param features_Ln:\n",
        "    :param var_p: 1-average pooling, np.inf-max pooling\n",
        "    :return:\n",
        "    '''\n",
        "    var_p = 2.14  # average pooling\n",
        "#   var_p = np.inf  # max pooling\n",
        "    lpnorm = tf.norm(features_Ln,ord=var_p,axis=1)\n",
        "    result = lpnorm * (1/features_Ln.shape[1])**(1/var_p)\n",
        "\n",
        "    #print(result)\n",
        "    result = tf.math.reduce_max(features_Ln,axis = 1)\n",
        "    #result = np.average(features_Ln,axis = 0)\n",
        "    #print(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "def subpart():\n",
        "    \n",
        "    input_layer = Input((227,227,3))\n",
        "\n",
        "    X = keras.layers.experimental.preprocessing.Resizing(227,227)(input_layer)\n",
        "    \n",
        "      \n",
        "    X = Conv2D(96,(11,11),strides = 4,name=\"conv0\")(X)\n",
        "    X = BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
        "    \n",
        "    X = Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3 ,name='bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D(2)(X)\n",
        "    \n",
        "    X = Flatten()(X)\n",
        "    \n",
        "    X = Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
        "    \n",
        "    X = Dense(4096, activation = 'relu', name = 'fc1')(X) \n",
        "\n",
        "    Y = Reshape((1,4096))(X)\n",
        "\n",
        "    return Model(inputs = input_layer,outputs = Y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def paper_2():\n",
        "    input_layer = Input((27,64,64,3))\n",
        "\n",
        "    sp = subpart()\n",
        "\n",
        "    for i in range(input_layer.shape[1]):\n",
        "      #print(input_layer[:,0,:,:,:].shape)\n",
        "      inp = keras.layers.experimental.preprocessing.Resizing(227,227)(input_layer[:,i,:,:,:])\n",
        "      output_layer = sp(inp)\n",
        "\n",
        "      if i == 0:\n",
        "        output_layers = output_layer\n",
        "      else:\n",
        "        output_layers = Concatenate(axis = 1)([output_layers,output_layer])\n",
        "    \n",
        "    print(output_layers.shape)\n",
        "    t,n, d = output_layers.shape\n",
        "    #rint(X.shape)\n",
        "\n",
        "    if n == 3:\n",
        "        features = np.row_stack((X, X[-1]))\n",
        "    if n == 2:\n",
        "        features = np.row_stack((X, X))\n",
        "    if n == 1:\n",
        "        print(n)\n",
        "        features = tf.stack((X, X, X, X),axis =1)\n",
        "\n",
        "    #print(features.shape)\n",
        "    t,n, d = output_layers.shape\n",
        "\n",
        "    [a, b], [c, d, e, f] = div_L0(n)\n",
        "\n",
        "    L0 = lpnorm_pooling(output_layers)\n",
        "    #print(a,b,c,d,e,f, features.shape)\n",
        "    L1_1 = lpnorm_pooling(output_layers[:,:a,:])\n",
        "    #print(features[:,:a,].shape)\n",
        "    L1_2 = lpnorm_pooling(output_layers[:,a:,:])\n",
        "\n",
        "    L2_1 = lpnorm_pooling(output_layers[:,:c,:])\n",
        "    L2_2 = lpnorm_pooling(output_layers[:,c:a,:])\n",
        "    L2_3 = lpnorm_pooling(output_layers[:,a:a+e,:])\n",
        "    L2_4 = lpnorm_pooling(output_layers[:,a+e:,:])\n",
        "\n",
        "    W_L0=1/4;\n",
        "    W_L1=1/4;\n",
        "    W_L2=1/2;\n",
        "\n",
        "    Weights_L = [[W_L0,0,0,0,0,0,0],\n",
        "                 [0,W_L1,0,0,0,0,0],\n",
        "                 [0,0,W_L1,0,0,0,0],\n",
        "                 [0,0,0,W_L2,0,0,0],\n",
        "                 [0,0,0,0,W_L2,0,0],\n",
        "                 [0,0,0,0,0,W_L2,0],\n",
        "                 [0,0,0,0,0,0,W_L2]]\n",
        "\n",
        "    features_Vp = Concatenate(axis =1)([W_L0*L0, W_L1*L1_1, W_L1*L1_2, W_L2*L2_1, W_L2*L2_2, W_L2*L2_3, W_L2*L2_4])\n",
        "\n",
        "    op = Dense(4,activation = 'softmax',kernel_regularizer=keras.regularizers.l2(0.01))(features_Vp)\n",
        "    #features_Up = np.matmul(Weights_L,features_Vp)\n",
        "\n",
        "    return Model(inputs=input_layer,outputs=op)\n",
        "\n",
        "p5 = paper_2()\n",
        "p5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 27, 4096)\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 27, 64, 64,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_46 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_47 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_37 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_46[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "resizing_38 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_47[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_48 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_4 (Functional)            (None, 1, 4096)      58286848    resizing_37[0][0]                \n",
            "                                                                 resizing_38[0][0]                \n",
            "                                                                 resizing_39[0][0]                \n",
            "                                                                 resizing_40[0][0]                \n",
            "                                                                 resizing_41[0][0]                \n",
            "                                                                 resizing_42[0][0]                \n",
            "                                                                 resizing_43[0][0]                \n",
            "                                                                 resizing_44[0][0]                \n",
            "                                                                 resizing_45[0][0]                \n",
            "                                                                 resizing_46[0][0]                \n",
            "                                                                 resizing_47[0][0]                \n",
            "                                                                 resizing_48[0][0]                \n",
            "                                                                 resizing_49[0][0]                \n",
            "                                                                 resizing_50[0][0]                \n",
            "                                                                 resizing_51[0][0]                \n",
            "                                                                 resizing_52[0][0]                \n",
            "                                                                 resizing_53[0][0]                \n",
            "                                                                 resizing_54[0][0]                \n",
            "                                                                 resizing_55[0][0]                \n",
            "                                                                 resizing_56[0][0]                \n",
            "                                                                 resizing_57[0][0]                \n",
            "                                                                 resizing_58[0][0]                \n",
            "                                                                 resizing_59[0][0]                \n",
            "                                                                 resizing_60[0][0]                \n",
            "                                                                 resizing_61[0][0]                \n",
            "                                                                 resizing_62[0][0]                \n",
            "                                                                 resizing_63[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "resizing_39 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_48[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_49 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 2, 4096)      0           model_4[0][0]                    \n",
            "                                                                 model_4[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_40 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_49[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_50 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 3, 4096)      0           concatenate_34[0][0]             \n",
            "                                                                 model_4[2][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_41 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_50[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_51 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 4, 4096)      0           concatenate_35[0][0]             \n",
            "                                                                 model_4[3][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_42 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_51[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_52 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 5, 4096)      0           concatenate_36[0][0]             \n",
            "                                                                 model_4[4][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_43 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_52[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_53 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 6, 4096)      0           concatenate_37[0][0]             \n",
            "                                                                 model_4[5][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_44 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_53[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_54 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 7, 4096)      0           concatenate_38[0][0]             \n",
            "                                                                 model_4[6][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_45 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_54[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_55 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 8, 4096)      0           concatenate_39[0][0]             \n",
            "                                                                 model_4[7][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_46 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_55[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_56 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 9, 4096)      0           concatenate_40[0][0]             \n",
            "                                                                 model_4[8][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_47 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_56[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_57 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 10, 4096)     0           concatenate_41[0][0]             \n",
            "                                                                 model_4[9][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "resizing_48 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_57[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_58 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 11, 4096)     0           concatenate_42[0][0]             \n",
            "                                                                 model_4[10][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_49 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_58[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_59 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 12, 4096)     0           concatenate_43[0][0]             \n",
            "                                                                 model_4[11][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_50 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_59[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_60 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 13, 4096)     0           concatenate_44[0][0]             \n",
            "                                                                 model_4[12][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_51 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_60[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_61 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 14, 4096)     0           concatenate_45[0][0]             \n",
            "                                                                 model_4[13][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_52 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_61[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_62 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 15, 4096)     0           concatenate_46[0][0]             \n",
            "                                                                 model_4[14][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_53 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_62[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_63 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 16, 4096)     0           concatenate_47[0][0]             \n",
            "                                                                 model_4[15][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_54 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_63[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_64 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 17, 4096)     0           concatenate_48[0][0]             \n",
            "                                                                 model_4[16][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_55 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_64[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_65 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 18, 4096)     0           concatenate_49[0][0]             \n",
            "                                                                 model_4[17][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_56 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_65[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_66 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 19, 4096)     0           concatenate_50[0][0]             \n",
            "                                                                 model_4[18][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_57 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_66[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_67 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 20, 4096)     0           concatenate_51[0][0]             \n",
            "                                                                 model_4[19][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_58 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_67[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_68 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 21, 4096)     0           concatenate_52[0][0]             \n",
            "                                                                 model_4[20][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_59 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_68[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_69 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 22, 4096)     0           concatenate_53[0][0]             \n",
            "                                                                 model_4[21][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_60 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_69[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_70 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 23, 4096)     0           concatenate_54[0][0]             \n",
            "                                                                 model_4[22][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_61 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_70[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_71 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 24, 4096)     0           concatenate_55[0][0]             \n",
            "                                                                 model_4[23][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_62 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_71[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_72 (Sl (None, 64, 64, 3)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_57 (Concatenate)    (None, 25, 4096)     0           concatenate_56[0][0]             \n",
            "                                                                 model_4[24][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_63 (Resizing)          (None, 227, 227, 3)  0           tf.__operators__.getitem_72[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "concatenate_58 (Concatenate)    (None, 26, 4096)     0           concatenate_57[0][0]             \n",
            "                                                                 model_4[25][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_59 (Concatenate)    (None, 27, 4096)     0           concatenate_58[0][0]             \n",
            "                                                                 model_4[26][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_73 (Sl (None, 13, 4096)     0           concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_74 (Sl (None, 14, 4096)     0           concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_75 (Sl (None, 6, 4096)      0           concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_76 (Sl (None, 7, 4096)      0           concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_77 (Sl (None, 7, 4096)      0           concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_78 (Sl (None, 7, 4096)      0           concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_14 (TFOpLamb (None, 4096)         0           concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_15 (TFOpLamb (None, 4096)         0           tf.__operators__.getitem_73[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_16 (TFOpLamb (None, 4096)         0           tf.__operators__.getitem_74[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_17 (TFOpLamb (None, 4096)         0           tf.__operators__.getitem_75[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_18 (TFOpLamb (None, 4096)         0           tf.__operators__.getitem_76[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_19 (TFOpLamb (None, 4096)         0           tf.__operators__.getitem_77[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_20 (TFOpLamb (None, 4096)         0           tf.__operators__.getitem_78[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_35 (TFOpLambda (None, 4096)         0           tf.math.reduce_max_14[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_36 (TFOpLambda (None, 4096)         0           tf.math.reduce_max_15[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_37 (TFOpLambda (None, 4096)         0           tf.math.reduce_max_16[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_38 (TFOpLambda (None, 4096)         0           tf.math.reduce_max_17[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_39 (TFOpLambda (None, 4096)         0           tf.math.reduce_max_18[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_40 (TFOpLambda (None, 4096)         0           tf.math.reduce_max_19[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_41 (TFOpLambda (None, 4096)         0           tf.math.reduce_max_20[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_60 (Concatenate)    (None, 28672)        0           tf.math.multiply_35[0][0]        \n",
            "                                                                 tf.math.multiply_36[0][0]        \n",
            "                                                                 tf.math.multiply_37[0][0]        \n",
            "                                                                 tf.math.multiply_38[0][0]        \n",
            "                                                                 tf.math.multiply_39[0][0]        \n",
            "                                                                 tf.math.multiply_40[0][0]        \n",
            "                                                                 tf.math.multiply_41[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4)            114692      concatenate_60[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 58,401,540\n",
            "Trainable params: 58,398,788\n",
            "Non-trainable params: 2,752\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztMUWyRg0wM7",
        "outputId": "c4f80279-9601-4cf3-9190-e1ed37a2c4c4"
      },
      "source": [
        "p5.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMODB//models//paper_5_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMODB//models//paper_5_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = p5.fit(X_train_spec,Y_train_spec, batch_size=8,validation_data=(X_val_spec, Y_val_spec),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "30/30 [==============================] - 26s 589ms/step - loss: 14.6457 - accuracy: 0.2465 - val_loss: 1.3495 - val_accuracy: 0.3725\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.34954, saving model to EMODB//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.37255, saving model to EMODB//models/paper_5_acc.h5\n",
            "Epoch 2/30\n",
            "30/30 [==============================] - 16s 526ms/step - loss: 1.3352 - accuracy: 0.4076 - val_loss: 1.4382 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.34954\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.37255\n",
            "Epoch 3/30\n",
            "30/30 [==============================] - 16s 528ms/step - loss: 1.3690 - accuracy: 0.3956 - val_loss: 1.3443 - val_accuracy: 0.4118\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.34954 to 1.34430, saving model to EMODB//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.37255 to 0.41176, saving model to EMODB//models/paper_5_acc.h5\n",
            "Epoch 4/30\n",
            "30/30 [==============================] - 15s 505ms/step - loss: 1.4062 - accuracy: 0.3706 - val_loss: 1.3453 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.34430\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.41176\n",
            "Epoch 5/30\n",
            "30/30 [==============================] - 16s 520ms/step - loss: 1.4190 - accuracy: 0.3454 - val_loss: 1.2908 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.34430 to 1.29081, saving model to EMODB//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.41176\n",
            "Epoch 6/30\n",
            "30/30 [==============================] - 16s 524ms/step - loss: 1.3317 - accuracy: 0.4517 - val_loss: 1.3710 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.29081\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.41176\n",
            "Epoch 7/30\n",
            "30/30 [==============================] - 15s 516ms/step - loss: 1.3499 - accuracy: 0.4247 - val_loss: 1.3949 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.29081\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.41176\n",
            "Epoch 8/30\n",
            "30/30 [==============================] - 15s 510ms/step - loss: 1.3772 - accuracy: 0.4321 - val_loss: 1.4574 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.29081\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.41176\n",
            "Epoch 9/30\n",
            "30/30 [==============================] - 15s 508ms/step - loss: 1.3211 - accuracy: 0.4653 - val_loss: 1.2808 - val_accuracy: 0.3725\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.29081 to 1.28084, saving model to EMODB//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.41176\n",
            "Epoch 10/30\n",
            "30/30 [==============================] - 15s 506ms/step - loss: 1.2815 - accuracy: 0.4793 - val_loss: 1.3233 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.28084\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.41176\n",
            "Epoch 11/30\n",
            "30/30 [==============================] - 15s 514ms/step - loss: 1.2609 - accuracy: 0.4584 - val_loss: 1.2724 - val_accuracy: 0.3725\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.28084 to 1.27242, saving model to EMODB//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.41176\n",
            "Epoch 12/30\n",
            "30/30 [==============================] - 15s 508ms/step - loss: 1.2441 - accuracy: 0.4508 - val_loss: 1.3835 - val_accuracy: 0.2745\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.27242\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.41176\n",
            "Epoch 13/30\n",
            "30/30 [==============================] - 15s 509ms/step - loss: 1.3273 - accuracy: 0.3998 - val_loss: 1.2704 - val_accuracy: 0.3725\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.27242 to 1.27039, saving model to EMODB//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.41176\n",
            "Epoch 14/30\n",
            "30/30 [==============================] - 15s 507ms/step - loss: 1.3555 - accuracy: 0.3810 - val_loss: 1.4416 - val_accuracy: 0.2941\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.27039\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.41176\n",
            "Epoch 15/30\n",
            "30/30 [==============================] - 15s 507ms/step - loss: 1.3459 - accuracy: 0.4165 - val_loss: 1.3243 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.27039\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.41176\n",
            "Epoch 16/30\n",
            "30/30 [==============================] - 15s 505ms/step - loss: 1.2725 - accuracy: 0.4591 - val_loss: 1.2957 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.27039\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.41176\n",
            "Epoch 17/30\n",
            "30/30 [==============================] - 15s 504ms/step - loss: 1.2848 - accuracy: 0.4351 - val_loss: 1.3670 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.27039\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.41176\n",
            "Epoch 18/30\n",
            "30/30 [==============================] - 15s 501ms/step - loss: 1.2708 - accuracy: 0.4750 - val_loss: 1.3512 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.27039\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.41176\n",
            "Epoch 19/30\n",
            "30/30 [==============================] - 15s 504ms/step - loss: 1.3280 - accuracy: 0.3638 - val_loss: 1.2784 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.27039\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.41176\n",
            "Epoch 20/30\n",
            "30/30 [==============================] - 15s 504ms/step - loss: 1.2675 - accuracy: 0.4386 - val_loss: 1.3036 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.27039\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.41176\n",
            "Epoch 21/30\n",
            "30/30 [==============================] - 15s 504ms/step - loss: 1.2461 - accuracy: 0.3960 - val_loss: 1.2946 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.27039\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.41176\n",
            "Epoch 22/30\n",
            "30/30 [==============================] - 15s 504ms/step - loss: 1.2682 - accuracy: 0.4572 - val_loss: 1.4341 - val_accuracy: 0.2745\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.27039\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.41176\n",
            "Epoch 23/30\n",
            "30/30 [==============================] - 15s 508ms/step - loss: 1.3027 - accuracy: 0.4472 - val_loss: 1.2598 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.27039 to 1.25978, saving model to EMODB//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.41176\n",
            "Epoch 24/30\n",
            "30/30 [==============================] - 15s 507ms/step - loss: 1.2412 - accuracy: 0.4922 - val_loss: 1.3344 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.25978\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.41176\n",
            "Epoch 25/30\n",
            "30/30 [==============================] - 15s 508ms/step - loss: 1.2908 - accuracy: 0.4065 - val_loss: 1.2751 - val_accuracy: 0.3922\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.25978\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.41176\n",
            "Epoch 26/30\n",
            "30/30 [==============================] - 15s 509ms/step - loss: 1.2440 - accuracy: 0.4796 - val_loss: 1.2566 - val_accuracy: 0.3922\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.25978 to 1.25658, saving model to EMODB//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.41176\n",
            "Epoch 27/30\n",
            "30/30 [==============================] - 15s 506ms/step - loss: 1.2863 - accuracy: 0.4359 - val_loss: 1.3664 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.25658\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.41176\n",
            "Epoch 28/30\n",
            "30/30 [==============================] - 15s 508ms/step - loss: 1.2875 - accuracy: 0.4743 - val_loss: 1.4879 - val_accuracy: 0.3137\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.25658\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.41176\n",
            "Epoch 29/30\n",
            "30/30 [==============================] - 15s 506ms/step - loss: 1.2087 - accuracy: 0.4665 - val_loss: 1.4122 - val_accuracy: 0.2745\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.25658\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.41176\n",
            "Epoch 30/30\n",
            "30/30 [==============================] - 15s 505ms/step - loss: 1.2653 - accuracy: 0.4589 - val_loss: 1.2723 - val_accuracy: 0.3529\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.25658\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.41176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYxhCqiP08dU",
        "outputId": "9f2fd0a4-0b9a-4ad4-d1a7-210a99333a1b"
      },
      "source": [
        "p5.load_weights('EMODB//models//paper_5_acc.h5')\n",
        "print(p5.evaluate(X_test_spec,Y_test_spec))\n",
        "p5.load_weights('EMODB//models//paper_5_loss.h5')\n",
        "p5.evaluate(X_test_spec,Y_test_spec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 269ms/step - loss: 1.1365 - accuracy: 0.6000\n",
            "[1.1364706754684448, 0.6000000238418579]\n",
            "2/2 [==============================] - 1s 271ms/step - loss: 1.1289 - accuracy: 0.5600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1289010047912598, 0.5600000023841858]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "Km50ClTQ4AO0",
        "outputId": "787f60f0-d131-468b-b7fa-0d4ce1f74dc1"
      },
      "source": [
        "#test set\n",
        "#p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 SCORE: 0.6644570707070707\n",
            "Kappa: 0.6453900709219859\n",
            "Accuracy: 0.76\n",
            "Jaccard Score: 0.5600288600288601\n",
            "Precision: 0.6837412587412588\n",
            "Recall: 0.6561688311688312\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.95      0.88        22\n",
            "           1       0.20      0.14      0.17         7\n",
            "           2       0.73      0.73      0.73        11\n",
            "           3       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.76        50\n",
            "   macro avg       0.68      0.66      0.66        50\n",
            "weighted avg       0.74      0.76      0.75        50\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGsk6dKAon_l"
      },
      "source": [
        "# paper 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8HvyWTg4MXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d449b590-cfaf-4da6-d89a-5e34269c84c9"
      },
      "source": [
        "max_x = 96\n",
        "max_y = 898\n",
        "T = 64\n",
        "print(max_y,T,(int(max_y/T)+1)*T,int(max_y/T)+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "898 64 960 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFjRtvYDorpq",
        "outputId": "2389f71b-2384-4e8f-868d-f45ff25b9ef8"
      },
      "source": [
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "def extract_mel_spectrogram(df,max_x = max_x,max_y = (int(max_y/T)+1)*T):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path']\n",
        " \n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      #print(y.shape)\n",
        "      # Computing the mel spectrograms\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = max_x)\n",
        "      \n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        " \n",
        "            \n",
        "      \n",
        "      if spect.shape[1] != max_y:\n",
        "                #print('Sizes arent same')\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        "      s=[]\n",
        "      for i in range(int(max_y/T)):\n",
        "        #print(spect[:,i*64:(i+1)*64].shape)\n",
        "        q=spect[:,i*T:(i+1)*T]\n",
        "        delta = librosa.feature.delta(q).reshape((max_x,T,1))\n",
        "        d_delta = librosa.feature.delta(q,order = 2).reshape((max_x,T,1))\n",
        "        #print(q.shape,delta.shape,d_delta.shape)\n",
        "        q = q.reshape((max_x,T,1))\n",
        "\n",
        "        z = np.concatenate((q,delta,d_delta),axis = -1)\n",
        "        #print(z.shape)\n",
        "        s.append(z)\n",
        "      mel_specs.append(np.asarray(s))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  #print(len(mel_specs),mel_specs[0].shape)\n",
        "  mel_specs = np.asarray(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        " \n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "#X_train_spec = np.expand_dims(X_train_spec,axis=-1)\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        " \n",
        " \n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "#X_test_spec = np.expand_dims(X_test_spec,axis=-1)\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        " \n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "#X_val_spec = np.expand_dims(X_val_spec,axis=-1)\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(237, 15, 96, 64, 3) (237, 4)\n",
            "(50, 15, 96, 64, 3) (50, 4)\n",
            "(51, 15, 96, 64, 3) (51, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb8-mrAIo1T_",
        "outputId": "94552b27-4547-4b5f-a6b2-cab7895bb2f9"
      },
      "source": [
        "import keras\n",
        "\n",
        "def VGG_net():\n",
        "  input = Input((96,64,3))\n",
        "  t = Conv2D(64, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(input)\n",
        "  t = Conv2D(64, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = MaxPooling2D(2)(t)\n",
        "\n",
        "  t = Conv2D(128, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(128, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = MaxPooling2D(2)(t)\n",
        "\n",
        "  t = Conv2D(256, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(256, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(256, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(256, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = MaxPooling2D(2)(t)\n",
        "\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = MaxPooling2D(2)(t)\n",
        "\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = MaxPooling2D(2)(t)\n",
        "\n",
        "  t = Flatten()(t)\n",
        "\n",
        "  t = Dense(4096, activation = 'relu')(t)\n",
        "  t = Dense(4096, activation = 'relu')(t)\n",
        "  t = Dense(128, activation = 'relu')(t)\n",
        "\n",
        "  t = Reshape((1,128))(t)\n",
        "\n",
        "  return Model(inputs = input, outputs = t)\n",
        "\n",
        "\n",
        "#change shape\n",
        "def paper_6():\n",
        "  ip = Input((15, 96,64,3))\n",
        "  vgg = VGG_net()\n",
        "\n",
        "  for i in range(ip.shape[1]):\n",
        "    op_layer = vgg(ip[:,i,:,:,:])\n",
        "    if i==0:\n",
        "      op_layers = op_layer\n",
        "    else:\n",
        "      op_layers = Concatenate(axis = 1)([op_layers,op_layer])\n",
        "\n",
        "  lstmb = Bidirectional(LSTM(256,return_sequences=True), merge_mode = 'sum')\n",
        "  t = lstmb(op_layers)  \n",
        "  lstmb2 = Bidirectional(LSTM(256,return_sequences=True), merge_mode = None)\n",
        "  t2 = lstmb2(t)  \n",
        "\n",
        "  h1 = t2[0]\n",
        "  h2 = t2[1]\n",
        "  print(h1.shape, h2.shape)\n",
        "  h1 = Softmax(axis = -1)(h1)\n",
        "  h2 = Softmax(axis =-1)(h2)\n",
        "  \n",
        "\n",
        "  sum1 = tf.keras.backend.sum(axis =1,x = h1)\n",
        "  sum2 = tf.keras.backend.sum(axis =1,x= h2)\n",
        "  sum = Concatenate()([sum1,sum2])\n",
        "  print(sum.shape)\n",
        "\n",
        "  mean1 = sum1/256.\n",
        "  mean2 = sum2/256.\n",
        "  mean = Concatenate()([mean1, mean2])\n",
        "\n",
        "  std1 = tf.keras.backend.std(axis =1, x= h1)\n",
        "  std2 =tf.keras.backend.std(axis =1, x =h2)\n",
        "  std = Concatenate()([std1, std2])\n",
        "\n",
        "  min1 = tf.keras.backend.min(axis =1,x=h1)\n",
        "  min2 = tf.keras.backend.min(axis =1, x=h2)\n",
        "  min = Concatenate()([min1, min2])\n",
        "\n",
        "  max1 = tf.keras.backend.max(axis =1, x=h1)\n",
        "  max2 = tf.keras.backend.max(axis=1, x =h2)\n",
        "  max = Concatenate()([max1,max2])\n",
        "\n",
        "  attention = Concatenate()([sum, mean, std, min, max])\n",
        "  print(attention.shape)\n",
        "\n",
        "  fc1 = Dense(512, activation = 'relu')(attention)\n",
        "  fc2 = Dense(4, activation = 'softmax')(fc1)  \n",
        "\n",
        "\n",
        "  return Model(inputs=ip,outputs=fc2)\n",
        "\n",
        "p6 = paper_6()\n",
        "p6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15, 256) (None, 15, 256)\n",
            "(None, 512)\n",
            "(None, 2560)\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 15, 96, 64,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_1 (Sli (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model (Functional)              (None, 1, 128)       49917120    tf.__operators__.getitem[0][0]   \n",
            "                                                                 tf.__operators__.getitem_1[0][0] \n",
            "                                                                 tf.__operators__.getitem_2[0][0] \n",
            "                                                                 tf.__operators__.getitem_3[0][0] \n",
            "                                                                 tf.__operators__.getitem_4[0][0] \n",
            "                                                                 tf.__operators__.getitem_5[0][0] \n",
            "                                                                 tf.__operators__.getitem_6[0][0] \n",
            "                                                                 tf.__operators__.getitem_7[0][0] \n",
            "                                                                 tf.__operators__.getitem_8[0][0] \n",
            "                                                                 tf.__operators__.getitem_9[0][0] \n",
            "                                                                 tf.__operators__.getitem_10[0][0]\n",
            "                                                                 tf.__operators__.getitem_11[0][0]\n",
            "                                                                 tf.__operators__.getitem_12[0][0]\n",
            "                                                                 tf.__operators__.getitem_13[0][0]\n",
            "                                                                 tf.__operators__.getitem_14[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_2 (Sli (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 2, 128)       0           model[0][0]                      \n",
            "                                                                 model[1][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_3 (Sli (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 128)       0           concatenate[0][0]                \n",
            "                                                                 model[2][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_4 (Sli (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 4, 128)       0           concatenate_1[0][0]              \n",
            "                                                                 model[3][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_5 (Sli (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 5, 128)       0           concatenate_2[0][0]              \n",
            "                                                                 model[4][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_6 (Sli (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 6, 128)       0           concatenate_3[0][0]              \n",
            "                                                                 model[5][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_7 (Sli (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 7, 128)       0           concatenate_4[0][0]              \n",
            "                                                                 model[6][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_8 (Sli (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 8, 128)       0           concatenate_5[0][0]              \n",
            "                                                                 model[7][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_9 (Sli (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 9, 128)       0           concatenate_6[0][0]              \n",
            "                                                                 model[8][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_10 (Sl (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 10, 128)      0           concatenate_7[0][0]              \n",
            "                                                                 model[9][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_11 (Sl (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 11, 128)      0           concatenate_8[0][0]              \n",
            "                                                                 model[10][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_12 (Sl (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 12, 128)      0           concatenate_9[0][0]              \n",
            "                                                                 model[11][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_13 (Sl (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 13, 128)      0           concatenate_10[0][0]             \n",
            "                                                                 model[12][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_14 (Sl (None, 96, 64, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 14, 128)      0           concatenate_11[0][0]             \n",
            "                                                                 model[13][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 15, 128)      0           concatenate_12[0][0]             \n",
            "                                                                 model[14][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 15, 256)      788480      concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) [(None, 15, 256), (N 1050624     bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 15, 256)      0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "softmax_1 (Softmax)             (None, 15, 256)      0           bidirectional_1[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_sum (TFOpLambda) (None, 256)          0           softmax[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_sum_1 (TFOpLambd (None, 256)          0           softmax_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.truediv (TFOpLambda)    (None, 256)          0           tf.math.reduce_sum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.truediv_1 (TFOpLambda)  (None, 256)          0           tf.math.reduce_sum_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_std (TFOpLambda) (None, 256)          0           softmax[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_std_1 (TFOpLambd (None, 256)          0           softmax_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_min (TFOpLambda) (None, 256)          0           softmax[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_min_1 (TFOpLambd (None, 256)          0           softmax_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max (TFOpLambda) (None, 256)          0           softmax[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_1 (TFOpLambd (None, 256)          0           softmax_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 512)          0           tf.math.reduce_sum[0][0]         \n",
            "                                                                 tf.math.reduce_sum_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 512)          0           tf.math.truediv[0][0]            \n",
            "                                                                 tf.math.truediv_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 512)          0           tf.math.reduce_std[0][0]         \n",
            "                                                                 tf.math.reduce_std_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 512)          0           tf.math.reduce_min[0][0]         \n",
            "                                                                 tf.math.reduce_min_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 512)          0           tf.math.reduce_max[0][0]         \n",
            "                                                                 tf.math.reduce_max_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 2560)         0           concatenate_14[0][0]             \n",
            "                                                                 concatenate_15[0][0]             \n",
            "                                                                 concatenate_16[0][0]             \n",
            "                                                                 concatenate_17[0][0]             \n",
            "                                                                 concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 512)          1311232     concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            2052        dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 53,069,508\n",
            "Trainable params: 53,069,508\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1mufewxqK_1",
        "outputId": "268b9f3d-b483-475c-d3d8-01ffed001fd3"
      },
      "source": [
        "p6.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMODB//models//paper_6_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMODB//models//paper_6_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = p6.fit(X_train_spec,Y_train_spec, batch_size=8,validation_data=(X_val_spec, Y_val_spec),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "30/30 [==============================] - 68s 771ms/step - loss: 1.3883 - accuracy: 0.2709 - val_loss: 1.4724 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.47245, saving model to EMODB//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.25490, saving model to EMODB//models/paper_6_acc.h5\n",
            "Epoch 2/30\n",
            "30/30 [==============================] - 18s 610ms/step - loss: 1.3691 - accuracy: 0.3534 - val_loss: 1.4676 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.47245 to 1.46764, saving model to EMODB//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.25490\n",
            "Epoch 3/30\n",
            "30/30 [==============================] - 19s 620ms/step - loss: 1.3645 - accuracy: 0.3639 - val_loss: 1.4598 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.46764 to 1.45979, saving model to EMODB//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.25490\n",
            "Epoch 4/30\n",
            "30/30 [==============================] - 19s 630ms/step - loss: 1.3459 - accuracy: 0.3720 - val_loss: 1.4522 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.45979 to 1.45224, saving model to EMODB//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.25490\n",
            "Epoch 5/30\n",
            "30/30 [==============================] - 19s 631ms/step - loss: 1.3622 - accuracy: 0.3844 - val_loss: 1.4443 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.45224 to 1.44433, saving model to EMODB//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.25490\n",
            "Epoch 6/30\n",
            "30/30 [==============================] - 19s 625ms/step - loss: 1.3333 - accuracy: 0.3950 - val_loss: 1.4254 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.44433 to 1.42540, saving model to EMODB//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.25490\n",
            "Epoch 7/30\n",
            "30/30 [==============================] - 19s 625ms/step - loss: 1.3326 - accuracy: 0.4185 - val_loss: 1.4480 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.25490\n",
            "Epoch 8/30\n",
            "30/30 [==============================] - 19s 630ms/step - loss: 1.3298 - accuracy: 0.4074 - val_loss: 1.4398 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.25490\n",
            "Epoch 9/30\n",
            "30/30 [==============================] - 19s 628ms/step - loss: 1.3207 - accuracy: 0.4205 - val_loss: 1.4485 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.25490\n",
            "Epoch 10/30\n",
            "30/30 [==============================] - 19s 626ms/step - loss: 1.3522 - accuracy: 0.3642 - val_loss: 1.4408 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.25490\n",
            "Epoch 11/30\n",
            "30/30 [==============================] - 19s 625ms/step - loss: 1.3461 - accuracy: 0.3665 - val_loss: 1.4631 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.25490\n",
            "Epoch 12/30\n",
            "30/30 [==============================] - 19s 626ms/step - loss: 1.3387 - accuracy: 0.3823 - val_loss: 1.4411 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.25490\n",
            "Epoch 13/30\n",
            "30/30 [==============================] - 19s 628ms/step - loss: 1.3347 - accuracy: 0.3917 - val_loss: 1.4479 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.25490\n",
            "Epoch 14/30\n",
            "30/30 [==============================] - 19s 628ms/step - loss: 1.3200 - accuracy: 0.4178 - val_loss: 1.4325 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.25490\n",
            "Epoch 15/30\n",
            "30/30 [==============================] - 19s 627ms/step - loss: 1.3496 - accuracy: 0.3733 - val_loss: 1.4440 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.25490\n",
            "Epoch 16/30\n",
            "30/30 [==============================] - 19s 627ms/step - loss: 1.3471 - accuracy: 0.3573 - val_loss: 1.4371 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.25490\n",
            "Epoch 17/30\n",
            "30/30 [==============================] - 19s 629ms/step - loss: 1.3810 - accuracy: 0.3251 - val_loss: 1.4819 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.25490\n",
            "Epoch 18/30\n",
            "30/30 [==============================] - 19s 627ms/step - loss: 1.3440 - accuracy: 0.3901 - val_loss: 1.4352 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.25490\n",
            "Epoch 19/30\n",
            "30/30 [==============================] - 19s 628ms/step - loss: 1.3216 - accuracy: 0.4247 - val_loss: 1.4593 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.25490\n",
            "Epoch 20/30\n",
            "30/30 [==============================] - 19s 628ms/step - loss: 1.3183 - accuracy: 0.4007 - val_loss: 1.4281 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.25490\n",
            "Epoch 21/30\n",
            "30/30 [==============================] - 19s 628ms/step - loss: 1.3391 - accuracy: 0.3976 - val_loss: 1.4400 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.25490\n",
            "Epoch 22/30\n",
            "30/30 [==============================] - 19s 627ms/step - loss: 1.3373 - accuracy: 0.3826 - val_loss: 1.4514 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.25490\n",
            "Epoch 23/30\n",
            "30/30 [==============================] - 19s 627ms/step - loss: 1.3466 - accuracy: 0.3681 - val_loss: 1.4446 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.25490\n",
            "Epoch 24/30\n",
            "30/30 [==============================] - 19s 626ms/step - loss: 1.3319 - accuracy: 0.3908 - val_loss: 1.4355 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.25490\n",
            "Epoch 25/30\n",
            "30/30 [==============================] - 19s 626ms/step - loss: 1.3484 - accuracy: 0.3659 - val_loss: 1.4447 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.25490\n",
            "Epoch 26/30\n",
            "30/30 [==============================] - 19s 627ms/step - loss: 1.3346 - accuracy: 0.3698 - val_loss: 1.4468 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.25490\n",
            "Epoch 27/30\n",
            "30/30 [==============================] - 19s 627ms/step - loss: 1.3469 - accuracy: 0.3835 - val_loss: 1.4494 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.25490\n",
            "Epoch 28/30\n",
            "30/30 [==============================] - 19s 627ms/step - loss: 1.3423 - accuracy: 0.3806 - val_loss: 1.4434 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.25490\n",
            "Epoch 29/30\n",
            "30/30 [==============================] - 19s 627ms/step - loss: 1.3499 - accuracy: 0.3650 - val_loss: 1.4492 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.25490\n",
            "Epoch 30/30\n",
            "30/30 [==============================] - 19s 628ms/step - loss: 1.3501 - accuracy: 0.3585 - val_loss: 1.4439 - val_accuracy: 0.2549\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.42540\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.25490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm3iSlBBqh2A",
        "outputId": "7b7c620b-29f1-4160-969e-dfc531ce596d"
      },
      "source": [
        "p6.load_weights('EMODB//models//paper_6_acc.h5')\n",
        "print(p6.evaluate(X_test_spec,Y_test_spec))\n",
        "p6.load_weights('EMODB//models//paper_6_loss.h5')\n",
        "p6.evaluate(X_test_spec,Y_test_spec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 4s 2s/step - loss: 1.3335 - accuracy: 0.4400\n",
            "[1.3334697484970093, 0.4399999976158142]\n",
            "2/2 [==============================] - 1s 277ms/step - loss: 1.3319 - accuracy: 0.4400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3318769931793213, 0.4399999976158142]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "CAzUQtKe4rgt",
        "outputId": "5918931a-eb10-496f-d9b4-20dcf255651c"
      },
      "source": [
        "#test set\n",
        "#p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p6.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p6.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 SCORE: 0.1527777777777778\n",
            "Kappa: 0.0\n",
            "Accuracy: 0.44\n",
            "Jaccard Score: 0.11\n",
            "Precision: 0.11\n",
            "Recall: 0.25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      1.00      0.61        22\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.00      0.00      0.00        11\n",
            "           3       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.44        50\n",
            "   macro avg       0.11      0.25      0.15        50\n",
            "weighted avg       0.19      0.44      0.27        50\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jan 2022"
      ],
      "metadata": {
        "id": "b7L4RVk_SSIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensembled"
      ],
      "metadata": {
        "id": "Jy0TooqwSUG8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJfznUT96h4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85581cc5-6197-4e9a-ad4e-eb6a202c5224"
      },
      "source": [
        "time = 4\n",
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*time), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "  #out = Conv1D(4,1,activation='softmax')(out)\n",
        "  #out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (26))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  #out2 = Dense(4)(layer2)\n",
        "  #out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out,layer3])\n",
        "  output_layer = Flatten()(output_layer)\n",
        "  output_layer = Dense(4,activation='softmax')(output_layer)\n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled = Wavenet()\n",
        "ensembled.summary()\n",
        "\n",
        "ensembled.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 64000, 8)     48          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 64000, 8)     0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 64000, 8)     328         ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 64000, 8)     0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d (AveragePool  (None, 32000, 8)    0           ['leaky_re_lu_1[0][0]']          \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 32000, 16)    656         ['average_pooling1d[0][0]']      \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 32000, 16)    0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 32000, 16)    1296        ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 32000, 16)    0           ['conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d_1 (AveragePo  (None, 16000, 16)   0           ['leaky_re_lu_3[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 16000, 16)    1296        ['average_pooling1d_1[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 16000, 16)    0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 16000, 16)    1296        ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 16000, 16)    0           ['conv1d_5[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d_2 (AveragePo  (None, 8000, 16)    0           ['leaky_re_lu_5[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 8000, 32)     544         ['average_pooling1d_2[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 8000, 64)     4160        ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 8000, 64)     4160        ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 8000, 64)     0           ['conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 8000, 64)     0           ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 8000, 64)     0           ['activation[0][0]',             \n",
            "                                                                  'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 8000, 32)     2080        ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 8000, 32)     0           ['conv1d_6[0][0]',               \n",
            "                                                                  'conv1d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 8000, 32)     1056        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 8000, 64)     0           ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 8000, 64)     0           ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 8000, 64)     0           ['activation_2[0][0]',           \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 8000, 32)     2080        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 8000, 32)     0           ['conv1d_10[0][0]',              \n",
            "                                                                  'conv1d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 8000, 32)     1056        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 8000, 64)     0           ['conv1d_15[0][0]']              \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 8000, 64)     0           ['conv1d_16[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 8000, 64)     0           ['activation_4[0][0]',           \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 8000, 32)     2080        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 8000, 32)     0           ['conv1d_9[0][0]',               \n",
            "                                                                  'conv1d_13[0][0]',              \n",
            "                                                                  'conv1d_17[0][0]']              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 8000, 32)     0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling1d_3 (AveragePo  (None, 1, 32)       0           ['activation_6[0][0]']           \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 32, 1)        0           ['average_pooling1d_3[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 32)        0           ['conv1d_19[0][0]']              \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 32, 1)        0           ['conv1d_18[0][0]']              \n",
            "                                                                                                  \n",
            " permute_1 (Permute)            (None, 32, 1)        0           ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 32, 32)       0           ['reshape[0][0]',                \n",
            "                                                                  'permute_1[0][0]']              \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 32, 32)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " softmax (Softmax)              (None, 32, 32)       0           ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 32)        0           ['conv1d_20[0][0]']              \n",
            "                                                                                                  \n",
            " permute_2 (Permute)            (None, 32, 32)       0           ['softmax[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          3456        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 1, 32)        0           ['reshape_2[0][0]',              \n",
            "                                                                  'permute_2[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 32, 1)        0           ['dot_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 32, 1)        0           ['reshape_3[0][0]',              \n",
            "                                                                  'permute[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 32)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " permute_3 (Permute)            (None, 1, 32)        0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)            (None, 1, 32)        0           ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " average (Average)              (None, 1, 32)        0           ['permute_3[0][0]',              \n",
            "                                                                  'reshape_4[0][0]']              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 32)           0           ['average[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            132         ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 46,498\n",
            "Trainable params: 46,498\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing on TESS"
      ],
      "metadata": {
        "id": "5gDJP8S6YSfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = 4,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"TESS//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"TESS//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"TESS//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "id": "whX0mkRDYW6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "697adeb8-6a30-46f6-d1db-c5947be7ccf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (1114, 64000, 1) (1114, 4)\n",
            "Test Data (239, 64000, 1) (239, 4)\n",
            "Val Data (239, 64000, 1) (239, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'TESS/hand_engineered_features_TESS_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'TESS/hand_engineered_features_TESS_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'TESS/hand_engineered_features_TESS_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "id": "n2QMciZfYdH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a557d81a-8937-4d1f-d687-b2a1eeb012aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1114, 26) (1114, 1)\n",
            "(239, 26) (239, 1)\n",
            "(239, 26) (239, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "ensembled.load_weights(\"EMO_DB//models/ensembled_loss.h5\")\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "\n",
        "ensembled.load_weights(\"EMO_DB//models/ensembled_acc.h5\")\n",
        "ensembled.evaluate([X_test,X_test_features],Y_test)"
      ],
      "metadata": {
        "id": "tie7VT9IYjfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c78cfd-a0b9-4e65-b455-2c4334e5c4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 12s 190ms/step - loss: 3.0839 - accuracy: 0.3849\n",
            "[3.083902597427368, 0.38493722677230835]\n",
            "8/8 [==============================] - 1s 153ms/step - loss: 2.0765 - accuracy: 0.4100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.076495885848999, 0.41004183888435364]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]).reshape(Y_test.shape),axis = -1)\n",
        "\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]).reshape(Y_test.shape),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n"
      ],
      "metadata": {
        "id": "wpaS5K11Yo4O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "50fb5418-ff50-4038-94ee-8f6563714f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 158ms/step - loss: 2.0765 - accuracy: 0.4100\n",
            "[2.076495885848999, 0.41004183888435364]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.35266798418972334\n",
            "Kappa: 0.21980413492927098\n",
            "Accuracy: 0.4100418410041841\n",
            "Jaccard Score: 0.24258524737567372\n",
            "Precision: 0.31233822903363134\n",
            "Recall: 0.4142538806694155\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0986b5c610>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing on Crema D"
      ],
      "metadata": {
        "id": "zwqDWOBzSj2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = 4,sr = 16000)      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"CREMA//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"CREMA//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"CREMA//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlyyPzi3SZWx",
        "outputId": "05c9e0f0-216b-430e-8d11-104723c27bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (3430, 64000, 1) (3430, 4)\n",
            "Test Data (735, 64000, 1) (735, 4)\n",
            "Val Data (735, 64000, 1) (735, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'CREMA/hand_engineered_features_CREMA_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'CREMA/hand_engineered_features_CREMA_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'CREMA/hand_engineered_features_CREMA_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ET8BkRDSzZa",
        "outputId": "ce5a9b9c-45f7-4fad-ae06-ea11ac936bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3430, 26) (3430, 1)\n",
            "(735, 26) (735, 1)\n",
            "(735, 26) (735, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "ensembled.load_weights(\"EMO_DB//models/ensembled_loss.h5\")\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "\n",
        "ensembled.load_weights(\"EMO_DB//models/ensembled_acc.h5\")\n",
        "ensembled.evaluate([X_test,X_test_features],Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUt4fUBSS2gU",
        "outputId": "cad003f3-ead9-4128-fa9c-8a1b24a5fff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 4s 185ms/step - loss: 3.3563 - accuracy: 0.3687\n",
            "[3.356342315673828, 0.36870747804641724]\n",
            "23/23 [==============================] - 4s 160ms/step - loss: 2.4289 - accuracy: 0.3551\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.42889404296875, 0.3551020324230194]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]).reshape(Y_test.shape),axis = -1)\n",
        "\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]).reshape(Y_test.shape),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n"
      ],
      "metadata": {
        "id": "vOkcxlhsTLEv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "603b7754-31ee-4433-c502-d9b81fe9fa4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 4s 159ms/step - loss: 2.4289 - accuracy: 0.3551\n",
            "[2.42889404296875, 0.3551020324230194]\n",
            "F1 SCORE: 0.30307083624248216\n",
            "Kappa: 0.13290524901067713\n",
            "Accuracy: 0.3551020408163265\n",
            "Jaccard Score: 0.19211782815760478\n",
            "Precision: 0.516602733686067\n",
            "Recall: 0.34926875143150204\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0986e7d390>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing on SAVEE( manipulation on time var) ⚛"
      ],
      "metadata": {
        "id": "5KAsZ3rox1Sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"SAVEE//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"SAVEE//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"SAVEE//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFDQKOE0x3cu",
        "outputId": "fa9da4b7-ad6d-4658-b54b-8f6fd87e59da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (207, 64000, 1) (207, 4)\n",
            "Test Data (45, 64000, 1) (45, 4)\n",
            "Val Data (44, 64000, 1) (44, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'SAVEE/hand_engineered_features_SAVEE_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'SAVEE/hand_engineered_features_SAVEE_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'SAVEE/hand_engineered_features_SAVEE_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHvAzjLIyR-l",
        "outputId": "e322a7e3-8205-4b03-d0f9-c4225e1fc545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(207, 26) (207, 1)\n",
            "(45, 26) (45, 1)\n",
            "(44, 26) (44, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "ensembled.load_weights(\"EMO_DB//models/ensembled_loss.h5\")\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "\n",
        "ensembled.load_weights(\"EMO_DB//models/ensembled_acc.h5\")\n",
        "ensembled.evaluate([X_test,X_test_features],Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIXuZs96yZpI",
        "outputId": "097126dd-6180-4600-bdb7-2e293e5a6356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 384ms/step - loss: 2.1133 - accuracy: 0.4667\n",
            "[2.11334228515625, 0.46666666865348816]\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 1.4076 - accuracy: 0.5778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4075660705566406, 0.5777778029441833]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]).reshape(Y_test.shape),axis = -1)\n",
        "\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]).reshape(Y_test.shape),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "pBtUggJsycg1",
        "outputId": "bfae4006-ba48-4278-d60e-df7750c52b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 104ms/step - loss: 1.4076 - accuracy: 0.5778\n",
            "[1.4075660705566406, 0.5777778029441833]\n",
            "F1 SCORE: 0.5727875243664717\n",
            "Kappa: 0.44444444444444453\n",
            "Accuracy: 0.5777777777777777\n",
            "Jaccard Score: 0.4101762820512821\n",
            "Precision: 0.5944444444444444\n",
            "Recall: 0.6150793650793651\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f098720a290>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feb 2022"
      ],
      "metadata": {
        "id": "SPjt0zQ7Spnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hamming Window"
      ],
      "metadata": {
        "id": "mGq94iXASsTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#angry, happy, neutral, sad\n",
        "import csv\n",
        "\n",
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "\n",
        "def extract_features(csvpath,path):\n",
        "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
        "    for i in range(1, 21):\n",
        "        header += f' mfcc{i}'\n",
        "    header += ' label'\n",
        "    header = header.split()\n",
        "    file = open(csvpath, 'w', newline='')\n",
        "    with file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow(header)\n",
        "    rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "        filename = row['path']\n",
        "        y, sr = librosa.load(row['path'], mono=True, duration=30)\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr,window=\"hamming\")\n",
        "        rmse = librosa.feature.rms(y=y)\n",
        "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr,window=\"hamming\")\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr,window=\"hamming\")\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr,window=\"hamming\")\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr,window=\"hamming\")\n",
        "        to_append = f' {filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
        "        for e in mfcc:\n",
        "                    to_append += f' {np.mean(e)}'\n",
        "        onehot_label = label_to_onehot(row['labels'])\n",
        "        to_append += f' {np.argmax(onehot_label)}'\n",
        "        file = open(csvpath, 'a', newline='')\n",
        "        with file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow(to_append.split())\n",
        "\n",
        "train_csv = \"EMO_DB//train.csv\"\n",
        "test_csv = \"EMO_DB//test.csv\"\n",
        "val_csv = \"EMO_DB//val.csv\"\n",
        "csvpath = 'EMO_DB//hamming_hand_engineered_features_EMODB_train.csv'\n",
        "extract_features(csvpath,train_csv)\n",
        "csvpath = 'EMO_DB//hamming_hand_engineered_features_EMODB_test.csv'\n",
        "extract_features(csvpath,test_csv)\n",
        "csvpath = 'EMO_DB//hamming_hand_engineered_features_EMODB_val.csv'\n",
        "extract_features(csvpath,val_csv)"
      ],
      "metadata": {
        "id": "O46RE-ljH-an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'EMO_DB/hamming_hand_engineered_features_EMODB_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB/hamming_hand_engineered_features_EMODB_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB/hamming_hand_engineered_features_EMODB_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XepDXz2sNzt",
        "outputId": "95d03ba6-d73d-4505-a7da-deb1a3c955dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 26) (237, 1)\n",
            "(50, 26) (50, 1)\n",
            "(51, 26) (51, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7sJtLiBtAkZ",
        "outputId": "9ca801d1-02eb-45cf-dec9-5206167290a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (237, 64000, 1) (237, 4)\n",
            "Test Data (50, 64000, 1) (50, 4)\n",
            "Val Data (51, 64000, 1) (51, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time = 4\n",
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*time), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "  #out = Conv1D(4,1,activation='softmax')(out)\n",
        "  #out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (26))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  #out2 = Dense(4)(layer2)\n",
        "  #out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out,layer3])\n",
        "  output_layer = Flatten()(output_layer)\n",
        "  output_layer = Dense(4,activation='softmax')(output_layer)\n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled = Wavenet()\n",
        "ensembled.summary()\n",
        "\n",
        "ensembled.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9qyobqOtIO6",
        "outputId": "c2d812df-ee5b-421f-e245-48164bae9fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 64000, 8)     48          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 64000, 8)     0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 64000, 8)     328         ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 64000, 8)     0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d (AveragePool  (None, 32000, 8)    0           ['leaky_re_lu_1[0][0]']          \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 32000, 16)    656         ['average_pooling1d[0][0]']      \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 32000, 16)    0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 32000, 16)    1296        ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 32000, 16)    0           ['conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d_1 (AveragePo  (None, 16000, 16)   0           ['leaky_re_lu_3[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 16000, 16)    1296        ['average_pooling1d_1[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 16000, 16)    0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 16000, 16)    1296        ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 16000, 16)    0           ['conv1d_5[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d_2 (AveragePo  (None, 8000, 16)    0           ['leaky_re_lu_5[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 8000, 32)     544         ['average_pooling1d_2[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 8000, 64)     4160        ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 8000, 64)     4160        ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 8000, 64)     0           ['conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 8000, 64)     0           ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 8000, 64)     0           ['activation[0][0]',             \n",
            "                                                                  'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 8000, 32)     2080        ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 8000, 32)     0           ['conv1d_6[0][0]',               \n",
            "                                                                  'conv1d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 8000, 32)     1056        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 8000, 64)     0           ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 8000, 64)     0           ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 8000, 64)     0           ['activation_2[0][0]',           \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 8000, 32)     2080        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 8000, 32)     0           ['conv1d_10[0][0]',              \n",
            "                                                                  'conv1d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 8000, 32)     1056        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 8000, 64)     0           ['conv1d_15[0][0]']              \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 8000, 64)     0           ['conv1d_16[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 8000, 64)     0           ['activation_4[0][0]',           \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 8000, 32)     2080        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 8000, 32)     0           ['conv1d_9[0][0]',               \n",
            "                                                                  'conv1d_13[0][0]',              \n",
            "                                                                  'conv1d_17[0][0]']              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 8000, 32)     0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling1d_3 (AveragePo  (None, 1, 32)       0           ['activation_6[0][0]']           \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 32, 1)        0           ['average_pooling1d_3[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 32)        0           ['conv1d_19[0][0]']              \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 32, 1)        0           ['conv1d_18[0][0]']              \n",
            "                                                                                                  \n",
            " permute_1 (Permute)            (None, 32, 1)        0           ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 32, 32)       0           ['reshape[0][0]',                \n",
            "                                                                  'permute_1[0][0]']              \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 32, 32)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " softmax (Softmax)              (None, 32, 32)       0           ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 32)        0           ['conv1d_20[0][0]']              \n",
            "                                                                                                  \n",
            " permute_2 (Permute)            (None, 32, 32)       0           ['softmax[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          3456        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 1, 32)        0           ['reshape_2[0][0]',              \n",
            "                                                                  'permute_2[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 32, 1)        0           ['dot_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 32, 1)        0           ['reshape_3[0][0]',              \n",
            "                                                                  'permute[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 32)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " permute_3 (Permute)            (None, 1, 32)        0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)            (None, 1, 32)        0           ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " average (Average)              (None, 1, 32)        0           ['permute_3[0][0]',              \n",
            "                                                                  'reshape_4[0][0]']              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 32)           0           ['average[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            132         ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 46,498\n",
            "Trainable params: 46,498\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMO_DB//models//ensembled_hamming_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMO_DB//models//ensembled_hamming_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "ensembled.fit([X_train,X_train_features],Y_train, batch_size=16,\n",
        "                        validation_data=([X_val,X_val_features], Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UvR5KLgt1hu",
        "outputId": "a65df445-5744-449d-a4db-b93e254a977a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1737 - accuracy: 0.5992\n",
            "Epoch 00001: val_loss improved from inf to 0.96931, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.66667, saving model to EMO_DB//models/ensembled_hamming_acc.h5\n",
            "15/15 [==============================] - 25s 485ms/step - loss: 1.1737 - accuracy: 0.5992 - val_loss: 0.9693 - val_accuracy: 0.6667\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8389 - accuracy: 0.7595\n",
            "Epoch 00002: val_loss improved from 0.96931 to 0.76569, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.66667 to 0.70588, saving model to EMO_DB//models/ensembled_hamming_acc.h5\n",
            "15/15 [==============================] - 4s 260ms/step - loss: 0.8389 - accuracy: 0.7595 - val_loss: 0.7657 - val_accuracy: 0.7059\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.7890\n",
            "Epoch 00003: val_loss improved from 0.76569 to 0.62904, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70588 to 0.76471, saving model to EMO_DB//models/ensembled_hamming_acc.h5\n",
            "15/15 [==============================] - 4s 252ms/step - loss: 0.6346 - accuracy: 0.7890 - val_loss: 0.6290 - val_accuracy: 0.7647\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5179 - accuracy: 0.8312\n",
            "Epoch 00004: val_loss improved from 0.62904 to 0.53338, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.76471 to 0.80392, saving model to EMO_DB//models/ensembled_hamming_acc.h5\n",
            "15/15 [==============================] - 4s 251ms/step - loss: 0.5179 - accuracy: 0.8312 - val_loss: 0.5334 - val_accuracy: 0.8039\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4451 - accuracy: 0.8397\n",
            "Epoch 00005: val_loss improved from 0.53338 to 0.47621, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.80392\n",
            "15/15 [==============================] - 3s 233ms/step - loss: 0.4451 - accuracy: 0.8397 - val_loss: 0.4762 - val_accuracy: 0.8039\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3881 - accuracy: 0.8650\n",
            "Epoch 00006: val_loss improved from 0.47621 to 0.44769, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.80392 to 0.82353, saving model to EMO_DB//models/ensembled_hamming_acc.h5\n",
            "15/15 [==============================] - 4s 253ms/step - loss: 0.3881 - accuracy: 0.8650 - val_loss: 0.4477 - val_accuracy: 0.8235\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.8819\n",
            "Epoch 00007: val_loss improved from 0.44769 to 0.40779, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.82353 to 0.84314, saving model to EMO_DB//models/ensembled_hamming_acc.h5\n",
            "15/15 [==============================] - 5s 316ms/step - loss: 0.3477 - accuracy: 0.8819 - val_loss: 0.4078 - val_accuracy: 0.8431\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3088 - accuracy: 0.9030\n",
            "Epoch 00008: val_loss did not improve from 0.40779\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.84314\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.3088 - accuracy: 0.9030 - val_loss: 0.4088 - val_accuracy: 0.8431\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2799 - accuracy: 0.9325\n",
            "Epoch 00009: val_loss improved from 0.40779 to 0.38705, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.84314\n",
            "15/15 [==============================] - 4s 254ms/step - loss: 0.2799 - accuracy: 0.9325 - val_loss: 0.3871 - val_accuracy: 0.8235\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.9072\n",
            "Epoch 00010: val_loss did not improve from 0.38705\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.84314 to 0.86275, saving model to EMO_DB//models/ensembled_hamming_acc.h5\n",
            "15/15 [==============================] - 4s 276ms/step - loss: 0.2685 - accuracy: 0.9072 - val_loss: 0.4157 - val_accuracy: 0.8627\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2605 - accuracy: 0.8903\n",
            "Epoch 00011: val_loss improved from 0.38705 to 0.36572, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 4s 248ms/step - loss: 0.2605 - accuracy: 0.8903 - val_loss: 0.3657 - val_accuracy: 0.8039\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2431 - accuracy: 0.9198\n",
            "Epoch 00012: val_loss improved from 0.36572 to 0.35889, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.2431 - accuracy: 0.9198 - val_loss: 0.3589 - val_accuracy: 0.8235\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.9241\n",
            "Epoch 00013: val_loss improved from 0.35889 to 0.32293, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 4s 254ms/step - loss: 0.2230 - accuracy: 0.9241 - val_loss: 0.3229 - val_accuracy: 0.8235\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.9409\n",
            "Epoch 00014: val_loss did not improve from 0.32293\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 232ms/step - loss: 0.2043 - accuracy: 0.9409 - val_loss: 0.3331 - val_accuracy: 0.8627\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.9536\n",
            "Epoch 00015: val_loss did not improve from 0.32293\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.1989 - accuracy: 0.9536 - val_loss: 0.3490 - val_accuracy: 0.8235\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9451\n",
            "Epoch 00016: val_loss improved from 0.32293 to 0.30728, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 4s 250ms/step - loss: 0.1874 - accuracy: 0.9451 - val_loss: 0.3073 - val_accuracy: 0.8627\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.9578\n",
            "Epoch 00017: val_loss did not improve from 0.30728\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 226ms/step - loss: 0.1752 - accuracy: 0.9578 - val_loss: 0.3151 - val_accuracy: 0.8627\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1703 - accuracy: 0.9536\n",
            "Epoch 00018: val_loss improved from 0.30728 to 0.28696, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.86275 to 0.88235, saving model to EMO_DB//models/ensembled_hamming_acc.h5\n",
            "15/15 [==============================] - 4s 301ms/step - loss: 0.1703 - accuracy: 0.9536 - val_loss: 0.2870 - val_accuracy: 0.8824\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9536\n",
            "Epoch 00019: val_loss did not improve from 0.28696\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.1591 - accuracy: 0.9536 - val_loss: 0.2953 - val_accuracy: 0.8627\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.9494\n",
            "Epoch 00020: val_loss did not improve from 0.28696\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 226ms/step - loss: 0.1592 - accuracy: 0.9494 - val_loss: 0.3090 - val_accuracy: 0.8235\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1555 - accuracy: 0.9578\n",
            "Epoch 00021: val_loss did not improve from 0.28696\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 227ms/step - loss: 0.1555 - accuracy: 0.9578 - val_loss: 0.3091 - val_accuracy: 0.8627\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9620\n",
            "Epoch 00022: val_loss improved from 0.28696 to 0.27770, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 4s 298ms/step - loss: 0.1477 - accuracy: 0.9620 - val_loss: 0.2777 - val_accuracy: 0.8627\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 0.9662\n",
            "Epoch 00023: val_loss did not improve from 0.27770\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.1380 - accuracy: 0.9662 - val_loss: 0.2926 - val_accuracy: 0.8627\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1328 - accuracy: 0.9662\n",
            "Epoch 00024: val_loss did not improve from 0.27770\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.1328 - accuracy: 0.9662 - val_loss: 0.2890 - val_accuracy: 0.8627\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.9620\n",
            "Epoch 00025: val_loss improved from 0.27770 to 0.26478, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 236ms/step - loss: 0.1279 - accuracy: 0.9620 - val_loss: 0.2648 - val_accuracy: 0.8627\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9620\n",
            "Epoch 00026: val_loss did not improve from 0.26478\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.1267 - accuracy: 0.9620 - val_loss: 0.2860 - val_accuracy: 0.8235\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.9747\n",
            "Epoch 00027: val_loss improved from 0.26478 to 0.25418, saving model to EMO_DB//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.1250 - accuracy: 0.9747 - val_loss: 0.2542 - val_accuracy: 0.8627\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9705\n",
            "Epoch 00028: val_loss did not improve from 0.25418\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 217ms/step - loss: 0.1160 - accuracy: 0.9705 - val_loss: 0.2628 - val_accuracy: 0.8627\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.9705\n",
            "Epoch 00029: val_loss did not improve from 0.25418\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.1109 - accuracy: 0.9705 - val_loss: 0.2680 - val_accuracy: 0.8235\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.9747\n",
            "Epoch 00030: val_loss did not improve from 0.25418\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.1062 - accuracy: 0.9747 - val_loss: 0.2544 - val_accuracy: 0.8627\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45002bf590>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled.load_weights('EMO_DB//models//ensembled_hamming_loss.h5')\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "\n",
        "ensembled.load_weights('EMO_DB//models//ensembled_hamming_acc.h5')\n",
        "ensembled.evaluate([X_test,X_test_features],Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyXCkZVauCH6",
        "outputId": "483da8e7-dbb8-40d2-8dc2-095572c5b0d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 414ms/step - loss: 0.1403 - accuracy: 0.9400\n",
            "[0.1403397023677826, 0.9399999976158142]\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 0.1685 - accuracy: 0.9400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16848304867744446, 0.9399999976158142]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled.load_weights('EMO_DB//models//ensembled_hamming_loss.h5')\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "kmuzs6NWuUIa",
        "outputId": "b5aa5e62-0e9f-4076-ac2d-2b57e8d6aab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 126ms/step - loss: 0.1403 - accuracy: 0.9400\n",
            "[0.1403397023677826, 0.9399999976158142]\n",
            "F1 SCORE: 0.9291125541125542\n",
            "Kappa: 0.9141385231825987\n",
            "Accuracy: 0.94\n",
            "Jaccard Score: 0.870306324110672\n",
            "Precision: 0.9301948051948052\n",
            "Recall: 0.9301948051948052\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f44976dff90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## without mfcc's"
      ],
      "metadata": {
        "id": "vt0xe_gx-SPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#angry, happy, neutral, sad\n",
        "import csv\n",
        "\n",
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "\n",
        "def extract_features(csvpath,path):\n",
        "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
        "    \n",
        "    header += ' label'\n",
        "    header = header.split()\n",
        "    file = open(csvpath, 'w', newline='')\n",
        "    with file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow(header)\n",
        "    rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "        filename = row['path']\n",
        "        y, sr = librosa.load(row['path'], mono=True, duration=30)\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "        rmse = librosa.feature.rms(y=y)\n",
        "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)\n",
        "        \n",
        "        to_append = f' {filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
        "        \n",
        "        onehot_label = label_to_onehot(row['labels'])\n",
        "        to_append += f' {np.argmax(onehot_label)}'\n",
        "        file = open(csvpath, 'a', newline='')\n",
        "        with file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow(to_append.split())\n",
        "\n",
        "train_csv = \"EMO_DB//train.csv\"\n",
        "test_csv = \"EMO_DB//test.csv\"\n",
        "val_csv = \"EMO_DB//val.csv\"\n",
        "csvpath = 'EMO_DB//hand_engineered_features_without_mfcc_train.csv'\n",
        "extract_features(csvpath,train_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_without_mfcc_test.csv'\n",
        "extract_features(csvpath,test_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_without_mfcc_val.csv'\n",
        "extract_features(csvpath,val_csv)"
      ],
      "metadata": {
        "id": "HbkVhAvevH1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'EMO_DB//hand_engineered_features_without_mfcc_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_without_mfcc_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_without_mfcc_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnwpGzhVEVJW",
        "outputId": "fbd9325d-5e48-4717-c8a2-d94f11eeed2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 6) (237, 1)\n",
            "(50, 6) (50, 1)\n",
            "(51, 6) (51, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3ujqEvOJiA8",
        "outputId": "a80621ce-6edb-4ead-ea31-2745048dc15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (237, 64000, 1) (237, 4)\n",
            "Test Data (50, 64000, 1) (50, 4)\n",
            "Val Data (51, 64000, 1) (51, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time = 4\n",
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*time), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "  #out = Conv1D(4,1,activation='softmax')(out)\n",
        "  #out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (6))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  #out2 = Dense(4)(layer2)\n",
        "  #out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out,layer3])\n",
        "  output_layer = Flatten()(output_layer)\n",
        "  output_layer = Dense(4,activation='softmax')(output_layer)\n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled_withoutmfcc = Wavenet()\n",
        "ensembled_withoutmfcc.summary()\n",
        "\n",
        "ensembled_withoutmfcc.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjYHVdjfJsMV",
        "outputId": "5e4eba69-c398-4440-8ba6-fad2fb732c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 64000, 8)     48          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 64000, 8)     0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 64000, 8)     328         ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 64000, 8)     0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d (AveragePool  (None, 32000, 8)    0           ['leaky_re_lu_1[0][0]']          \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 32000, 16)    656         ['average_pooling1d[0][0]']      \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 32000, 16)    0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 32000, 16)    1296        ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 32000, 16)    0           ['conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d_1 (AveragePo  (None, 16000, 16)   0           ['leaky_re_lu_3[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 16000, 16)    1296        ['average_pooling1d_1[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 16000, 16)    0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 16000, 16)    1296        ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 16000, 16)    0           ['conv1d_5[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d_2 (AveragePo  (None, 8000, 16)    0           ['leaky_re_lu_5[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 8000, 32)     544         ['average_pooling1d_2[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 8000, 64)     4160        ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 8000, 64)     4160        ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 8000, 64)     0           ['conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 8000, 64)     0           ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 8000, 64)     0           ['activation[0][0]',             \n",
            "                                                                  'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 8000, 32)     2080        ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 8000, 32)     0           ['conv1d_6[0][0]',               \n",
            "                                                                  'conv1d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 8000, 32)     1056        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 8000, 64)     0           ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 8000, 64)     0           ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 8000, 64)     0           ['activation_2[0][0]',           \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 8000, 32)     2080        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 8000, 32)     0           ['conv1d_10[0][0]',              \n",
            "                                                                  'conv1d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 8000, 32)     1056        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 8000, 64)     0           ['conv1d_15[0][0]']              \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 8000, 64)     0           ['conv1d_16[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 8000, 64)     0           ['activation_4[0][0]',           \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 8000, 32)     2080        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 8000, 32)     0           ['conv1d_9[0][0]',               \n",
            "                                                                  'conv1d_13[0][0]',              \n",
            "                                                                  'conv1d_17[0][0]']              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 8000, 32)     0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling1d_3 (AveragePo  (None, 1, 32)       0           ['activation_6[0][0]']           \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 32, 1)        0           ['average_pooling1d_3[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 32)        0           ['conv1d_19[0][0]']              \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 32, 1)        0           ['conv1d_18[0][0]']              \n",
            "                                                                                                  \n",
            " permute_1 (Permute)            (None, 32, 1)        0           ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 32, 32)       0           ['reshape[0][0]',                \n",
            "                                                                  'permute_1[0][0]']              \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 32, 32)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " softmax (Softmax)              (None, 32, 32)       0           ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 6)]          0           []                               \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 32)        0           ['conv1d_20[0][0]']              \n",
            "                                                                                                  \n",
            " permute_2 (Permute)            (None, 32, 32)       0           ['softmax[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          896         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 1, 32)        0           ['reshape_2[0][0]',              \n",
            "                                                                  'permute_2[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 32, 1)        0           ['dot_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 32, 1)        0           ['reshape_3[0][0]',              \n",
            "                                                                  'permute[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 32)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " permute_3 (Permute)            (None, 1, 32)        0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)            (None, 1, 32)        0           ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " average (Average)              (None, 1, 32)        0           ['permute_3[0][0]',              \n",
            "                                                                  'reshape_4[0][0]']              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 32)           0           ['average[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            132         ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 43,938\n",
            "Trainable params: 43,938\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_withoutmfcc.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMO_DB//models//ensembled_withoutmfcc_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMO_DB//models//ensembled_withoutmfcc_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "ensembled_withoutmfcc.fit([X_train,X_train_features],Y_train, batch_size=16,\n",
        "                        validation_data=([X_val,X_val_features], Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3NIZCjSJ7rn",
        "outputId": "cc5d192c-036a-46b4-b8ba-3ac227b22e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2972 - accuracy: 0.4979\n",
            "Epoch 1: val_loss improved from inf to 1.23943, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.43137, saving model to EMO_DB//models/ensembled_withoutmfcc_acc.h5\n",
            "15/15 [==============================] - 23s 453ms/step - loss: 1.2972 - accuracy: 0.4979 - val_loss: 1.2394 - val_accuracy: 0.4314\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1103 - accuracy: 0.5738\n",
            "Epoch 2: val_loss improved from 1.23943 to 1.12699, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.43137 to 0.56863, saving model to EMO_DB//models/ensembled_withoutmfcc_acc.h5\n",
            "15/15 [==============================] - 4s 274ms/step - loss: 1.1103 - accuracy: 0.5738 - val_loss: 1.1270 - val_accuracy: 0.5686\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9875 - accuracy: 0.6287\n",
            "Epoch 3: val_loss improved from 1.12699 to 1.01245, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.56863 to 0.60784, saving model to EMO_DB//models/ensembled_withoutmfcc_acc.h5\n",
            "15/15 [==============================] - 4s 257ms/step - loss: 0.9875 - accuracy: 0.6287 - val_loss: 1.0124 - val_accuracy: 0.6078\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9063 - accuracy: 0.6414\n",
            "Epoch 4: val_loss improved from 1.01245 to 0.94739, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.60784\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.9063 - accuracy: 0.6414 - val_loss: 0.9474 - val_accuracy: 0.6078\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8502 - accuracy: 0.6414\n",
            "Epoch 5: val_loss improved from 0.94739 to 0.88053, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.60784 to 0.64706, saving model to EMO_DB//models/ensembled_withoutmfcc_acc.h5\n",
            "15/15 [==============================] - 4s 254ms/step - loss: 0.8502 - accuracy: 0.6414 - val_loss: 0.8805 - val_accuracy: 0.6471\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8071 - accuracy: 0.6540\n",
            "Epoch 6: val_loss improved from 0.88053 to 0.82694, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.64706 to 0.66667, saving model to EMO_DB//models/ensembled_withoutmfcc_acc.h5\n",
            "15/15 [==============================] - 4s 253ms/step - loss: 0.8071 - accuracy: 0.6540 - val_loss: 0.8269 - val_accuracy: 0.6667\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7771 - accuracy: 0.6751\n",
            "Epoch 7: val_loss improved from 0.82694 to 0.82208, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.66667\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.7771 - accuracy: 0.6751 - val_loss: 0.8221 - val_accuracy: 0.6275\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7420 - accuracy: 0.6962\n",
            "Epoch 8: val_loss improved from 0.82208 to 0.76235, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.66667 to 0.68627, saving model to EMO_DB//models/ensembled_withoutmfcc_acc.h5\n",
            "15/15 [==============================] - 4s 297ms/step - loss: 0.7420 - accuracy: 0.6962 - val_loss: 0.7623 - val_accuracy: 0.6863\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7151 - accuracy: 0.6920\n",
            "Epoch 9: val_loss improved from 0.76235 to 0.74405, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.68627\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.7151 - accuracy: 0.6920 - val_loss: 0.7440 - val_accuracy: 0.6471\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6676 - accuracy: 0.7215\n",
            "Epoch 10: val_loss improved from 0.74405 to 0.71362, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.68627\n",
            "15/15 [==============================] - 4s 237ms/step - loss: 0.6676 - accuracy: 0.7215 - val_loss: 0.7136 - val_accuracy: 0.6667\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.7257\n",
            "Epoch 11: val_loss improved from 0.71362 to 0.69967, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.68627\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.6381 - accuracy: 0.7257 - val_loss: 0.6997 - val_accuracy: 0.6863\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.7426\n",
            "Epoch 12: val_loss improved from 0.69967 to 0.65930, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.68627\n",
            "15/15 [==============================] - 4s 236ms/step - loss: 0.6042 - accuracy: 0.7426 - val_loss: 0.6593 - val_accuracy: 0.6863\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5833 - accuracy: 0.7342\n",
            "Epoch 13: val_loss did not improve from 0.65930\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.68627\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.5833 - accuracy: 0.7342 - val_loss: 0.7118 - val_accuracy: 0.6667\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.7257\n",
            "Epoch 14: val_loss did not improve from 0.65930\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.68627\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.5956 - accuracy: 0.7257 - val_loss: 0.6614 - val_accuracy: 0.6667\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.7679\n",
            "Epoch 15: val_loss improved from 0.65930 to 0.63036, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.68627 to 0.70588, saving model to EMO_DB//models/ensembled_withoutmfcc_acc.h5\n",
            "15/15 [==============================] - 4s 290ms/step - loss: 0.5408 - accuracy: 0.7679 - val_loss: 0.6304 - val_accuracy: 0.7059\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.7595\n",
            "Epoch 16: val_loss improved from 0.63036 to 0.61120, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.70588\n",
            "15/15 [==============================] - 4s 236ms/step - loss: 0.5272 - accuracy: 0.7595 - val_loss: 0.6112 - val_accuracy: 0.6863\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.7722\n",
            "Epoch 17: val_loss did not improve from 0.61120\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.70588\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.5259 - accuracy: 0.7722 - val_loss: 0.6795 - val_accuracy: 0.6275\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.7553\n",
            "Epoch 18: val_loss improved from 0.61120 to 0.59932, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.70588\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.5270 - accuracy: 0.7553 - val_loss: 0.5993 - val_accuracy: 0.6863\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5045 - accuracy: 0.7637\n",
            "Epoch 19: val_loss improved from 0.59932 to 0.59507, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.70588\n",
            "15/15 [==============================] - 4s 239ms/step - loss: 0.5045 - accuracy: 0.7637 - val_loss: 0.5951 - val_accuracy: 0.6863\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.7848\n",
            "Epoch 20: val_loss did not improve from 0.59507\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.70588\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.4966 - accuracy: 0.7848 - val_loss: 0.6312 - val_accuracy: 0.6667\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.7764\n",
            "Epoch 21: val_loss improved from 0.59507 to 0.58731, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.70588\n",
            "15/15 [==============================] - 4s 236ms/step - loss: 0.4846 - accuracy: 0.7764 - val_loss: 0.5873 - val_accuracy: 0.7059\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4971 - accuracy: 0.7890\n",
            "Epoch 22: val_loss did not improve from 0.58731\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.70588\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.4971 - accuracy: 0.7890 - val_loss: 0.6106 - val_accuracy: 0.6863\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.8059\n",
            "Epoch 23: val_loss did not improve from 0.58731\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.70588\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.4742 - accuracy: 0.8059 - val_loss: 0.5937 - val_accuracy: 0.7059\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.8143\n",
            "Epoch 24: val_loss did not improve from 0.58731\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.70588\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.4573 - accuracy: 0.8143 - val_loss: 0.5879 - val_accuracy: 0.7059\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4614 - accuracy: 0.7890\n",
            "Epoch 25: val_loss improved from 0.58731 to 0.56230, saving model to EMO_DB//models/ensembled_withoutmfcc_loss.h5\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.70588\n",
            "15/15 [==============================] - 4s 288ms/step - loss: 0.4614 - accuracy: 0.7890 - val_loss: 0.5623 - val_accuracy: 0.7059\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4574 - accuracy: 0.8270\n",
            "Epoch 26: val_loss did not improve from 0.56230\n",
            "\n",
            "Epoch 26: val_accuracy improved from 0.70588 to 0.72549, saving model to EMO_DB//models/ensembled_withoutmfcc_acc.h5\n",
            "15/15 [==============================] - 4s 274ms/step - loss: 0.4574 - accuracy: 0.8270 - val_loss: 0.5738 - val_accuracy: 0.7255\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4458 - accuracy: 0.7764\n",
            "Epoch 27: val_loss did not improve from 0.56230\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.72549\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.4458 - accuracy: 0.7764 - val_loss: 0.5944 - val_accuracy: 0.7059\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.8143\n",
            "Epoch 28: val_loss did not improve from 0.56230\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.72549\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.4528 - accuracy: 0.8143 - val_loss: 0.6324 - val_accuracy: 0.6863\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.8059\n",
            "Epoch 29: val_loss did not improve from 0.56230\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.72549\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.4428 - accuracy: 0.8059 - val_loss: 0.6052 - val_accuracy: 0.6863\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.8143\n",
            "Epoch 30: val_loss did not improve from 0.56230\n",
            "\n",
            "Epoch 30: val_accuracy improved from 0.72549 to 0.76471, saving model to EMO_DB//models/ensembled_withoutmfcc_acc.h5\n",
            "15/15 [==============================] - 4s 284ms/step - loss: 0.4432 - accuracy: 0.8143 - val_loss: 0.5624 - val_accuracy: 0.7647\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd00b130bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_withoutmfcc.load_weights('EMO_DB//models//ensembled_withoutmfcc_loss.h5')\n",
        "print(ensembled_withoutmfcc.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_withoutmfcc.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_withoutmfcc.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "RHVd9tAdKL8D",
        "outputId": "8562ec67-82fa-445f-ea21-cb1db4d46ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 15s 460ms/step - loss: 0.4038 - accuracy: 0.8200\n",
            "[0.40375038981437683, 0.8199999928474426]\n",
            "F1 SCORE: 0.8070842868039665\n",
            "Kappa: 0.7512437810945274\n",
            "Accuracy: 0.82\n",
            "Jaccard Score: 0.6839084828215263\n",
            "Precision: 0.8147824397824397\n",
            "Recall: 0.8392857142857142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc6203a0bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_withoutmfcc.load_weights('EMO_DB//models//ensembled_withoutmfcc_acc.h5')\n",
        "print(ensembled_withoutmfcc.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_withoutmfcc.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_withoutmfcc.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "yn6QmTEwpAyh",
        "outputId": "3aa7c4ec-9f86-4839-b4c3-8e5e238f4251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 131ms/step - loss: 0.3765 - accuracy: 0.8200\n",
            "[0.37652450799942017, 0.8199999928474426]\n",
            "F1 SCORE: 0.8070842868039665\n",
            "Kappa: 0.7512437810945274\n",
            "Accuracy: 0.82\n",
            "Jaccard Score: 0.6839084828215263\n",
            "Precision: 0.8147824397824397\n",
            "Recall: 0.8392857142857142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc61fd20650>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## only MFCCs"
      ],
      "metadata": {
        "id": "75g_iK-rrWM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#angry, happy, neutral, sad\n",
        "import csv\n",
        "\n",
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "\n",
        "def extract_features(csvpath,path):\n",
        "    header = 'filename'\n",
        "    for i in range(1, 21):\n",
        "        header += f' mfcc{i}'\n",
        "    header += ' label'\n",
        "    header = header.split()\n",
        "    file = open(csvpath, 'w', newline='')\n",
        "    with file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow(header)\n",
        "    rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "        filename = row['path']\n",
        "        y, sr = librosa.load(row['path'], mono=True, duration=30)\n",
        "        \n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "        to_append = f' '    \n",
        "        for e in mfcc:\n",
        "                    to_append += f' {np.mean(e)}'\n",
        "        onehot_label = label_to_onehot(row['labels'])\n",
        "        to_append += f' {np.argmax(onehot_label)}'\n",
        "        file = open(csvpath, 'a', newline='')\n",
        "        with file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow(to_append.split())\n",
        "\n",
        "train_csv = \"EMO_DB//train.csv\"\n",
        "test_csv = \"EMO_DB//test.csv\"\n",
        "val_csv = \"EMO_DB//val.csv\"\n",
        "csvpath = 'EMO_DB//hand_engineered_features_only_mfcc_train.csv'\n",
        "extract_features(csvpath,train_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_only_mfcc_test.csv'\n",
        "extract_features(csvpath,test_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_only_mfcc_val.csv'\n",
        "extract_features(csvpath,val_csv)"
      ],
      "metadata": {
        "id": "ArYNJpa4pZqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'EMO_DB//hand_engineered_features_only_mfcc_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_only_mfcc_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_only_mfcc_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "720ebbitr3l7",
        "outputId": "4e5f4249-807e-480d-9130-f701e89aead9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 20) (237, 1)\n",
            "(50, 20) (50, 1)\n",
            "(51, 20) (51, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time = 4\n",
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*time), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "  #out = Conv1D(4,1,activation='softmax')(out)\n",
        "  #out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (20))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  #out2 = Dense(4)(layer2)\n",
        "  #out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out,layer3])\n",
        "  output_layer = Flatten()(output_layer)\n",
        "  output_layer = Dense(4,activation='softmax')(output_layer)\n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled_onlymfcc = Wavenet()\n",
        "ensembled_onlymfcc.summary()\n",
        "\n",
        "ensembled_onlymfcc.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMpZFVzgsriO",
        "outputId": "bc6cc76d-bbba-4a98-bdc3-d4aa7a98a98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d_42 (Conv1D)             (None, 64000, 8)     48          ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_16 (LeakyReLU)     (None, 64000, 8)     0           ['conv1d_42[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_43 (Conv1D)             (None, 64000, 8)     328         ['leaky_re_lu_16[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_17 (LeakyReLU)     (None, 64000, 8)     0           ['conv1d_43[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_8 (AveragePo  (None, 32000, 8)    0           ['leaky_re_lu_17[0][0]']         \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_44 (Conv1D)             (None, 32000, 16)    656         ['average_pooling1d_8[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_18 (LeakyReLU)     (None, 32000, 16)    0           ['conv1d_44[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_45 (Conv1D)             (None, 32000, 16)    1296        ['leaky_re_lu_18[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_19 (LeakyReLU)     (None, 32000, 16)    0           ['conv1d_45[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_9 (AveragePo  (None, 16000, 16)   0           ['leaky_re_lu_19[0][0]']         \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_46 (Conv1D)             (None, 16000, 16)    1296        ['average_pooling1d_9[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_20 (LeakyReLU)     (None, 16000, 16)    0           ['conv1d_46[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_47 (Conv1D)             (None, 16000, 16)    1296        ['leaky_re_lu_20[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_21 (LeakyReLU)     (None, 16000, 16)    0           ['conv1d_47[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_10 (AverageP  (None, 8000, 16)    0           ['leaky_re_lu_21[0][0]']         \n",
            " ooling1D)                                                                                        \n",
            "                                                                                                  \n",
            " conv1d_48 (Conv1D)             (None, 8000, 32)     544         ['average_pooling1d_10[0][0]']   \n",
            "                                                                                                  \n",
            " conv1d_49 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_48[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_50 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_48[0][0]']              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 8000, 64)     0           ['conv1d_49[0][0]']              \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 8000, 64)     0           ['conv1d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 8000, 64)     0           ['activation_14[0][0]',          \n",
            "                                                                  'activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_51 (Conv1D)             (None, 8000, 32)     2080        ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 8000, 32)     0           ['conv1d_48[0][0]',              \n",
            "                                                                  'conv1d_51[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_52 (Conv1D)             (None, 8000, 32)     1056        ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_53 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_52[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_54 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_52[0][0]']              \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 8000, 64)     0           ['conv1d_53[0][0]']              \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 8000, 64)     0           ['conv1d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 8000, 64)     0           ['activation_16[0][0]',          \n",
            "                                                                  'activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_55 (Conv1D)             (None, 8000, 32)     2080        ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 8000, 32)     0           ['conv1d_52[0][0]',              \n",
            "                                                                  'conv1d_55[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_56 (Conv1D)             (None, 8000, 32)     1056        ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_57 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_56[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_58 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_56[0][0]']              \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 8000, 64)     0           ['conv1d_57[0][0]']              \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 8000, 64)     0           ['conv1d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 8000, 64)     0           ['activation_18[0][0]',          \n",
            "                                                                  'activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_59 (Conv1D)             (None, 8000, 32)     2080        ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 8000, 32)     0           ['conv1d_51[0][0]',              \n",
            "                                                                  'conv1d_55[0][0]',              \n",
            "                                                                  'conv1d_59[0][0]']              \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 8000, 32)     0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " average_pooling1d_11 (AverageP  (None, 1, 32)       0           ['activation_20[0][0]']          \n",
            " ooling1D)                                                                                        \n",
            "                                                                                                  \n",
            " permute_8 (Permute)            (None, 32, 1)        0           ['average_pooling1d_11[0][0]']   \n",
            "                                                                                                  \n",
            " conv1d_61 (Conv1D)             (None, 32, 1)        2           ['permute_8[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_60 (Conv1D)             (None, 32, 1)        2           ['permute_8[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_11 (Reshape)           (None, 1, 32)        0           ['conv1d_61[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_10 (Reshape)           (None, 32, 1)        0           ['conv1d_60[0][0]']              \n",
            "                                                                                                  \n",
            " permute_9 (Permute)            (None, 32, 1)        0           ['reshape_11[0][0]']             \n",
            "                                                                                                  \n",
            " dot_4 (Dot)                    (None, 32, 32)       0           ['reshape_10[0][0]',             \n",
            "                                                                  'permute_9[0][0]']              \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 32, 32)       0           ['dot_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_62 (Conv1D)             (None, 32, 1)        2           ['permute_8[0][0]']              \n",
            "                                                                                                  \n",
            " softmax_2 (Softmax)            (None, 32, 32)       0           ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 20)]         0           []                               \n",
            "                                                                                                  \n",
            " reshape_12 (Reshape)           (None, 1, 32)        0           ['conv1d_62[0][0]']              \n",
            "                                                                                                  \n",
            " permute_10 (Permute)           (None, 32, 32)       0           ['softmax_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          2688        ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dot_5 (Dot)                    (None, 1, 32)        0           ['reshape_12[0][0]',             \n",
            "                                                                  'permute_10[0][0]']             \n",
            "                                                                                                  \n",
            " leaky_re_lu_22 (LeakyReLU)     (None, 128)          0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_13 (Reshape)           (None, 32, 1)        0           ['dot_5[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 32)           4128        ['leaky_re_lu_22[0][0]']         \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 32, 1)        0           ['reshape_13[0][0]',             \n",
            "                                                                  'permute_8[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_23 (LeakyReLU)     (None, 32)           0           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " permute_11 (Permute)           (None, 1, 32)        0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " reshape_14 (Reshape)           (None, 1, 32)        0           ['leaky_re_lu_23[0][0]']         \n",
            "                                                                                                  \n",
            " average_2 (Average)            (None, 1, 32)        0           ['permute_11[0][0]',             \n",
            "                                                                  'reshape_14[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 32)           0           ['average_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 4)            132         ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 45,730\n",
            "Trainable params: 45,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_onlymfcc.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMO_DB//models//ensembled_onlymfcc_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMO_DB//models//ensembled_onlymfcc_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "ensembled_onlymfcc.fit([X_train,X_train_features],Y_train, batch_size=16,\n",
        "                        validation_data=([X_val,X_val_features], Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr2K_wT8s0cv",
        "outputId": "0f71d6a2-2a21-4f17-d4a9-cf6660773b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2968 - accuracy: 0.4262\n",
            "Epoch 1: val_loss improved from inf to 1.11284, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.64706, saving model to EMO_DB//models/ensembled_onlymfcc_acc.h5\n",
            "15/15 [==============================] - 18s 509ms/step - loss: 1.2968 - accuracy: 0.4262 - val_loss: 1.1128 - val_accuracy: 0.6471\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9546 - accuracy: 0.7975\n",
            "Epoch 2: val_loss improved from 1.11284 to 0.84750, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.64706 to 0.76471, saving model to EMO_DB//models/ensembled_onlymfcc_acc.h5\n",
            "15/15 [==============================] - 4s 300ms/step - loss: 0.9546 - accuracy: 0.7975 - val_loss: 0.8475 - val_accuracy: 0.7647\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7201 - accuracy: 0.8059\n",
            "Epoch 3: val_loss improved from 0.84750 to 0.70273, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.76471\n",
            "15/15 [==============================] - 4s 300ms/step - loss: 0.7201 - accuracy: 0.8059 - val_loss: 0.7027 - val_accuracy: 0.6863\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.8228\n",
            "Epoch 4: val_loss improved from 0.70273 to 0.55540, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.76471 to 0.78431, saving model to EMO_DB//models/ensembled_onlymfcc_acc.h5\n",
            "15/15 [==============================] - 5s 323ms/step - loss: 0.5628 - accuracy: 0.8228 - val_loss: 0.5554 - val_accuracy: 0.7843\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4518 - accuracy: 0.8439\n",
            "Epoch 5: val_loss improved from 0.55540 to 0.47065, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.78431 to 0.82353, saving model to EMO_DB//models/ensembled_onlymfcc_acc.h5\n",
            "15/15 [==============================] - 4s 295ms/step - loss: 0.4518 - accuracy: 0.8439 - val_loss: 0.4707 - val_accuracy: 0.8235\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3725 - accuracy: 0.8776\n",
            "Epoch 6: val_loss improved from 0.47065 to 0.42213, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.82353 to 0.86275, saving model to EMO_DB//models/ensembled_onlymfcc_acc.h5\n",
            "15/15 [==============================] - 4s 282ms/step - loss: 0.3725 - accuracy: 0.8776 - val_loss: 0.4221 - val_accuracy: 0.8627\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.9409\n",
            "Epoch 7: val_loss improved from 0.42213 to 0.35151, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.86275 to 0.90196, saving model to EMO_DB//models/ensembled_onlymfcc_acc.h5\n",
            "15/15 [==============================] - 4s 292ms/step - loss: 0.3059 - accuracy: 0.9409 - val_loss: 0.3515 - val_accuracy: 0.9020\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.9451\n",
            "Epoch 8: val_loss improved from 0.35151 to 0.33378, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 266ms/step - loss: 0.2528 - accuracy: 0.9451 - val_loss: 0.3338 - val_accuracy: 0.8627\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.9409\n",
            "Epoch 9: val_loss improved from 0.33378 to 0.31057, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 281ms/step - loss: 0.2191 - accuracy: 0.9409 - val_loss: 0.3106 - val_accuracy: 0.9020\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.9536\n",
            "Epoch 10: val_loss improved from 0.31057 to 0.29624, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 287ms/step - loss: 0.2032 - accuracy: 0.9536 - val_loss: 0.2962 - val_accuracy: 0.8824\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.9705\n",
            "Epoch 11: val_loss improved from 0.29624 to 0.26643, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 284ms/step - loss: 0.1779 - accuracy: 0.9705 - val_loss: 0.2664 - val_accuracy: 0.8824\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9747\n",
            "Epoch 12: val_loss improved from 0.26643 to 0.22887, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.90196 to 0.92157, saving model to EMO_DB//models/ensembled_onlymfcc_acc.h5\n",
            "15/15 [==============================] - 5s 338ms/step - loss: 0.1569 - accuracy: 0.9747 - val_loss: 0.2289 - val_accuracy: 0.9216\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.9705\n",
            "Epoch 13: val_loss did not improve from 0.22887\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.92157\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.1371 - accuracy: 0.9705 - val_loss: 0.2477 - val_accuracy: 0.8824\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1253 - accuracy: 0.9747\n",
            "Epoch 14: val_loss improved from 0.22887 to 0.21178, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.92157\n",
            "15/15 [==============================] - 4s 267ms/step - loss: 0.1253 - accuracy: 0.9747 - val_loss: 0.2118 - val_accuracy: 0.9216\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9705\n",
            "Epoch 15: val_loss improved from 0.21178 to 0.19367, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.92157\n",
            "15/15 [==============================] - 4s 269ms/step - loss: 0.1160 - accuracy: 0.9705 - val_loss: 0.1937 - val_accuracy: 0.9216\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9831\n",
            "Epoch 16: val_loss improved from 0.19367 to 0.19132, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.92157\n",
            "15/15 [==============================] - 4s 266ms/step - loss: 0.1054 - accuracy: 0.9831 - val_loss: 0.1913 - val_accuracy: 0.9216\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9831\n",
            "Epoch 17: val_loss improved from 0.19132 to 0.16645, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.92157\n",
            "15/15 [==============================] - 4s 257ms/step - loss: 0.0922 - accuracy: 0.9831 - val_loss: 0.1664 - val_accuracy: 0.9020\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9873\n",
            "Epoch 18: val_loss did not improve from 0.16645\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.92157\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.0851 - accuracy: 0.9873 - val_loss: 0.1774 - val_accuracy: 0.9216\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9873\n",
            "Epoch 19: val_loss did not improve from 0.16645\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.92157 to 0.94118, saving model to EMO_DB//models/ensembled_onlymfcc_acc.h5\n",
            "15/15 [==============================] - 4s 273ms/step - loss: 0.0821 - accuracy: 0.9873 - val_loss: 0.1946 - val_accuracy: 0.9412\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9958\n",
            "Epoch 20: val_loss improved from 0.16645 to 0.14760, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.94118 to 0.96078, saving model to EMO_DB//models/ensembled_onlymfcc_acc.h5\n",
            "15/15 [==============================] - 4s 281ms/step - loss: 0.0771 - accuracy: 0.9958 - val_loss: 0.1476 - val_accuracy: 0.9608\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9873\n",
            "Epoch 21: val_loss improved from 0.14760 to 0.14415, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.96078\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.0742 - accuracy: 0.9873 - val_loss: 0.1442 - val_accuracy: 0.9412\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9873\n",
            "Epoch 22: val_loss improved from 0.14415 to 0.13978, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.96078\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.0582 - accuracy: 0.9873 - val_loss: 0.1398 - val_accuracy: 0.9412\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9958\n",
            "Epoch 23: val_loss improved from 0.13978 to 0.12269, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.96078\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.0508 - accuracy: 0.9958 - val_loss: 0.1227 - val_accuracy: 0.9608\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9916\n",
            "Epoch 24: val_loss improved from 0.12269 to 0.11091, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 24: val_accuracy improved from 0.96078 to 0.98039, saving model to EMO_DB//models/ensembled_onlymfcc_acc.h5\n",
            "15/15 [==============================] - 4s 272ms/step - loss: 0.0455 - accuracy: 0.9916 - val_loss: 0.1109 - val_accuracy: 0.9804\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 1.0000\n",
            "Epoch 25: val_loss improved from 0.11091 to 0.10488, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.98039\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9608\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 1.0000\n",
            "Epoch 26: val_loss improved from 0.10488 to 0.09553, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.98039\n",
            "15/15 [==============================] - 4s 246ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9804\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 0.09553\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.98039\n",
            "15/15 [==============================] - 3s 227ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9608\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 0.09553\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.98039\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9804\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 1.0000\n",
            "Epoch 29: val_loss improved from 0.09553 to 0.08399, saving model to EMO_DB//models/ensembled_onlymfcc_loss.h5\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.98039\n",
            "15/15 [==============================] - 4s 261ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9804\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 1.0000\n",
            "Epoch 30: val_loss did not improve from 0.08399\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.98039\n",
            "15/15 [==============================] - 3s 227ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9804\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc5aede6950>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_onlymfcc.load_weights('EMO_DB//models//ensembled_onlymfcc_acc.h5')\n",
        "print(ensembled_onlymfcc.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_onlymfcc.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_onlymfcc.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "6RDli0M8s_Kr",
        "outputId": "957388a8-92a3-465f-b2d9-6178b48b17eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 124ms/step - loss: 0.0609 - accuracy: 0.9800\n",
            "[0.06085257977247238, 0.9800000190734863]\n",
            "F1 SCORE: 0.9761904761904763\n",
            "Kappa: 0.9713795077275329\n",
            "Accuracy: 0.98\n",
            "Jaccard Score: 0.9545454545454546\n",
            "Precision: 0.9772727272727273\n",
            "Recall: 0.9772727272727273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc5a42c6d10>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## only MFCC + chroma stft + rmse"
      ],
      "metadata": {
        "id": "yG6eyze8u0K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#angry, happy, neutral, sad\n",
        "import csv\n",
        "\n",
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "\n",
        "def extract_features(csvpath,path):\n",
        "    header = 'filename chroma_stft rmse'\n",
        "    for i in range(1, 21):\n",
        "        header += f' mfcc{i}'\n",
        "    header += ' label'\n",
        "    header = header.split()\n",
        "    file = open(csvpath, 'w', newline='')\n",
        "    with file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow(header)\n",
        "    rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "        filename = row['path']\n",
        "        y, sr = librosa.load(row['path'], mono=True, duration=30)\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "        rmse = librosa.feature.rms(y=y)\n",
        "        \n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "        to_append = f' {filename} {np.mean(chroma_stft)} {np.mean(rmse)}'    \n",
        "        for e in mfcc:\n",
        "                    to_append += f' {np.mean(e)}'\n",
        "        onehot_label = label_to_onehot(row['labels'])\n",
        "        to_append += f' {np.argmax(onehot_label)}'\n",
        "        file = open(csvpath, 'a', newline='')\n",
        "        with file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow(to_append.split())\n",
        "\n",
        "train_csv = \"EMO_DB//train.csv\"\n",
        "test_csv = \"EMO_DB//test.csv\"\n",
        "val_csv = \"EMO_DB//val.csv\"\n",
        "csvpath = 'EMO_DB//hand_engineered_features_only_mfcc_chromastft_rmse_train.csv'\n",
        "extract_features(csvpath,train_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_only_mfcc_chromastft_rmse_test.csv'\n",
        "extract_features(csvpath,test_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_only_mfcc_chromastft_rmse_val.csv'\n",
        "extract_features(csvpath,val_csv)"
      ],
      "metadata": {
        "id": "yU0mvac8tv0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'EMO_DB//hand_engineered_features_only_mfcc_chromastft_rmse_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_only_mfcc_chromastft_rmse_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_only_mfcc_chromastft_rmse_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4in9f6JIvmd6",
        "outputId": "0d7aeeb5-e91f-436c-a3ba-323e16fe8944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 22) (237, 1)\n",
            "(50, 22) (50, 1)\n",
            "(51, 22) (51, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time = 4\n",
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*time), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "  #out = Conv1D(4,1,activation='softmax')(out)\n",
        "  #out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (22))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  #out2 = Dense(4)(layer2)\n",
        "  #out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out,layer3])\n",
        "  output_layer = Flatten()(output_layer)\n",
        "  output_layer = Dense(4,activation='softmax')(output_layer)\n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled_onlymfcc_chromastft_rmse = Wavenet()\n",
        "ensembled_onlymfcc_chromastft_rmse.summary()\n",
        "\n",
        "ensembled_onlymfcc_chromastft_rmse.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEy6_-RBv3pq",
        "outputId": "31e7875a-6382-4748-95eb-f94f435e94da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d_63 (Conv1D)             (None, 64000, 8)     48          ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_24 (LeakyReLU)     (None, 64000, 8)     0           ['conv1d_63[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_64 (Conv1D)             (None, 64000, 8)     328         ['leaky_re_lu_24[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_25 (LeakyReLU)     (None, 64000, 8)     0           ['conv1d_64[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_12 (AverageP  (None, 32000, 8)    0           ['leaky_re_lu_25[0][0]']         \n",
            " ooling1D)                                                                                        \n",
            "                                                                                                  \n",
            " conv1d_65 (Conv1D)             (None, 32000, 16)    656         ['average_pooling1d_12[0][0]']   \n",
            "                                                                                                  \n",
            " leaky_re_lu_26 (LeakyReLU)     (None, 32000, 16)    0           ['conv1d_65[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_66 (Conv1D)             (None, 32000, 16)    1296        ['leaky_re_lu_26[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_27 (LeakyReLU)     (None, 32000, 16)    0           ['conv1d_66[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_13 (AverageP  (None, 16000, 16)   0           ['leaky_re_lu_27[0][0]']         \n",
            " ooling1D)                                                                                        \n",
            "                                                                                                  \n",
            " conv1d_67 (Conv1D)             (None, 16000, 16)    1296        ['average_pooling1d_13[0][0]']   \n",
            "                                                                                                  \n",
            " leaky_re_lu_28 (LeakyReLU)     (None, 16000, 16)    0           ['conv1d_67[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_68 (Conv1D)             (None, 16000, 16)    1296        ['leaky_re_lu_28[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_29 (LeakyReLU)     (None, 16000, 16)    0           ['conv1d_68[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_14 (AverageP  (None, 8000, 16)    0           ['leaky_re_lu_29[0][0]']         \n",
            " ooling1D)                                                                                        \n",
            "                                                                                                  \n",
            " conv1d_69 (Conv1D)             (None, 8000, 32)     544         ['average_pooling1d_14[0][0]']   \n",
            "                                                                                                  \n",
            " conv1d_70 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_69[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_71 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_69[0][0]']              \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 8000, 64)     0           ['conv1d_70[0][0]']              \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 8000, 64)     0           ['conv1d_71[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 8000, 64)     0           ['activation_21[0][0]',          \n",
            "                                                                  'activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_72 (Conv1D)             (None, 8000, 32)     2080        ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 8000, 32)     0           ['conv1d_69[0][0]',              \n",
            "                                                                  'conv1d_72[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_73 (Conv1D)             (None, 8000, 32)     1056        ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_74 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_73[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_75 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_73[0][0]']              \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 8000, 64)     0           ['conv1d_74[0][0]']              \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 8000, 64)     0           ['conv1d_75[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 8000, 64)     0           ['activation_23[0][0]',          \n",
            "                                                                  'activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_76 (Conv1D)             (None, 8000, 32)     2080        ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 8000, 32)     0           ['conv1d_73[0][0]',              \n",
            "                                                                  'conv1d_76[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_77 (Conv1D)             (None, 8000, 32)     1056        ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_78 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_77[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_79 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_77[0][0]']              \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 8000, 64)     0           ['conv1d_78[0][0]']              \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 8000, 64)     0           ['conv1d_79[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 8000, 64)     0           ['activation_25[0][0]',          \n",
            "                                                                  'activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_80 (Conv1D)             (None, 8000, 32)     2080        ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 8000, 32)     0           ['conv1d_72[0][0]',              \n",
            "                                                                  'conv1d_76[0][0]',              \n",
            "                                                                  'conv1d_80[0][0]']              \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 8000, 32)     0           ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " average_pooling1d_15 (AverageP  (None, 1, 32)       0           ['activation_27[0][0]']          \n",
            " ooling1D)                                                                                        \n",
            "                                                                                                  \n",
            " permute_12 (Permute)           (None, 32, 1)        0           ['average_pooling1d_15[0][0]']   \n",
            "                                                                                                  \n",
            " conv1d_82 (Conv1D)             (None, 32, 1)        2           ['permute_12[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_81 (Conv1D)             (None, 32, 1)        2           ['permute_12[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_16 (Reshape)           (None, 1, 32)        0           ['conv1d_82[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_15 (Reshape)           (None, 32, 1)        0           ['conv1d_81[0][0]']              \n",
            "                                                                                                  \n",
            " permute_13 (Permute)           (None, 32, 1)        0           ['reshape_16[0][0]']             \n",
            "                                                                                                  \n",
            " dot_6 (Dot)                    (None, 32, 32)       0           ['reshape_15[0][0]',             \n",
            "                                                                  'permute_13[0][0]']             \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 32, 32)       0           ['dot_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_83 (Conv1D)             (None, 32, 1)        2           ['permute_12[0][0]']             \n",
            "                                                                                                  \n",
            " softmax_3 (Softmax)            (None, 32, 32)       0           ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 22)]         0           []                               \n",
            "                                                                                                  \n",
            " reshape_17 (Reshape)           (None, 1, 32)        0           ['conv1d_83[0][0]']              \n",
            "                                                                                                  \n",
            " permute_14 (Permute)           (None, 32, 32)       0           ['softmax_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 128)          2944        ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " dot_7 (Dot)                    (None, 1, 32)        0           ['reshape_17[0][0]',             \n",
            "                                                                  'permute_14[0][0]']             \n",
            "                                                                                                  \n",
            " leaky_re_lu_30 (LeakyReLU)     (None, 128)          0           ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_18 (Reshape)           (None, 32, 1)        0           ['dot_7[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 32)           4128        ['leaky_re_lu_30[0][0]']         \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 32, 1)        0           ['reshape_18[0][0]',             \n",
            "                                                                  'permute_12[0][0]']             \n",
            "                                                                                                  \n",
            " leaky_re_lu_31 (LeakyReLU)     (None, 32)           0           ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " permute_15 (Permute)           (None, 1, 32)        0           ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " reshape_19 (Reshape)           (None, 1, 32)        0           ['leaky_re_lu_31[0][0]']         \n",
            "                                                                                                  \n",
            " average_3 (Average)            (None, 1, 32)        0           ['permute_15[0][0]',             \n",
            "                                                                  'reshape_19[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 32)           0           ['average_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 4)            132         ['flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 45,986\n",
            "Trainable params: 45,986\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_onlymfcc_chromastft_rmse.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMO_DB//models//ensembled_onlymfcc_chromastft_rmse_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMO_DB//models//ensembled_onlymfcc_chromastft_rmse_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "ensembled_onlymfcc_chromastft_rmse.fit([X_train,X_train_features],Y_train, batch_size=16,\n",
        "                        validation_data=([X_val,X_val_features], Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avIO8qw4wTVG",
        "outputId": "72f5ae48-a931-46ba-95bb-60bec69baa29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2453 - accuracy: 0.5274\n",
            "Epoch 1: val_loss improved from inf to 0.98708, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.78431, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_acc.h5\n",
            "15/15 [==============================] - 14s 422ms/step - loss: 1.2453 - accuracy: 0.5274 - val_loss: 0.9871 - val_accuracy: 0.7843\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8770 - accuracy: 0.7342\n",
            "Epoch 2: val_loss improved from 0.98708 to 0.76336, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.78431\n",
            "15/15 [==============================] - 4s 293ms/step - loss: 0.8770 - accuracy: 0.7342 - val_loss: 0.7634 - val_accuracy: 0.7647\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6838 - accuracy: 0.7806\n",
            "Epoch 3: val_loss improved from 0.76336 to 0.62416, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.78431 to 0.80392, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_acc.h5\n",
            "15/15 [==============================] - 4s 302ms/step - loss: 0.6838 - accuracy: 0.7806 - val_loss: 0.6242 - val_accuracy: 0.8039\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.8143\n",
            "Epoch 4: val_loss improved from 0.62416 to 0.51138, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.80392 to 0.82353, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_acc.h5\n",
            "15/15 [==============================] - 4s 289ms/step - loss: 0.5482 - accuracy: 0.8143 - val_loss: 0.5114 - val_accuracy: 0.8235\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4747 - accuracy: 0.8481\n",
            "Epoch 5: val_loss improved from 0.51138 to 0.47775, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.82353\n",
            "15/15 [==============================] - 4s 258ms/step - loss: 0.4747 - accuracy: 0.8481 - val_loss: 0.4778 - val_accuracy: 0.8039\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4182 - accuracy: 0.8650\n",
            "Epoch 6: val_loss improved from 0.47775 to 0.40861, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.82353 to 0.86275, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_acc.h5\n",
            "15/15 [==============================] - 4s 278ms/step - loss: 0.4182 - accuracy: 0.8650 - val_loss: 0.4086 - val_accuracy: 0.8627\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3525 - accuracy: 0.8987\n",
            "Epoch 7: val_loss improved from 0.40861 to 0.39756, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 4s 255ms/step - loss: 0.3525 - accuracy: 0.8987 - val_loss: 0.3976 - val_accuracy: 0.8627\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.9030\n",
            "Epoch 8: val_loss improved from 0.39756 to 0.37010, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.86275 to 0.88235, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_acc.h5\n",
            "15/15 [==============================] - 4s 281ms/step - loss: 0.3144 - accuracy: 0.9030 - val_loss: 0.3701 - val_accuracy: 0.8824\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2865 - accuracy: 0.9072\n",
            "Epoch 9: val_loss improved from 0.37010 to 0.35476, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 4s 246ms/step - loss: 0.2865 - accuracy: 0.9072 - val_loss: 0.3548 - val_accuracy: 0.8431\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2648 - accuracy: 0.9241\n",
            "Epoch 10: val_loss did not improve from 0.35476\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.2648 - accuracy: 0.9241 - val_loss: 0.3654 - val_accuracy: 0.8431\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.9325\n",
            "Epoch 11: val_loss improved from 0.35476 to 0.30627, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.2405 - accuracy: 0.9325 - val_loss: 0.3063 - val_accuracy: 0.8824\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.9283\n",
            "Epoch 12: val_loss did not improve from 0.30627\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 226ms/step - loss: 0.2311 - accuracy: 0.9283 - val_loss: 0.3447 - val_accuracy: 0.8431\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9325\n",
            "Epoch 13: val_loss improved from 0.30627 to 0.28785, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.2135 - accuracy: 0.9325 - val_loss: 0.2879 - val_accuracy: 0.8824\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1997 - accuracy: 0.9451\n",
            "Epoch 14: val_loss did not improve from 0.28785\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.1997 - accuracy: 0.9451 - val_loss: 0.3210 - val_accuracy: 0.8431\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.9367\n",
            "Epoch 15: val_loss improved from 0.28785 to 0.28687, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 4s 246ms/step - loss: 0.1881 - accuracy: 0.9367 - val_loss: 0.2869 - val_accuracy: 0.8431\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.9494\n",
            "Epoch 16: val_loss did not improve from 0.28687\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 229ms/step - loss: 0.1817 - accuracy: 0.9494 - val_loss: 0.3125 - val_accuracy: 0.8235\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9367\n",
            "Epoch 17: val_loss improved from 0.28687 to 0.24927, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 4s 261ms/step - loss: 0.1723 - accuracy: 0.9367 - val_loss: 0.2493 - val_accuracy: 0.8627\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9578\n",
            "Epoch 18: val_loss did not improve from 0.24927\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 227ms/step - loss: 0.1616 - accuracy: 0.9578 - val_loss: 0.2711 - val_accuracy: 0.8431\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1712 - accuracy: 0.9409\n",
            "Epoch 19: val_loss did not improve from 0.24927\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.1712 - accuracy: 0.9409 - val_loss: 0.3000 - val_accuracy: 0.8431\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9494\n",
            "Epoch 20: val_loss did not improve from 0.24927\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.1569 - accuracy: 0.9494 - val_loss: 0.2676 - val_accuracy: 0.8431\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.9451\n",
            "Epoch 21: val_loss improved from 0.24927 to 0.24226, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 4s 259ms/step - loss: 0.1503 - accuracy: 0.9451 - val_loss: 0.2423 - val_accuracy: 0.8431\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.9620\n",
            "Epoch 22: val_loss improved from 0.24226 to 0.23809, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.1401 - accuracy: 0.9620 - val_loss: 0.2381 - val_accuracy: 0.8627\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1328 - accuracy: 0.9578\n",
            "Epoch 23: val_loss did not improve from 0.23809\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.1328 - accuracy: 0.9578 - val_loss: 0.2646 - val_accuracy: 0.8431\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1225 - accuracy: 0.9705\n",
            "Epoch 24: val_loss improved from 0.23809 to 0.23487, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 24: val_accuracy improved from 0.88235 to 0.90196, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_acc.h5\n",
            "15/15 [==============================] - 4s 280ms/step - loss: 0.1225 - accuracy: 0.9705 - val_loss: 0.2349 - val_accuracy: 0.9020\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1208 - accuracy: 0.9536\n",
            "Epoch 25: val_loss did not improve from 0.23487\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 230ms/step - loss: 0.1208 - accuracy: 0.9536 - val_loss: 0.2664 - val_accuracy: 0.8431\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.9662\n",
            "Epoch 26: val_loss did not improve from 0.23487\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 227ms/step - loss: 0.1179 - accuracy: 0.9662 - val_loss: 0.2430 - val_accuracy: 0.8431\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9705\n",
            "Epoch 27: val_loss improved from 0.23487 to 0.22454, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 259ms/step - loss: 0.1175 - accuracy: 0.9705 - val_loss: 0.2245 - val_accuracy: 0.8431\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9662\n",
            "Epoch 28: val_loss did not improve from 0.22454\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 227ms/step - loss: 0.1214 - accuracy: 0.9662 - val_loss: 0.2796 - val_accuracy: 0.8235\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9620\n",
            "Epoch 29: val_loss improved from 0.22454 to 0.20626, saving model to EMO_DB//models/ensembled_onlymfcc_chromastft_rmse_loss.h5\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.1200 - accuracy: 0.9620 - val_loss: 0.2063 - val_accuracy: 0.8627\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9747\n",
            "Epoch 30: val_loss did not improve from 0.20626\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 227ms/step - loss: 0.1086 - accuracy: 0.9747 - val_loss: 0.2417 - val_accuracy: 0.8431\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc5ac6a2810>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_onlymfcc_chromastft_rmse.load_weights('EMO_DB//models//ensembled_onlymfcc_chromastft_rmse_acc.h5')\n",
        "print(ensembled_onlymfcc_chromastft_rmse.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_onlymfcc_chromastft_rmse.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_onlymfcc_chromastft_rmse.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "gVRFoVRFwg92",
        "outputId": "0e891b12-db2f-4e34-9fea-20f1a17328b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 128ms/step - loss: 0.1596 - accuracy: 0.9200\n",
            "[0.1596069484949112, 0.9200000166893005]\n",
            "F1 SCORE: 0.9085306795806503\n",
            "Kappa: 0.8863636363636364\n",
            "Accuracy: 0.92\n",
            "Jaccard Score: 0.8382246376811594\n",
            "Precision: 0.9047619047619048\n",
            "Recall: 0.9165584415584415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc5ae04e850>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_onlymfcc_chromastft_rmse.load_weights('EMO_DB//models//ensembled_onlymfcc_chromastft_rmse_loss.h5')\n",
        "print(ensembled_onlymfcc_chromastft_rmse.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_onlymfcc_chromastft_rmse.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_onlymfcc_chromastft_rmse.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "vLKVNMRWyvBo",
        "outputId": "86d50b3d-b6eb-459b-eb52-1bb6770759c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 133ms/step - loss: 0.1431 - accuracy: 0.9200\n",
            "[0.1431337296962738, 0.9200000166893005]\n",
            "F1 SCORE: 0.9087486157253599\n",
            "Kappa: 0.8864926220204313\n",
            "Accuracy: 0.92\n",
            "Jaccard Score: 0.8386034255599473\n",
            "Precision: 0.9028679653679654\n",
            "Recall: 0.9188311688311688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc61d40f590>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## last shot (- (zcr + roll off))"
      ],
      "metadata": {
        "id": "RVNyKMXii_66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#angry, happy, neutral, sad\n",
        "import csv\n",
        "\n",
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "\n",
        "def extract_features(csvpath,path):\n",
        "    #header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
        "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth'\n",
        "    for i in range(1, 21):\n",
        "        header += f' mfcc{i}'\n",
        "    header += ' label'\n",
        "    header = header.split()\n",
        "    file = open(csvpath, 'w', newline='')\n",
        "    with file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow(header)\n",
        "    rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "        filename = row['path']\n",
        "        y, sr = librosa.load(row['path'], mono=True, duration=30)\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "        rmse = librosa.feature.rms(y=y)\n",
        "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "        #rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "        #zcr = librosa.feature.zero_crossing_rate(y)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "        #to_append = f' {filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
        "        to_append = f' {filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)}'    \n",
        "        for e in mfcc:\n",
        "                    to_append += f' {np.mean(e)}'\n",
        "        onehot_label = label_to_onehot(row['labels'])\n",
        "        to_append += f' {np.argmax(onehot_label)}'\n",
        "        file = open(csvpath, 'a', newline='')\n",
        "        with file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow(to_append.split())\n",
        "\n",
        "train_csv = \"EMO_DB//train.csv\"\n",
        "test_csv = \"EMO_DB//test.csv\"\n",
        "val_csv = \"EMO_DB//val.csv\"\n",
        "csvpath = 'EMO_DB//hand_engineered_features_without_zcr_rolloff_train.csv'\n",
        "extract_features(csvpath,train_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_without_zcr_rolloff_test.csv'\n",
        "extract_features(csvpath,test_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_without_zcr_rolloff_val.csv'\n",
        "extract_features(csvpath,val_csv)"
      ],
      "metadata": {
        "id": "km4GsjFC1Ij5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'EMO_DB//hand_engineered_features_without_zcr_rolloff_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_without_zcr_rolloff_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_without_zcr_rolloff_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOXAo7j2i9Qr",
        "outputId": "2c4587fc-f18a-4f6d-9014-fc5b3dfc9aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 24) (237, 1)\n",
            "(50, 24) (50, 1)\n",
            "(51, 24) (51, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time = 4\n",
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*time), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "  #out = Conv1D(4,1,activation='softmax')(out)\n",
        "  #out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (24))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  #out2 = Dense(4)(layer2)\n",
        "  #out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out,layer3])\n",
        "  output_layer = Flatten()(output_layer)\n",
        "  output_layer = Dense(4,activation='softmax')(output_layer)\n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled_lastshot = Wavenet()\n",
        "ensembled_lastshot.summary()\n",
        "\n",
        "ensembled_lastshot.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4aairY3jRLG",
        "outputId": "7f381408-d726-4fd6-f769-1d6c52cea036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d_21 (Conv1D)             (None, 64000, 8)     48          ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 64000, 8)     0           ['conv1d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_22 (Conv1D)             (None, 64000, 8)     328         ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 64000, 8)     0           ['conv1d_22[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_4 (AveragePo  (None, 32000, 8)    0           ['leaky_re_lu_9[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_23 (Conv1D)             (None, 32000, 16)    656         ['average_pooling1d_4[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 32000, 16)    0           ['conv1d_23[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_24 (Conv1D)             (None, 32000, 16)    1296        ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 32000, 16)    0           ['conv1d_24[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_5 (AveragePo  (None, 16000, 16)   0           ['leaky_re_lu_11[0][0]']         \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_25 (Conv1D)             (None, 16000, 16)    1296        ['average_pooling1d_5[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)     (None, 16000, 16)    0           ['conv1d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_26 (Conv1D)             (None, 16000, 16)    1296        ['leaky_re_lu_12[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_13 (LeakyReLU)     (None, 16000, 16)    0           ['conv1d_26[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_6 (AveragePo  (None, 8000, 16)    0           ['leaky_re_lu_13[0][0]']         \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_27 (Conv1D)             (None, 8000, 32)     544         ['average_pooling1d_6[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_28 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_27[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_29 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_27[0][0]']              \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 8000, 64)     0           ['conv1d_28[0][0]']              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 8000, 64)     0           ['conv1d_29[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 8000, 64)     0           ['activation_7[0][0]',           \n",
            "                                                                  'activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_30 (Conv1D)             (None, 8000, 32)     2080        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 8000, 32)     0           ['conv1d_27[0][0]',              \n",
            "                                                                  'conv1d_30[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_31 (Conv1D)             (None, 8000, 32)     1056        ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_32 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_31[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_33 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_31[0][0]']              \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 8000, 64)     0           ['conv1d_32[0][0]']              \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 8000, 64)     0           ['conv1d_33[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 8000, 64)     0           ['activation_9[0][0]',           \n",
            "                                                                  'activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_34 (Conv1D)             (None, 8000, 32)     2080        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 8000, 32)     0           ['conv1d_31[0][0]',              \n",
            "                                                                  'conv1d_34[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_35 (Conv1D)             (None, 8000, 32)     1056        ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_36 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_35[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_37 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_35[0][0]']              \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 8000, 64)     0           ['conv1d_36[0][0]']              \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 8000, 64)     0           ['conv1d_37[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 8000, 64)     0           ['activation_11[0][0]',          \n",
            "                                                                  'activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_38 (Conv1D)             (None, 8000, 32)     2080        ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 8000, 32)     0           ['conv1d_30[0][0]',              \n",
            "                                                                  'conv1d_34[0][0]',              \n",
            "                                                                  'conv1d_38[0][0]']              \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 8000, 32)     0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling1d_7 (AveragePo  (None, 1, 32)       0           ['activation_13[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " permute_4 (Permute)            (None, 32, 1)        0           ['average_pooling1d_7[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_40 (Conv1D)             (None, 32, 1)        2           ['permute_4[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_39 (Conv1D)             (None, 32, 1)        2           ['permute_4[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_6 (Reshape)            (None, 1, 32)        0           ['conv1d_40[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)            (None, 32, 1)        0           ['conv1d_39[0][0]']              \n",
            "                                                                                                  \n",
            " permute_5 (Permute)            (None, 32, 1)        0           ['reshape_6[0][0]']              \n",
            "                                                                                                  \n",
            " dot_2 (Dot)                    (None, 32, 32)       0           ['reshape_5[0][0]',              \n",
            "                                                                  'permute_5[0][0]']              \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 32, 32)       0           ['dot_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_41 (Conv1D)             (None, 32, 1)        2           ['permute_4[0][0]']              \n",
            "                                                                                                  \n",
            " softmax_1 (Softmax)            (None, 32, 32)       0           ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 24)]         0           []                               \n",
            "                                                                                                  \n",
            " reshape_7 (Reshape)            (None, 1, 32)        0           ['conv1d_41[0][0]']              \n",
            "                                                                                                  \n",
            " permute_6 (Permute)            (None, 32, 32)       0           ['softmax_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          3200        ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dot_3 (Dot)                    (None, 1, 32)        0           ['reshape_7[0][0]',              \n",
            "                                                                  'permute_6[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_14 (LeakyReLU)     (None, 128)          0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_8 (Reshape)            (None, 32, 1)        0           ['dot_3[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 32)           4128        ['leaky_re_lu_14[0][0]']         \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 32, 1)        0           ['reshape_8[0][0]',              \n",
            "                                                                  'permute_4[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_15 (LeakyReLU)     (None, 32)           0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " permute_7 (Permute)            (None, 1, 32)        0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_9 (Reshape)            (None, 1, 32)        0           ['leaky_re_lu_15[0][0]']         \n",
            "                                                                                                  \n",
            " average_1 (Average)            (None, 1, 32)        0           ['permute_7[0][0]',              \n",
            "                                                                  'reshape_9[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 32)           0           ['average_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 4)            132         ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 46,242\n",
            "Trainable params: 46,242\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_lastshot.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMO_DB//models//ensembled_lastshot_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMO_DB//models//ensembled_lastshot_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "ensembled_lastshot.fit([X_train,X_train_features],Y_train, batch_size=16,\n",
        "                        validation_data=([X_val,X_val_features], Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGLt2Kigj_SF",
        "outputId": "c8415b46-1f81-479f-fd2f-b139bf917447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1641 - accuracy: 0.6034\n",
            "Epoch 1: val_loss improved from inf to 0.97326, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.62745, saving model to EMO_DB//models/ensembled_lastshot_acc.h5\n",
            "15/15 [==============================] - 24s 459ms/step - loss: 1.1641 - accuracy: 0.6034 - val_loss: 0.9733 - val_accuracy: 0.6275\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8152 - accuracy: 0.7300\n",
            "Epoch 2: val_loss improved from 0.97326 to 0.71806, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.62745 to 0.74510, saving model to EMO_DB//models/ensembled_lastshot_acc.h5\n",
            "15/15 [==============================] - 4s 279ms/step - loss: 0.8152 - accuracy: 0.7300 - val_loss: 0.7181 - val_accuracy: 0.7451\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6188 - accuracy: 0.8101\n",
            "Epoch 3: val_loss improved from 0.71806 to 0.57767, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.74510 to 0.82353, saving model to EMO_DB//models/ensembled_lastshot_acc.h5\n",
            "15/15 [==============================] - 4s 281ms/step - loss: 0.6188 - accuracy: 0.8101 - val_loss: 0.5777 - val_accuracy: 0.8235\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5068 - accuracy: 0.8439\n",
            "Epoch 4: val_loss improved from 0.57767 to 0.50213, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.82353 to 0.84314, saving model to EMO_DB//models/ensembled_lastshot_acc.h5\n",
            "15/15 [==============================] - 5s 325ms/step - loss: 0.5068 - accuracy: 0.8439 - val_loss: 0.5021 - val_accuracy: 0.8431\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.8608\n",
            "Epoch 5: val_loss improved from 0.50213 to 0.43920, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.84314\n",
            "15/15 [==============================] - 4s 267ms/step - loss: 0.4365 - accuracy: 0.8608 - val_loss: 0.4392 - val_accuracy: 0.8431\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8945\n",
            "Epoch 6: val_loss improved from 0.43920 to 0.42862, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.84314\n",
            "15/15 [==============================] - 4s 271ms/step - loss: 0.3792 - accuracy: 0.8945 - val_loss: 0.4286 - val_accuracy: 0.8431\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3393 - accuracy: 0.8945\n",
            "Epoch 7: val_loss improved from 0.42862 to 0.40699, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.84314 to 0.86275, saving model to EMO_DB//models/ensembled_lastshot_acc.h5\n",
            "15/15 [==============================] - 5s 335ms/step - loss: 0.3393 - accuracy: 0.8945 - val_loss: 0.4070 - val_accuracy: 0.8627\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.8861\n",
            "Epoch 8: val_loss improved from 0.40699 to 0.37149, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.86275 to 0.90196, saving model to EMO_DB//models/ensembled_lastshot_acc.h5\n",
            "15/15 [==============================] - 4s 284ms/step - loss: 0.3165 - accuracy: 0.8861 - val_loss: 0.3715 - val_accuracy: 0.9020\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2964 - accuracy: 0.9156\n",
            "Epoch 9: val_loss did not improve from 0.37149\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 237ms/step - loss: 0.2964 - accuracy: 0.9156 - val_loss: 0.3787 - val_accuracy: 0.8627\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.9367\n",
            "Epoch 10: val_loss improved from 0.37149 to 0.32610, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 288ms/step - loss: 0.2611 - accuracy: 0.9367 - val_loss: 0.3261 - val_accuracy: 0.8431\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.9241\n",
            "Epoch 11: val_loss improved from 0.32610 to 0.32064, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 279ms/step - loss: 0.2476 - accuracy: 0.9241 - val_loss: 0.3206 - val_accuracy: 0.8824\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2254 - accuracy: 0.9494\n",
            "Epoch 12: val_loss did not improve from 0.32064\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.2254 - accuracy: 0.9494 - val_loss: 0.3219 - val_accuracy: 0.8627\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.9451\n",
            "Epoch 13: val_loss improved from 0.32064 to 0.28901, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 289ms/step - loss: 0.2133 - accuracy: 0.9451 - val_loss: 0.2890 - val_accuracy: 0.9020\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.9367\n",
            "Epoch 14: val_loss did not improve from 0.28901\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 243ms/step - loss: 0.2021 - accuracy: 0.9367 - val_loss: 0.3038 - val_accuracy: 0.8627\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1982 - accuracy: 0.9409\n",
            "Epoch 15: val_loss did not improve from 0.28901\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 244ms/step - loss: 0.1982 - accuracy: 0.9409 - val_loss: 0.2915 - val_accuracy: 0.8627\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.9451\n",
            "Epoch 16: val_loss did not improve from 0.28901\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 238ms/step - loss: 0.1950 - accuracy: 0.9451 - val_loss: 0.3020 - val_accuracy: 0.8431\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9451\n",
            "Epoch 17: val_loss improved from 0.28901 to 0.27857, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 295ms/step - loss: 0.1755 - accuracy: 0.9451 - val_loss: 0.2786 - val_accuracy: 0.8627\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.9620\n",
            "Epoch 18: val_loss improved from 0.27857 to 0.26769, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 262ms/step - loss: 0.1656 - accuracy: 0.9620 - val_loss: 0.2677 - val_accuracy: 0.8627\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.9451\n",
            "Epoch 19: val_loss improved from 0.26769 to 0.26311, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 251ms/step - loss: 0.1596 - accuracy: 0.9451 - val_loss: 0.2631 - val_accuracy: 0.8824\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9662\n",
            "Epoch 20: val_loss improved from 0.26311 to 0.25919, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 273ms/step - loss: 0.1519 - accuracy: 0.9662 - val_loss: 0.2592 - val_accuracy: 0.8824\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1455 - accuracy: 0.9620\n",
            "Epoch 21: val_loss did not improve from 0.25919\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 233ms/step - loss: 0.1455 - accuracy: 0.9620 - val_loss: 0.3163 - val_accuracy: 0.8431\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1486 - accuracy: 0.9494\n",
            "Epoch 22: val_loss improved from 0.25919 to 0.24021, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 255ms/step - loss: 0.1486 - accuracy: 0.9494 - val_loss: 0.2402 - val_accuracy: 0.8824\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 0.9662\n",
            "Epoch 23: val_loss did not improve from 0.24021\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 241ms/step - loss: 0.1336 - accuracy: 0.9662 - val_loss: 0.2776 - val_accuracy: 0.8627\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.9620\n",
            "Epoch 24: val_loss did not improve from 0.24021\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 231ms/step - loss: 0.1335 - accuracy: 0.9620 - val_loss: 0.2649 - val_accuracy: 0.8627\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.9662\n",
            "Epoch 25: val_loss improved from 0.24021 to 0.23081, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 255ms/step - loss: 0.1333 - accuracy: 0.9662 - val_loss: 0.2308 - val_accuracy: 0.9020\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.9662\n",
            "Epoch 26: val_loss did not improve from 0.23081\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 226ms/step - loss: 0.1302 - accuracy: 0.9662 - val_loss: 0.2415 - val_accuracy: 0.8824\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1248 - accuracy: 0.9662\n",
            "Epoch 27: val_loss improved from 0.23081 to 0.23059, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.1248 - accuracy: 0.9662 - val_loss: 0.2306 - val_accuracy: 0.8627\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9705\n",
            "Epoch 28: val_loss did not improve from 0.23059\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.1181 - accuracy: 0.9705 - val_loss: 0.2513 - val_accuracy: 0.8627\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.9662\n",
            "Epoch 29: val_loss improved from 0.23059 to 0.23024, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 243ms/step - loss: 0.1149 - accuracy: 0.9662 - val_loss: 0.2302 - val_accuracy: 0.8627\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.9747\n",
            "Epoch 30: val_loss improved from 0.23024 to 0.21046, saving model to EMO_DB//models/ensembled_lastshot_loss.h5\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.1110 - accuracy: 0.9747 - val_loss: 0.2105 - val_accuracy: 0.8824\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0500461950>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_lastshot.load_weights('EMO_DB//models//ensembled_lastshot_loss.h5')\n",
        "print(ensembled_lastshot.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_lastshot.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_lastshot.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "G4NbsYUOkId8",
        "outputId": "a2407f73-6025-4793-f5a1-13e9c0913d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 404ms/step - loss: 0.1231 - accuracy: 0.9600\n",
            "[0.12308147549629211, 0.9599999785423279]\n",
            "F1 SCORE: 0.9537098560354376\n",
            "Kappa: 0.9432463110102156\n",
            "Accuracy: 0.96\n",
            "Jaccard Score: 0.9119318181818182\n",
            "Precision: 0.9460227272727273\n",
            "Recall: 0.9659090909090909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0510fde0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_lastshot.load_weights('EMO_DB//models//ensembled_lastshot_acc.h5')\n",
        "print(ensembled_lastshot.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_lastshot.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_lastshot.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "OLSMWlydkhvf",
        "outputId": "7b364f1a-b900-4723-92ce-cce4cdad8c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 102ms/step - loss: 0.2647 - accuracy: 0.9200\n",
            "[0.26474544405937195, 0.9200000166893005]\n",
            "F1 SCORE: 0.894927536231884\n",
            "Kappa: 0.8834498834498835\n",
            "Accuracy: 0.92\n",
            "Jaccard Score: 0.835\n",
            "Precision: 0.91875\n",
            "Recall: 0.8814935064935066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f04924cc310>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MFCC  + chroma stft + rmse + spectral bw + zcr"
      ],
      "metadata": {
        "id": "BRkEuRAQCIXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#angry, happy, neutral, sad\n",
        "import csv\n",
        "\n",
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "\n",
        "def extract_features(csvpath,path):\n",
        "    header = 'filename chroma_stft rmse spectral_bandwidth zero_crossing_rate'\n",
        "    for i in range(1, 21):\n",
        "        header += f' mfcc{i}'\n",
        "    header += ' label'\n",
        "    header = header.split()\n",
        "    file = open(csvpath, 'w', newline='')\n",
        "    with file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow(header)\n",
        "    rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "        filename = row['path']\n",
        "        y, sr = librosa.load(row['path'], mono=True, duration=30)\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "        rmse = librosa.feature.rms(y=y)\n",
        "        #spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "        #rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "        to_append = f' {filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_bw)} {np.mean(zcr)}'    \n",
        "        for e in mfcc:\n",
        "                    to_append += f' {np.mean(e)}'\n",
        "        onehot_label = label_to_onehot(row['labels'])\n",
        "        to_append += f' {np.argmax(onehot_label)}'\n",
        "        file = open(csvpath, 'a', newline='')\n",
        "        with file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow(to_append.split())\n",
        "\n",
        "train_csv = \"EMO_DB//train.csv\"\n",
        "test_csv = \"EMO_DB//test.csv\"\n",
        "val_csv = \"EMO_DB//val.csv\"\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_rolloff_train.csv'\n",
        "extract_features(csvpath,train_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_rolloff_test.csv'\n",
        "extract_features(csvpath,test_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_rolloff_val.csv'\n",
        "extract_features(csvpath,val_csv)"
      ],
      "metadata": {
        "id": "OMIFgSsTkvbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_rolloff_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_rolloff_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_rolloff_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "id": "Wcu45KN-Gxhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time = 4\n",
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*time), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "  #out = Conv1D(4,1,activation='softmax')(out)\n",
        "  #out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (24))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  #out2 = Dense(4)(layer2)\n",
        "  #out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out,layer3])\n",
        "  output_layer = Flatten()(output_layer)\n",
        "  output_layer = Dense(4,activation='softmax')(output_layer)\n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled_minusscro = Wavenet()\n",
        "ensembled_minusscro.summary()\n",
        "\n",
        "ensembled_minusscro.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7oc_HyuIvEN",
        "outputId": "07bebcd0-3ccc-4e32-a711-01ffbad96d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d_42 (Conv1D)             (None, 64000, 8)     48          ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_16 (LeakyReLU)     (None, 64000, 8)     0           ['conv1d_42[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_43 (Conv1D)             (None, 64000, 8)     328         ['leaky_re_lu_16[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_17 (LeakyReLU)     (None, 64000, 8)     0           ['conv1d_43[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_8 (AveragePo  (None, 32000, 8)    0           ['leaky_re_lu_17[0][0]']         \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_44 (Conv1D)             (None, 32000, 16)    656         ['average_pooling1d_8[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_18 (LeakyReLU)     (None, 32000, 16)    0           ['conv1d_44[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_45 (Conv1D)             (None, 32000, 16)    1296        ['leaky_re_lu_18[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_19 (LeakyReLU)     (None, 32000, 16)    0           ['conv1d_45[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_9 (AveragePo  (None, 16000, 16)   0           ['leaky_re_lu_19[0][0]']         \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_46 (Conv1D)             (None, 16000, 16)    1296        ['average_pooling1d_9[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_20 (LeakyReLU)     (None, 16000, 16)    0           ['conv1d_46[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_47 (Conv1D)             (None, 16000, 16)    1296        ['leaky_re_lu_20[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_21 (LeakyReLU)     (None, 16000, 16)    0           ['conv1d_47[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_10 (AverageP  (None, 8000, 16)    0           ['leaky_re_lu_21[0][0]']         \n",
            " ooling1D)                                                                                        \n",
            "                                                                                                  \n",
            " conv1d_48 (Conv1D)             (None, 8000, 32)     544         ['average_pooling1d_10[0][0]']   \n",
            "                                                                                                  \n",
            " conv1d_49 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_48[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_50 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_48[0][0]']              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 8000, 64)     0           ['conv1d_49[0][0]']              \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 8000, 64)     0           ['conv1d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 8000, 64)     0           ['activation_14[0][0]',          \n",
            "                                                                  'activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_51 (Conv1D)             (None, 8000, 32)     2080        ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 8000, 32)     0           ['conv1d_48[0][0]',              \n",
            "                                                                  'conv1d_51[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_52 (Conv1D)             (None, 8000, 32)     1056        ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_53 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_52[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_54 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_52[0][0]']              \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 8000, 64)     0           ['conv1d_53[0][0]']              \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 8000, 64)     0           ['conv1d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 8000, 64)     0           ['activation_16[0][0]',          \n",
            "                                                                  'activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_55 (Conv1D)             (None, 8000, 32)     2080        ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 8000, 32)     0           ['conv1d_52[0][0]',              \n",
            "                                                                  'conv1d_55[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_56 (Conv1D)             (None, 8000, 32)     1056        ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_57 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_56[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_58 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_56[0][0]']              \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 8000, 64)     0           ['conv1d_57[0][0]']              \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 8000, 64)     0           ['conv1d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 8000, 64)     0           ['activation_18[0][0]',          \n",
            "                                                                  'activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_59 (Conv1D)             (None, 8000, 32)     2080        ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 8000, 32)     0           ['conv1d_51[0][0]',              \n",
            "                                                                  'conv1d_55[0][0]',              \n",
            "                                                                  'conv1d_59[0][0]']              \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 8000, 32)     0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " average_pooling1d_11 (AverageP  (None, 1, 32)       0           ['activation_20[0][0]']          \n",
            " ooling1D)                                                                                        \n",
            "                                                                                                  \n",
            " permute_8 (Permute)            (None, 32, 1)        0           ['average_pooling1d_11[0][0]']   \n",
            "                                                                                                  \n",
            " conv1d_61 (Conv1D)             (None, 32, 1)        2           ['permute_8[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_60 (Conv1D)             (None, 32, 1)        2           ['permute_8[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_11 (Reshape)           (None, 1, 32)        0           ['conv1d_61[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_10 (Reshape)           (None, 32, 1)        0           ['conv1d_60[0][0]']              \n",
            "                                                                                                  \n",
            " permute_9 (Permute)            (None, 32, 1)        0           ['reshape_11[0][0]']             \n",
            "                                                                                                  \n",
            " dot_4 (Dot)                    (None, 32, 32)       0           ['reshape_10[0][0]',             \n",
            "                                                                  'permute_9[0][0]']              \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 32, 32)       0           ['dot_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_62 (Conv1D)             (None, 32, 1)        2           ['permute_8[0][0]']              \n",
            "                                                                                                  \n",
            " softmax_2 (Softmax)            (None, 32, 32)       0           ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 24)]         0           []                               \n",
            "                                                                                                  \n",
            " reshape_12 (Reshape)           (None, 1, 32)        0           ['conv1d_62[0][0]']              \n",
            "                                                                                                  \n",
            " permute_10 (Permute)           (None, 32, 32)       0           ['softmax_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          3200        ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dot_5 (Dot)                    (None, 1, 32)        0           ['reshape_12[0][0]',             \n",
            "                                                                  'permute_10[0][0]']             \n",
            "                                                                                                  \n",
            " leaky_re_lu_22 (LeakyReLU)     (None, 128)          0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_13 (Reshape)           (None, 32, 1)        0           ['dot_5[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 32)           4128        ['leaky_re_lu_22[0][0]']         \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 32, 1)        0           ['reshape_13[0][0]',             \n",
            "                                                                  'permute_8[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_23 (LeakyReLU)     (None, 32)           0           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " permute_11 (Permute)           (None, 1, 32)        0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " reshape_14 (Reshape)           (None, 1, 32)        0           ['leaky_re_lu_23[0][0]']         \n",
            "                                                                                                  \n",
            " average_2 (Average)            (None, 1, 32)        0           ['permute_11[0][0]',             \n",
            "                                                                  'reshape_14[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 32)           0           ['average_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 4)            132         ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 46,242\n",
            "Trainable params: 46,242\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_minusscro.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMO_DB//models//ensembled_minusscro_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMO_DB//models//ensembled_minusscro_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "ensembled_minusscro.fit([X_train,X_train_features],Y_train, batch_size=16,\n",
        "                        validation_data=([X_val,X_val_features], Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWYSuwYpI3LC",
        "outputId": "539d7d25-6de4-49a8-88ba-10cbe15070a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1938 - accuracy: 0.5316\n",
            "Epoch 1: val_loss improved from inf to 0.97015, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.72549, saving model to EMO_DB//models/ensembled_minusscro_acc.h5\n",
            "15/15 [==============================] - 11s 370ms/step - loss: 1.1938 - accuracy: 0.5316 - val_loss: 0.9702 - val_accuracy: 0.7255\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8407 - accuracy: 0.7257\n",
            "Epoch 2: val_loss improved from 0.97015 to 0.74949, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.72549 to 0.78431, saving model to EMO_DB//models/ensembled_minusscro_acc.h5\n",
            "15/15 [==============================] - 4s 270ms/step - loss: 0.8407 - accuracy: 0.7257 - val_loss: 0.7495 - val_accuracy: 0.7843\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6426 - accuracy: 0.8017\n",
            "Epoch 3: val_loss improved from 0.74949 to 0.61154, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.78431 to 0.80392, saving model to EMO_DB//models/ensembled_minusscro_acc.h5\n",
            "15/15 [==============================] - 4s 269ms/step - loss: 0.6426 - accuracy: 0.8017 - val_loss: 0.6115 - val_accuracy: 0.8039\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5189 - accuracy: 0.8228\n",
            "Epoch 4: val_loss improved from 0.61154 to 0.51790, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.80392\n",
            "15/15 [==============================] - 4s 248ms/step - loss: 0.5189 - accuracy: 0.8228 - val_loss: 0.5179 - val_accuracy: 0.8039\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.8650\n",
            "Epoch 5: val_loss improved from 0.51790 to 0.49203, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.80392\n",
            "15/15 [==============================] - 4s 246ms/step - loss: 0.4256 - accuracy: 0.8650 - val_loss: 0.4920 - val_accuracy: 0.7451\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3723 - accuracy: 0.8734\n",
            "Epoch 6: val_loss improved from 0.49203 to 0.42686, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.80392 to 0.84314, saving model to EMO_DB//models/ensembled_minusscro_acc.h5\n",
            "15/15 [==============================] - 5s 317ms/step - loss: 0.3723 - accuracy: 0.8734 - val_loss: 0.4269 - val_accuracy: 0.8431\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3306 - accuracy: 0.8945\n",
            "Epoch 7: val_loss improved from 0.42686 to 0.40454, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.84314\n",
            "15/15 [==============================] - 4s 240ms/step - loss: 0.3306 - accuracy: 0.8945 - val_loss: 0.4045 - val_accuracy: 0.8431\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2955 - accuracy: 0.9198\n",
            "Epoch 8: val_loss improved from 0.40454 to 0.38187, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.84314 to 0.86275, saving model to EMO_DB//models/ensembled_minusscro_acc.h5\n",
            "15/15 [==============================] - 4s 252ms/step - loss: 0.2955 - accuracy: 0.9198 - val_loss: 0.3819 - val_accuracy: 0.8627\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.9114\n",
            "Epoch 9: val_loss improved from 0.38187 to 0.36543, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 233ms/step - loss: 0.2849 - accuracy: 0.9114 - val_loss: 0.3654 - val_accuracy: 0.8627\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2591 - accuracy: 0.9198\n",
            "Epoch 10: val_loss improved from 0.36543 to 0.34045, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.86275 to 0.88235, saving model to EMO_DB//models/ensembled_minusscro_acc.h5\n",
            "15/15 [==============================] - 4s 295ms/step - loss: 0.2591 - accuracy: 0.9198 - val_loss: 0.3405 - val_accuracy: 0.8824\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.9409\n",
            "Epoch 11: val_loss improved from 0.34045 to 0.33530, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.2383 - accuracy: 0.9409 - val_loss: 0.3353 - val_accuracy: 0.8431\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.9494\n",
            "Epoch 12: val_loss improved from 0.33530 to 0.32567, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 4s 237ms/step - loss: 0.2201 - accuracy: 0.9494 - val_loss: 0.3257 - val_accuracy: 0.8824\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.9494\n",
            "Epoch 13: val_loss improved from 0.32567 to 0.30806, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.2047 - accuracy: 0.9494 - val_loss: 0.3081 - val_accuracy: 0.8627\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.9367\n",
            "Epoch 14: val_loss improved from 0.30806 to 0.29143, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.2096 - accuracy: 0.9367 - val_loss: 0.2914 - val_accuracy: 0.8824\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.9494\n",
            "Epoch 15: val_loss did not improve from 0.29143\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.1871 - accuracy: 0.9494 - val_loss: 0.3367 - val_accuracy: 0.8627\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.9494\n",
            "Epoch 16: val_loss improved from 0.29143 to 0.26789, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.88235 to 0.90196, saving model to EMO_DB//models/ensembled_minusscro_acc.h5\n",
            "15/15 [==============================] - 4s 288ms/step - loss: 0.1807 - accuracy: 0.9494 - val_loss: 0.2679 - val_accuracy: 0.9020\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9578\n",
            "Epoch 17: val_loss did not improve from 0.26789\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.1717 - accuracy: 0.9578 - val_loss: 0.2995 - val_accuracy: 0.8824\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.9578\n",
            "Epoch 18: val_loss improved from 0.26789 to 0.26763, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 237ms/step - loss: 0.1592 - accuracy: 0.9578 - val_loss: 0.2676 - val_accuracy: 0.9020\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.9578\n",
            "Epoch 19: val_loss did not improve from 0.26763\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 217ms/step - loss: 0.1578 - accuracy: 0.9578 - val_loss: 0.2817 - val_accuracy: 0.9020\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1500 - accuracy: 0.9620\n",
            "Epoch 20: val_loss did not improve from 0.26763\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.1500 - accuracy: 0.9620 - val_loss: 0.2877 - val_accuracy: 0.8627\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1449 - accuracy: 0.9620\n",
            "Epoch 21: val_loss did not improve from 0.26763\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.1449 - accuracy: 0.9620 - val_loss: 0.2809 - val_accuracy: 0.9020\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.9536\n",
            "Epoch 22: val_loss improved from 0.26763 to 0.24423, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 271ms/step - loss: 0.1448 - accuracy: 0.9536 - val_loss: 0.2442 - val_accuracy: 0.9020\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1326 - accuracy: 0.9789\n",
            "Epoch 23: val_loss did not improve from 0.24423\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 217ms/step - loss: 0.1326 - accuracy: 0.9789 - val_loss: 0.2578 - val_accuracy: 0.8824\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.9578\n",
            "Epoch 24: val_loss improved from 0.24423 to 0.24379, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.1302 - accuracy: 0.9578 - val_loss: 0.2438 - val_accuracy: 0.9020\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9705\n",
            "Epoch 25: val_loss improved from 0.24379 to 0.23404, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 245ms/step - loss: 0.1243 - accuracy: 0.9705 - val_loss: 0.2340 - val_accuracy: 0.8824\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9620\n",
            "Epoch 26: val_loss did not improve from 0.23404\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 222ms/step - loss: 0.1125 - accuracy: 0.9620 - val_loss: 0.2726 - val_accuracy: 0.8824\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9789\n",
            "Epoch 27: val_loss improved from 0.23404 to 0.22588, saving model to EMO_DB//models/ensembled_minusscro_loss.h5\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.1129 - accuracy: 0.9789 - val_loss: 0.2259 - val_accuracy: 0.9020\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9789\n",
            "Epoch 28: val_loss did not improve from 0.22588\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 0.1101 - accuracy: 0.9789 - val_loss: 0.2434 - val_accuracy: 0.8627\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.9789\n",
            "Epoch 29: val_loss did not improve from 0.22588\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.1088 - accuracy: 0.9789 - val_loss: 0.2417 - val_accuracy: 0.8627\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9789\n",
            "Epoch 30: val_loss did not improve from 0.22588\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.1031 - accuracy: 0.9789 - val_loss: 0.2362 - val_accuracy: 0.9020\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b4577acd0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_minusscro.save_weights('EMO_DB//models//ensembled_minusscro.h5')\n",
        "print(ensembled_minusscro.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_minusscro.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_minusscro.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "MZqJEXKvJf2D",
        "outputId": "3930b466-35fc-435b-c0dc-df0d44bf7c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 129ms/step - loss: 0.1296 - accuracy: 0.9400\n",
            "[0.1296497881412506, 0.9399999976158142]\n",
            "F1 SCORE: 0.9234363081617087\n",
            "Kappa: 0.912536443148688\n",
            "Accuracy: 0.94\n",
            "Jaccard Score: 0.8619047619047618\n",
            "Precision: 0.9583333333333333\n",
            "Recall: 0.9035714285714286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8aced15710>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_minusscro.load_weights('EMO_DB//models//ensembled_minusscro_loss.h5')\n",
        "print(ensembled_minusscro.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_minusscro.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_minusscro.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "EDy9Dx3EMR7x",
        "outputId": "4dc893d0-6544-4171-aafd-917694b9f660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 102ms/step - loss: 0.1440 - accuracy: 0.9400\n",
            "[0.14403213560581207, 0.9399999976158142]\n",
            "F1 SCORE: 0.9236542443064182\n",
            "Kappa: 0.912638322655795\n",
            "Accuracy: 0.94\n",
            "Jaccard Score: 0.8622835497835498\n",
            "Precision: 0.9564393939393939\n",
            "Recall: 0.9058441558441559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8acd4c7ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_minusscro.load_weights('EMO_DB//models//ensembled_minusscro_acc.h5')\n",
        "print(ensembled_minusscro.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_minusscro.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_minusscro.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "2iZSX4nANPHs",
        "outputId": "5fa68dce-fe71-49c1-a094-e80abe62d7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 102ms/step - loss: 0.1909 - accuracy: 0.9200\n",
            "[0.19090396165847778, 0.9200000166893005]\n",
            "F1 SCORE: 0.9018315018315017\n",
            "Kappa: 0.8845265588914549\n",
            "Accuracy: 0.92\n",
            "Jaccard Score: 0.8295454545454546\n",
            "Precision: 0.9138669301712781\n",
            "Recall: 0.8944805194805195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8acd4b5310>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hCwngBN3NTuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MFCC  + chroma stft + rmse + spectral bw + roll off"
      ],
      "metadata": {
        "id": "kFObsoHqQax5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#angry, happy, neutral, sad\n",
        "import csv\n",
        "\n",
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "\n",
        "def extract_features(csvpath,path):\n",
        "    header = 'filename chroma_stft rmse spectral_bandwidth rolloff'\n",
        "    for i in range(1, 21):\n",
        "        header += f' mfcc{i}'\n",
        "    header += ' label'\n",
        "    header = header.split()\n",
        "    file = open(csvpath, 'w', newline='')\n",
        "    with file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow(header)\n",
        "    rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "        filename = row['path']\n",
        "        y, sr = librosa.load(row['path'], mono=True, duration=30)\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "        rmse = librosa.feature.rms(y=y)\n",
        "        #spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "        #zcr = librosa.feature.zero_crossing_rate(y)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "        to_append = f' {filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_bw)} {np.mean(rolloff)}'    \n",
        "        for e in mfcc:\n",
        "                    to_append += f' {np.mean(e)}'\n",
        "        onehot_label = label_to_onehot(row['labels'])\n",
        "        to_append += f' {np.argmax(onehot_label)}'\n",
        "        file = open(csvpath, 'a', newline='')\n",
        "        with file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow(to_append.split())\n",
        "\n",
        "train_csv = \"EMO_DB//train.csv\"\n",
        "test_csv = \"EMO_DB//test.csv\"\n",
        "val_csv = \"EMO_DB//val.csv\"\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_zcr_train.csv'\n",
        "extract_features(csvpath,train_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_zcr_test.csv'\n",
        "extract_features(csvpath,test_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_zcr_val.csv'\n",
        "extract_features(csvpath,val_csv)"
      ],
      "metadata": {
        "id": "qw0UiLprQhHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_zcr_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_zcr_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_zcr_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rITfgDyXYbH9",
        "outputId": "64c39c6d-f53e-4286-bb60-9e884b7aa0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 24) (237, 1)\n",
            "(50, 24) (50, 1)\n",
            "(51, 24) (51, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time = 4\n",
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*time), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "  #out = Conv1D(4,1,activation='softmax')(out)\n",
        "  #out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (24))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  #out2 = Dense(4)(layer2)\n",
        "  #out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out,layer3])\n",
        "  output_layer = Flatten()(output_layer)\n",
        "  output_layer = Dense(4,activation='softmax')(output_layer)\n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled_minussczcr = Wavenet()\n",
        "ensembled_minussczcr.summary()\n",
        "\n",
        "ensembled_minussczcr.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju2A7CoJY77Y",
        "outputId": "2faef1d2-8e28-4c64-81f9-c60505dd9532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 64000, 8)     48          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 64000, 8)     0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 64000, 8)     328         ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 64000, 8)     0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d (AveragePool  (None, 32000, 8)    0           ['leaky_re_lu_1[0][0]']          \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 32000, 16)    656         ['average_pooling1d[0][0]']      \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 32000, 16)    0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 32000, 16)    1296        ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 32000, 16)    0           ['conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d_1 (AveragePo  (None, 16000, 16)   0           ['leaky_re_lu_3[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 16000, 16)    1296        ['average_pooling1d_1[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 16000, 16)    0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 16000, 16)    1296        ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 16000, 16)    0           ['conv1d_5[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d_2 (AveragePo  (None, 8000, 16)    0           ['leaky_re_lu_5[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 8000, 32)     544         ['average_pooling1d_2[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 8000, 64)     4160        ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 8000, 64)     4160        ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 8000, 64)     0           ['conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 8000, 64)     0           ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 8000, 64)     0           ['activation[0][0]',             \n",
            "                                                                  'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 8000, 32)     2080        ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 8000, 32)     0           ['conv1d_6[0][0]',               \n",
            "                                                                  'conv1d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 8000, 32)     1056        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 8000, 64)     0           ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 8000, 64)     0           ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 8000, 64)     0           ['activation_2[0][0]',           \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 8000, 32)     2080        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 8000, 32)     0           ['conv1d_10[0][0]',              \n",
            "                                                                  'conv1d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 8000, 32)     1056        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 8000, 64)     0           ['conv1d_15[0][0]']              \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 8000, 64)     0           ['conv1d_16[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 8000, 64)     0           ['activation_4[0][0]',           \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 8000, 32)     2080        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 8000, 32)     0           ['conv1d_9[0][0]',               \n",
            "                                                                  'conv1d_13[0][0]',              \n",
            "                                                                  'conv1d_17[0][0]']              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 8000, 32)     0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling1d_3 (AveragePo  (None, 1, 32)       0           ['activation_6[0][0]']           \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 32, 1)        0           ['average_pooling1d_3[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 32)        0           ['conv1d_19[0][0]']              \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 32, 1)        0           ['conv1d_18[0][0]']              \n",
            "                                                                                                  \n",
            " permute_1 (Permute)            (None, 32, 1)        0           ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 32, 32)       0           ['reshape[0][0]',                \n",
            "                                                                  'permute_1[0][0]']              \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 32, 32)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " softmax (Softmax)              (None, 32, 32)       0           ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 24)]         0           []                               \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 32)        0           ['conv1d_20[0][0]']              \n",
            "                                                                                                  \n",
            " permute_2 (Permute)            (None, 32, 32)       0           ['softmax[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          3200        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 1, 32)        0           ['reshape_2[0][0]',              \n",
            "                                                                  'permute_2[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 32, 1)        0           ['dot_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 32, 1)        0           ['reshape_3[0][0]',              \n",
            "                                                                  'permute[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 32)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " permute_3 (Permute)            (None, 1, 32)        0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)            (None, 1, 32)        0           ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " average (Average)              (None, 1, 32)        0           ['permute_3[0][0]',              \n",
            "                                                                  'reshape_4[0][0]']              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 32)           0           ['average[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            132         ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 46,242\n",
            "Trainable params: 46,242\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_minussczcr.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMO_DB//models//ensembled_minussczcr_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMO_DB//models//ensembled_minussczcr_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "ensembled_minussczcr.fit([X_train,X_train_features],Y_train, batch_size=16,\n",
        "                        validation_data=([X_val,X_val_features], Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa78LeBlZL_K",
        "outputId": "b5ddcf15-5a12-48fb-b1ca-8fc7514fa88f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1911 - accuracy: 0.5190\n",
            "Epoch 1: val_loss improved from inf to 0.97256, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.70588, saving model to EMO_DB//models/ensembled_minussczcr_acc.h5\n",
            "15/15 [==============================] - 21s 427ms/step - loss: 1.1911 - accuracy: 0.5190 - val_loss: 0.9726 - val_accuracy: 0.7059\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8396 - accuracy: 0.7468\n",
            "Epoch 2: val_loss improved from 0.97256 to 0.75326, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.70588 to 0.78431, saving model to EMO_DB//models/ensembled_minussczcr_acc.h5\n",
            "15/15 [==============================] - 4s 249ms/step - loss: 0.8396 - accuracy: 0.7468 - val_loss: 0.7533 - val_accuracy: 0.7843\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6612 - accuracy: 0.8101\n",
            "Epoch 3: val_loss improved from 0.75326 to 0.63122, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.78431 to 0.80392, saving model to EMO_DB//models/ensembled_minussczcr_acc.h5\n",
            "15/15 [==============================] - 4s 249ms/step - loss: 0.6612 - accuracy: 0.8101 - val_loss: 0.6312 - val_accuracy: 0.8039\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5477 - accuracy: 0.8228\n",
            "Epoch 4: val_loss improved from 0.63122 to 0.53888, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.80392 to 0.82353, saving model to EMO_DB//models/ensembled_minussczcr_acc.h5\n",
            "15/15 [==============================] - 4s 249ms/step - loss: 0.5477 - accuracy: 0.8228 - val_loss: 0.5389 - val_accuracy: 0.8235\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4625 - accuracy: 0.8354\n",
            "Epoch 5: val_loss improved from 0.53888 to 0.46444, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.82353\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.4625 - accuracy: 0.8354 - val_loss: 0.4644 - val_accuracy: 0.8039\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8692\n",
            "Epoch 6: val_loss improved from 0.46444 to 0.43997, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.82353\n",
            "15/15 [==============================] - 3s 233ms/step - loss: 0.3876 - accuracy: 0.8692 - val_loss: 0.4400 - val_accuracy: 0.8039\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3412 - accuracy: 0.8987\n",
            "Epoch 7: val_loss improved from 0.43997 to 0.38420, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.82353\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.3412 - accuracy: 0.8987 - val_loss: 0.3842 - val_accuracy: 0.8235\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.9114\n",
            "Epoch 8: val_loss improved from 0.38420 to 0.37891, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.82353\n",
            "15/15 [==============================] - 3s 233ms/step - loss: 0.2976 - accuracy: 0.9114 - val_loss: 0.3789 - val_accuracy: 0.8039\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2648 - accuracy: 0.9241\n",
            "Epoch 9: val_loss improved from 0.37891 to 0.37437, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.82353 to 0.84314, saving model to EMO_DB//models/ensembled_minussczcr_acc.h5\n",
            "15/15 [==============================] - 4s 276ms/step - loss: 0.2648 - accuracy: 0.9241 - val_loss: 0.3744 - val_accuracy: 0.8431\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.9283\n",
            "Epoch 10: val_loss improved from 0.37437 to 0.35417, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.84314\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.2475 - accuracy: 0.9283 - val_loss: 0.3542 - val_accuracy: 0.8431\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2275 - accuracy: 0.9409\n",
            "Epoch 11: val_loss improved from 0.35417 to 0.32294, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.84314\n",
            "15/15 [==============================] - 3s 236ms/step - loss: 0.2275 - accuracy: 0.9409 - val_loss: 0.3229 - val_accuracy: 0.8431\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.9494\n",
            "Epoch 12: val_loss improved from 0.32294 to 0.30797, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.84314 to 0.86275, saving model to EMO_DB//models/ensembled_minussczcr_acc.h5\n",
            "15/15 [==============================] - 4s 283ms/step - loss: 0.2133 - accuracy: 0.9494 - val_loss: 0.3080 - val_accuracy: 0.8627\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2025 - accuracy: 0.9409\n",
            "Epoch 13: val_loss improved from 0.30797 to 0.29543, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.2025 - accuracy: 0.9409 - val_loss: 0.2954 - val_accuracy: 0.8431\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.9494\n",
            "Epoch 14: val_loss improved from 0.29543 to 0.28903, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 233ms/step - loss: 0.1907 - accuracy: 0.9494 - val_loss: 0.2890 - val_accuracy: 0.8431\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.9662\n",
            "Epoch 15: val_loss did not improve from 0.28903\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 217ms/step - loss: 0.1783 - accuracy: 0.9662 - val_loss: 0.2937 - val_accuracy: 0.8431\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9536\n",
            "Epoch 16: val_loss improved from 0.28903 to 0.28721, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.1744 - accuracy: 0.9536 - val_loss: 0.2872 - val_accuracy: 0.8431\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9578\n",
            "Epoch 17: val_loss improved from 0.28721 to 0.27727, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.1582 - accuracy: 0.9578 - val_loss: 0.2773 - val_accuracy: 0.8627\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1531 - accuracy: 0.9662\n",
            "Epoch 18: val_loss did not improve from 0.27727\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 217ms/step - loss: 0.1531 - accuracy: 0.9662 - val_loss: 0.2877 - val_accuracy: 0.8627\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1461 - accuracy: 0.9662\n",
            "Epoch 19: val_loss improved from 0.27727 to 0.27294, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.1461 - accuracy: 0.9662 - val_loss: 0.2729 - val_accuracy: 0.8627\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.9662\n",
            "Epoch 20: val_loss did not improve from 0.27294\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 217ms/step - loss: 0.1469 - accuracy: 0.9662 - val_loss: 0.3024 - val_accuracy: 0.8235\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1475 - accuracy: 0.9620\n",
            "Epoch 21: val_loss did not improve from 0.27294\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 217ms/step - loss: 0.1475 - accuracy: 0.9620 - val_loss: 0.3269 - val_accuracy: 0.8235\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9578\n",
            "Epoch 22: val_loss improved from 0.27294 to 0.26122, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 4s 264ms/step - loss: 0.1362 - accuracy: 0.9578 - val_loss: 0.2612 - val_accuracy: 0.8431\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9747\n",
            "Epoch 23: val_loss did not improve from 0.26122\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.1200 - accuracy: 0.9747 - val_loss: 0.2733 - val_accuracy: 0.8431\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 0.9789\n",
            "Epoch 24: val_loss did not improve from 0.26122\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.1177 - accuracy: 0.9789 - val_loss: 0.2654 - val_accuracy: 0.8627\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9620\n",
            "Epoch 25: val_loss improved from 0.26122 to 0.23846, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 236ms/step - loss: 0.1229 - accuracy: 0.9620 - val_loss: 0.2385 - val_accuracy: 0.8431\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9789\n",
            "Epoch 26: val_loss did not improve from 0.23846\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.1212 - accuracy: 0.9789 - val_loss: 0.2467 - val_accuracy: 0.8627\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.9789\n",
            "Epoch 27: val_loss improved from 0.23846 to 0.23654, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 235ms/step - loss: 0.1110 - accuracy: 0.9789 - val_loss: 0.2365 - val_accuracy: 0.8235\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9747\n",
            "Epoch 28: val_loss did not improve from 0.23654\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.1029 - accuracy: 0.9747 - val_loss: 0.2607 - val_accuracy: 0.8431\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9831\n",
            "Epoch 29: val_loss did not improve from 0.23654\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.1024 - accuracy: 0.9831 - val_loss: 0.2467 - val_accuracy: 0.8431\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9789\n",
            "Epoch 30: val_loss improved from 0.23654 to 0.22055, saving model to EMO_DB//models/ensembled_minussczcr_loss.h5\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.86275\n",
            "15/15 [==============================] - 4s 277ms/step - loss: 0.0973 - accuracy: 0.9789 - val_loss: 0.2205 - val_accuracy: 0.8627\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7facb33d24d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_minussczcr.load_weights('EMO_DB//models//ensembled_minussczcr_loss.h5')\n",
        "print(ensembled_minussczcr.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_minussczcr.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_minussczcr.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "HxWXBbqCZaCm",
        "outputId": "331d4d5a-37e4-4aa8-875d-402b3162c0b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 461ms/step - loss: 0.1147 - accuracy: 0.9600\n",
            "[0.11469070613384247, 0.9599999785423279]\n",
            "F1 SCORE: 0.9537098560354376\n",
            "Kappa: 0.9432463110102156\n",
            "Accuracy: 0.96\n",
            "Jaccard Score: 0.9119318181818182\n",
            "Precision: 0.9460227272727273\n",
            "Recall: 0.9659090909090909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fac2a872650>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_minussczcr.load_weights('EMO_DB//models//ensembled_minussczcr_acc.h5')\n",
        "print(ensembled_minussczcr.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_minussczcr.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_minussczcr.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "Q0xR5RTzZa1u",
        "outputId": "ba3aa563-b97e-43b1-85c2-db17627c6051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 111ms/step - loss: 0.1773 - accuracy: 0.9200\n",
            "[0.17726950347423553, 0.9200000166893005]\n",
            "F1 SCORE: 0.9018315018315017\n",
            "Kappa: 0.8845265588914549\n",
            "Accuracy: 0.92\n",
            "Jaccard Score: 0.8295454545454546\n",
            "Precision: 0.9138669301712781\n",
            "Recall: 0.8944805194805195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fac2aad4690>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MINUS sc"
      ],
      "metadata": {
        "id": "htpWYl5wbDqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#angry, happy, neutral, sad\n",
        "import csv\n",
        "\n",
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "\n",
        "def extract_features(csvpath,path):\n",
        "    header = 'filename chroma_stft rmse spectral_bandwidth rolloff zero_crossing_rate'\n",
        "    for i in range(1, 21):\n",
        "        header += f' mfcc{i}'\n",
        "    header += ' label'\n",
        "    header = header.split()\n",
        "    file = open(csvpath, 'w', newline='')\n",
        "    with file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow(header)\n",
        "    rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "        filename = row['path']\n",
        "        y, sr = librosa.load(row['path'], mono=True, duration=30)\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "        rmse = librosa.feature.rms(y=y)\n",
        "        #spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "        to_append = f' {filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
        "        for e in mfcc:\n",
        "                    to_append += f' {np.mean(e)}'\n",
        "        onehot_label = label_to_onehot(row['labels'])\n",
        "        to_append += f' {np.argmax(onehot_label)}'\n",
        "        file = open(csvpath, 'a', newline='')\n",
        "        with file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow(to_append.split())\n",
        "\n",
        "train_csv = \"EMO_DB//train.csv\"\n",
        "test_csv = \"EMO_DB//test.csv\"\n",
        "val_csv = \"EMO_DB//val.csv\"\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_train.csv'\n",
        "extract_features(csvpath,train_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_test.csv'\n",
        "extract_features(csvpath,test_csv)\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_val.csv'\n",
        "extract_features(csvpath,val_csv)"
      ],
      "metadata": {
        "id": "EVmjLnQmayYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB//hand_engineered_features_minus_sc_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6RDRwWUb8uK",
        "outputId": "e9767295-57b1-4cf5-a21a-7962c81c23b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 25) (237, 1)\n",
            "(50, 25) (50, 1)\n",
            "(51, 25) (51, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time = 4\n",
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*time), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "  #out = Conv1D(4,1,activation='softmax')(out)\n",
        "  #out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (25))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  #out2 = Dense(4)(layer2)\n",
        "  #out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out,layer3])\n",
        "  output_layer = Flatten()(output_layer)\n",
        "  output_layer = Dense(4,activation='softmax')(output_layer)\n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled_minussc = Wavenet()\n",
        "ensembled_minussc.summary()\n",
        "\n",
        "ensembled_minussc.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLzln-lPcDIM",
        "outputId": "ed71605c-f102-49b6-8983-054180a07011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d_21 (Conv1D)             (None, 64000, 8)     48          ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 64000, 8)     0           ['conv1d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_22 (Conv1D)             (None, 64000, 8)     328         ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 64000, 8)     0           ['conv1d_22[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_4 (AveragePo  (None, 32000, 8)    0           ['leaky_re_lu_9[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_23 (Conv1D)             (None, 32000, 16)    656         ['average_pooling1d_4[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 32000, 16)    0           ['conv1d_23[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_24 (Conv1D)             (None, 32000, 16)    1296        ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 32000, 16)    0           ['conv1d_24[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_5 (AveragePo  (None, 16000, 16)   0           ['leaky_re_lu_11[0][0]']         \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_25 (Conv1D)             (None, 16000, 16)    1296        ['average_pooling1d_5[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)     (None, 16000, 16)    0           ['conv1d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_26 (Conv1D)             (None, 16000, 16)    1296        ['leaky_re_lu_12[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_13 (LeakyReLU)     (None, 16000, 16)    0           ['conv1d_26[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_6 (AveragePo  (None, 8000, 16)    0           ['leaky_re_lu_13[0][0]']         \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_27 (Conv1D)             (None, 8000, 32)     544         ['average_pooling1d_6[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_28 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_27[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_29 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_27[0][0]']              \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 8000, 64)     0           ['conv1d_28[0][0]']              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 8000, 64)     0           ['conv1d_29[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 8000, 64)     0           ['activation_7[0][0]',           \n",
            "                                                                  'activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_30 (Conv1D)             (None, 8000, 32)     2080        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 8000, 32)     0           ['conv1d_27[0][0]',              \n",
            "                                                                  'conv1d_30[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_31 (Conv1D)             (None, 8000, 32)     1056        ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_32 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_31[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_33 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_31[0][0]']              \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 8000, 64)     0           ['conv1d_32[0][0]']              \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 8000, 64)     0           ['conv1d_33[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 8000, 64)     0           ['activation_9[0][0]',           \n",
            "                                                                  'activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_34 (Conv1D)             (None, 8000, 32)     2080        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 8000, 32)     0           ['conv1d_31[0][0]',              \n",
            "                                                                  'conv1d_34[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_35 (Conv1D)             (None, 8000, 32)     1056        ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_36 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_35[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_37 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_35[0][0]']              \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 8000, 64)     0           ['conv1d_36[0][0]']              \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 8000, 64)     0           ['conv1d_37[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 8000, 64)     0           ['activation_11[0][0]',          \n",
            "                                                                  'activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_38 (Conv1D)             (None, 8000, 32)     2080        ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 8000, 32)     0           ['conv1d_30[0][0]',              \n",
            "                                                                  'conv1d_34[0][0]',              \n",
            "                                                                  'conv1d_38[0][0]']              \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 8000, 32)     0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling1d_7 (AveragePo  (None, 1, 32)       0           ['activation_13[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " permute_4 (Permute)            (None, 32, 1)        0           ['average_pooling1d_7[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_40 (Conv1D)             (None, 32, 1)        2           ['permute_4[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_39 (Conv1D)             (None, 32, 1)        2           ['permute_4[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_6 (Reshape)            (None, 1, 32)        0           ['conv1d_40[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)            (None, 32, 1)        0           ['conv1d_39[0][0]']              \n",
            "                                                                                                  \n",
            " permute_5 (Permute)            (None, 32, 1)        0           ['reshape_6[0][0]']              \n",
            "                                                                                                  \n",
            " dot_2 (Dot)                    (None, 32, 32)       0           ['reshape_5[0][0]',              \n",
            "                                                                  'permute_5[0][0]']              \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 32, 32)       0           ['dot_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_41 (Conv1D)             (None, 32, 1)        2           ['permute_4[0][0]']              \n",
            "                                                                                                  \n",
            " softmax_1 (Softmax)            (None, 32, 32)       0           ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 25)]         0           []                               \n",
            "                                                                                                  \n",
            " reshape_7 (Reshape)            (None, 1, 32)        0           ['conv1d_41[0][0]']              \n",
            "                                                                                                  \n",
            " permute_6 (Permute)            (None, 32, 32)       0           ['softmax_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          3328        ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dot_3 (Dot)                    (None, 1, 32)        0           ['reshape_7[0][0]',              \n",
            "                                                                  'permute_6[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_14 (LeakyReLU)     (None, 128)          0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_8 (Reshape)            (None, 32, 1)        0           ['dot_3[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 32)           4128        ['leaky_re_lu_14[0][0]']         \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 32, 1)        0           ['reshape_8[0][0]',              \n",
            "                                                                  'permute_4[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_15 (LeakyReLU)     (None, 32)           0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " permute_7 (Permute)            (None, 1, 32)        0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_9 (Reshape)            (None, 1, 32)        0           ['leaky_re_lu_15[0][0]']         \n",
            "                                                                                                  \n",
            " average_1 (Average)            (None, 1, 32)        0           ['permute_7[0][0]',              \n",
            "                                                                  'reshape_9[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 32)           0           ['average_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 4)            132         ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 46,370\n",
            "Trainable params: 46,370\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_minussc.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('EMO_DB//models//ensembled_minussc_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('EMO_DB//models//ensembled_minussc_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "ensembled_minussc.fit([X_train,X_train_features],Y_train, batch_size=16,\n",
        "                        validation_data=([X_val,X_val_features], Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltt1R0elcM3q",
        "outputId": "0501fee5-48c1-4a82-ca17-c0eeecc98ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2579 - accuracy: 0.4557\n",
            "Epoch 1: val_loss improved from inf to 1.05754, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.70588, saving model to EMO_DB//models/ensembled_minussc_acc.h5\n",
            "15/15 [==============================] - 13s 429ms/step - loss: 1.2579 - accuracy: 0.4557 - val_loss: 1.0575 - val_accuracy: 0.7059\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8852 - accuracy: 0.7257\n",
            "Epoch 2: val_loss improved from 1.05754 to 0.84097, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.70588 to 0.78431, saving model to EMO_DB//models/ensembled_minussc_acc.h5\n",
            "15/15 [==============================] - 4s 289ms/step - loss: 0.8852 - accuracy: 0.7257 - val_loss: 0.8410 - val_accuracy: 0.7843\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.7553\n",
            "Epoch 3: val_loss improved from 0.84097 to 0.67317, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.78431\n",
            "15/15 [==============================] - 4s 252ms/step - loss: 0.6857 - accuracy: 0.7553 - val_loss: 0.6732 - val_accuracy: 0.7647\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5692 - accuracy: 0.8228\n",
            "Epoch 4: val_loss improved from 0.67317 to 0.56088, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.78431 to 0.80392, saving model to EMO_DB//models/ensembled_minussc_acc.h5\n",
            "15/15 [==============================] - 4s 276ms/step - loss: 0.5692 - accuracy: 0.8228 - val_loss: 0.5609 - val_accuracy: 0.8039\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4767 - accuracy: 0.8354\n",
            "Epoch 5: val_loss improved from 0.56088 to 0.50842, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.80392 to 0.84314, saving model to EMO_DB//models/ensembled_minussc_acc.h5\n",
            "15/15 [==============================] - 4s 270ms/step - loss: 0.4767 - accuracy: 0.8354 - val_loss: 0.5084 - val_accuracy: 0.8431\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4182 - accuracy: 0.8565\n",
            "Epoch 6: val_loss improved from 0.50842 to 0.45447, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.84314 to 0.86275, saving model to EMO_DB//models/ensembled_minussc_acc.h5\n",
            "15/15 [==============================] - 5s 336ms/step - loss: 0.4182 - accuracy: 0.8565 - val_loss: 0.4545 - val_accuracy: 0.8627\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3793 - accuracy: 0.8734\n",
            "Epoch 7: val_loss improved from 0.45447 to 0.41986, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.86275 to 0.88235, saving model to EMO_DB//models/ensembled_minussc_acc.h5\n",
            "15/15 [==============================] - 4s 276ms/step - loss: 0.3793 - accuracy: 0.8734 - val_loss: 0.4199 - val_accuracy: 0.8824\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.8819\n",
            "Epoch 8: val_loss did not improve from 0.41986\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 226ms/step - loss: 0.3333 - accuracy: 0.8819 - val_loss: 0.4206 - val_accuracy: 0.8431\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.9114\n",
            "Epoch 9: val_loss improved from 0.41986 to 0.38605, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 4s 247ms/step - loss: 0.3132 - accuracy: 0.9114 - val_loss: 0.3860 - val_accuracy: 0.8627\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2904 - accuracy: 0.9114\n",
            "Epoch 10: val_loss did not improve from 0.38605\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 226ms/step - loss: 0.2904 - accuracy: 0.9114 - val_loss: 0.4138 - val_accuracy: 0.8235\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.9114\n",
            "Epoch 11: val_loss improved from 0.38605 to 0.34174, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 4s 248ms/step - loss: 0.2665 - accuracy: 0.9114 - val_loss: 0.3417 - val_accuracy: 0.8824\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2524 - accuracy: 0.9283\n",
            "Epoch 12: val_loss did not improve from 0.34174\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.2524 - accuracy: 0.9283 - val_loss: 0.3525 - val_accuracy: 0.8627\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.9325\n",
            "Epoch 13: val_loss improved from 0.34174 to 0.33512, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 4s 252ms/step - loss: 0.2368 - accuracy: 0.9325 - val_loss: 0.3351 - val_accuracy: 0.8824\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.9367\n",
            "Epoch 14: val_loss did not improve from 0.33512\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.88235\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.2165 - accuracy: 0.9367 - val_loss: 0.3695 - val_accuracy: 0.8431\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9325\n",
            "Epoch 15: val_loss improved from 0.33512 to 0.29432, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.88235 to 0.90196, saving model to EMO_DB//models/ensembled_minussc_acc.h5\n",
            "15/15 [==============================] - 4s 299ms/step - loss: 0.2135 - accuracy: 0.9325 - val_loss: 0.2943 - val_accuracy: 0.9020\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1983 - accuracy: 0.9578\n",
            "Epoch 16: val_loss did not improve from 0.29432\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.1983 - accuracy: 0.9578 - val_loss: 0.3271 - val_accuracy: 0.8824\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.9451\n",
            "Epoch 17: val_loss did not improve from 0.29432\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.1928 - accuracy: 0.9451 - val_loss: 0.2956 - val_accuracy: 0.8627\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9536\n",
            "Epoch 18: val_loss did not improve from 0.29432\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 224ms/step - loss: 0.1748 - accuracy: 0.9536 - val_loss: 0.3192 - val_accuracy: 0.8627\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1799 - accuracy: 0.9536\n",
            "Epoch 19: val_loss did not improve from 0.29432\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.1799 - accuracy: 0.9536 - val_loss: 0.2996 - val_accuracy: 0.8627\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1649 - accuracy: 0.9578\n",
            "Epoch 20: val_loss improved from 0.29432 to 0.27918, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 293ms/step - loss: 0.1649 - accuracy: 0.9578 - val_loss: 0.2792 - val_accuracy: 0.8824\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1555 - accuracy: 0.9662\n",
            "Epoch 21: val_loss did not improve from 0.27918\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 223ms/step - loss: 0.1555 - accuracy: 0.9662 - val_loss: 0.2923 - val_accuracy: 0.8627\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.9705\n",
            "Epoch 22: val_loss did not improve from 0.27918\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.1469 - accuracy: 0.9705 - val_loss: 0.2898 - val_accuracy: 0.8627\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.9578\n",
            "Epoch 23: val_loss did not improve from 0.27918\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.1472 - accuracy: 0.9578 - val_loss: 0.2844 - val_accuracy: 0.8627\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.9705\n",
            "Epoch 24: val_loss improved from 0.27918 to 0.25642, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 270ms/step - loss: 0.1368 - accuracy: 0.9705 - val_loss: 0.2564 - val_accuracy: 0.8824\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 0.9662\n",
            "Epoch 25: val_loss did not improve from 0.25642\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.1340 - accuracy: 0.9662 - val_loss: 0.2893 - val_accuracy: 0.8431\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9662\n",
            "Epoch 26: val_loss improved from 0.25642 to 0.23339, saving model to EMO_DB//models/ensembled_minussc_loss.h5\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 4s 238ms/step - loss: 0.1321 - accuracy: 0.9662 - val_loss: 0.2334 - val_accuracy: 0.8824\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.9705\n",
            "Epoch 27: val_loss did not improve from 0.23339\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.1223 - accuracy: 0.9705 - val_loss: 0.2907 - val_accuracy: 0.8431\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9662\n",
            "Epoch 28: val_loss did not improve from 0.23339\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.1238 - accuracy: 0.9662 - val_loss: 0.2388 - val_accuracy: 0.8824\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 0.9662\n",
            "Epoch 29: val_loss did not improve from 0.23339\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.1177 - accuracy: 0.9662 - val_loss: 0.2427 - val_accuracy: 0.8627\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1123 - accuracy: 0.9705\n",
            "Epoch 30: val_loss did not improve from 0.23339\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.90196\n",
            "15/15 [==============================] - 3s 220ms/step - loss: 0.1123 - accuracy: 0.9705 - val_loss: 0.2440 - val_accuracy: 0.8627\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fab37fdc9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_minussc.save_weights('EMO_DB//models//ensembled_minussc.h5')\n",
        "print(ensembled_minussc.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_minussc.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_minussc.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "dyzxs7ExciKi",
        "outputId": "618d3bc6-1f16-47fd-bab1-79620c9fbad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 128ms/step - loss: 0.1399 - accuracy: 0.9400\n",
            "[0.13989382982254028, 0.9399999976158142]\n",
            "F1 SCORE: 0.9288946179678446\n",
            "Kappa: 0.9140401146131805\n",
            "Accuracy: 0.94\n",
            "Jaccard Score: 0.869927536231884\n",
            "Precision: 0.9320887445887446\n",
            "Recall: 0.9279220779220779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fab38b52590>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_minussc.load_weights('EMO_DB//models//ensembled_minussc_loss.h5')\n",
        "print(ensembled_minussc.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_minussc.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_minussc.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "OnOVKg5OdLIG",
        "outputId": "4261f00d-a65e-46a4-dcb7-5db976ca9b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 131ms/step - loss: 0.1529 - accuracy: 0.9400\n",
            "[0.15292352437973022, 0.9399999976158142]\n",
            "F1 SCORE: 0.9291125541125542\n",
            "Kappa: 0.9141385231825987\n",
            "Accuracy: 0.94\n",
            "Jaccard Score: 0.870306324110672\n",
            "Precision: 0.9301948051948052\n",
            "Recall: 0.9301948051948052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fab38243590>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled_minussc.load_weights('EMO_DB//models//ensembled_minussc_acc.h5')\n",
        "print(ensembled_minussc.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled_minussc.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled_minussc.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "ky2NOgu7dWZ0",
        "outputId": "e5481c8e-93e0-4726-9bba-388f469b256e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 126ms/step - loss: 0.2286 - accuracy: 0.9000\n",
            "[0.22855211794376373, 0.8999999761581421]\n",
            "F1 SCORE: 0.8779137529137528\n",
            "Kappa: 0.8557414887478361\n",
            "Accuracy: 0.9\n",
            "Jaccard Score: 0.787878787878788\n",
            "Precision: 0.8949275362318841\n",
            "Recall: 0.8717532467532468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fab389ea290>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tYyZWgIwdZHX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}