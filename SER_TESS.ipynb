{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SER_TESS.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mqft35CfflBt",
        "ATNCVOzhNq_W",
        "8B7kLFGeO9XR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B_K8Gyz9McF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee0f779-d13c-4fa5-de57-14372b98ab2c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kR2zE8v9ZVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c6d578-9a08-4060-f327-d672de2775e2"
      },
      "source": [
        "%cd '/content/drive/My Drive/AudioProcessing/Emotion_Recognition'\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/AudioProcessing/Emotion_Recognition\n",
            " \u001b[0m\u001b[01;34mCREMA\u001b[0m/     kaggle.json            \u001b[01;34mRAVDESS_copied\u001b[0m/                     \u001b[01;34mtry\u001b[0m/\n",
            " \u001b[01;34mEMODB\u001b[0m/     model.png              \u001b[01;34mSAVEE\u001b[0m/\n",
            " \u001b[01;34mEMO_DB\u001b[0m/   \u001b[01;36m'Papers & Materials'\u001b[0m@   speech-emotion-recognition-en.zip\n",
            " \u001b[01;34mIEMOCAP\u001b[0m/   \u001b[01;34mRAVDESS\u001b[0m/               \u001b[01;34mTESS\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEtH2fNxFM7E"
      },
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.callbacks import ModelCheckpoint, Callback\n",
        "from sklearn.preprocessing import  StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYK90awQGJF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5038f3d-e7fa-4c69-e0fc-71f0de960a96"
      },
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = 4,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"TESS//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"TESS//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"TESS//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (1114, 64000, 1) (1114, 4)\n",
            "Test Data (239, 64000, 1) (239, 4)\n",
            "Val Data (239, 64000, 1) (239, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcYnleVRB1hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537c996c-02e1-4567-d00b-817e5fe592cc"
      },
      "source": [
        "csvpath = 'TESS/hand_engineered_features_TESS_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'TESS/hand_engineered_features_TESS_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'TESS/hand_engineered_features_TESS_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1114, 26) (1114, 1)\n",
            "(239, 26) (239, 1)\n",
            "(239, 26) (239, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNuIp18FIFPk"
      },
      "source": [
        "def findmaxsize(rslt_df):\n",
        "\n",
        "    sizes = []\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "      filename = row['path']\n",
        "\n",
        "      y, sr = librosa.core.load(filename)\n",
        "          \n",
        "      # Computing the mel spectrograms\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        "      \n",
        "      # Adding the size to the list\n",
        "      sizes.append(spect.shape)\n",
        "    print(f'The sizes of all the mel spectrograms in our data set are equal: {len(set(sizes)) == 1}')\n",
        "\n",
        "    # Checking the max size\n",
        "    print(f'The maximum size is: {max(sizes)}')\n",
        "\n",
        "\n",
        "    return max(sizes)\n",
        "\n",
        "\n",
        "X = pd.read_csv('TESS/TESS_details.csv',usecols=['labels','path'])\n",
        "options = ['angry', 'happy','neutral','sad'] \n",
        "\n",
        "time = 4\n",
        "rslt_df = X[X['labels'].isin(options)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "max_x,max_y = findmaxsize(rslt_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmg1N7diJhEK"
      },
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def extract_mel_spectrogram(df,max_x,max_y):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path']\n",
        "\n",
        "      y, sr = librosa.core.load(filename)\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        "\n",
        "            # Adjusting the size to be 128 x 660\n",
        "      if spect.shape[1] != max_y:\n",
        "                #print('Sizes arent same')\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        "\n",
        "      mel_specs.append(spect)\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  mel_specs = np.array(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        "\n",
        "train_path = \"TESS//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv,max_x,max_y)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "X_train_spec = np.expand_dims(X_train_spec,axis=3)\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        "\n",
        "\n",
        "test_path = \"TESS//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv,max_x,max_y)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "X_test_spec = np.expand_dims(X_test_spec,axis=3)\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        "\n",
        "val_path = \"TESS//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv,max_x,max_y)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "X_val_spec = np.expand_dims(X_val_spec,axis=3)\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXy-FScJczf6"
      },
      "source": [
        "# TESS Dataset download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKferg0fFxlb"
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1brdU_NCbrXU"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN18iH2jbuVJ",
        "outputId": "655678b0-62fd-4982-995c-db6cc042cf0a"
      },
      "source": [
        "!kaggle datasets download -d ejlok1/toronto-emotional-speech-set-tess"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading toronto-emotional-speech-set-tess.zip to /content/drive/My Drive/AudioProcessing/Emotion_Recognition\n",
            " 98% 419M/428M [00:05<00:00, 94.4MB/s]\n",
            "100% 428M/428M [00:05<00:00, 79.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5zRlj0Lce-W"
      },
      "source": [
        "import zipfile\n",
        "path_to_zip_file = \"TESS//toronto-emotional-speech-set-tess.zip\"\n",
        "directory_to_extract_to = \"TESS\"\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqft35CfflBt"
      },
      "source": [
        "# TESS dataset processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpyi37vffp4m"
      },
      "source": [
        "def decompose_tess():\n",
        "\n",
        "        PATH = 'TESS/TESS Toronto emotional speech set data/'\n",
        "        emotion = []\n",
        "        path = []\n",
        "        for dirname, _, filenames in os.walk(PATH):\n",
        "          for name in filenames[1:]:\n",
        "                    #print(dirname,dirname.split('_')[-1])\n",
        "                    e = dirname.split('_')[-1]\n",
        "                \n",
        "                    if e == 'angry':  \n",
        "                        emotion.append('angry')\n",
        "                    elif e == 'disgust':  \n",
        "                        emotion.append('disgust')\n",
        "                    elif e == 'Fear' or e == 'fear':  \n",
        "                        emotion.append('fear')\n",
        "                    elif e == 'happy':  \n",
        "                        emotion.append('happy')\n",
        "                    elif e == 'neutral':  \n",
        "                        emotion.append('neutral')\n",
        "                    elif e == 'sad' or e == 'Sad' :  \n",
        "                        emotion.append('sad')\n",
        "                    elif e == 'surprised' or e == 'surprise':  \n",
        "                        emotion.append('surprise')\n",
        "                    elif e == 'calm':  \n",
        "                        emotion.append('calm')\n",
        "                    else:\n",
        "                        print(dirname, \"Error\")\n",
        "                        #emotion.append('m_neutral')\n",
        "                \n",
        "\n",
        "                    path.append(os.path.join(dirname,name))\n",
        "\n",
        "        print(len(path),len(emotion))\n",
        "        tess_df = pd.DataFrame(emotion, columns=['labels'])\n",
        "        #emodb_df['source'] = 'EMODB'\n",
        "        tess_df = pd.concat([tess_df, pd.DataFrame(path, columns=['path'])], axis=1)\n",
        "        \n",
        "        return tess_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o51mAonz1ewu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b119dfc3-b16d-49c5-a7c5-975f01343aae"
      },
      "source": [
        "df = decompose_tess()\n",
        "print(df.shape)\n",
        "df.to_csv('TESS/TESS_details.csv',index=False,index_label=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2786 2786\n",
            "(2786, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "OrYlyViq6Vdu",
        "outputId": "c895e52f-9f4c-44e9-8e5c-bd74420d499a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fear</td>\n",
              "      <td>TESS/TESS Toronto emotional speech set data/OA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fear</td>\n",
              "      <td>TESS/TESS Toronto emotional speech set data/OA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fear</td>\n",
              "      <td>TESS/TESS Toronto emotional speech set data/OA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fear</td>\n",
              "      <td>TESS/TESS Toronto emotional speech set data/OA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fear</td>\n",
              "      <td>TESS/TESS Toronto emotional speech set data/OA...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  labels                                               path\n",
              "0   fear  TESS/TESS Toronto emotional speech set data/OA...\n",
              "1   fear  TESS/TESS Toronto emotional speech set data/OA...\n",
              "2   fear  TESS/TESS Toronto emotional speech set data/OA...\n",
              "3   fear  TESS/TESS Toronto emotional speech set data/OA...\n",
              "4   fear  TESS/TESS Toronto emotional speech set data/OA..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "fHM4n_6S6amu",
        "outputId": "e5b1dc9c-49f6-4584-9e45-d6bfe756f9fa"
      },
      "source": [
        "#angry, happy, neutral, sad\n",
        "X = pd.read_csv('TESS/TESS_details.csv',usecols=['labels','path'])\n",
        "options = ['angry', 'happy','neutral','sad'] \n",
        "  \n",
        "rslt_df = X[X['labels'].isin(options)] \n",
        "print(np.unique(rslt_df.labels))\n",
        "print(rslt_df.shape)\n",
        "rslt_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['angry' 'happy' 'neutral' 'sad']\n",
            "(1592, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>sad</td>\n",
              "      <td>TESS/TESS Toronto emotional speech set data/OA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>sad</td>\n",
              "      <td>TESS/TESS Toronto emotional speech set data/OA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>sad</td>\n",
              "      <td>TESS/TESS Toronto emotional speech set data/OA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>sad</td>\n",
              "      <td>TESS/TESS Toronto emotional speech set data/OA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>sad</td>\n",
              "      <td>TESS/TESS Toronto emotional speech set data/OA...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    labels                                               path\n",
              "398    sad  TESS/TESS Toronto emotional speech set data/OA...\n",
              "399    sad  TESS/TESS Toronto emotional speech set data/OA...\n",
              "400    sad  TESS/TESS Toronto emotional speech set data/OA...\n",
              "401    sad  TESS/TESS Toronto emotional speech set data/OA...\n",
              "402    sad  TESS/TESS Toronto emotional speech set data/OA..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_mUM8I25XLV",
        "outputId": "b470e407-27fb-44b3-f48a-86523abbf7e3"
      },
      "source": [
        "sizes = []\n",
        "for index, row in rslt_df.iterrows(): \n",
        "    #print(row['labels'],row['path'])\n",
        "    y, sr = librosa.load(row['path'], mono=True, duration=30)\n",
        "    sizes.append(y.shape[0])\n",
        "    \n",
        "print('The max size is',max(sizes))\n",
        "print('The average size is ', sum(sizes)/len(sizes))\n",
        "print(sr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The max size is 65815\n",
            "The average size is  45596.97173366834\n",
            "22050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWmJJ_yj6gjc",
        "outputId": "e480c799-90c6-4c5d-b4ea-e9462fcd9c28"
      },
      "source": [
        "test_val= rslt_df.sample(frac = 0.3)\n",
        "train = rslt_df.drop(test_val.index)\n",
        "\n",
        "test= test_val.sample(frac = 0.5)\n",
        "val = test_val.drop(test.index)\n",
        "print(val['labels'].unique())\n",
        "print(test['labels'].unique())\n",
        "print(train['labels'].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['happy' 'angry' 'sad' 'neutral']\n",
            "['angry' 'happy' 'neutral' 'sad']\n",
            "['sad' 'angry' 'happy' 'neutral']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAL3qmcU8yU_"
      },
      "source": [
        "train.to_csv(\"TESS//train.csv\")\n",
        "test.to_csv(\"TESS//test.csv\")\n",
        "val.to_csv(\"TESS//val.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxXNb_Q-F-6Q"
      },
      "source": [
        "# WaveNetPaper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpiaWJ2EGBAZ",
        "outputId": "deb0337c-be43-47bf-cca2-f78aed30162c"
      },
      "source": [
        "# hyper-parameters\n",
        "n_filters = 32\n",
        "filter_width = 2\n",
        "dilation_rates = [2**i for i in range(4)] * 2 \n",
        "sr = 16000\n",
        "# define an input history series and pass it through a stack of dilated causal convolution blocks\n",
        "history_seq = Input(shape=(int(sr*time), 1))\n",
        "x = history_seq\n",
        "\n",
        "skips = []\n",
        "for dilation_rate in dilation_rates:\n",
        "    \n",
        "    # preprocessing - equivalent to time-distributed dense\n",
        "    x = Conv1D(16, 1, padding='same', activation='relu')(x) \n",
        "    \n",
        "    # filter\n",
        "    x_f = Conv1D(filters=n_filters,\n",
        "                 kernel_size=filter_width, \n",
        "                 padding='causal',\n",
        "                 dilation_rate=dilation_rate)(x)\n",
        "    \n",
        "    # gate\n",
        "    x_g = Conv1D(filters=n_filters,\n",
        "                 kernel_size=filter_width, \n",
        "                 padding='causal',\n",
        "                 dilation_rate=dilation_rate)(x)\n",
        "    \n",
        "    # combine filter and gating branches\n",
        "    z = Multiply()([Activation('tanh')(x_f),\n",
        "                    Activation('sigmoid')(x_g)])\n",
        "    \n",
        "    # postprocessing - equivalent to time-distributed dense\n",
        "    z = Conv1D(16, 1, padding='same', activation='relu')(z)\n",
        "    \n",
        "    # residual connection\n",
        "    x = Add()([x, z])    \n",
        "    \n",
        "    # collect skip connections\n",
        "    skips.append(z)\n",
        "\n",
        "# add all skip connection outputs \n",
        "out = Activation('relu')(Add()(skips))\n",
        "out = AveragePooling1D(sr*time)(out)\n",
        "out = Conv1D(8,1,activation='relu')(out)\n",
        "out = Conv1D(4,1,activation='softmax')(out)\n",
        "out = Reshape((4,1))(out)\n",
        "\n",
        "Wavenet_paper = Model(history_seq, out)\n",
        "Wavenet_paper.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 64000, 16)    32          ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 64000, 32)    1056        ['conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 64000, 32)    1056        ['conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 64000, 32)    0           ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 64000, 32)    0           ['conv1d_9[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 64000, 32)    0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 64000, 16)    528         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 64000, 16)    0           ['conv1d_7[0][0]',               \n",
            "                                                                  'conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 64000, 16)    272         ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 64000, 32)    0           ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 64000, 32)    0           ['conv1d_13[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 64000, 32)    0           ['activation_7[0][0]',           \n",
            "                                                                  'activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 64000, 16)    528         ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 64000, 16)    0           ['conv1d_11[0][0]',              \n",
            "                                                                  'conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 64000, 16)    272         ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_15[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_15[0][0]']              \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 64000, 32)    0           ['conv1d_16[0][0]']              \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 64000, 32)    0           ['conv1d_17[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 64000, 32)    0           ['activation_9[0][0]',           \n",
            "                                                                  'activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 64000, 16)    528         ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 64000, 16)    0           ['conv1d_15[0][0]',              \n",
            "                                                                  'conv1d_18[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 64000, 16)    272         ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_19[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_21 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_19[0][0]']              \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 64000, 32)    0           ['conv1d_20[0][0]']              \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 64000, 32)    0           ['conv1d_21[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 64000, 32)    0           ['activation_11[0][0]',          \n",
            "                                                                  'activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_22 (Conv1D)             (None, 64000, 16)    528         ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 64000, 16)    0           ['conv1d_19[0][0]',              \n",
            "                                                                  'conv1d_22[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_23 (Conv1D)             (None, 64000, 16)    272         ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_24 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_23[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_25 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_23[0][0]']              \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 64000, 32)    0           ['conv1d_24[0][0]']              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 64000, 32)    0           ['conv1d_25[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 64000, 32)    0           ['activation_13[0][0]',          \n",
            "                                                                  'activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_26 (Conv1D)             (None, 64000, 16)    528         ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 64000, 16)    0           ['conv1d_23[0][0]',              \n",
            "                                                                  'conv1d_26[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_27 (Conv1D)             (None, 64000, 16)    272         ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_28 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_27[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_29 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_27[0][0]']              \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 64000, 32)    0           ['conv1d_28[0][0]']              \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 64000, 32)    0           ['conv1d_29[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 64000, 32)    0           ['activation_15[0][0]',          \n",
            "                                                                  'activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_30 (Conv1D)             (None, 64000, 16)    528         ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 64000, 16)    0           ['conv1d_27[0][0]',              \n",
            "                                                                  'conv1d_30[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_31 (Conv1D)             (None, 64000, 16)    272         ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_32 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_31[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_33 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_31[0][0]']              \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 64000, 32)    0           ['conv1d_32[0][0]']              \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 64000, 32)    0           ['conv1d_33[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 64000, 32)    0           ['activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_34 (Conv1D)             (None, 64000, 16)    528         ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 64000, 16)    0           ['conv1d_31[0][0]',              \n",
            "                                                                  'conv1d_34[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_35 (Conv1D)             (None, 64000, 16)    272         ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_36 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_35[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_37 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_35[0][0]']              \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 64000, 32)    0           ['conv1d_36[0][0]']              \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 64000, 32)    0           ['conv1d_37[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 64000, 32)    0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_38 (Conv1D)             (None, 64000, 16)    528         ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 64000, 16)    0           ['conv1d_10[0][0]',              \n",
            "                                                                  'conv1d_14[0][0]',              \n",
            "                                                                  'conv1d_18[0][0]',              \n",
            "                                                                  'conv1d_22[0][0]',              \n",
            "                                                                  'conv1d_26[0][0]',              \n",
            "                                                                  'conv1d_30[0][0]',              \n",
            "                                                                  'conv1d_34[0][0]',              \n",
            "                                                                  'conv1d_38[0][0]']              \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 64000, 16)    0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling1d (AveragePool  (None, 1, 16)       0           ['activation_21[0][0]']          \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " conv1d_39 (Conv1D)             (None, 1, 8)         136         ['average_pooling1d[0][0]']      \n",
            "                                                                                                  \n",
            " conv1d_40 (Conv1D)             (None, 1, 4)         36          ['conv1d_39[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 4, 1)         0           ['conv1d_40[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,228\n",
            "Trainable params: 23,228\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 1"
      ],
      "metadata": {
        "id": "GcxthiGyAbBy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zpdd4_lEHwt6",
        "outputId": "725ac446-395e-4f28-80f0-ea980a252a9b"
      },
      "source": [
        "Wavenet_paper.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//wavenet_paper_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//wavenet_paper_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = Wavenet_paper.fit(X_train,Y_train, batch_size=12,validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "93/93 [==============================] - 77s 446ms/step - loss: 1.3870 - accuracy: 0.7500 - val_loss: 1.3847 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.38472, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.75000, saving model to TESS//models/wavenet_paper_acc.h5\n",
            "Epoch 2/30\n",
            "93/93 [==============================] - 42s 449ms/step - loss: 1.3602 - accuracy: 0.7502 - val_loss: 1.2987 - val_accuracy: 0.7615\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.38472 to 1.29867, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.75000 to 0.76151, saving model to TESS//models/wavenet_paper_acc.h5\n",
            "Epoch 3/30\n",
            "93/93 [==============================] - 42s 451ms/step - loss: 1.2494 - accuracy: 0.7675 - val_loss: 1.2175 - val_accuracy: 0.7615\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.29867 to 1.21747, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.76151\n",
            "Epoch 4/30\n",
            "93/93 [==============================] - 42s 449ms/step - loss: 1.1657 - accuracy: 0.7671 - val_loss: 1.1509 - val_accuracy: 0.7605\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.21747 to 1.15090, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.76151\n",
            "Epoch 5/30\n",
            "93/93 [==============================] - 42s 450ms/step - loss: 1.1311 - accuracy: 0.7616 - val_loss: 1.1260 - val_accuracy: 0.7552\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.15090 to 1.12597, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.76151\n",
            "Epoch 6/30\n",
            "93/93 [==============================] - 42s 449ms/step - loss: 1.1140 - accuracy: 0.7685 - val_loss: 1.1158 - val_accuracy: 0.7626\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.12597 to 1.11583, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.76151 to 0.76255, saving model to TESS//models/wavenet_paper_acc.h5\n",
            "Epoch 7/30\n",
            "93/93 [==============================] - 42s 450ms/step - loss: 1.0919 - accuracy: 0.7657 - val_loss: 1.0745 - val_accuracy: 0.7552\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.11583 to 1.07448, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.76255\n",
            "Epoch 8/30\n",
            "93/93 [==============================] - 42s 450ms/step - loss: 1.0842 - accuracy: 0.7673 - val_loss: 1.0967 - val_accuracy: 0.7626\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.07448\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.76255\n",
            "Epoch 9/30\n",
            "93/93 [==============================] - 42s 450ms/step - loss: 1.0928 - accuracy: 0.7626 - val_loss: 1.0788 - val_accuracy: 0.7626\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.07448\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.76255\n",
            "Epoch 10/30\n",
            "93/93 [==============================] - 42s 449ms/step - loss: 1.0620 - accuracy: 0.7676 - val_loss: 1.0442 - val_accuracy: 0.7678\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.07448 to 1.04421, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.76255 to 0.76778, saving model to TESS//models/wavenet_paper_acc.h5\n",
            "Epoch 11/30\n",
            "93/93 [==============================] - 42s 449ms/step - loss: 1.0592 - accuracy: 0.7784 - val_loss: 1.0425 - val_accuracy: 0.7678\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.04421 to 1.04248, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.76778\n",
            "Epoch 12/30\n",
            "93/93 [==============================] - 42s 449ms/step - loss: 1.0522 - accuracy: 0.7731 - val_loss: 1.0410 - val_accuracy: 0.7887\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.04248 to 1.04100, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.76778 to 0.78870, saving model to TESS//models/wavenet_paper_acc.h5\n",
            "Epoch 13/30\n",
            "93/93 [==============================] - 42s 449ms/step - loss: 1.0615 - accuracy: 0.7838 - val_loss: 1.0279 - val_accuracy: 0.7939\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.04100 to 1.02792, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.78870 to 0.79393, saving model to TESS//models/wavenet_paper_acc.h5\n",
            "Epoch 14/30\n",
            "93/93 [==============================] - 42s 449ms/step - loss: 1.0426 - accuracy: 0.7916 - val_loss: 1.0246 - val_accuracy: 0.7950\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.02792 to 1.02456, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.79393 to 0.79498, saving model to TESS//models/wavenet_paper_acc.h5\n",
            "Epoch 15/30\n",
            "93/93 [==============================] - 42s 448ms/step - loss: 1.0201 - accuracy: 0.7847 - val_loss: 1.0357 - val_accuracy: 0.7887\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.02456\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.79498\n",
            "Epoch 16/30\n",
            "93/93 [==============================] - 42s 448ms/step - loss: 1.0544 - accuracy: 0.7892 - val_loss: 1.0203 - val_accuracy: 0.8002\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.02456 to 1.02031, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.79498 to 0.80021, saving model to TESS//models/wavenet_paper_acc.h5\n",
            "Epoch 17/30\n",
            "93/93 [==============================] - 42s 448ms/step - loss: 1.0360 - accuracy: 0.7960 - val_loss: 1.0218 - val_accuracy: 0.7929\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.02031\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.80021\n",
            "Epoch 18/30\n",
            "93/93 [==============================] - 42s 448ms/step - loss: 1.0253 - accuracy: 0.7958 - val_loss: 1.0134 - val_accuracy: 0.7971\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.02031 to 1.01342, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.80021\n",
            "Epoch 19/30\n",
            "93/93 [==============================] - 42s 448ms/step - loss: 1.0223 - accuracy: 0.7953 - val_loss: 1.0050 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.01342 to 1.00495, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.80021 to 0.80544, saving model to TESS//models/wavenet_paper_acc.h5\n",
            "Epoch 20/30\n",
            "93/93 [==============================] - 42s 448ms/step - loss: 1.0137 - accuracy: 0.7856 - val_loss: 1.0035 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.00495 to 1.00354, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.80544\n",
            "Epoch 21/30\n",
            "93/93 [==============================] - 42s 448ms/step - loss: 1.0260 - accuracy: 0.7946 - val_loss: 1.0029 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.00354 to 1.00294, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.80544\n",
            "Epoch 22/30\n",
            "93/93 [==============================] - 42s 448ms/step - loss: 1.0181 - accuracy: 0.7969 - val_loss: 0.9960 - val_accuracy: 0.8044\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.00294 to 0.99604, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.80544\n",
            "Epoch 23/30\n",
            "93/93 [==============================] - 42s 447ms/step - loss: 1.0188 - accuracy: 0.7954 - val_loss: 1.0019 - val_accuracy: 0.7960\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.99604\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.80544\n",
            "Epoch 24/30\n",
            "93/93 [==============================] - 41s 447ms/step - loss: 1.0162 - accuracy: 0.7972 - val_loss: 1.0015 - val_accuracy: 0.8013\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.99604\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.80544\n",
            "Epoch 25/30\n",
            "93/93 [==============================] - 41s 446ms/step - loss: 1.0096 - accuracy: 0.7942 - val_loss: 1.0019 - val_accuracy: 0.8013\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.99604\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.80544\n",
            "Epoch 26/30\n",
            "93/93 [==============================] - 41s 446ms/step - loss: 1.0076 - accuracy: 0.7952 - val_loss: 0.9972 - val_accuracy: 0.8023\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.99604\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.80544\n",
            "Epoch 27/30\n",
            "93/93 [==============================] - 41s 446ms/step - loss: 1.0237 - accuracy: 0.7930 - val_loss: 1.0094 - val_accuracy: 0.7877\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.99604\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.80544\n",
            "Epoch 28/30\n",
            "93/93 [==============================] - 41s 447ms/step - loss: 1.0018 - accuracy: 0.7937 - val_loss: 0.9970 - val_accuracy: 0.7939\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.99604\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.80544\n",
            "Epoch 29/30\n",
            "93/93 [==============================] - 41s 446ms/step - loss: 1.0071 - accuracy: 0.7952 - val_loss: 0.9894 - val_accuracy: 0.8096\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.99604 to 0.98936, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.80544 to 0.80962, saving model to TESS//models/wavenet_paper_acc.h5\n",
            "Epoch 30/30\n",
            "93/93 [==============================] - 41s 446ms/step - loss: 0.9990 - accuracy: 0.8025 - val_loss: 0.9873 - val_accuracy: 0.8138\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.98936 to 0.98733, saving model to TESS//models/wavenet_paper_loss.h5\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.80962 to 0.81381, saving model to TESS//models/wavenet_paper_acc.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_N02Ug0H-XM",
        "outputId": "8e80e082-688f-4783-c2af-41beec63a554"
      },
      "source": [
        "Wavenet_paper.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "Wavenet_paper.load_weights('TESS//models//wavenet_paper_loss.h5')\n",
        "print(Wavenet_paper.evaluate(X_test,Y_test))\n",
        "Wavenet_paper.load_weights('TESS//models//wavenet_paper_acc.h5')\n",
        "Wavenet_paper.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 8s 810ms/step - loss: 0.9409 - accuracy: 0.8110\n",
            "[0.938992977142334, 0.8117154836654663]\n",
            "8/8 [==============================] - 7s 809ms/step - loss: 0.9390 - accuracy: 0.8117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.938992977142334, 0.8117154836654663]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBllEajrNdC3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "ff842570-056a-4759-d3a9-bdbb41168cd3"
      },
      "source": [
        "Wavenet_paper.evaluate(X_test,Y_test)\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(Wavenet_paper.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1)\n",
        "print(g.shape,p.shape)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))\n",
        "cf_matrix = confusion_matrix(Y_test_features,np.argmax(Wavenet_paper.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 7s 810ms/step - loss: 0.9390 - accuracy: 0.8117\n",
            "(239,) (239,)\n",
            "F1 SCORE: 0.5373307173340762\n",
            "Kappa: 0.4188895708417921\n",
            "Accuracy: 0.5690376569037657\n",
            "Jaccard Score: 0.3991169741169741\n",
            "Precision: 0.5975876519255128\n",
            "Recall: 0.5546549716023931\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82        62\n",
            "           1       0.77      0.43      0.55        56\n",
            "           2       0.32      0.14      0.20        57\n",
            "           3       0.44      0.86      0.58        64\n",
            "\n",
            "    accuracy                           0.57       239\n",
            "   macro avg       0.60      0.55      0.54       239\n",
            "weighted avg       0.60      0.57      0.54       239\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8bbe4ff0d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trial 2"
      ],
      "metadata": {
        "id": "ZCv-RsusAgO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Wavenet_paper.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//wavenet_paper_loss_2.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//wavenet_paper_acc_2.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = Wavenet_paper.fit(X_train,Y_train, batch_size=12,validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brW0eimBAh4o",
        "outputId": "caf24f5c-9dde-41f9-f1e6-4b0141bb7d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.3635 - accuracy: 0.7509\n",
            "Epoch 1: val_loss improved from inf to 1.29748, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.75628, saving model to TESS//models/wavenet_paper_acc_2.h5\n",
            "93/93 [==============================] - 50s 461ms/step - loss: 1.3635 - accuracy: 0.7509 - val_loss: 1.2975 - val_accuracy: 0.7563\n",
            "Epoch 2/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.2184 - accuracy: 0.7637\n",
            "Epoch 2: val_loss improved from 1.29748 to 1.15973, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.75628 to 0.76046, saving model to TESS//models/wavenet_paper_acc_2.h5\n",
            "93/93 [==============================] - 42s 455ms/step - loss: 1.2184 - accuracy: 0.7637 - val_loss: 1.1597 - val_accuracy: 0.7605\n",
            "Epoch 3/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.1219 - accuracy: 0.7695\n",
            "Epoch 3: val_loss improved from 1.15973 to 1.09904, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.76046 to 0.77197, saving model to TESS//models/wavenet_paper_acc_2.h5\n",
            "93/93 [==============================] - 42s 447ms/step - loss: 1.1219 - accuracy: 0.7695 - val_loss: 1.0990 - val_accuracy: 0.7720\n",
            "Epoch 4/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0857 - accuracy: 0.7877\n",
            "Epoch 4: val_loss did not improve from 1.09904\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.77197 to 0.77615, saving model to TESS//models/wavenet_paper_acc_2.h5\n",
            "93/93 [==============================] - 41s 444ms/step - loss: 1.0857 - accuracy: 0.7877 - val_loss: 1.1210 - val_accuracy: 0.7762\n",
            "Epoch 5/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0680 - accuracy: 0.7902\n",
            "Epoch 5: val_loss improved from 1.09904 to 1.03116, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.77615 to 0.80126, saving model to TESS//models/wavenet_paper_acc_2.h5\n",
            "93/93 [==============================] - 42s 450ms/step - loss: 1.0680 - accuracy: 0.7902 - val_loss: 1.0312 - val_accuracy: 0.8013\n",
            "Epoch 6/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0526 - accuracy: 0.7947\n",
            "Epoch 6: val_loss improved from 1.03116 to 1.03070, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.80126\n",
            "93/93 [==============================] - 41s 445ms/step - loss: 1.0526 - accuracy: 0.7947 - val_loss: 1.0307 - val_accuracy: 0.7939\n",
            "Epoch 7/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0447 - accuracy: 0.7991\n",
            "Epoch 7: val_loss improved from 1.03070 to 1.02125, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.80126\n",
            "93/93 [==============================] - 41s 446ms/step - loss: 1.0447 - accuracy: 0.7991 - val_loss: 1.0213 - val_accuracy: 0.7918\n",
            "Epoch 8/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0406 - accuracy: 0.7942\n",
            "Epoch 8: val_loss improved from 1.02125 to 0.99462, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.80126 to 0.80544, saving model to TESS//models/wavenet_paper_acc_2.h5\n",
            "93/93 [==============================] - 42s 452ms/step - loss: 1.0406 - accuracy: 0.7942 - val_loss: 0.9946 - val_accuracy: 0.8054\n",
            "Epoch 9/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0350 - accuracy: 0.7947\n",
            "Epoch 9: val_loss did not improve from 0.99462\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.80544 to 0.80858, saving model to TESS//models/wavenet_paper_acc_2.h5\n",
            "93/93 [==============================] - 42s 447ms/step - loss: 1.0350 - accuracy: 0.7947 - val_loss: 1.0112 - val_accuracy: 0.8086\n",
            "Epoch 10/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0252 - accuracy: 0.7976\n",
            "Epoch 10: val_loss did not improve from 0.99462\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.80858\n",
            "93/93 [==============================] - 42s 448ms/step - loss: 1.0252 - accuracy: 0.7976 - val_loss: 1.0124 - val_accuracy: 0.7939\n",
            "Epoch 11/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0351 - accuracy: 0.7931\n",
            "Epoch 11: val_loss improved from 0.99462 to 0.98152, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.80858 to 0.81381, saving model to TESS//models/wavenet_paper_acc_2.h5\n",
            "93/93 [==============================] - 42s 456ms/step - loss: 1.0351 - accuracy: 0.7931 - val_loss: 0.9815 - val_accuracy: 0.8138\n",
            "Epoch 12/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0110 - accuracy: 0.8018\n",
            "Epoch 12: val_loss did not improve from 0.98152\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.81381 to 0.81485, saving model to TESS//models/wavenet_paper_acc_2.h5\n",
            "93/93 [==============================] - 42s 451ms/step - loss: 1.0110 - accuracy: 0.8018 - val_loss: 0.9926 - val_accuracy: 0.8149\n",
            "Epoch 13/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0126 - accuracy: 0.8003\n",
            "Epoch 13: val_loss improved from 0.98152 to 0.97675, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.81485\n",
            "93/93 [==============================] - 42s 450ms/step - loss: 1.0126 - accuracy: 0.8003 - val_loss: 0.9767 - val_accuracy: 0.8117\n",
            "Epoch 14/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0121 - accuracy: 0.8007\n",
            "Epoch 14: val_loss improved from 0.97675 to 0.96697, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 14: val_accuracy improved from 0.81485 to 0.81695, saving model to TESS//models/wavenet_paper_acc_2.h5\n",
            "93/93 [==============================] - 42s 455ms/step - loss: 1.0121 - accuracy: 0.8007 - val_loss: 0.9670 - val_accuracy: 0.8169\n",
            "Epoch 15/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0077 - accuracy: 0.8003\n",
            "Epoch 15: val_loss did not improve from 0.96697\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.81695\n",
            "93/93 [==============================] - 41s 445ms/step - loss: 1.0077 - accuracy: 0.8003 - val_loss: 0.9709 - val_accuracy: 0.8096\n",
            "Epoch 16/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0012 - accuracy: 0.8032\n",
            "Epoch 16: val_loss improved from 0.96697 to 0.96658, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.81695\n",
            "93/93 [==============================] - 42s 450ms/step - loss: 1.0012 - accuracy: 0.8032 - val_loss: 0.9666 - val_accuracy: 0.8086\n",
            "Epoch 17/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.9973 - accuracy: 0.8023\n",
            "Epoch 17: val_loss did not improve from 0.96658\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.81695\n",
            "93/93 [==============================] - 41s 445ms/step - loss: 0.9973 - accuracy: 0.8023 - val_loss: 1.0163 - val_accuracy: 0.7992\n",
            "Epoch 18/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.7980\n",
            "Epoch 18: val_loss did not improve from 0.96658\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.81695\n",
            "93/93 [==============================] - 41s 445ms/step - loss: 1.0054 - accuracy: 0.7980 - val_loss: 0.9707 - val_accuracy: 0.8149\n",
            "Epoch 19/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 1.0033 - accuracy: 0.8014\n",
            "Epoch 19: val_loss improved from 0.96658 to 0.96390, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.81695\n",
            "93/93 [==============================] - 42s 450ms/step - loss: 1.0033 - accuracy: 0.8014 - val_loss: 0.9639 - val_accuracy: 0.8128\n",
            "Epoch 20/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.9971 - accuracy: 0.8005\n",
            "Epoch 20: val_loss improved from 0.96390 to 0.95713, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.81695\n",
            "93/93 [==============================] - 42s 450ms/step - loss: 0.9971 - accuracy: 0.8005 - val_loss: 0.9571 - val_accuracy: 0.8128\n",
            "Epoch 21/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.9884 - accuracy: 0.8007\n",
            "Epoch 21: val_loss did not improve from 0.95713\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.81695\n",
            "93/93 [==============================] - 41s 445ms/step - loss: 0.9884 - accuracy: 0.8007 - val_loss: 0.9639 - val_accuracy: 0.8023\n",
            "Epoch 22/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.9882 - accuracy: 0.8000\n",
            "Epoch 22: val_loss improved from 0.95713 to 0.94893, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.81695\n",
            "93/93 [==============================] - 42s 451ms/step - loss: 0.9882 - accuracy: 0.8000 - val_loss: 0.9489 - val_accuracy: 0.8107\n",
            "Epoch 23/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.9912 - accuracy: 0.8000\n",
            "Epoch 23: val_loss did not improve from 0.94893\n",
            "\n",
            "Epoch 23: val_accuracy improved from 0.81695 to 0.81799, saving model to TESS//models/wavenet_paper_acc_2.h5\n",
            "93/93 [==============================] - 42s 450ms/step - loss: 0.9912 - accuracy: 0.8000 - val_loss: 0.9529 - val_accuracy: 0.8180\n",
            "Epoch 24/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.9795 - accuracy: 0.8023\n",
            "Epoch 24: val_loss did not improve from 0.94893\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.81799\n",
            "93/93 [==============================] - 41s 445ms/step - loss: 0.9795 - accuracy: 0.8023 - val_loss: 0.9576 - val_accuracy: 0.8138\n",
            "Epoch 25/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.9797 - accuracy: 0.8045\n",
            "Epoch 25: val_loss did not improve from 0.94893\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.81799\n",
            "93/93 [==============================] - 41s 445ms/step - loss: 0.9797 - accuracy: 0.8045 - val_loss: 0.9562 - val_accuracy: 0.8149\n",
            "Epoch 26/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.9791 - accuracy: 0.7994\n",
            "Epoch 26: val_loss improved from 0.94893 to 0.94829, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.81799\n",
            "93/93 [==============================] - 42s 451ms/step - loss: 0.9791 - accuracy: 0.7994 - val_loss: 0.9483 - val_accuracy: 0.8180\n",
            "Epoch 27/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.9715 - accuracy: 0.8041\n",
            "Epoch 27: val_loss improved from 0.94829 to 0.93796, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.81799\n",
            "93/93 [==============================] - 42s 451ms/step - loss: 0.9715 - accuracy: 0.8041 - val_loss: 0.9380 - val_accuracy: 0.8149\n",
            "Epoch 28/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.9642 - accuracy: 0.8052\n",
            "Epoch 28: val_loss did not improve from 0.93796\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.81799\n",
            "93/93 [==============================] - 41s 445ms/step - loss: 0.9642 - accuracy: 0.8052 - val_loss: 0.9549 - val_accuracy: 0.8138\n",
            "Epoch 29/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.9688 - accuracy: 0.8043\n",
            "Epoch 29: val_loss improved from 0.93796 to 0.93728, saving model to TESS//models/wavenet_paper_loss_2.h5\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.81799\n",
            "93/93 [==============================] - 42s 451ms/step - loss: 0.9688 - accuracy: 0.8043 - val_loss: 0.9373 - val_accuracy: 0.8149\n",
            "Epoch 30/30\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.9729 - accuracy: 0.8059\n",
            "Epoch 30: val_loss did not improve from 0.93728\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.81799\n",
            "93/93 [==============================] - 41s 445ms/step - loss: 0.9729 - accuracy: 0.8059 - val_loss: 0.9416 - val_accuracy: 0.8107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Wavenet_paper.evaluate(X_test,Y_test)\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(Wavenet_paper.predict(X_test).reshape(X_test.shape[0],4),axis = -1)\n",
        "print(g.shape,p.shape)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(Wavenet_paper.predict(X_test).reshape(X_test.shape[0],4),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "kB4NzBSgFrQ1",
        "outputId": "3d7faaef-fc93-4dd3-d002-a2a82181a9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 3s 394ms/step - loss: 0.8906 - accuracy: 0.8096\n",
            "(239,) (239,)\n",
            "F1 SCORE: 0.5371855344592591\n",
            "Kappa: 0.42402835203780265\n",
            "Accuracy: 0.5732217573221757\n",
            "Jaccard Score: 0.4007224236726654\n",
            "Precision: 0.6128169307620667\n",
            "Recall: 0.5578231743673701\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84        62\n",
            "           1       0.85      0.39      0.54        56\n",
            "           2       0.33      0.14      0.20        57\n",
            "           3       0.43      0.86      0.58        64\n",
            "\n",
            "    accuracy                           0.57       239\n",
            "   macro avg       0.61      0.56      0.54       239\n",
            "weighted avg       0.61      0.57      0.54       239\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa9868f9a50>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 3"
      ],
      "metadata": {
        "id": "lVfWEiqXGhWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Wavenet_paper.load_weights('TESS//models//wavenet_paper_loss_2.h5')\n",
        "Wavenet_paper.evaluate(X_test,Y_test)\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(Wavenet_paper.predict(X_test).reshape(X_test.shape[0],4),axis = -1)\n",
        "print(g.shape,p.shape)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(Wavenet_paper.predict(X_test).reshape(X_test.shape[0],4),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "id": "XtJWFBv1GjFS",
        "outputId": "068ab760-a180-4385-e854-ade1d17c1a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 3s 394ms/step - loss: 0.8910 - accuracy: 0.8086\n",
            "(239,) (239,)\n",
            "F1 SCORE: 0.47843914543363797\n",
            "Kappa: 0.3971629564492989\n",
            "Accuracy: 0.5439330543933054\n",
            "Jaccard Score: 0.36432748538011694\n",
            "Precision: 0.5139311126813797\n",
            "Recall: 0.5535057401568437\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84        62\n",
            "           1       0.85      0.39      0.54        56\n",
            "           2       0.37      0.98      0.54        57\n",
            "           3       0.00      0.00      0.00        64\n",
            "\n",
            "    accuracy                           0.54       239\n",
            "   macro avg       0.51      0.55      0.48       239\n",
            "weighted avg       0.50      0.54      0.47       239\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa986817fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 4"
      ],
      "metadata": {
        "id": "p6wKVKjtHTmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Wavenet_paper.load_weights('TESS//models//wavenet_paper_acc_2.h5')\n",
        "Wavenet_paper.evaluate(X_test,Y_test)\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(Wavenet_paper.predict(X_test).reshape(X_test.shape[0],4),axis = -1)\n",
        "print(g.shape,p.shape)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(Wavenet_paper.predict(X_test).reshape(X_test.shape[0],4),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "id": "mGYu5ZORAwJq",
        "outputId": "78c76dee-81b2-4e55-f67b-f6a8f6b8f9d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 3s 391ms/step - loss: 0.9032 - accuracy: 0.8107\n",
            "(239,) (239,)\n",
            "F1 SCORE: 0.48455171530399266\n",
            "Kappa: 0.4027764923646461\n",
            "Accuracy: 0.5481171548117155\n",
            "Jaccard Score: 0.3710371880405239\n",
            "Precision: 0.5187929488494031\n",
            "Recall: 0.5579700258711294\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.85        62\n",
            "           1       0.85      0.41      0.55        56\n",
            "           2       0.37      0.98      0.54        57\n",
            "           3       0.00      0.00      0.00        64\n",
            "\n",
            "    accuracy                           0.55       239\n",
            "   macro avg       0.52      0.56      0.48       239\n",
            "weighted avg       0.51      0.55      0.48       239\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa9868e7cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATNCVOzhNq_W"
      },
      "source": [
        "# Wavenet 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWaEZZqoNtwp",
        "outputId": "e4fed532-6ecc-4edb-cde9-7f09f14275ea"
      },
      "source": [
        "# hyper-parameters\n",
        "\n",
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "n_filters = 64\n",
        "filter_width = 2\n",
        "dilation_rates = [2**i for i in range(3)]  \n",
        "sr = 16000\n",
        "\n",
        "history_seq = Input(shape=(int(sr*time), 1))\n",
        "x = history_seq\n",
        "\n",
        "\n",
        "x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "x = AveragePooling1D()(x)\n",
        "\n",
        "x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "x = AveragePooling1D()(x)\n",
        "\n",
        "x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "x = AveragePooling1D()(x)\n",
        "skips = []\n",
        "for dilation_rate in dilation_rates:\n",
        "    \n",
        "    \n",
        "    x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "    \n",
        "    # filter\n",
        "    x_f = Conv1D(filters=n_filters,\n",
        "                 kernel_size=filter_width, \n",
        "                 padding='causal',\n",
        "                 dilation_rate=dilation_rate)(x)\n",
        "    \n",
        "    # gate\n",
        "    x_g = Conv1D(filters=n_filters,\n",
        "                 kernel_size=filter_width, \n",
        "                 padding='causal',\n",
        "                 dilation_rate=dilation_rate)(x)\n",
        "    \n",
        "    # combine filter and gating branches\n",
        "    z = Multiply()([Activation('tanh')(x_f),\n",
        "                    Activation('sigmoid')(x_g)])\n",
        "    \n",
        "    # postprocessing - equivalent to time-distributed dense\n",
        "    z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "    \n",
        "    # residual connection\n",
        "    x = Add()([x, z])    \n",
        "    \n",
        "    \n",
        "    skips.append(z)\n",
        "\n",
        "\n",
        "out = Activation('relu')(Add()(skips))\n",
        "\n",
        "out = AveragePooling1D(8000)(out)\n",
        "out = self_attention(out)\n",
        "\n",
        "out = Conv1D(4,1,activation='softmax')(out)\n",
        "out = Reshape((4,1))(out)\n",
        "\n",
        "Wavenet5 = Model(history_seq, out)\n",
        "Wavenet5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 64000, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_77 (Conv1D)              (None, 64000, 8)     48          input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, 64000, 8)     0           conv1d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_78 (Conv1D)              (None, 64000, 8)     328         leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, 64000, 8)     0           conv1d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_9 (AveragePoo (None, 32000, 8)     0           leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_79 (Conv1D)              (None, 32000, 16)    656         average_pooling1d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 32000, 16)    0           conv1d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_80 (Conv1D)              (None, 32000, 16)    1296        leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, 32000, 16)    0           conv1d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_10 (AveragePo (None, 16000, 16)    0           leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_81 (Conv1D)              (None, 16000, 16)    1296        average_pooling1d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, 16000, 16)    0           conv1d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_82 (Conv1D)              (None, 16000, 16)    1296        leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 16000, 16)    0           conv1d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_11 (AveragePo (None, 8000, 16)     0           leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_83 (Conv1D)              (None, 8000, 32)     544         average_pooling1d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_84 (Conv1D)              (None, 8000, 64)     4160        conv1d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_85 (Conv1D)              (None, 8000, 64)     4160        conv1d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8000, 64)     0           conv1d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8000, 64)     0           conv1d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_14 (Multiply)          (None, 8000, 64)     0           activation_31[0][0]              \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_86 (Conv1D)              (None, 8000, 32)     2080        multiply_14[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 8000, 32)     0           conv1d_83[0][0]                  \n",
            "                                                                 conv1d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_87 (Conv1D)              (None, 8000, 32)     1056        add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_88 (Conv1D)              (None, 8000, 64)     4160        conv1d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_89 (Conv1D)              (None, 8000, 64)     4160        conv1d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8000, 64)     0           conv1d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8000, 64)     0           conv1d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_15 (Multiply)          (None, 8000, 64)     0           activation_33[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_90 (Conv1D)              (None, 8000, 32)     2080        multiply_15[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 8000, 32)     0           conv1d_87[0][0]                  \n",
            "                                                                 conv1d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_91 (Conv1D)              (None, 8000, 32)     1056        add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_92 (Conv1D)              (None, 8000, 64)     4160        conv1d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_93 (Conv1D)              (None, 8000, 64)     4160        conv1d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8000, 64)     0           conv1d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8000, 64)     0           conv1d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_16 (Multiply)          (None, 8000, 64)     0           activation_35[0][0]              \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_94 (Conv1D)              (None, 8000, 32)     2080        multiply_16[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 8000, 32)     0           conv1d_86[0][0]                  \n",
            "                                                                 conv1d_90[0][0]                  \n",
            "                                                                 conv1d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8000, 32)     0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_12 (AveragePo (None, 1, 32)        0           activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "permute_8 (Permute)             (None, 32, 1)        0           average_pooling1d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_96 (Conv1D)              (None, 32, 1)        2           permute_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_95 (Conv1D)              (None, 32, 1)        2           permute_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_12 (Reshape)            (None, 1, 32)        0           conv1d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_11 (Reshape)            (None, 32, 1)        0           conv1d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_9 (Permute)             (None, 32, 1)        0           reshape_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dot_4 (Dot)                     (None, 32, 32)       0           reshape_11[0][0]                 \n",
            "                                                                 permute_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 32, 32)       0           dot_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_97 (Conv1D)              (None, 32, 1)        2           permute_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "softmax_2 (Softmax)             (None, 32, 32)       0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_13 (Reshape)            (None, 1, 32)        0           conv1d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_10 (Permute)            (None, 32, 32)       0           softmax_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dot_5 (Dot)                     (None, 1, 32)        0           reshape_13[0][0]                 \n",
            "                                                                 permute_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_14 (Reshape)            (None, 32, 1)        0           dot_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 32, 1)        0           reshape_14[0][0]                 \n",
            "                                                                 permute_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_11 (Permute)            (None, 1, 32)        0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_98 (Conv1D)              (None, 1, 4)         132         permute_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_15 (Reshape)            (None, 4, 1)         0           conv1d_98[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 38,914\n",
            "Trainable params: 38,914\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEoIR77XNwwP",
        "outputId": "d12f26b7-2586-4585-d414-3ee786a23800"
      },
      "source": [
        "Wavenet5.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//wavenet5_loss_1.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//wavenet5_acc_1.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = Wavenet5.fit(X_train,Y_train, batch_size=12,validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "93/93 [==============================] - 19s 182ms/step - loss: 1.3863 - accuracy: 0.7500 - val_loss: 1.3889 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.38887, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.75000, saving model to TESS//models/wavenet5_acc_1.h5\n",
            "Epoch 2/30\n",
            "93/93 [==============================] - 16s 175ms/step - loss: 1.3874 - accuracy: 0.7500 - val_loss: 1.3773 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.38887 to 1.37730, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.75000\n",
            "Epoch 3/30\n",
            "93/93 [==============================] - 16s 172ms/step - loss: 1.2867 - accuracy: 0.7537 - val_loss: 1.1317 - val_accuracy: 0.7824\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.37730 to 1.13171, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.75000 to 0.78243, saving model to TESS//models/wavenet5_acc_1.h5\n",
            "Epoch 4/30\n",
            "93/93 [==============================] - 16s 174ms/step - loss: 1.1155 - accuracy: 0.7813 - val_loss: 1.0858 - val_accuracy: 0.7772\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.13171 to 1.08583, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.78243\n",
            "Epoch 5/30\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 1.0598 - accuracy: 0.7899 - val_loss: 1.0073 - val_accuracy: 0.7877\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.08583 to 1.00726, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.78243 to 0.78766, saving model to TESS//models/wavenet5_acc_1.h5\n",
            "Epoch 6/30\n",
            "93/93 [==============================] - 16s 172ms/step - loss: 1.0264 - accuracy: 0.7907 - val_loss: 0.9316 - val_accuracy: 0.8033\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.00726 to 0.93162, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.78766 to 0.80335, saving model to TESS//models/wavenet5_acc_1.h5\n",
            "Epoch 7/30\n",
            "93/93 [==============================] - 16s 174ms/step - loss: 0.9066 - accuracy: 0.8114 - val_loss: 0.9384 - val_accuracy: 0.8054\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.93162\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.80335 to 0.80544, saving model to TESS//models/wavenet5_acc_1.h5\n",
            "Epoch 8/30\n",
            "93/93 [==============================] - 16s 175ms/step - loss: 0.8738 - accuracy: 0.8248 - val_loss: 0.7468 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.93162 to 0.74677, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.80544 to 0.84623, saving model to TESS//models/wavenet5_acc_1.h5\n",
            "Epoch 9/30\n",
            "93/93 [==============================] - 16s 175ms/step - loss: 0.7458 - accuracy: 0.8466 - val_loss: 0.7957 - val_accuracy: 0.8347\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.74677\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.84623\n",
            "Epoch 10/30\n",
            "93/93 [==============================] - 16s 173ms/step - loss: 0.7058 - accuracy: 0.8421 - val_loss: 0.8202 - val_accuracy: 0.8347\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.74677\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.84623\n",
            "Epoch 11/30\n",
            "93/93 [==============================] - 16s 175ms/step - loss: 0.7385 - accuracy: 0.8416 - val_loss: 0.5498 - val_accuracy: 0.8776\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.74677 to 0.54979, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.84623 to 0.87762, saving model to TESS//models/wavenet5_acc_1.h5\n",
            "Epoch 12/30\n",
            "93/93 [==============================] - 16s 172ms/step - loss: 0.5392 - accuracy: 0.8800 - val_loss: 0.6467 - val_accuracy: 0.8421\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.54979\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.87762\n",
            "Epoch 13/30\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 0.4375 - accuracy: 0.8823 - val_loss: 0.2939 - val_accuracy: 0.9477\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.54979 to 0.29393, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.87762 to 0.94770, saving model to TESS//models/wavenet5_acc_1.h5\n",
            "Epoch 14/30\n",
            "93/93 [==============================] - 16s 174ms/step - loss: 0.2678 - accuracy: 0.9601 - val_loss: 0.2230 - val_accuracy: 0.9718\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.29393 to 0.22297, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.94770 to 0.97176, saving model to TESS//models/wavenet5_acc_1.h5\n",
            "Epoch 15/30\n",
            "93/93 [==============================] - 16s 172ms/step - loss: 0.2529 - accuracy: 0.9533 - val_loss: 0.1729 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.22297 to 0.17289, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.97176\n",
            "Epoch 16/30\n",
            "93/93 [==============================] - 16s 173ms/step - loss: 0.1646 - accuracy: 0.9716 - val_loss: 0.2562 - val_accuracy: 0.9414\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.17289\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.97176\n",
            "Epoch 17/30\n",
            "93/93 [==============================] - 16s 173ms/step - loss: 0.1452 - accuracy: 0.9805 - val_loss: 0.1389 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.17289 to 0.13885, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.97176 to 0.97490, saving model to TESS//models/wavenet5_acc_1.h5\n",
            "Epoch 18/30\n",
            "93/93 [==============================] - 16s 176ms/step - loss: 0.1385 - accuracy: 0.9781 - val_loss: 0.1548 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.13885\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.97490\n",
            "Epoch 19/30\n",
            "93/93 [==============================] - 16s 174ms/step - loss: 0.1362 - accuracy: 0.9742 - val_loss: 0.1084 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.13885 to 0.10839, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.97490 to 0.98326, saving model to TESS//models/wavenet5_acc_1.h5\n",
            "Epoch 20/30\n",
            "93/93 [==============================] - 16s 175ms/step - loss: 0.1029 - accuracy: 0.9841 - val_loss: 0.1282 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.10839\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.98326\n",
            "Epoch 21/30\n",
            "93/93 [==============================] - 16s 173ms/step - loss: 0.1032 - accuracy: 0.9826 - val_loss: 0.1922 - val_accuracy: 0.9613\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.10839\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.98326\n",
            "Epoch 22/30\n",
            "93/93 [==============================] - 16s 173ms/step - loss: 0.0813 - accuracy: 0.9899 - val_loss: 0.0967 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.10839 to 0.09674, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.98326\n",
            "Epoch 23/30\n",
            "93/93 [==============================] - 16s 174ms/step - loss: 0.0848 - accuracy: 0.9887 - val_loss: 0.1655 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.09674\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.98326\n",
            "Epoch 24/30\n",
            "93/93 [==============================] - 16s 174ms/step - loss: 0.1300 - accuracy: 0.9812 - val_loss: 0.1038 - val_accuracy: 0.9874\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.09674\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.98326 to 0.98745, saving model to TESS//models/wavenet5_acc_1.h5\n",
            "Epoch 25/30\n",
            "93/93 [==============================] - 16s 173ms/step - loss: 0.0746 - accuracy: 0.9916 - val_loss: 0.0975 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.09674\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.98745\n",
            "Epoch 26/30\n",
            "93/93 [==============================] - 16s 175ms/step - loss: 0.0796 - accuracy: 0.9897 - val_loss: 0.0913 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.09674 to 0.09127, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.98745\n",
            "Epoch 27/30\n",
            "93/93 [==============================] - 16s 175ms/step - loss: 0.0586 - accuracy: 0.9918 - val_loss: 0.0711 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.09127 to 0.07108, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.98745 to 0.98954, saving model to TESS//models/wavenet5_acc_1.h5\n",
            "Epoch 28/30\n",
            "93/93 [==============================] - 16s 173ms/step - loss: 0.0456 - accuracy: 0.9967 - val_loss: 0.0661 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.07108 to 0.06614, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.98954\n",
            "Epoch 29/30\n",
            "93/93 [==============================] - 16s 173ms/step - loss: 0.0485 - accuracy: 0.9936 - val_loss: 0.0619 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.06614 to 0.06190, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.98954\n",
            "Epoch 30/30\n",
            "93/93 [==============================] - 16s 175ms/step - loss: 0.0359 - accuracy: 0.9960 - val_loss: 0.0545 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.06190 to 0.05450, saving model to TESS//models/wavenet5_loss_1.h5\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.98954 to 0.99372, saving model to TESS//models/wavenet5_acc_1.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9eVug4dN829",
        "outputId": "8483b1ab-c4d5-4e5d-a816-5f8152774942"
      },
      "source": [
        "Wavenet5.load_weights('TESS//models//wavenet5_loss_1.h5')\n",
        "print(Wavenet5.evaluate(X_test,Y_test))\n",
        "Wavenet5.load_weights('TESS//models//wavenet5_acc_1.h5')\n",
        "Wavenet5.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 1s 154ms/step - loss: 0.0429 - accuracy: 0.9937\n",
            "[0.04285595938563347, 0.9937238693237305]\n",
            "8/8 [==============================] - 1s 145ms/step - loss: 0.0429 - accuracy: 0.9937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04285595938563347, 0.9937238693237305]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWGbHVkQOm3g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "ba0c9fad-36a7-456c-d410-25dfd06eaa09"
      },
      "source": [
        "\n",
        "\n",
        "Wavenet5.evaluate(X_test,Y_test)\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(Wavenet5.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1)\n",
        "print(g.shape,p.shape)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(Y_test_features,np.argmax(Wavenet5.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 1s 146ms/step - loss: 0.0545 - accuracy: 0.9937\n",
            "(239,) (239,)\n",
            "F1 SCORE: 0.987440122044241\n",
            "Kappa: 0.9832550970363624\n",
            "Accuracy: 0.9874476987447699\n",
            "Jaccard Score: 0.9753502155172414\n",
            "Precision: 0.9870689655172414\n",
            "Recall: 0.98828125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8bbc78f4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B7kLFGeO9XR"
      },
      "source": [
        "# Hand Engineered"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9M2Dkb1PIue"
      },
      "source": [
        "def extract_features(csvpath,path):\n",
        "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
        "    for i in range(1, 21):\n",
        "        header += f' mfcc{i}'\n",
        "    header += ' label'\n",
        "    header = header.split()\n",
        "    file = open(csvpath, 'w', newline='')\n",
        "    with file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow(header)\n",
        "    rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "        filename = row['path']\n",
        "        y, sr = librosa.load(row['path'], mono=True, duration=30)\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "        rmse = librosa.feature.rms(y=y)\n",
        "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "        to_append = f' {filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
        "        for e in mfcc:\n",
        "                    to_append += f' {np.mean(e)}'\n",
        "        onehot_label = label_to_onehot(row['labels'])\n",
        "        to_append += f' {np.argmax(onehot_label)}'\n",
        "        file = open(csvpath, 'a', newline='')\n",
        "        with file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow(to_append.split())\n",
        "\n",
        "train_csv = \"TESS//train.csv\"\n",
        "test_csv = \"TESS//test.csv\"\n",
        "val_csv = \"TESS//val.csv\"\n",
        "csvpath = 'TESS//hand_engineered_features_EMODB_train.csv'\n",
        "extract_features(csvpath,train_csv)\n",
        "csvpath = 'TESS//hand_engineered_features_EMODB_test.csv'\n",
        "extract_features(csvpath,test_csv)\n",
        "csvpath = 'TESS//hand_engineered_features_EMODB_val.csv'\n",
        "extract_features(csvpath,val_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH4fah10Pe4F",
        "outputId": "8c753815-a287-49cb-ecc5-206f858bc54f"
      },
      "source": [
        "csvpath = 'TESS/hand_engineered_features_EMODB_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'TESS/hand_engineered_features_EMODB_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'TESS/hand_engineered_features_EMODB_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1114, 26) (1114, 1)\n",
            "(239, 26) (239, 1)\n",
            "(239, 26) (239, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv0jJxjpRPZ5",
        "outputId": "06129af0-ecc2-4424-fe52-52fabb24d9cc"
      },
      "source": [
        "ann_model = Sequential(name='Input_Layer')\n",
        "ann_model.add(Dense(256,name='Dense_1'))\n",
        "ann_model.add(LeakyReLU(name='Leaky_Relu_Activation_1'))\n",
        "ann_model.add(Dense(64,name='Dense_2'))\n",
        "ann_model.add(LeakyReLU(name = 'LEaky_Relu_Activation_2'))\n",
        "ann_model.add(Dense(4, activation='softmax',name='Output_Layer'))\n",
        "\n",
        "ann_model.compile(optimizer='Adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ann_model.fit(X_train_features,\n",
        "          Y_train_features,\n",
        "          epochs=30,\n",
        "          batch_size=16,\n",
        "          validation_data=(X_val_features, Y_val_features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "70/70 [==============================] - 1s 6ms/step - loss: 0.5814 - accuracy: 0.8398 - val_loss: 0.0709 - val_accuracy: 0.9833\n",
            "Epoch 2/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.9955 - val_loss: 0.0411 - val_accuracy: 0.9916\n",
            "Epoch 3/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9986 - val_loss: 0.0398 - val_accuracy: 0.9916\n",
            "Epoch 4/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.0345 - val_accuracy: 0.9916\n",
            "Epoch 5/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9916\n",
            "Epoch 6/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.0269 - val_accuracy: 0.9916\n",
            "Epoch 7/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9916\n",
            "Epoch 8/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9916\n",
            "Epoch 9/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9916\n",
            "Epoch 10/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 9.5353e-04 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9916\n",
            "Epoch 11/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 9.3028e-04 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9916\n",
            "Epoch 12/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9916\n",
            "Epoch 13/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 7.6947e-04 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9916\n",
            "Epoch 14/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 7.9015e-04 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9916\n",
            "Epoch 15/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 5.1223e-04 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.9916\n",
            "Epoch 16/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 4.7172e-04 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9916\n",
            "Epoch 17/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 4.0794e-04 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9916\n",
            "Epoch 18/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.2897e-04 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9916\n",
            "Epoch 19/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 2.8227e-04 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9916\n",
            "Epoch 20/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.8549e-04 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9916\n",
            "Epoch 21/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0603e-04 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9916\n",
            "Epoch 22/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 2.3554e-04 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9916\n",
            "Epoch 23/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 2.1463e-04 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9916\n",
            "Epoch 24/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.9649e-04 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9916\n",
            "Epoch 25/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.6284e-04 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9916\n",
            "Epoch 26/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4117e-04 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9916\n",
            "Epoch 27/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.3504e-04 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9916\n",
            "Epoch 28/30\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 1.4800e-04 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9916\n",
            "Epoch 29/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2780e-04 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9916\n",
            "Epoch 30/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2424e-04 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8bb815fdd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8iyaZvsRXop",
        "outputId": "fa608426-b9cb-42ec-baa6-bb2bff3d69cb"
      },
      "source": [
        "ann_model.load_weights('TESS//models//ANN_loss.h5')\n",
        "print(ann_model.evaluate(X_test_features,Y_test_features))\n",
        "ann_model.load_weights('TESS//models//ANN_acc.h5')\n",
        "ann_model.evaluate(X_test_features,Y_test_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9958\n",
            "[0.023911790922284126, 0.9958158731460571]\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02638118341565132, 0.991631805896759]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHbYXdI2RkW8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "7a2d7d73-d7e9-408f-b15b-d3cbf9b98cb4"
      },
      "source": [
        "\n",
        "ann_model.load_weights('TESS//models//ANN_acc.h5')\n",
        "ann_model.evaluate(X_test_features,Y_test_features)\n",
        "\n",
        "print(ann_model.evaluate(X_test_features,Y_test_features))\n",
        "g = Y_test_features\n",
        "p = np.argmax(ann_model.predict(X_test_features),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(Y_test_features,np.argmax(ann_model.predict(X_test_features),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9916\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9916\n",
            "[0.02638118341565132, 0.991631805896759]\n",
            "F1 SCORE: 0.9917077850877193\n",
            "Kappa: 0.9888307318440975\n",
            "Accuracy: 0.9916317991631799\n",
            "Jaccard Score: 0.98368700265252\n",
            "Precision: 0.9917077850877193\n",
            "Recall: 0.9917077850877193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8bb77d0810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAx9biobA1Z2"
      },
      "source": [
        "# Ensembled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvqESCBvA3PB",
        "outputId": "6ca33e7a-db9e-4102-ca76-0bf317ff74cc"
      },
      "source": [
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*time), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "  #out = Conv1D(4,1,activation='softmax')(out)\n",
        "  #out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (26))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  #out2 = Dense(4)(layer2)\n",
        "  #out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out,layer3])\n",
        "  output_layer = Flatten()(output_layer)\n",
        "  output_layer = Dense(4,activation='softmax')(output_layer)\n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled = Wavenet()\n",
        "ensembled.summary()\n",
        "ensembled.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d_83 (Conv1D)             (None, 64000, 8)     48          ['input_9[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_16 (LeakyReLU)     (None, 64000, 8)     0           ['conv1d_83[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_84 (Conv1D)             (None, 64000, 8)     328         ['leaky_re_lu_16[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_17 (LeakyReLU)     (None, 64000, 8)     0           ['conv1d_84[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_9 (AveragePo  (None, 32000, 8)    0           ['leaky_re_lu_17[0][0]']         \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_85 (Conv1D)             (None, 32000, 16)    656         ['average_pooling1d_9[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_18 (LeakyReLU)     (None, 32000, 16)    0           ['conv1d_85[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_86 (Conv1D)             (None, 32000, 16)    1296        ['leaky_re_lu_18[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_19 (LeakyReLU)     (None, 32000, 16)    0           ['conv1d_86[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_10 (AverageP  (None, 16000, 16)   0           ['leaky_re_lu_19[0][0]']         \n",
            " ooling1D)                                                                                        \n",
            "                                                                                                  \n",
            " conv1d_87 (Conv1D)             (None, 16000, 16)    1296        ['average_pooling1d_10[0][0]']   \n",
            "                                                                                                  \n",
            " leaky_re_lu_20 (LeakyReLU)     (None, 16000, 16)    0           ['conv1d_87[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_88 (Conv1D)             (None, 16000, 16)    1296        ['leaky_re_lu_20[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_21 (LeakyReLU)     (None, 16000, 16)    0           ['conv1d_88[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_11 (AverageP  (None, 8000, 16)    0           ['leaky_re_lu_21[0][0]']         \n",
            " ooling1D)                                                                                        \n",
            "                                                                                                  \n",
            " conv1d_89 (Conv1D)             (None, 8000, 32)     544         ['average_pooling1d_11[0][0]']   \n",
            "                                                                                                  \n",
            " conv1d_90 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_89[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_91 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_89[0][0]']              \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 8000, 64)     0           ['conv1d_90[0][0]']              \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 8000, 64)     0           ['conv1d_91[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 8000, 64)     0           ['activation_36[0][0]',          \n",
            "                                                                  'activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_92 (Conv1D)             (None, 8000, 32)     2080        ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 8000, 32)     0           ['conv1d_89[0][0]',              \n",
            "                                                                  'conv1d_92[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_93 (Conv1D)             (None, 8000, 32)     1056        ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_94 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_93[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_95 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_93[0][0]']              \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 8000, 64)     0           ['conv1d_94[0][0]']              \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 8000, 64)     0           ['conv1d_95[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 8000, 64)     0           ['activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_96 (Conv1D)             (None, 8000, 32)     2080        ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 8000, 32)     0           ['conv1d_93[0][0]',              \n",
            "                                                                  'conv1d_96[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_97 (Conv1D)             (None, 8000, 32)     1056        ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_98 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_97[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_99 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_97[0][0]']              \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 8000, 64)     0           ['conv1d_98[0][0]']              \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 8000, 64)     0           ['conv1d_99[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_16 (Multiply)         (None, 8000, 64)     0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_100 (Conv1D)            (None, 8000, 32)     2080        ['multiply_16[0][0]']            \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 8000, 32)     0           ['conv1d_92[0][0]',              \n",
            "                                                                  'conv1d_96[0][0]',              \n",
            "                                                                  'conv1d_100[0][0]']             \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 8000, 32)     0           ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " average_pooling1d_12 (AverageP  (None, 1, 32)       0           ['activation_42[0][0]']          \n",
            " ooling1D)                                                                                        \n",
            "                                                                                                  \n",
            " permute_8 (Permute)            (None, 32, 1)        0           ['average_pooling1d_12[0][0]']   \n",
            "                                                                                                  \n",
            " conv1d_102 (Conv1D)            (None, 32, 1)        2           ['permute_8[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_101 (Conv1D)            (None, 32, 1)        2           ['permute_8[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_13 (Reshape)           (None, 1, 32)        0           ['conv1d_102[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_12 (Reshape)           (None, 32, 1)        0           ['conv1d_101[0][0]']             \n",
            "                                                                                                  \n",
            " permute_9 (Permute)            (None, 32, 1)        0           ['reshape_13[0][0]']             \n",
            "                                                                                                  \n",
            " dot_4 (Dot)                    (None, 32, 32)       0           ['reshape_12[0][0]',             \n",
            "                                                                  'permute_9[0][0]']              \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 32, 32)       0           ['dot_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_103 (Conv1D)            (None, 32, 1)        2           ['permute_8[0][0]']              \n",
            "                                                                                                  \n",
            " softmax_2 (Softmax)            (None, 32, 32)       0           ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " reshape_14 (Reshape)           (None, 1, 32)        0           ['conv1d_103[0][0]']             \n",
            "                                                                                                  \n",
            " permute_10 (Permute)           (None, 32, 32)       0           ['softmax_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 128)          3456        ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " dot_5 (Dot)                    (None, 1, 32)        0           ['reshape_14[0][0]',             \n",
            "                                                                  'permute_10[0][0]']             \n",
            "                                                                                                  \n",
            " leaky_re_lu_22 (LeakyReLU)     (None, 128)          0           ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_15 (Reshape)           (None, 32, 1)        0           ['dot_5[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 32)           4128        ['leaky_re_lu_22[0][0]']         \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 32, 1)        0           ['reshape_15[0][0]',             \n",
            "                                                                  'permute_8[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_23 (LeakyReLU)     (None, 32)           0           ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " permute_11 (Permute)           (None, 1, 32)        0           ['add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " reshape_16 (Reshape)           (None, 1, 32)        0           ['leaky_re_lu_23[0][0]']         \n",
            "                                                                                                  \n",
            " average_2 (Average)            (None, 1, 32)        0           ['permute_11[0][0]',             \n",
            "                                                                  'reshape_16[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)            (None, 32)           0           ['average_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 4)            132         ['flatten_4[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 46,498\n",
            "Trainable params: 46,498\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbf607CWA8fb",
        "outputId": "6b24f51d-deb3-45f4-cb53-166fd455eeeb"
      },
      "source": [
        "ensembled.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//ensembled_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//ensembled_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "ensembled.fit([X_train,X_train_features],Y_train, batch_size=16,validation_data=([X_val,X_val_features], Y_val),epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "70/70 [==============================] - 11s 117ms/step - loss: 1.0285 - accuracy: 0.6922 - val_loss: 0.2685 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.26853, saving model to TESS//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.96653, saving model to TESS//models/ensembled_acc.h5\n",
            "Epoch 2/30\n",
            "70/70 [==============================] - 8s 111ms/step - loss: 0.1796 - accuracy: 0.9823 - val_loss: 0.0890 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.26853 to 0.08896, saving model to TESS//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.96653 to 0.97908, saving model to TESS//models/ensembled_acc.h5\n",
            "Epoch 3/30\n",
            "70/70 [==============================] - 8s 111ms/step - loss: 0.0628 - accuracy: 0.9897 - val_loss: 0.0595 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.08896 to 0.05954, saving model to TESS//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.97908 to 0.99163, saving model to TESS//models/ensembled_acc.h5\n",
            "Epoch 4/30\n",
            "70/70 [==============================] - 8s 110ms/step - loss: 0.0269 - accuracy: 0.9962 - val_loss: 0.0442 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.05954 to 0.04424, saving model to TESS//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.99163\n",
            "Epoch 5/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 0.0182 - accuracy: 0.9986 - val_loss: 0.0380 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.04424 to 0.03797, saving model to TESS//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.99163\n",
            "Epoch 6/30\n",
            "70/70 [==============================] - 8s 108ms/step - loss: 0.0131 - accuracy: 0.9990 - val_loss: 0.0354 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.03797 to 0.03536, saving model to TESS//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.99163\n",
            "Epoch 7/30\n",
            "70/70 [==============================] - 7s 107ms/step - loss: 0.0090 - accuracy: 0.9998 - val_loss: 0.0301 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.03536 to 0.03014, saving model to TESS//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.99163\n",
            "Epoch 8/30\n",
            "70/70 [==============================] - 8s 108ms/step - loss: 0.0061 - accuracy: 0.9999 - val_loss: 0.0302 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.03014\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.99163\n",
            "Epoch 9/30\n",
            "70/70 [==============================] - 8s 108ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.03014\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.99163\n",
            "Epoch 10/30\n",
            "70/70 [==============================] - 8s 108ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0276 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.03014 to 0.02762, saving model to TESS//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.99163\n",
            "Epoch 11/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.02762\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.99163\n",
            "Epoch 12/30\n",
            "70/70 [==============================] - 8s 110ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.02762 to 0.02609, saving model to TESS//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.99163\n",
            "Epoch 13/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.02609\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.99163\n",
            "Epoch 14/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.02609 to 0.02390, saving model to TESS//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.99163\n",
            "Epoch 15/30\n",
            "70/70 [==============================] - 8s 110ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.02390\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.99163\n",
            "Epoch 16/30\n",
            "70/70 [==============================] - 8s 110ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.02390\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.99163\n",
            "Epoch 17/30\n",
            "70/70 [==============================] - 8s 108ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.02390\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.99163\n",
            "Epoch 18/30\n",
            "70/70 [==============================] - 8s 108ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.02390\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.99163\n",
            "Epoch 19/30\n",
            "70/70 [==============================] - 8s 108ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.02390\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.99163\n",
            "Epoch 20/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 7.0538e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.02390\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.99163\n",
            "Epoch 21/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 7.2116e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.02390 to 0.02388, saving model to TESS//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.99163\n",
            "Epoch 22/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 7.5985e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.02388\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.99163\n",
            "Epoch 23/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 7.8274e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.02388\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.99163\n",
            "Epoch 24/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 8.7251e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.02388\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.99163\n",
            "Epoch 25/30\n",
            "70/70 [==============================] - 8s 110ms/step - loss: 5.3896e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.02388 to 0.02256, saving model to TESS//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99163\n",
            "Epoch 26/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 5.7006e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.02256\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99163\n",
            "Epoch 27/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 5.2884e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.02256\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.99163\n",
            "Epoch 28/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 5.3039e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.02256\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99163\n",
            "Epoch 29/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 4.3965e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.02256 to 0.02243, saving model to TESS//models/ensembled_loss.h5\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.99163\n",
            "Epoch 30/30\n",
            "70/70 [==============================] - 8s 109ms/step - loss: 4.8026e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.02243\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.99163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f07ca418090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYy33ZRdB6pm",
        "outputId": "da88f4a8-d597-4eb2-809d-850124ab0ec6"
      },
      "source": [
        "ensembled.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "ensembled.load_weights(\"TESS//models/ensembled_loss.h5\")\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "\n",
        "ensembled.load_weights(\"TESS//models/ensembled_acc.h5\")\n",
        "ensembled.evaluate([X_test,X_test_features],Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 3s 183ms/step - loss: 0.0088 - accuracy: 0.9986\n",
            "[0.021812191233038902, 0.9958158731460571]\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 0.0389 - accuracy: 0.9874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03890075162053108, 0.9874476790428162]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goZ-nvwGD_dO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "20d9cdd8-c59a-4bd2-e32a-b4e9d3b00f6b"
      },
      "source": [
        "ensembled.load_weights(\"TESS//models/ensembled_loss.h5\")\n",
        "#test set\n",
        "\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 1s 155ms/step - loss: 0.0218 - accuracy: 0.9958\n",
            "[0.021812191233038902, 0.9958158731460571]\n",
            "F1 SCORE: 0.9958575830195139\n",
            "Kappa: 0.9944162792327641\n",
            "Accuracy: 0.99581589958159\n",
            "Jaccard Score: 0.9917834051724138\n",
            "Precision: 0.9956896551724138\n",
            "Recall: 0.99609375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8bc02abc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 2"
      ],
      "metadata": {
        "id": "nxfXww3iIuD_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcTVYXvKzkly",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "13c7a3b7-fecb-4b21-cd66-3a663b37cfed"
      },
      "source": [
        "ensembled.load_weights(\"TESS//models/ensembled_acc.h5\")\n",
        "#test set\n",
        "\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 2s 98ms/step - loss: 0.0389 - accuracy: 0.9874\n",
            "[0.038900747895240784, 0.9874476790428162]\n",
            "F1 SCORE: 0.987548878370035\n",
            "Kappa: 0.9832433569375307\n",
            "Accuracy: 0.9874476987447699\n",
            "Jaccard Score: 0.975705329153605\n",
            "Precision: 0.9878434065934066\n",
            "Recall: 0.9873218201754386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa69ee47b90>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 3"
      ],
      "metadata": {
        "id": "ARdLiO65JJl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint1 = ModelCheckpoint('TESS//models//ensembled_loss_2.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//ensembled_acc_2.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "ensembled.fit([X_train,X_train_features],Y_train, batch_size=16,validation_data=([X_val,X_val_features], Y_val),epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLGVOp2KJK-6",
        "outputId": "4f8e9b6c-6d8f-4e77-d8cf-59ca04b0badf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.7388 - accuracy: 0.8483\n",
            "Epoch 1: val_loss improved from inf to 0.29269, saving model to TESS//models/ensembled_loss_2.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96653, saving model to TESS//models/ensembled_acc_2.h5\n",
            "70/70 [==============================] - 65s 140ms/step - loss: 0.7388 - accuracy: 0.8483 - val_loss: 0.2927 - val_accuracy: 0.9665\n",
            "Epoch 2/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.9883\n",
            "Epoch 2: val_loss improved from 0.29269 to 0.08948, saving model to TESS//models/ensembled_loss_2.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.96653 to 0.97908, saving model to TESS//models/ensembled_acc_2.h5\n",
            "70/70 [==============================] - 8s 118ms/step - loss: 0.1349 - accuracy: 0.9883 - val_loss: 0.0895 - val_accuracy: 0.9791\n",
            "Epoch 3/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9937\n",
            "Epoch 3: val_loss improved from 0.08948 to 0.05593, saving model to TESS//models/ensembled_loss_2.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.97908 to 0.98745, saving model to TESS//models/ensembled_acc_2.h5\n",
            "70/70 [==============================] - 8s 119ms/step - loss: 0.0484 - accuracy: 0.9937 - val_loss: 0.0559 - val_accuracy: 0.9874\n",
            "Epoch 4/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9964\n",
            "Epoch 4: val_loss improved from 0.05593 to 0.04360, saving model to TESS//models/ensembled_loss_2.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.98745 to 0.99163, saving model to TESS//models/ensembled_acc_2.h5\n",
            "70/70 [==============================] - 9s 123ms/step - loss: 0.0278 - accuracy: 0.9964 - val_loss: 0.0436 - val_accuracy: 0.9916\n",
            "Epoch 5/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9973\n",
            "Epoch 5: val_loss improved from 0.04360 to 0.03610, saving model to TESS//models/ensembled_loss_2.h5\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 9s 127ms/step - loss: 0.0177 - accuracy: 0.9973 - val_loss: 0.0361 - val_accuracy: 0.9916\n",
            "Epoch 6/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9982\n",
            "Epoch 6: val_loss improved from 0.03610 to 0.03498, saving model to TESS//models/ensembled_loss_2.h5\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 9s 127ms/step - loss: 0.0129 - accuracy: 0.9982 - val_loss: 0.0350 - val_accuracy: 0.9916\n",
            "Epoch 7/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9991\n",
            "Epoch 7: val_loss improved from 0.03498 to 0.03180, saving model to TESS//models/ensembled_loss_2.h5\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 9s 128ms/step - loss: 0.0105 - accuracy: 0.9991 - val_loss: 0.0318 - val_accuracy: 0.9916\n",
            "Epoch 8/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9991\n",
            "Epoch 8: val_loss improved from 0.03180 to 0.03143, saving model to TESS//models/ensembled_loss_2.h5\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 9s 125ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.0314 - val_accuracy: 0.9916\n",
            "Epoch 9/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9991\n",
            "Epoch 9: val_loss did not improve from 0.03143\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 9s 122ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.0329 - val_accuracy: 0.9916\n",
            "Epoch 10/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 10: val_loss improved from 0.03143 to 0.02963, saving model to TESS//models/ensembled_loss_2.h5\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 9s 128ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9916\n",
            "Epoch 11/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 11: val_loss did not improve from 0.02963\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 121ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.9916\n",
            "Epoch 12/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991\n",
            "Epoch 12: val_loss improved from 0.02963 to 0.02694, saving model to TESS//models/ensembled_loss_2.h5\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 9s 127ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0269 - val_accuracy: 0.9916\n",
            "Epoch 13/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 13: val_loss did not improve from 0.02694\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 121ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9916\n",
            "Epoch 14/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 0.02694\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 121ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.9916\n",
            "Epoch 15/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 15: val_loss improved from 0.02694 to 0.02366, saving model to TESS//models/ensembled_loss_2.h5\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 9s 130ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9916\n",
            "Epoch 16/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 16: val_loss did not improve from 0.02366\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 120ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9916\n",
            "Epoch 17/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 0.02366\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 120ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9916\n",
            "Epoch 18/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 18: val_loss did not improve from 0.02366\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 121ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9916\n",
            "Epoch 19/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 19: val_loss did not improve from 0.02366\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 121ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9916\n",
            "Epoch 20/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 0.02366\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 9s 122ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9916\n",
            "Epoch 21/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 9.1210e-04 - accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 0.02366\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 119ms/step - loss: 9.1210e-04 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9916\n",
            "Epoch 22/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 9.1437e-04 - accuracy: 1.0000\n",
            "Epoch 22: val_loss improved from 0.02366 to 0.02250, saving model to TESS//models/ensembled_loss_2.h5\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 9s 122ms/step - loss: 9.1437e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9916\n",
            "Epoch 23/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 7.6319e-04 - accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 0.02250\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 116ms/step - loss: 7.6319e-04 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9916\n",
            "Epoch 24/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 6.7977e-04 - accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 0.02250\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 116ms/step - loss: 6.7977e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9916\n",
            "Epoch 25/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 6.2582e-04 - accuracy: 1.0000\n",
            "Epoch 25: val_loss did not improve from 0.02250\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 116ms/step - loss: 6.2582e-04 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9916\n",
            "Epoch 26/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 6.7628e-04 - accuracy: 1.0000\n",
            "Epoch 26: val_loss did not improve from 0.02250\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 116ms/step - loss: 6.7628e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9916\n",
            "Epoch 27/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 5.1387e-04 - accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 0.02250\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 116ms/step - loss: 5.1387e-04 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9916\n",
            "Epoch 28/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 4.8233e-04 - accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 0.02250\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 116ms/step - loss: 4.8233e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9916\n",
            "Epoch 29/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 4.3261e-04 - accuracy: 1.0000\n",
            "Epoch 29: val_loss did not improve from 0.02250\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 116ms/step - loss: 4.3261e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9916\n",
            "Epoch 30/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 3.9756e-04 - accuracy: 1.0000\n",
            "Epoch 30: val_loss did not improve from 0.02250\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 8s 116ms/step - loss: 3.9756e-04 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9916\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa69ed9d610>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ensembled.load_weights(\"TESS//models/ensembled_acc_2.h5\")\n",
        "#test set\n",
        "\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "ozanGa1kJoKV",
        "outputId": "25ae9697-22fa-4a38-f4ff-de71c0ed8bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 84ms/step - loss: 0.0278 - accuracy: 0.9958\n",
            "[0.02779996581375599, 0.9958158731460571]\n",
            "F1 SCORE: 0.9958575830195139\n",
            "Kappa: 0.9944162792327641\n",
            "Accuracy: 0.99581589958159\n",
            "Jaccard Score: 0.9917834051724138\n",
            "Precision: 0.9956896551724138\n",
            "Recall: 0.99609375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa9863e15d0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 4"
      ],
      "metadata": {
        "id": "QgarPcdFK0Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled.load_weights(\"TESS//models/ensembled_acc_2.h5\")\n",
        "#test set\n",
        "\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "SElIaPtRK2WB",
        "outputId": "21f40f89-35b7-4268-8e10-2d7ee372be43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 83ms/step - loss: 0.0308 - accuracy: 0.9916\n",
            "[0.03083842620253563, 0.991631805896759]\n",
            "F1 SCORE: 0.9917077850877193\n",
            "Kappa: 0.9888307318440975\n",
            "Accuracy: 0.9916317991631799\n",
            "Jaccard Score: 0.98368700265252\n",
            "Precision: 0.9917077850877193\n",
            "Recall: 0.9917077850877193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa99f74b710>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled.load_weights(\"TESS//models/ensembled_loss_2.h5\")\n",
        "#test set\n",
        "\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "id": "OKHU-rnLK8pT",
        "outputId": "3f061ca9-fc3d-4267-d2df-18b9bc3e8ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 80ms/step - loss: 0.0290 - accuracy: 0.9958\n",
            "[0.02900487184524536, 0.9958158731460571]\n",
            "F1 SCORE: 0.9958575830195139\n",
            "Kappa: 0.9944162792327641\n",
            "Accuracy: 0.99581589958159\n",
            "Jaccard Score: 0.9917834051724138\n",
            "Precision: 0.9956896551724138\n",
            "Recall: 0.99609375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa99f68d9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZl5aEHwMwtW"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2g_O9kAMyhj",
        "outputId": "f8ff34ee-4dab-4e3a-8737-40fa22df680e"
      },
      "source": [
        "cnn_model = Sequential(name='Convolutional_Neural_Network')\n",
        "\n",
        "cnn_model.add(Conv2D(filters=16,\n",
        "                     kernel_size=(3,3),\n",
        "                     input_shape=(max_x,max_y,1),name = \"Input_Convolution_Layer\"))\n",
        "cnn_model.add(LeakyReLU( name = \"Leaky_Relu_Activation_1\"))\n",
        "# Adding max pooling layer\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2,4),name = 'Max_Pooling_1'))\n",
        "\n",
        "# Adding convolutional layer\n",
        "cnn_model.add(Conv2D(filters=32,\n",
        "                     kernel_size=(3,3),name = \"Convolution_Layer_2\"\n",
        "                     ))\n",
        "cnn_model.add(LeakyReLU(name = \"Leaky_Relu_Activation_2\"))\n",
        "# Adding max pooling layer\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2,4),name = 'Max_Pooling_2'))\n",
        "\n",
        "# Adding a flattened layer to input our image data\n",
        "cnn_model.add(Flatten(name = 'Flatten'))\n",
        "\n",
        "# Adding a dense layer with 64 neurons\n",
        "cnn_model.add(Dense(64,name = 'Dense_1' ))\n",
        "cnn_model.add(LeakyReLU())\n",
        "\n",
        "# Adding a dropout layer for regularization\n",
        "cnn_model.add(Dropout(0.25,name = 'Dropout'))\n",
        "\n",
        "# Adding an output layer\n",
        "cnn_model.add(Dense(4, activation='softmax',name = 'Output_Layer'))\n",
        "\n",
        "# Compiling our neural network\n",
        "cnn_model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "model_checkpoint = ModelCheckpoint(f'TESS//models//CNN.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "# Fitting our neural network\n",
        "history = cnn_model.fit(X_train_spec,\n",
        "                        Y_train_spec, \n",
        "                        batch_size=16,\n",
        "                        validation_data=(X_val_spec, Y_val_spec),\n",
        "                        epochs=30,callbacks = model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.9154 - accuracy: 0.6153 - val_loss: 0.1867 - val_accuracy: 0.9205\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.18670, saving model to TESS//models/CNN.h5\n",
            "Epoch 2/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.1905 - accuracy: 0.9193 - val_loss: 0.0613 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.18670 to 0.06125, saving model to TESS//models/CNN.h5\n",
            "Epoch 3/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0578 - accuracy: 0.9830 - val_loss: 0.0464 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.06125 to 0.04639, saving model to TESS//models/CNN.h5\n",
            "Epoch 4/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9910 - val_loss: 0.0310 - val_accuracy: 0.9874\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.04639 to 0.03102, saving model to TESS//models/CNN.h5\n",
            "Epoch 5/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.0395 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.03102\n",
            "Epoch 6/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.0247 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.03102 to 0.02470, saving model to TESS//models/CNN.h5\n",
            "Epoch 7/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9874\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.02470 to 0.02154, saving model to TESS//models/CNN.h5\n",
            "Epoch 8/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0186 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.02154 to 0.01864, saving model to TESS//models/CNN.h5\n",
            "Epoch 9/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9874\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01864\n",
            "Epoch 10/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01864 to 0.01009, saving model to TESS//models/CNN.h5\n",
            "Epoch 11/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01009\n",
            "Epoch 12/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 8.3671e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01009\n",
            "Epoch 13/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 7.3083e-04 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01009\n",
            "Epoch 14/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 4.1479e-04 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.01009\n",
            "Epoch 15/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 5.9534e-04 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9874\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01009\n",
            "Epoch 16/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01009\n",
            "Epoch 17/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 5.1243e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01009\n",
            "Epoch 18/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01009\n",
            "Epoch 19/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0230 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01009\n",
            "Epoch 20/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9874 - val_loss: 0.0237 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01009\n",
            "Epoch 21/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01009\n",
            "Epoch 22/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 5.4253e-04 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01009\n",
            "Epoch 23/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 2.6990e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01009\n",
            "Epoch 24/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 3.0244e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01009\n",
            "Epoch 25/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 1.8803e-04 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01009\n",
            "Epoch 26/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 1.8185e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01009\n",
            "Epoch 27/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 1.0391e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01009\n",
            "Epoch 28/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 2.4095e-04 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01009\n",
            "Epoch 29/30\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1429e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01009\n",
            "Epoch 30/30\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 8.8549e-05 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV5yBjyANJfH",
        "outputId": "b7dba553-27e3-4e0d-aaf0-833be973bbc3"
      },
      "source": [
        "cnn_model.load_weights('TESS//models//CNN.h5')\n",
        "cnn_model.evaluate(X_test_spec,Y_test_spec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.027469299733638763, 0.9874476790428162]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "FHfb1qbnM8Ws",
        "outputId": "32f99f36-0566-472e-b831-fa084f338231"
      },
      "source": [
        "#test set\n",
        "\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(cnn_model.predict(X_test_spec),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(cnn_model.predict(X_test_spec),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 SCORE: 0.9957550902942658\n",
            "Kappa: 0.9944161487780945\n",
            "Accuracy: 0.99581589958159\n",
            "Jaccard Score: 0.9915817770232032\n",
            "Precision: 0.9956140350877193\n",
            "Recall: 0.9959677419354839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f31aa111f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0pRbRaONmmv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycCMb8b3fXDh"
      },
      "source": [
        "# Paper_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0flJcW8fYtv",
        "outputId": "1d74b1ab-7e5d-4116-a44b-c9fdbeb80aae"
      },
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 8\n",
        "srk = 44100\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = srk)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"TESS//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"TESS//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"TESS//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (1114, 352800, 1) (1114, 4)\n",
            "Test Data (239, 352800, 1) (239, 4)\n",
            "Val Data (239, 352800, 1) (239, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmWQUWpGfjPN",
        "outputId": "a97327ee-b536-4bcd-caf3-7df7e5ff477e"
      },
      "source": [
        "def paper_model():\n",
        "  inp = Input((352800,1))\n",
        "  l1 = BatchNormalization()(Conv1D(32,21,activation='relu',padding = 'same')(inp))\n",
        "  m1 = MaxPool1D(2)(l1)\n",
        "\n",
        "  l2 = BatchNormalization()(Conv1D(64,19,activation='relu',padding = 'same')(m1))\n",
        "  m2 = MaxPool1D(2)(l2)\n",
        "\n",
        "  l3 = BatchNormalization()(Conv1D(128,17,activation='relu',padding = 'same')(m2))\n",
        "  m3 = MaxPool1D(2)(l3)\n",
        "\n",
        "\n",
        "  l4 = BatchNormalization()(Conv1D(256,15,activation='relu',padding = 'same')(m3))\n",
        "  m4 = MaxPool1D(2)(l4)\n",
        "\n",
        "  l5 = BatchNormalization()(Conv1D(512,13,activation='relu',padding = 'same')(m4))\n",
        "  m5 = MaxPool1D(2)(l5)\n",
        "\n",
        "  l6 = BatchNormalization()(Conv1D(1024,11,activation='relu',padding = 'same')(m5))\n",
        "  m6 = MaxPool1D(2)(l6)\n",
        "\n",
        "  l7 = BatchNormalization()(Conv1D(1024,9,activation='relu',padding = 'same')(m6))\n",
        "  m7 = GlobalMaxPool1D()(l7)\n",
        "\n",
        "  fl = Flatten()(m7)\n",
        "  d1 = Dense(128,activation='relu')(fl)\n",
        "  out = Dense(4,activation='softmax')(d1)\n",
        "\n",
        "  return Model(inputs = inp,outputs = out)\n",
        "\n",
        "m = paper_model()\n",
        "m.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 352800, 1)]       0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 352800, 32)        704       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 352800, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 176400, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 176400, 64)        38976     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 176400, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 88200, 64)        0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 88200, 128)        139392    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 88200, 128)       512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 44100, 128)       0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 44100, 256)        491776    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 44100, 256)       1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 22050, 256)       0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 22050, 512)        1704448   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 22050, 512)       2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 11025, 512)       0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 11025, 1024)       5768192   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 11025, 1024)      4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 5512, 1024)       0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 5512, 1024)        9438208   \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 5512, 1024)       4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 1024)             0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               131200    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,725,572\n",
            "Trainable params: 17,719,492\n",
            "Non-trainable params: 6,080\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 1\n",
        "\n"
      ],
      "metadata": {
        "id": "3NBY6zfNNibT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX8DeXhWfsOq",
        "outputId": "650928fa-2417-4064-ee32-efc03f9bd45f"
      },
      "source": [
        "m.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//paper_1_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//paper_1_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = m.fit(X_train,Y_train, batch_size=8,validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "140/140 [==============================] - 463s 3s/step - loss: 3.6194 - accuracy: 0.4833 - val_loss: 2.8061 - val_accuracy: 0.0251\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.80608, saving model to TESS//models/paper_1_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.02510, saving model to TESS//models/paper_1_acc.h5\n",
            "Epoch 2/30\n",
            "140/140 [==============================] - 458s 3s/step - loss: 1.1805 - accuracy: 0.6726 - val_loss: 3.6209 - val_accuracy: 0.2385\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 2.80608\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.02510 to 0.23849, saving model to TESS//models/paper_1_acc.h5\n",
            "Epoch 3/30\n",
            "140/140 [==============================] - 456s 3s/step - loss: 0.1924 - accuracy: 0.9388 - val_loss: 1.9987 - val_accuracy: 0.5565\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.80608 to 1.99872, saving model to TESS//models/paper_1_loss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.23849 to 0.55649, saving model to TESS//models/paper_1_acc.h5\n",
            "Epoch 4/30\n",
            "140/140 [==============================] - 461s 3s/step - loss: 0.3068 - accuracy: 0.9170 - val_loss: 3.0232 - val_accuracy: 0.4728\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.99872\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.55649\n",
            "Epoch 5/30\n",
            "140/140 [==============================] - 460s 3s/step - loss: 0.2697 - accuracy: 0.9282 - val_loss: 1.6036 - val_accuracy: 0.4686\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.99872 to 1.60364, saving model to TESS//models/paper_1_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.55649\n",
            "Epoch 6/30\n",
            "140/140 [==============================] - 461s 3s/step - loss: 0.1618 - accuracy: 0.9567 - val_loss: 0.0372 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.60364 to 0.03722, saving model to TESS//models/paper_1_loss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.55649 to 0.99163, saving model to TESS//models/paper_1_acc.h5\n",
            "Epoch 7/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.3831 - accuracy: 0.9098 - val_loss: 0.5156 - val_accuracy: 0.7406\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.03722\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.99163\n",
            "Epoch 8/30\n",
            "140/140 [==============================] - 463s 3s/step - loss: 0.1634 - accuracy: 0.9453 - val_loss: 0.2362 - val_accuracy: 0.9205\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.03722\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.99163\n",
            "Epoch 9/30\n",
            "140/140 [==============================] - 463s 3s/step - loss: 0.8800 - accuracy: 0.8497 - val_loss: 0.2463 - val_accuracy: 0.8912\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.03722\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.99163\n",
            "Epoch 10/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.1096 - accuracy: 0.9630 - val_loss: 0.3462 - val_accuracy: 0.8828\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.03722\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.99163\n",
            "Epoch 11/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.1315 - accuracy: 0.9621 - val_loss: 0.8637 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.03722\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.99163\n",
            "Epoch 12/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.2071 - val_accuracy: 0.9372\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.03722\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.99163\n",
            "Epoch 13/30\n",
            "140/140 [==============================] - 463s 3s/step - loss: 0.0432 - accuracy: 0.9816 - val_loss: 0.0196 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.03722 to 0.01956, saving model to TESS//models/paper_1_loss.h5\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.99163\n",
            "Epoch 14/30\n",
            "140/140 [==============================] - 458s 3s/step - loss: 0.0487 - accuracy: 0.9831 - val_loss: 0.2975 - val_accuracy: 0.9121\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.99163\n",
            "Epoch 15/30\n",
            "140/140 [==============================] - 461s 3s/step - loss: 0.1099 - accuracy: 0.9713 - val_loss: 0.4983 - val_accuracy: 0.8661\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.99163\n",
            "Epoch 16/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.0699 - accuracy: 0.9836 - val_loss: 0.0499 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.99163\n",
            "Epoch 17/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.0455 - accuracy: 0.9919 - val_loss: 0.1677 - val_accuracy: 0.9456\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.99163\n",
            "Epoch 18/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0553 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.99163\n",
            "Epoch 19/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.0406 - accuracy: 0.9895 - val_loss: 0.0452 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.99163\n",
            "Epoch 20/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.0151 - accuracy: 0.9942 - val_loss: 0.0671 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.99163\n",
            "Epoch 21/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.0238 - val_accuracy: 0.9874\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.99163\n",
            "Epoch 22/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.0114 - accuracy: 0.9952 - val_loss: 0.3567 - val_accuracy: 0.8870\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.99163\n",
            "Epoch 23/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.6221 - val_accuracy: 0.8326\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.99163\n",
            "Epoch 24/30\n",
            "140/140 [==============================] - 463s 3s/step - loss: 0.1163 - accuracy: 0.9745 - val_loss: 7.9010 - val_accuracy: 0.3975\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.99163\n",
            "Epoch 25/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.3554 - accuracy: 0.9054 - val_loss: 0.0740 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99163\n",
            "Epoch 26/30\n",
            "140/140 [==============================] - 463s 3s/step - loss: 0.1024 - accuracy: 0.9656 - val_loss: 0.3489 - val_accuracy: 0.8828\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99163\n",
            "Epoch 27/30\n",
            "140/140 [==============================] - 461s 3s/step - loss: 0.0481 - accuracy: 0.9834 - val_loss: 0.0588 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.99163\n",
            "Epoch 28/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.0335 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99163\n",
            "Epoch 29/30\n",
            "140/140 [==============================] - 461s 3s/step - loss: 0.0268 - accuracy: 0.9890 - val_loss: 0.0422 - val_accuracy: 0.9874\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01956\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.99163\n",
            "Epoch 30/30\n",
            "140/140 [==============================] - 462s 3s/step - loss: 0.0804 - accuracy: 0.9775 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.01956 to 0.01206, saving model to TESS//models/paper_1_loss.h5\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.99163 to 1.00000, saving model to TESS//models/paper_1_acc.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zuVtzQGjzkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4757e918-7ab5-42ea-90c2-136f705cc7ef"
      },
      "source": [
        "m.load_weights('TESS//models//paper_1_acc.h5')\n",
        "print(m.evaluate(X_test,Y_test))\n",
        "m.load_weights('TESS//models//paper_1_loss.h5')\n",
        "m.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 14s 2s/step - loss: 0.0179 - accuracy: 0.9916\n",
            "[0.017868367955088615, 0.991631805896759]\n",
            "8/8 [==============================] - 14s 2s/step - loss: 0.0179 - accuracy: 0.9916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.017868367955088615, 0.991631805896759]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "TnBnZTwOopZL",
        "outputId": "92462bc2-628c-43b4-8040-d162257e019f"
      },
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(m.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(m.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 SCORE: 0.9916675847042694\n",
            "Kappa: 0.9888304708493983\n",
            "Accuracy: 0.9916317991631799\n",
            "Jaccard Score: 0.9835330617658204\n",
            "Precision: 0.9917834051724138\n",
            "Recall: 0.9916294642857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        62\n",
            "           1       1.00      0.98      0.99        56\n",
            "           2       0.98      1.00      0.99        57\n",
            "           3       0.98      0.98      0.98        64\n",
            "\n",
            "    accuracy                           0.99       239\n",
            "   macro avg       0.99      0.99      0.99       239\n",
            "weighted avg       0.99      0.99      0.99       239\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 2"
      ],
      "metadata": {
        "id": "sNuFsjLVNdO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//paper_1_loss_2.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//paper_1_acc_2.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = m.fit(X_train,Y_train, batch_size=8,validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "GlBvgZcoNglm",
        "outputId": "30081152-127c-4b59-949c-f33fd36f696e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 2.5032 - accuracy: 0.4713\n",
            "Epoch 1: val_loss improved from inf to 6.49118, saving model to TESS//models/paper_1_loss_2.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.24686, saving model to TESS//models/paper_1_acc_2.h5\n",
            "140/140 [==============================] - 468s 3s/step - loss: 2.5032 - accuracy: 0.4713 - val_loss: 6.4912 - val_accuracy: 0.2469\n",
            "Epoch 2/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.8016 - accuracy: 0.7549\n",
            "Epoch 2: val_loss improved from 6.49118 to 4.38487, saving model to TESS//models/paper_1_loss_2.h5\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.24686\n",
            "140/140 [==============================] - 438s 3s/step - loss: 0.8016 - accuracy: 0.7549 - val_loss: 4.3849 - val_accuracy: 0.2469\n",
            "Epoch 3/30\n",
            " 99/140 [====================>.........] - ETA: 1:59 - loss: 0.5300 - accuracy: 0.8699"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2839c2aeb48f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_checkpoint2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TESS//models//paper_1_acc_2.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m history = m.fit(X_train,Y_train, batch_size=8,validation_data=(X_val, Y_val),\n\u001b[0;32m----> 9\u001b[0;31m                         epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.load_weights('TESS//models//paper_1_acc_2.h5')\n",
        "print(m.evaluate(X_test,Y_test))\n",
        "m.load_weights('TESS//models//paper_1_loss_2.h5')\n",
        "m.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "d0HoWI_tNpn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(m.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(m.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "id": "MBCOZxv2OP9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot for Trial 2"
      ],
      "metadata": {
        "id": "ZArm0O1vSeAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fQ0ITtRASVyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dw_XThE1mm6"
      },
      "source": [
        "# Paper_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yet6gb6VJksG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "eac4b722-315c-4486-e9f9-58d3326287c5"
      },
      "source": [
        "def findmaxsize(rslt_df):\n",
        "\n",
        "    sizes = []\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "      filename = row['path']\n",
        "\n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      #print(y.shape)\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      \n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        "      #print(spect.shape)\n",
        "      \n",
        "      # Adding the size to the list\n",
        "      sizes.append(spect.shape)\n",
        "    print(f'The sizes of all the mel spectrograms in our data set are equal: {len(set(sizes)) == 1}')\n",
        "\n",
        "    # Checking the max size\n",
        "    print(f'The maximum size is: {max(sizes)}')\n",
        "\n",
        "\n",
        "    return max(sizes)\n",
        "\n",
        "\n",
        "X = pd.read_csv('TESS/TESS_details.csv',usecols=['labels','path'])\n",
        "options = ['angry', 'happy','neutral','sad'] \n",
        "\n",
        "time = 4\n",
        "rslt_df = X[X['labels'].isin(options)]\n",
        "\n",
        "max_x,max_y = findmaxsize(rslt_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-87f053000f59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mrslt_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmax_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindmaxsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrslt_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-87f053000f59>\u001b[0m in \u001b[0;36mfindmaxsize\u001b[0;34m(rslt_df)\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0;31m#print(y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mspect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hamming\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.010\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_mels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/resampy/core.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mresample_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqUP_nRM10GU",
        "outputId": "43a2e7a7-c5b5-4ae8-95f5-24914a6afbdc"
      },
      "source": [
        "max_x = 64\n",
        "max_y = 299\n",
        "T = 80\n",
        "print(max_y,T,(int(max_y/T)+1)*T,int(max_y/T)+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "299 80 320 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNQjseDa2ELP",
        "outputId": "3d800d6e-29fc-44d9-9658-27489043be24"
      },
      "source": [
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  #l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "def extract_mel_spectrogram(df,max_x = max_x,max_y = (int(max_y/T)+1)*T):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path']\n",
        " \n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      #print(y.shape)\n",
        "      # Computing the mel spectrograms\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      \n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        " \n",
        "            \n",
        "      \n",
        "      if spect.shape[1] != max_y:\n",
        "                #print('Sizes arent same')\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        "      s=[]\n",
        "      for i in range(int(max_y/T)):\n",
        "        #print(spect[:,i*64:(i+1)*64].shape)\n",
        "        q=spect[:,i*T:(i+1)*T]\n",
        "        delta = librosa.feature.delta(q).reshape((max_x,T,1))\n",
        "        d_delta = librosa.feature.delta(q,order = 2).reshape((max_x,T,1))\n",
        "        #print(q.shape,delta.shape,d_delta.shape)\n",
        "        q = q.reshape((max_x,T,1))\n",
        "\n",
        "        z = np.concatenate((q,delta,d_delta),axis = -1)\n",
        "        #print(z.shape)\n",
        "        s.append(z)\n",
        "      mel_specs.append(np.asarray(s))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  #print(len(mel_specs),mel_specs[0].shape)\n",
        "  mel_specs = np.asarray(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        " \n",
        "train_path = \"TESS//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "#X_train_spec = np.expand_dims(X_train_spec,axis=-1)\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        " \n",
        " \n",
        "test_path = \"TESS//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "#X_test_spec = np.expand_dims(X_test_spec,axis=-1)\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        " \n",
        "val_path = \"TESS//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "#X_val_spec = np.expand_dims(X_val_spec,axis=-1)\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1114, 4, 64, 80, 3) (1114, 4)\n",
            "(239, 4, 64, 80, 3) (239, 4)\n",
            "(239, 4, 64, 80, 3) (239, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gQ5rs-_49S6",
        "outputId": "67bec526-2ce0-467c-ca8b-dbc538f7a596"
      },
      "source": [
        "import keras\n",
        "def AlexNet(input_shape):\n",
        "    \n",
        "    X_input = Input(input_shape)\n",
        "    \n",
        "    X = Conv2D(96,(11,11),strides = 4,name=\"conv0\")(X_input)\n",
        "    X = BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
        "    \n",
        "    X = Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3 ,name='bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max2')(X)\n",
        "    \n",
        "    X = Reshape((36,256))(X)\n",
        "\n",
        "    X= LSTM(256,return_sequences=True)(X)\n",
        "    X= LSTM(256)(X)\n",
        "\n",
        "    \n",
        "    #X = Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
        "    \n",
        "    #X = Dense(4096, activation = 'relu', name = 'fc1')(X) \n",
        "    \n",
        "    \n",
        "\n",
        "    model = Model(inputs = X_input, outputs = X, name='AlexNet')\n",
        "\n",
        "    return model\n",
        "\n",
        "def paper_2():\n",
        "    input_layer = Input((int(max_y/T)+1,max_x,T,3))\n",
        "    alex = AlexNet((227,227,3))\n",
        "    \n",
        "    for i in range(int(max_y/T)+1):\n",
        "      #print(input_layer[:,0,:,:,:].shape)\n",
        "      inp = Resizing(227,227)(input_layer[:,i,:,:,:])\n",
        "      \n",
        "      cnn = alex(inp)\n",
        "\n",
        "      #cnn = Reshape((1,4096))(cnn)\n",
        "\n",
        "      if i == 0:\n",
        "        output_layers = cnn\n",
        "      else:\n",
        "        output_layers = Concatenate(axis = 1)([output_layers,cnn])\n",
        "      \n",
        "    \n",
        "    #print(len(output_layers))\n",
        "    #lstm = LSTM(256,return_sequences=True)(output_layers)\n",
        "    #lstm = LSTM(256,return_sequences=True)(lstm)\n",
        "    #lstm = LSTM(256)(lstm)\n",
        "    \n",
        "    out = Dense(4,activation='softmax')(output_layers)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return Model(inputs=input_layer,outputs=out)\n",
        "p2 = paper_2()\n",
        "p2.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 4, 64, 80,   0           []                               \n",
            "                                3)]                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_8 (Sl  (None, 64, 80, 3)   0           ['input_8[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_9 (Sl  (None, 64, 80, 3)   0           ['input_8[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " resizing_8 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_8[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " resizing_9 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_9[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_10 (S  (None, 64, 80, 3)   0           ['input_8[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " AlexNet (Functional)           (None, 256)          4803328     ['resizing_8[0][0]',             \n",
            "                                                                  'resizing_9[0][0]',             \n",
            "                                                                  'resizing_10[0][0]',            \n",
            "                                                                  'resizing_11[0][0]']            \n",
            "                                                                                                  \n",
            " resizing_10 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_10[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_11 (S  (None, 64, 80, 3)   0           ['input_8[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 512)          0           ['AlexNet[0][0]',                \n",
            "                                                                  'AlexNet[1][0]']                \n",
            "                                                                                                  \n",
            " resizing_11 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_11[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 768)          0           ['concatenate_6[0][0]',          \n",
            "                                                                  'AlexNet[2][0]']                \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 1024)         0           ['concatenate_7[0][0]',          \n",
            "                                                                  'AlexNet[3][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 4)            4100        ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,807,428\n",
            "Trainable params: 4,804,676\n",
            "Non-trainable params: 2,752\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 1"
      ],
      "metadata": {
        "id": "3aw_2-kdV_OD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvAp5SUs6XOM",
        "outputId": "2a2e861c-5341-40e3-ea75-4322d16b1a61"
      },
      "source": [
        "p2.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//paper_2_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//paper_2_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = p2.fit(X_train_spec,Y_train_spec, batch_size=8,validation_data=(X_val_spec, Y_val_spec),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "140/140 [==============================] - 55s 98ms/step - loss: 1.0231 - accuracy: 0.5912 - val_loss: 0.9509 - val_accuracy: 0.6025\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.95087, saving model to TESS//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.60251, saving model to TESS//models/paper_2_acc.h5\n",
            "Epoch 2/30\n",
            "140/140 [==============================] - 10s 72ms/step - loss: 0.7640 - accuracy: 0.6988 - val_loss: 2.0006 - val_accuracy: 0.4393\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.95087\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.60251\n",
            "Epoch 3/30\n",
            "140/140 [==============================] - 10s 72ms/step - loss: 0.5203 - accuracy: 0.8076 - val_loss: 0.5777 - val_accuracy: 0.7699\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.95087 to 0.57773, saving model to TESS//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.60251 to 0.76987, saving model to TESS//models/paper_2_acc.h5\n",
            "Epoch 4/30\n",
            "140/140 [==============================] - 10s 73ms/step - loss: 0.4115 - accuracy: 0.8375 - val_loss: 0.9383 - val_accuracy: 0.6695\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.57773\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.76987\n",
            "Epoch 5/30\n",
            "140/140 [==============================] - 10s 73ms/step - loss: 0.4835 - accuracy: 0.7914 - val_loss: 0.3114 - val_accuracy: 0.8828\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.57773 to 0.31145, saving model to TESS//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.76987 to 0.88285, saving model to TESS//models/paper_2_acc.h5\n",
            "Epoch 6/30\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 0.3891 - accuracy: 0.8367 - val_loss: 2.3550 - val_accuracy: 0.4812\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.31145\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.88285\n",
            "Epoch 7/30\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 0.3490 - accuracy: 0.8510 - val_loss: 0.2347 - val_accuracy: 0.9038\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.31145 to 0.23475, saving model to TESS//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.88285 to 0.90377, saving model to TESS//models/paper_2_acc.h5\n",
            "Epoch 8/30\n",
            "140/140 [==============================] - 10s 75ms/step - loss: 0.2767 - accuracy: 0.8971 - val_loss: 0.8313 - val_accuracy: 0.7155\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.23475\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.90377\n",
            "Epoch 9/30\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 0.2558 - accuracy: 0.9088 - val_loss: 0.2801 - val_accuracy: 0.8870\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.23475\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.90377\n",
            "Epoch 10/30\n",
            "140/140 [==============================] - 10s 74ms/step - loss: 0.2162 - accuracy: 0.9073 - val_loss: 0.5202 - val_accuracy: 0.7824\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.23475\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.90377\n",
            "Epoch 11/30\n",
            "140/140 [==============================] - 10s 75ms/step - loss: 0.1916 - accuracy: 0.9135 - val_loss: 0.1192 - val_accuracy: 0.9623\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.23475 to 0.11919, saving model to TESS//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.90377 to 0.96234, saving model to TESS//models/paper_2_acc.h5\n",
            "Epoch 12/30\n",
            "140/140 [==============================] - 11s 76ms/step - loss: 0.2494 - accuracy: 0.9144 - val_loss: 0.1805 - val_accuracy: 0.9247\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.11919\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.96234\n",
            "Epoch 13/30\n",
            "140/140 [==============================] - 11s 75ms/step - loss: 0.4457 - accuracy: 0.8460 - val_loss: 0.1240 - val_accuracy: 0.9582\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.11919\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.96234\n",
            "Epoch 14/30\n",
            "140/140 [==============================] - 11s 75ms/step - loss: 0.2047 - accuracy: 0.9344 - val_loss: 0.2383 - val_accuracy: 0.8996\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.11919\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.96234\n",
            "Epoch 15/30\n",
            "140/140 [==============================] - 11s 76ms/step - loss: 0.1870 - accuracy: 0.9296 - val_loss: 0.3411 - val_accuracy: 0.8787\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.11919\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.96234\n",
            "Epoch 16/30\n",
            "140/140 [==============================] - 11s 76ms/step - loss: 0.2018 - accuracy: 0.9225 - val_loss: 0.4689 - val_accuracy: 0.8201\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.11919\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.96234\n",
            "Epoch 17/30\n",
            "140/140 [==============================] - 11s 76ms/step - loss: 0.1609 - accuracy: 0.9494 - val_loss: 0.3243 - val_accuracy: 0.8828\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.11919\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.96234\n",
            "Epoch 18/30\n",
            "140/140 [==============================] - 11s 76ms/step - loss: 0.1423 - accuracy: 0.9394 - val_loss: 0.7233 - val_accuracy: 0.7657\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.11919\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.96234\n",
            "Epoch 19/30\n",
            "140/140 [==============================] - 11s 76ms/step - loss: 0.1209 - accuracy: 0.9578 - val_loss: 0.5218 - val_accuracy: 0.8033\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.11919\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.96234\n",
            "Epoch 20/30\n",
            "140/140 [==============================] - 11s 77ms/step - loss: 0.1147 - accuracy: 0.9572 - val_loss: 0.0887 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.11919 to 0.08872, saving model to TESS//models/paper_2_loss.h5\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.96234 to 0.96653, saving model to TESS//models/paper_2_acc.h5\n",
            "Epoch 21/30\n",
            "140/140 [==============================] - 11s 77ms/step - loss: 0.1537 - accuracy: 0.9552 - val_loss: 0.1877 - val_accuracy: 0.8996\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.08872\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.96653\n",
            "Epoch 22/30\n",
            "140/140 [==============================] - 11s 77ms/step - loss: 0.1223 - accuracy: 0.9566 - val_loss: 0.2919 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.08872\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.96653\n",
            "Epoch 23/30\n",
            "140/140 [==============================] - 11s 77ms/step - loss: 0.1038 - accuracy: 0.9666 - val_loss: 1.1435 - val_accuracy: 0.6234\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.08872\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.96653\n",
            "Epoch 24/30\n",
            "140/140 [==============================] - 11s 77ms/step - loss: 0.1782 - accuracy: 0.9405 - val_loss: 0.5362 - val_accuracy: 0.7992\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.08872\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.96653\n",
            "Epoch 25/30\n",
            "140/140 [==============================] - 11s 77ms/step - loss: 0.1256 - accuracy: 0.9486 - val_loss: 0.0918 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.08872\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.96653 to 0.97071, saving model to TESS//models/paper_2_acc.h5\n",
            "Epoch 26/30\n",
            "140/140 [==============================] - 11s 77ms/step - loss: 0.0907 - accuracy: 0.9700 - val_loss: 0.0988 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.08872\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.97071\n",
            "Epoch 27/30\n",
            "140/140 [==============================] - 11s 77ms/step - loss: 0.1196 - accuracy: 0.9618 - val_loss: 0.1082 - val_accuracy: 0.9623\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.08872\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.97071\n",
            "Epoch 28/30\n",
            "140/140 [==============================] - 11s 77ms/step - loss: 0.1261 - accuracy: 0.9556 - val_loss: 0.8815 - val_accuracy: 0.7490\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.08872\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.97071\n",
            "Epoch 29/30\n",
            "140/140 [==============================] - 11s 77ms/step - loss: 0.0764 - accuracy: 0.9791 - val_loss: 0.1941 - val_accuracy: 0.9205\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.08872\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.97071\n",
            "Epoch 30/30\n",
            "140/140 [==============================] - 11s 77ms/step - loss: 0.3236 - accuracy: 0.9094 - val_loss: 0.6820 - val_accuracy: 0.7448\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.08872\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.97071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ7Xpjum6bkQ",
        "outputId": "b3e9aebf-82b2-4ca7-d556-3eacbadf57dd"
      },
      "source": [
        "p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "print(p2.evaluate(X_test_spec,Y_test_spec))\n",
        "p2.load_weights('TESS//models//paper_2_loss.h5')\n",
        "p2.evaluate(X_test_spec,Y_test_spec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 1s 105ms/step - loss: 0.1269 - accuracy: 0.9623\n",
            "[0.12693879008293152, 0.9623430967330933]\n",
            "8/8 [==============================] - 1s 60ms/step - loss: 0.0647 - accuracy: 0.9791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06467041373252869, 0.9790794849395752]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "y4OqJGku87-C",
        "outputId": "456c95ce-c838-4f20-c775-36d2e041d920"
      },
      "source": [
        "#test set\n",
        "p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 SCORE: 0.9621795908626358\n",
            "Kappa: 0.9497253710412528\n",
            "Accuracy: 0.9623430962343096\n",
            "Jaccard Score: 0.9271585344848797\n",
            "Precision: 0.9652173913043479\n",
            "Recall: 0.961941143180532\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97        62\n",
            "           1       0.93      1.00      0.97        56\n",
            "           2       1.00      0.91      0.95        57\n",
            "           3       0.93      1.00      0.96        64\n",
            "\n",
            "    accuracy                           0.96       239\n",
            "   macro avg       0.97      0.96      0.96       239\n",
            "weighted avg       0.96      0.96      0.96       239\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 2"
      ],
      "metadata": {
        "id": "jtyj4MxRWDdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "p2.load_weights('TESS//models//paper_2_loss.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "y1wuWje9WF6F",
        "outputId": "4811f835-4cc9-45e8-83ea-f99bd0f9de71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.9791796763488438\n",
            "Kappa: 0.9720774820665\n",
            "Accuracy: 0.9790794979079498\n",
            "Jaccard Score: 0.9593656929126531\n",
            "Precision: 0.9792573040464063\n",
            "Recall: 0.9791789832444013\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        62\n",
            "           1       0.96      0.98      0.97        56\n",
            "           2       1.00      0.98      0.99        57\n",
            "           3       0.98      0.98      0.98        64\n",
            "\n",
            "    accuracy                           0.98       239\n",
            "   macro avg       0.98      0.98      0.98       239\n",
            "weighted avg       0.98      0.98      0.98       239\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 3"
      ],
      "metadata": {
        "id": "P5lFUkd6Xa31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p2.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//paper_2_loss_3.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//paper_2_acc_3.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = p2.fit(X_train_spec,Y_train_spec, batch_size=8,validation_data=(X_val_spec, Y_val_spec),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4_rorDBXZYI",
        "outputId": "786a3b28-afe6-406f-b4ad-33d43eaaa414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.8934 - accuracy: 0.5871\n",
            "Epoch 1: val_loss improved from inf to 3.83024, saving model to TESS//models/paper_2_loss_3.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.30962, saving model to TESS//models/paper_2_acc_3.h5\n",
            "140/140 [==============================] - 61s 314ms/step - loss: 0.8934 - accuracy: 0.5871 - val_loss: 3.8302 - val_accuracy: 0.3096\n",
            "Epoch 2/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.7696 - accuracy: 0.6840\n",
            "Epoch 2: val_loss improved from 3.83024 to 2.20731, saving model to TESS//models/paper_2_loss_3.h5\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.30962\n",
            "140/140 [==============================] - 37s 265ms/step - loss: 0.7696 - accuracy: 0.6840 - val_loss: 2.2073 - val_accuracy: 0.3096\n",
            "Epoch 3/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.6405 - accuracy: 0.7540\n",
            "Epoch 3: val_loss did not improve from 2.20731\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.30962\n",
            "140/140 [==============================] - 36s 255ms/step - loss: 0.6405 - accuracy: 0.7540 - val_loss: 2.7731 - val_accuracy: 0.2385\n",
            "Epoch 4/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.8250\n",
            "Epoch 4: val_loss improved from 2.20731 to 0.29979, saving model to TESS//models/paper_2_loss_3.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.30962 to 0.87448, saving model to TESS//models/paper_2_acc_3.h5\n",
            "140/140 [==============================] - 37s 265ms/step - loss: 0.4500 - accuracy: 0.8250 - val_loss: 0.2998 - val_accuracy: 0.8745\n",
            "Epoch 5/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3657 - accuracy: 0.8636\n",
            "Epoch 5: val_loss did not improve from 0.29979\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.87448\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.3657 - accuracy: 0.8636 - val_loss: 1.8033 - val_accuracy: 0.5397\n",
            "Epoch 6/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3938 - accuracy: 0.8662\n",
            "Epoch 6: val_loss did not improve from 0.29979\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.87448\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.3938 - accuracy: 0.8662 - val_loss: 0.4460 - val_accuracy: 0.8452\n",
            "Epoch 7/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.8977\n",
            "Epoch 7: val_loss did not improve from 0.29979\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.87448\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.2787 - accuracy: 0.8977 - val_loss: 0.3543 - val_accuracy: 0.8619\n",
            "Epoch 8/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.9201\n",
            "Epoch 8: val_loss did not improve from 0.29979\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.87448\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.2228 - accuracy: 0.9201 - val_loss: 0.4565 - val_accuracy: 0.8201\n",
            "Epoch 9/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.9120\n",
            "Epoch 9: val_loss did not improve from 0.29979\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.87448\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.2421 - accuracy: 0.9120 - val_loss: 1.4999 - val_accuracy: 0.5816\n",
            "Epoch 10/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2399 - accuracy: 0.9147\n",
            "Epoch 10: val_loss improved from 0.29979 to 0.19080, saving model to TESS//models/paper_2_loss_3.h5\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.87448 to 0.93724, saving model to TESS//models/paper_2_acc_3.h5\n",
            "140/140 [==============================] - 37s 263ms/step - loss: 0.2399 - accuracy: 0.9147 - val_loss: 0.1908 - val_accuracy: 0.9372\n",
            "Epoch 11/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.9345\n",
            "Epoch 11: val_loss improved from 0.19080 to 0.10267, saving model to TESS//models/paper_2_loss_3.h5\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.93724 to 0.98326, saving model to TESS//models/paper_2_acc_3.h5\n",
            "140/140 [==============================] - 36s 261ms/step - loss: 0.1964 - accuracy: 0.9345 - val_loss: 0.1027 - val_accuracy: 0.9833\n",
            "Epoch 12/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.9147\n",
            "Epoch 12: val_loss did not improve from 0.10267\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.2414 - accuracy: 0.9147 - val_loss: 0.1302 - val_accuracy: 0.9749\n",
            "Epoch 13/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9524\n",
            "Epoch 13: val_loss did not improve from 0.10267\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.1387 - accuracy: 0.9524 - val_loss: 0.1065 - val_accuracy: 0.9749\n",
            "Epoch 14/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.9309\n",
            "Epoch 14: val_loss did not improve from 0.10267\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 35s 250ms/step - loss: 0.1693 - accuracy: 0.9309 - val_loss: 2.1883 - val_accuracy: 0.4310\n",
            "Epoch 15/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1391 - accuracy: 0.9560\n",
            "Epoch 15: val_loss did not improve from 0.10267\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 245ms/step - loss: 0.1391 - accuracy: 0.9560 - val_loss: 0.2999 - val_accuracy: 0.9121\n",
            "Epoch 16/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9623\n",
            "Epoch 16: val_loss did not improve from 0.10267\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.1117 - accuracy: 0.9623 - val_loss: 0.1335 - val_accuracy: 0.9498\n",
            "Epoch 17/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.9479\n",
            "Epoch 17: val_loss did not improve from 0.10267\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.1409 - accuracy: 0.9479 - val_loss: 0.6138 - val_accuracy: 0.7364\n",
            "Epoch 18/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.9174\n",
            "Epoch 18: val_loss did not improve from 0.10267\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.2411 - accuracy: 0.9174 - val_loss: 0.1456 - val_accuracy: 0.9414\n",
            "Epoch 19/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.9515\n",
            "Epoch 19: val_loss did not improve from 0.10267\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.1268 - accuracy: 0.9515 - val_loss: 0.5649 - val_accuracy: 0.8243\n",
            "Epoch 20/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9587\n",
            "Epoch 20: val_loss did not improve from 0.10267\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.1133 - accuracy: 0.9587 - val_loss: 0.4908 - val_accuracy: 0.8828\n",
            "Epoch 21/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 0.9623\n",
            "Epoch 21: val_loss did not improve from 0.10267\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 245ms/step - loss: 0.1177 - accuracy: 0.9623 - val_loss: 1.3349 - val_accuracy: 0.5439\n",
            "Epoch 22/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9632\n",
            "Epoch 22: val_loss did not improve from 0.10267\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.1058 - accuracy: 0.9632 - val_loss: 0.4990 - val_accuracy: 0.8117\n",
            "Epoch 23/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9767\n",
            "Epoch 23: val_loss improved from 0.10267 to 0.07193, saving model to TESS//models/paper_2_loss_3.h5\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 35s 253ms/step - loss: 0.0867 - accuracy: 0.9767 - val_loss: 0.0719 - val_accuracy: 0.9791\n",
            "Epoch 24/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.9623\n",
            "Epoch 24: val_loss did not improve from 0.07193\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.1020 - accuracy: 0.9623 - val_loss: 0.1646 - val_accuracy: 0.9498\n",
            "Epoch 25/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9740\n",
            "Epoch 25: val_loss did not improve from 0.07193\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.0814 - accuracy: 0.9740 - val_loss: 0.1454 - val_accuracy: 0.9456\n",
            "Epoch 26/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.9803\n",
            "Epoch 26: val_loss did not improve from 0.07193\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.0705 - accuracy: 0.9803 - val_loss: 0.4174 - val_accuracy: 0.8452\n",
            "Epoch 27/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9794\n",
            "Epoch 27: val_loss did not improve from 0.07193\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.0735 - accuracy: 0.9794 - val_loss: 0.2049 - val_accuracy: 0.9498\n",
            "Epoch 28/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9605\n",
            "Epoch 28: val_loss did not improve from 0.07193\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.1092 - accuracy: 0.9605 - val_loss: 0.2386 - val_accuracy: 0.9038\n",
            "Epoch 29/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9847\n",
            "Epoch 29: val_loss did not improve from 0.07193\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.0500 - accuracy: 0.9847 - val_loss: 0.1273 - val_accuracy: 0.9540\n",
            "Epoch 30/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9811\n",
            "Epoch 30: val_loss did not improve from 0.07193\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 34s 246ms/step - loss: 0.0649 - accuracy: 0.9811 - val_loss: 0.1138 - val_accuracy: 0.9456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p2.load_weights('TESS//models//paper_2_acc_3.h5')\n",
        "print(p2.evaluate(X_test_spec,Y_test_spec))\n",
        "p2.load_weights('TESS//models//paper_2_loss_3.h5')\n",
        "p2.evaluate(X_test_spec,Y_test_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whPaSnHrZP9N",
        "outputId": "0cf0522e-3415-4488-a482-dc0cadf5efbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 161ms/step - loss: 0.1113 - accuracy: 0.9540\n",
            "[0.11134571582078934, 0.9539749026298523]\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 0.0602 - accuracy: 0.9791\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.060210924595594406, 0.9790794849395752]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "p2.load_weights('TESS//models//paper_2_loss_3.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "SuEoGtapd9IF",
        "outputId": "c2fcbaad-550d-4c85-d3ea-197293993143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.9789548313223577\n",
            "Kappa: 0.9720716088622978\n",
            "Accuracy: 0.9790794979079498\n",
            "Jaccard Score: 0.9588165162121605\n",
            "Precision: 0.9795539519439433\n",
            "Recall: 0.9786992683321206\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98        62\n",
            "           1       0.96      0.98      0.97        56\n",
            "           2       1.00      0.96      0.98        57\n",
            "           3       0.97      1.00      0.98        64\n",
            "\n",
            "    accuracy                           0.98       239\n",
            "   macro avg       0.98      0.98      0.98       239\n",
            "weighted avg       0.98      0.98      0.98       239\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 4"
      ],
      "metadata": {
        "id": "eX_817MKeB9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "p2.load_weights('TESS//models//paper_2_acc_3.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "qah_jsB3eLCG",
        "outputId": "5abb112e-856c-4526-e530-381bbc9f54f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.9539396550838082\n",
            "Kappa: 0.9385977204783259\n",
            "Accuracy: 0.9539748953974896\n",
            "Jaccard Score: 0.911964872660335\n",
            "Precision: 0.9536317152802773\n",
            "Recall: 0.9545777245533188\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96        62\n",
            "           1       0.95      0.96      0.96        56\n",
            "           2       0.93      0.96      0.95        57\n",
            "           3       0.97      0.94      0.95        64\n",
            "\n",
            "    accuracy                           0.95       239\n",
            "   macro avg       0.95      0.95      0.95       239\n",
            "weighted avg       0.95      0.95      0.95       239\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting Trial"
      ],
      "metadata": {
        "id": "34TfZA50d4lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "_q5762pKdcxe",
        "outputId": "f4bc34de-3090-4916-c8f5-d79d79294399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxNUECgF90vf"
      },
      "source": [
        "# Paper_3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVI4edig9rE-",
        "outputId": "68783e18-ed5f-4d94-bbb4-86afb1e27467"
      },
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"TESS//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"TESS//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"TESS//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (1114, 64000, 1) (1114, 4)\n",
            "Test Data (239, 64000, 1) (239, 4)\n",
            "Val Data (239, 64000, 1) (239, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK29VADU-Ilr",
        "outputId": "5bda5bd0-ef17-43b3-93b3-638f43c965e5"
      },
      "source": [
        "def paper_3():\n",
        "  inp =  Input((time*16000,1))\n",
        "  l1 = Conv1D(64,80,strides = 4,padding = 'same')(inp)\n",
        "  m1 = MaxPooling1D(4)(l1)\n",
        "\n",
        "  l2 = Conv1D(128,3,strides = 1,padding = 'same')(m1)\n",
        "  l2 = Conv1D(128,3,strides = 1,padding = 'same')(l2)\n",
        "  m2 = MaxPooling1D(4)(l2)\n",
        "\n",
        "  l3 = Conv1D(256,3,strides = 1,padding = 'same')(m2)\n",
        "  l3 = Conv1D(256,3,strides = 1,padding = 'same')(l3)\n",
        "  m3 = MaxPooling1D(4)(l3)\n",
        "\n",
        "  l4 = Conv1D(512,3,strides = 1,padding = 'same')(m3)\n",
        "  l4 = Conv1D(512,3,strides = 1,padding = 'same')(l4)\n",
        "  m4 = GlobalAveragePooling1D()(l4)\n",
        "\n",
        "  f1 = Dense(1024)(m4)\n",
        "  f2 = Dense(4, activation='softmax')(f1)\n",
        "\n",
        "  return Model(inputs= inp,outputs=f2)\n",
        "\n",
        "p3 = paper_3()\n",
        "p3.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64000, 1)]        0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 16000, 64)         5184      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 4000, 64)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 4000, 128)         24704     \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 4000, 128)         49280     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1000, 128)        0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 1000, 256)         98560     \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 1000, 256)         196864    \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 250, 256)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 250, 512)          393728    \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 250, 512)          786944    \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 512)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 4100      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,084,676\n",
            "Trainable params: 2,084,676\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 1"
      ],
      "metadata": {
        "id": "Sas1tRNxfEL5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZktTG-zF-rx9",
        "outputId": "87a026e4-6abc-4390-c23c-ad627866fe78"
      },
      "source": [
        "p3.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//paper_3_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//paper_3_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = p3.fit(X_train,Y_train, batch_size=8,validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "140/140 [==============================] - 5s 31ms/step - loss: 1.2432 - accuracy: 0.3747 - val_loss: 0.8509 - val_accuracy: 0.4686\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.85094, saving model to TESS//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.46862, saving model to TESS//models/paper_3_acc.h5\n",
            "Epoch 2/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.8484 - accuracy: 0.5333 - val_loss: 0.7623 - val_accuracy: 0.4770\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.85094 to 0.76227, saving model to TESS//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.46862 to 0.47699, saving model to TESS//models/paper_3_acc.h5\n",
            "Epoch 3/30\n",
            "140/140 [==============================] - 4s 30ms/step - loss: 0.7864 - accuracy: 0.5744 - val_loss: 0.5283 - val_accuracy: 0.8033\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.76227 to 0.52831, saving model to TESS//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.47699 to 0.80335, saving model to TESS//models/paper_3_acc.h5\n",
            "Epoch 4/30\n",
            "140/140 [==============================] - 4s 30ms/step - loss: 4.9478 - accuracy: 0.5444 - val_loss: 0.4068 - val_accuracy: 0.8410\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.52831 to 0.40684, saving model to TESS//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.80335 to 0.84100, saving model to TESS//models/paper_3_acc.h5\n",
            "Epoch 5/30\n",
            "140/140 [==============================] - 4s 30ms/step - loss: 0.3617 - accuracy: 0.8482 - val_loss: 0.6103 - val_accuracy: 0.8159\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.40684\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.84100\n",
            "Epoch 6/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.3204 - accuracy: 0.8887 - val_loss: 0.1798 - val_accuracy: 0.9331\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.40684 to 0.17979, saving model to TESS//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.84100 to 0.93305, saving model to TESS//models/paper_3_acc.h5\n",
            "Epoch 7/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.2307 - accuracy: 0.9260 - val_loss: 0.0958 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.17979 to 0.09577, saving model to TESS//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.93305 to 0.97071, saving model to TESS//models/paper_3_acc.h5\n",
            "Epoch 8/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.1184 - accuracy: 0.9662 - val_loss: 0.1422 - val_accuracy: 0.9456\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.09577\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.97071\n",
            "Epoch 9/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.2074 - accuracy: 0.9212 - val_loss: 0.1317 - val_accuracy: 0.9582\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.09577\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.97071\n",
            "Epoch 10/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.2145 - accuracy: 0.9221 - val_loss: 0.2318 - val_accuracy: 0.9331\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.09577\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.97071\n",
            "Epoch 11/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.0850 - accuracy: 0.9670 - val_loss: 0.1478 - val_accuracy: 0.9540\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.09577\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.97071\n",
            "Epoch 12/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.0513 - accuracy: 0.9798 - val_loss: 0.0489 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.09577 to 0.04894, saving model to TESS//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.97071 to 0.99163, saving model to TESS//models/paper_3_acc.h5\n",
            "Epoch 13/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.5291 - accuracy: 0.8482 - val_loss: 0.1485 - val_accuracy: 0.9623\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.04894\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.99163\n",
            "Epoch 14/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.0546 - accuracy: 0.9873 - val_loss: 0.5668 - val_accuracy: 0.8828\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.04894\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.99163\n",
            "Epoch 15/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.7157 - accuracy: 0.8314 - val_loss: 0.1158 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.04894\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.99163\n",
            "Epoch 16/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.1642 - accuracy: 0.9408 - val_loss: 0.0887 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.04894\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.99163\n",
            "Epoch 17/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.0786 - accuracy: 0.9772 - val_loss: 0.2246 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.04894\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.99163\n",
            "Epoch 18/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.1955 - accuracy: 0.9501 - val_loss: 0.1034 - val_accuracy: 0.9665\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.04894\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.99163\n",
            "Epoch 19/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.1211 - accuracy: 0.9598 - val_loss: 0.0315 - val_accuracy: 0.9874\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.04894 to 0.03151, saving model to TESS//models/paper_3_loss.h5\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.99163\n",
            "Epoch 20/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.0612 - accuracy: 0.9871 - val_loss: 0.0335 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.03151\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.99163\n",
            "Epoch 21/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.0593 - accuracy: 0.9851 - val_loss: 0.0712 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.03151\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.99163\n",
            "Epoch 22/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.0272 - accuracy: 0.9930 - val_loss: 0.0394 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.03151\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.99163\n",
            "Epoch 23/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.0443 - accuracy: 0.9858 - val_loss: 0.5014 - val_accuracy: 0.7573\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.03151\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.99163\n",
            "Epoch 24/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.2279 - accuracy: 0.9141 - val_loss: 0.0729 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.03151\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.99163\n",
            "Epoch 25/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.4745 - accuracy: 0.8715 - val_loss: 0.1558 - val_accuracy: 0.9372\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.03151\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99163\n",
            "Epoch 26/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.1710 - accuracy: 0.9490 - val_loss: 0.0396 - val_accuracy: 0.9833\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.03151\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99163\n",
            "Epoch 27/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.0492 - accuracy: 0.9861 - val_loss: 0.0465 - val_accuracy: 0.9874\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.03151\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.99163\n",
            "Epoch 28/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.0764 - accuracy: 0.9736 - val_loss: 0.3623 - val_accuracy: 0.8870\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.03151\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99163\n",
            "Epoch 29/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.1271 - accuracy: 0.9501 - val_loss: 0.1331 - val_accuracy: 0.9540\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.03151\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.99163\n",
            "Epoch 30/30\n",
            "140/140 [==============================] - 4s 29ms/step - loss: 0.0158 - accuracy: 0.9923 - val_loss: 0.0742 - val_accuracy: 0.9749\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.03151\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.99163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MEsllKB-wIX",
        "outputId": "36fee651-c024-4b8a-e0bc-ddb6cff497c8"
      },
      "source": [
        "p3.save_weights('TESS//models//paper_3_acc.h5')\n",
        "#p3.load_weights('TESS//models//paper_3_acc.h5')\n",
        "#print(p3.evaluate(X_test,Y_test))\n",
        "#p3.load_weights('TESS//models//paper_3_loss.h5')\n",
        "p3.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0514 - accuracy: 0.9791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05138617381453514, 0.9790794849395752]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "rDSN4Xyi_TW5",
        "outputId": "66316060-79ef-48e2-82ae-70a93c9cef6d"
      },
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 SCORE: 0.978915324369134\n",
            "Kappa: 0.9720709561315353\n",
            "Accuracy: 0.9790794979079498\n",
            "Jaccard Score: 0.958892136296855\n",
            "Precision: 0.9793973103399333\n",
            "Recall: 0.9786209475301156\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98        62\n",
            "           1       0.96      0.96      0.96        56\n",
            "           2       1.00      0.98      0.99        57\n",
            "           3       0.97      1.00      0.98        64\n",
            "\n",
            "    accuracy                           0.98       239\n",
            "   macro avg       0.98      0.98      0.98       239\n",
            "weighted avg       0.98      0.98      0.98       239\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 2"
      ],
      "metadata": {
        "id": "3efcm2URfHbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p3.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//paper_3_loss_2.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//paper_3_acc_2.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = p3.fit(X_train,Y_train, batch_size=8,validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xse37zgvfI3d",
        "outputId": "513e8277-c8a5-4118-ebec-37b3f546b5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 1.0257 - accuracy: 0.4587\n",
            "Epoch 1: val_loss improved from inf to 0.74685, saving model to TESS//models/paper_3_loss_2.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.58996, saving model to TESS//models/paper_3_acc_2.h5\n",
            "140/140 [==============================] - 12s 68ms/step - loss: 1.0257 - accuracy: 0.4587 - val_loss: 0.7469 - val_accuracy: 0.5900\n",
            "Epoch 2/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 1.1056 - accuracy: 0.4874\n",
            "Epoch 2: val_loss improved from 0.74685 to 0.73310, saving model to TESS//models/paper_3_loss_2.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.58996 to 0.59414, saving model to TESS//models/paper_3_acc_2.h5\n",
            "140/140 [==============================] - 9s 62ms/step - loss: 1.1056 - accuracy: 0.4874 - val_loss: 0.7331 - val_accuracy: 0.5941\n",
            "Epoch 3/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.8302 - accuracy: 0.5692\n",
            "Epoch 3: val_loss did not improve from 0.73310\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.59414\n",
            "140/140 [==============================] - 8s 61ms/step - loss: 0.8303 - accuracy: 0.5682 - val_loss: 0.8607 - val_accuracy: 0.4979\n",
            "Epoch 4/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.8110 - accuracy: 0.5827\n",
            "Epoch 4: val_loss improved from 0.73310 to 0.67266, saving model to TESS//models/paper_3_loss_2.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.59414 to 0.64435, saving model to TESS//models/paper_3_acc_2.h5\n",
            "140/140 [==============================] - 10s 71ms/step - loss: 0.8109 - accuracy: 0.5835 - val_loss: 0.6727 - val_accuracy: 0.6444\n",
            "Epoch 5/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.7351 - accuracy: 0.6232\n",
            "Epoch 5: val_loss improved from 0.67266 to 0.52465, saving model to TESS//models/paper_3_loss_2.h5\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.64435 to 0.84100, saving model to TESS//models/paper_3_acc_2.h5\n",
            "140/140 [==============================] - 9s 62ms/step - loss: 0.7348 - accuracy: 0.6230 - val_loss: 0.5246 - val_accuracy: 0.8410\n",
            "Epoch 6/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.6525 - accuracy: 0.7104\n",
            "Epoch 6: val_loss improved from 0.52465 to 0.50348, saving model to TESS//models/paper_3_loss_2.h5\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.84100\n",
            "140/140 [==============================] - 9s 64ms/step - loss: 0.6515 - accuracy: 0.7110 - val_loss: 0.5035 - val_accuracy: 0.7824\n",
            "Epoch 7/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.6087 - accuracy: 0.7311\n",
            "Epoch 7: val_loss improved from 0.50348 to 0.30650, saving model to TESS//models/paper_3_loss_2.h5\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.84100\n",
            "140/140 [==============================] - 8s 60ms/step - loss: 0.6085 - accuracy: 0.7307 - val_loss: 0.3065 - val_accuracy: 0.8285\n",
            "Epoch 8/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.6307 - accuracy: 0.6915\n",
            "Epoch 8: val_loss did not improve from 0.30650\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.84100 to 0.88703, saving model to TESS//models/paper_3_acc_2.h5\n",
            "140/140 [==============================] - 9s 65ms/step - loss: 0.6299 - accuracy: 0.6921 - val_loss: 0.3297 - val_accuracy: 0.8870\n",
            "Epoch 9/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 12.8179 - accuracy: 0.5207\n",
            "Epoch 9: val_loss did not improve from 0.30650\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.88703\n",
            "140/140 [==============================] - 8s 59ms/step - loss: 12.7961 - accuracy: 0.5206 - val_loss: 0.6967 - val_accuracy: 0.6485\n",
            "Epoch 10/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4743 - accuracy: 0.7698\n",
            "Epoch 10: val_loss did not improve from 0.30650\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.88703\n",
            "140/140 [==============================] - 8s 60ms/step - loss: 0.4734 - accuracy: 0.7702 - val_loss: 0.6984 - val_accuracy: 0.7029\n",
            "Epoch 11/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.9011\n",
            "Epoch 11: val_loss did not improve from 0.30650\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.88703 to 0.89958, saving model to TESS//models/paper_3_acc_2.h5\n",
            "140/140 [==============================] - 9s 66ms/step - loss: 0.2668 - accuracy: 0.9004 - val_loss: 0.3122 - val_accuracy: 0.8996\n",
            "Epoch 12/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.2875 - accuracy: 0.8993\n",
            "Epoch 12: val_loss improved from 0.30650 to 0.18138, saving model to TESS//models/paper_3_loss_2.h5\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.89958 to 0.94561, saving model to TESS//models/paper_3_acc_2.h5\n",
            "140/140 [==============================] - 9s 66ms/step - loss: 0.2870 - accuracy: 0.8995 - val_loss: 0.1814 - val_accuracy: 0.9456\n",
            "Epoch 13/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.1693 - accuracy: 0.9406\n",
            "Epoch 13: val_loss improved from 0.18138 to 0.15943, saving model to TESS//models/paper_3_loss_2.h5\n",
            "\n",
            "Epoch 13: val_accuracy improved from 0.94561 to 0.96234, saving model to TESS//models/paper_3_acc_2.h5\n",
            "140/140 [==============================] - 11s 80ms/step - loss: 0.1690 - accuracy: 0.9408 - val_loss: 0.1594 - val_accuracy: 0.9623\n",
            "Epoch 14/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9677\n",
            "Epoch 14: val_loss did not improve from 0.15943\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96234\n",
            "140/140 [==============================] - 8s 56ms/step - loss: 0.0951 - accuracy: 0.9677 - val_loss: 0.4106 - val_accuracy: 0.8828\n",
            "Epoch 15/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.1329 - accuracy: 0.9559\n",
            "Epoch 15: val_loss did not improve from 0.15943\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96234\n",
            "140/140 [==============================] - 8s 58ms/step - loss: 0.1327 - accuracy: 0.9560 - val_loss: 0.1883 - val_accuracy: 0.9331\n",
            "Epoch 16/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.1087 - accuracy: 0.9685\n",
            "Epoch 16: val_loss did not improve from 0.15943\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.96234\n",
            "140/140 [==============================] - 8s 55ms/step - loss: 0.1085 - accuracy: 0.9686 - val_loss: 0.1914 - val_accuracy: 0.9372\n",
            "Epoch 17/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 0.9838\n",
            "Epoch 17: val_loss improved from 0.15943 to 0.08384, saving model to TESS//models/paper_3_loss_2.h5\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.96234 to 0.97071, saving model to TESS//models/paper_3_acc_2.h5\n",
            "140/140 [==============================] - 9s 65ms/step - loss: 0.0645 - accuracy: 0.9838 - val_loss: 0.0838 - val_accuracy: 0.9707\n",
            "Epoch 18/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0582 - accuracy: 0.9829\n",
            "Epoch 18: val_loss improved from 0.08384 to 0.08373, saving model to TESS//models/paper_3_loss_2.h5\n",
            "\n",
            "Epoch 18: val_accuracy improved from 0.97071 to 0.97490, saving model to TESS//models/paper_3_acc_2.h5\n",
            "140/140 [==============================] - 9s 67ms/step - loss: 0.0582 - accuracy: 0.9829 - val_loss: 0.0837 - val_accuracy: 0.9749\n",
            "Epoch 19/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.1320 - accuracy: 0.9613\n",
            "Epoch 19: val_loss did not improve from 0.08373\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.97490\n",
            "140/140 [==============================] - 8s 56ms/step - loss: 0.1396 - accuracy: 0.9605 - val_loss: 0.1429 - val_accuracy: 0.9331\n",
            "Epoch 20/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4377 - accuracy: 0.9083\n",
            "Epoch 20: val_loss improved from 0.08373 to 0.08242, saving model to TESS//models/paper_3_loss_2.h5\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.97490 to 0.98326, saving model to TESS//models/paper_3_acc_2.h5\n",
            "140/140 [==============================] - 9s 66ms/step - loss: 0.4369 - accuracy: 0.9084 - val_loss: 0.0824 - val_accuracy: 0.9833\n",
            "Epoch 21/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9874\n",
            "Epoch 21: val_loss did not improve from 0.08242\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.98326\n",
            "140/140 [==============================] - 8s 55ms/step - loss: 0.0538 - accuracy: 0.9874 - val_loss: 0.1385 - val_accuracy: 0.9623\n",
            "Epoch 22/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9865\n",
            "Epoch 22: val_loss improved from 0.08242 to 0.05518, saving model to TESS//models/paper_3_loss_2.h5\n",
            "\n",
            "Epoch 22: val_accuracy improved from 0.98326 to 0.98745, saving model to TESS//models/paper_3_acc_2.h5\n",
            "140/140 [==============================] - 9s 67ms/step - loss: 0.0512 - accuracy: 0.9865 - val_loss: 0.0552 - val_accuracy: 0.9874\n",
            "Epoch 23/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9937\n",
            "Epoch 23: val_loss did not improve from 0.05518\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.98745\n",
            "140/140 [==============================] - 8s 55ms/step - loss: 0.0291 - accuracy: 0.9937 - val_loss: 0.0643 - val_accuracy: 0.9833\n",
            "Epoch 24/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.1697 - accuracy: 0.9487\n",
            "Epoch 24: val_loss did not improve from 0.05518\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.98745\n",
            "140/140 [==============================] - 8s 55ms/step - loss: 0.1695 - accuracy: 0.9488 - val_loss: 0.1222 - val_accuracy: 0.9707\n",
            "Epoch 25/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9892\n",
            "Epoch 25: val_loss did not improve from 0.05518\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.98745\n",
            "140/140 [==============================] - 8s 55ms/step - loss: 0.0381 - accuracy: 0.9892 - val_loss: 0.0645 - val_accuracy: 0.9833\n",
            "Epoch 26/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9892\n",
            "Epoch 26: val_loss did not improve from 0.05518\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.98745\n",
            "140/140 [==============================] - 8s 56ms/step - loss: 0.0574 - accuracy: 0.9892 - val_loss: 0.0580 - val_accuracy: 0.9874\n",
            "Epoch 27/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0756 - accuracy: 0.9757\n",
            "Epoch 27: val_loss improved from 0.05518 to 0.03799, saving model to TESS//models/paper_3_loss_2.h5\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.98745\n",
            "140/140 [==============================] - 9s 61ms/step - loss: 0.0755 - accuracy: 0.9758 - val_loss: 0.0380 - val_accuracy: 0.9874\n",
            "Epoch 28/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3477 - accuracy: 0.9514\n",
            "Epoch 28: val_loss did not improve from 0.03799\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.98745\n",
            "140/140 [==============================] - 8s 58ms/step - loss: 0.3501 - accuracy: 0.9506 - val_loss: 1.4386 - val_accuracy: 0.7197\n",
            "Epoch 29/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8768\n",
            "Epoch 29: val_loss did not improve from 0.03799\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.98745\n",
            "140/140 [==============================] - 8s 55ms/step - loss: 0.3790 - accuracy: 0.8770 - val_loss: 0.1399 - val_accuracy: 0.9414\n",
            "Epoch 30/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9694\n",
            "Epoch 30: val_loss did not improve from 0.03799\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.98745\n",
            "140/140 [==============================] - 8s 55ms/step - loss: 0.0870 - accuracy: 0.9695 - val_loss: 0.2045 - val_accuracy: 0.9540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p3.evaluate(X_test,Y_test)\n",
        "p3.save_weights('TESS//models//paper_3_2.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ajhLEObgaJa",
        "outputId": "e1816ad7-d806-48dd-9764-9065deb1089b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 82ms/step - loss: 0.2365 - accuracy: 0.9289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "p3.load_weights('TESS//models//paper_3_2.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "id": "E9PE5sahgzLW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "c937a8d1-8a2a-4bad-c562-711a5099347b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.9271069472201696\n",
            "Kappa: 0.9048678264534408\n",
            "Accuracy: 0.9288702928870293\n",
            "Jaccard Score: 0.8674412114305321\n",
            "Precision: 0.940253159003159\n",
            "Recall: 0.9252538478252081\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.98      0.90        62\n",
            "           1       1.00      0.77      0.87        56\n",
            "           2       0.98      0.96      0.97        57\n",
            "           3       0.95      0.98      0.97        64\n",
            "\n",
            "    accuracy                           0.93       239\n",
            "   macro avg       0.94      0.93      0.93       239\n",
            "weighted avg       0.94      0.93      0.93       239\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD4CAYAAABPLjVeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXgUVdbA4d/pEFAEVHZCkF1RUFAWNxxhkEUlII7igh+iMqijo6joMA6ug6OjMoozDCMyCKKO4MauKCiCIkJYQ9g3IQlh32RNOuf7o5vYCSSphO6qTnNen3rsqrpdfeo+zcntW7duiapijDHGHT6vAzDGmNOJJV1jjHGRJV1jjHGRJV1jjHGRJV1jjHFRmUh/QNbODTY8IujMhGu8DsFEoTK+OK9DiBpHjmyWUz1GcXJOfNUGp/x5xWUtXWOMcVHEW7rGGOOqHL/XERTKkq4xJrb4s72OoFCWdI0xMUU1x+sQCmVJ1xgTW3Is6RpjjHuspWuMMS6yC2nGGOMia+kaY4x71EYvGGOMi+xCmjHGuMi6F4wxxkV2Ic0YY1xkLV1jjHGRXUgzxhgXRfmFNEdTO4rIH0Xk3EgHY4wxp0rV73jxgtP5dGsAC0RkvIh0ERHXJ/41xhhHNMf54gFHSVdVBwGNgf8CfYC1IvI3EWkYwdiMMab4cnKcLx5w/OQIVVUgM7hkA+cCn4jIqxGKzRhjii/KW7qOLqSJyKNAb2AnMBJ4UlWzRMQHrAWeilyIxhhTDP4sryMolNPRC+cCN6vqz6EbVTVHRLqGPyxjjCmh0j56QUTigNvzJ9zjVHVl2KMyxpiSivLuhSKTrgbGVawWkfNciKfYvp+XTNfb+3J9z3sZOXb8CfszMrdx3yMD6dH7Qfo8/BSZ23fk7hsy7L9073U/SXf2429vDCfQbR27OndqR+ry2axa8T1PPfmQ1+F4KtbromPHa1m27FtSU2czYMAfTthftmxZxo4dRmrqbGbPnkjduokAVK58DtOnf8TOnSt5440X87wnPj6eYcNeISVlFkuXfsNNN13vyrkUW4xcSDsXSBWRmSIy6fgSycCc8Pv9DB4yjOFD/sqkD95m2oxZrN+Yt0H++r9G0q1LBz5/bzgP3nMnb/5nNACLU1awOGUFn733byaMHU7qyjUsWJziwVm4w+fz8dbQl+iadBcXN2/PbbfdxIUXNvY6LE/Eel34fD6GDh1M9+5306JFB3r27EaTJnnPr0+f29i7dx9Nm/6Gf/5zJIMH/xmAI0eO8sILQxg48KUTjjtw4B/ZsWMnF1/cjhYtOjBnzjxXzqfYYiTpPgN0BV4EhoQsnkpZuYbzEhOoU7sW8fHxXN/hWr7J90VYv3EzbVq2AKDNZc35ds6PAIgIx44dIys7m2NZWWRl+6lS+RzXz8EtbVpfyvr1m9i4cTNZWVmMHz+RbkmdvQ7LE7FeF61bt8hzfh9/PJmkpE55yiQldeL99z8B4LPPptG+/dUAHDp0mLlzF3D06JETjnv33T159dVhAKgqu3btifCZlIz6sxwvXnA6Tve7ky2RDq4o23fspGb1arnrNapXZfuOXXnKXNC4ATO++wGAGd/N5eChw+zdt58WzS6k9WWX0L5bL9p368XVl19Gw3pR2YMSFgm1a7IlLSN3PS19KwkJNT2MyDuxXhcJCTVJCzm/9PStJCTUKLCM3+9n//4DVKlS8E2nZ59dCYDnnhvAjz9O5YMPhlO9etUIRB8Gpb1PF0BEDojI/nzLFhH5XEQaRDrIUzHgob4kL07hlj4PkbwkhRrVquDz+diclsGGTVuY+flYvpnwPvMXLmXhkuVeh2tMVCpTJo7ExATmzVvIlVfeyE8/LeSVVwZ5HdbJxUj3wpvAk0BtIBEYAHwIfASMyl9YRPqJSLKIJI9873/hivUE1atVzXNhbNv2nVSvViVfmSoMffkZPhk9jEf73Q1ApYoVmPHdXJo3bUL58mdSvvyZtL2iFUtTY3cgRkZ6JnUSE3LXE2vXIiMj08OIvBPrdZGRkUliyPnVrl2LjIxtBZaJi4ujUqWKhXYX7Nq1h4MHDzFhwhcAfPbZVFq0aBaB6MMgFlq6QDdVfVtVD6jqflUdAXRW1XEELrLloaojVLWVqrbq2/uOsAYcqlmT89mclkFaRiZZWVl8MfM72re9Ik+ZPXv3kRP8i/bO2HH0uDHQt1WrRjWSl6SQne0nKzub5CUpNKhbJ2Kxem1B8hIaNapPvXp1iI+Pp2fP7kye8pXXYXki1usiOXlpnvO79dYkpkz5Ok+ZKVO+5q67bgHg5ptvYNasuUUed+rUGVx77ZUAtG9/NStXrg1/8OEQ5S1dpzdHHBKRnsAnwfVbgOM97Z6NsypTJo6nH3uQ+x8fhN/vp0fXTjRqUJd/vfMeTZucT/trrmDB4mW8+Z/RiAgtmzdj0BOB4TOd2rdl/qKl9Oj9ICLQ9vJWtMuXsGOJ3+/n0f6DmDb1Q+J8PkaPGceKFWu8DssTsV4Xfr+f/v2fYfLkscTFxTFmzDhWrlzDs88+zsKFKUyd+jWjR49j1Kg3SU2dze7de+nd++Hc969e/QMVK1akbNl4kpI607XrXaxatZZBg15m1Kg3ee2159i5czf9+j3h4VkWIsonMRcnY1OD/bZDgSsJJNl5wGNAOtBSVb8v6L1ZOzfE9uDXYjgz4RqvQzBRqIwvzusQosaRI5tPeQbDw1PfdJxzzryxv+szJjpq6arqBiCpgN0FJlxjjHFdlLd0nU54Uw34PVAv9D2qem9kwjLGmBKK8rkXnPbpTgTmADOA6H7UpjHm9BYLLV2gvKr+KaKRGGNMOER5S9fpkLEpInJDRCMxxphwiPJxuk5buo8CT4vIUSALEAIPk6gUsciMMaYksmPgEeyqWlFEKhN4TtoZkQ3JGGNOQRinaBWRLgSGy8YBI1X1lXz7zwPGAOcEywxU1WmFHdPp6IW+BFq7icAS4ApgLtChmOdgjDGRFaY+3eADHIYBHYE0Ak9En6SqK0KKDQLGq+pwEbkImEZglFeBnPbpPgq0Bn5W1fbApcC+4p2CMca4IHy3AbcB1qnqBlU9RmCume75yihwvJv1bCCDIjjt0z2iqkdEBBEpp6qrROQCh+81xhj3FOMCmYj0A/qFbBoRnFsGAhN8bQnZlwZcnu8QzwNficgfgbOA64r6TKdJN01EzgEmAF+LyB7gpM9MM8YYT/md30oQTLAjiixYsDuA0ao6RESuBMaKSDPVgjO/0wtpPYIvnxeRbwk0o788hUCNMSYywjdONx0InXowMbgt1H1AFwBV/VFEzgCqAtsLOqjTlm6uaHhihDHGFCh8SXcB0FhE6hNItrcDd+Yrs5nAgILRInIhgdFdOyhEsZOuMcZEtTDd9KCq2SLyMDCdwHCwUaqaKiIvAsmqOgl4AnhHRB4jcFGtjxYxdaMlXWNMTNGc8I3TDY65nZZv27Mhr1cAVxfnmJZ0jTGxJcrnXrCka4yJLcUYveAFS7rGmNhiLV1jjHGRJV1jjHFRGCe8iQRLusaY2GItXWOMcVEYh4xFQsST7m0t+0f6I0qN/W/0KLrQaaLSY597HULUyM6J7qvtpY6NXjDGGPeodS8YY4yLTvfuBWOMcVWMPILdGGNKB2vpGmOMi7LtQpoxxrjHuheMMcZF1r1gjDHusSFjxhjjJmvpGmOMiyzpGmOMi+w2YGOMcU84n5EWCZZ0jTGxxZKuMca4KMpHL/icFBKRP4rIuZEOxhhjTlmOOl884CjpAjWABSIyXkS6iIhEMihjjCmxWEi6qjoIaAz8F+gDrBWRv4lIwwjGZowxxab+HMeLF5y2dFFVBTKDSzZwLvCJiLwaodiMMab4oryl6+hCmog8CvQGdgIjgSdVNUtEfMBa4KnIhWiMMc7FypCxysDNqvpz6EZVzRGRruEPyxhjSigWkq6qPicil4lId0CBH1R1UXDfykgGaIwxxRLdI8YcDxl7BhgDVAGqAu+KyKBIBmaMMSWh2TmOFy847V64C2iuqkcAROQVYAkwOFKBGWNMiUR5S9dp0s0AzgCOBNfLAekRiaiYLr32Mu59ri++uDhmfPQVnw//NM/+pL7due72jvizc9i/ex/DnnyLHek7AHhmzPOcf+n5rExeyd/u/asX4YfVD5t28trs1eSoclPT2tzbqn6e/a/PXs2CtN0AHMnOYfehY8x5oD0Ltuzm9Tmrc8tt2nOIV7pcTPuG1V2N302dO7XjH/94kTifj1Hv/o9XXxvmdUieibW6iJULafuAVBH5mkCfbkdgvoi8BaCqj0QovkL5fD5+/9f7eaHXs+zK3MWrk4awYMZ80tZuyS2zMXUDT3Z9nGNHjtH5ruvp/ec+DHn4NQAmjPiMcmeUo1OvLl6EH1b+HOWVWasY3uMyalQ4g17jfuLa+tVoWKVCbpkBv7kg9/X/lm5m9Y4DALSuU5lxd14JwL4jWXQb8z1XnFfF3RNwkc/n462hL9HlhjtIS9vKvB+nMXnKV6xcudbr0FwXk3UR5S1dp+N0PweeBr4FZgF/ASYCC4OLJxq1aMzWTVvZtmUb2VnZfD95Dm06Xp6nzPIfUzh25BgAaxavpkqtqrn7Un5YxuGDh12NOVKWb9tHnXPKk3h2eeLjfHRuXJNZG3YUWP7L1Zl0Ob/mCdtnrNvG1fWqcmZ8XCTD9VSb1peyfv0mNm7cTFZWFuPHT6RbUmevw/JELNaF5qjjxQtORy+MEZGyQBMCLd3VqnosopE5UKVmFXZt3Zm7vmvrThpfekGB5Tvc1pFFszz7GxFR2385So0K5XLXa1Qox/Jt+09aNmP/YTL2H6Z1YuUT9k1fk8ldl9aNWJzRIKF2TbakZeSup6VvpU3rSz2MyDsxWRex0NIVkRuA9cBbwL+AdSJyfSHl+4lIsogkb/zl54KKueo3PdrR6OJGTHj7M69D8dz0NZl0aFSDOF/eKTR2HDzK2p2/cGUMdy2Y2KfZzpeiBOeaWS0i60RkYAFleorIChFJFZEPizqm0z7dfwDtVXVd8EMaAlOBL05WWFVHACMAbq7bLWJt+F2Zu/J0F1SpVZXdmbtOKHfJ1c255eFbeabn02Qfc1DTpVD1CuXY9svR3PVtvxyl2lnlTlp2+pptDGzf5ITtX6/dxm8bVic+zvHd4aVSRnomdRITctcTa9ciIyPTw4i8E4t1Ea4nsItIHDCMwDWsNAKTfk1S1RUhZRoDfwauVtU9IlLk1Wen/7oOHE+4QRuAA46jj5B1S9dSq34C1evUoEx8GdomXcOCr3/KU6Z+0wY88PIfePm+wezbtc+jSCOvaY1KbN57iPR9h8ny5zB9bSbtGlQ7odzG3QfZfzSL5jXPPmFfQf28sWZB8hIaNapPvXp1iI+Pp2fP7kye8pXXYXkiJusipxhL4doA61R1Q7A79SOge74yvweGqeoeAFXdXtRBnbZ0k0VkGjCeQJ/urQSy/s3BD/LkN3uOP4eRz77Ns+89jy/Ox8zxM9iydgu3P34n65etY8GM+fR+ug9nlD+TAf/+EwA7M3bwct+XABj88cvUbpjIGWedwTvzRjHsqX+yZPZiL07llJXx+fhTuwv4w8RF5OQo3Zsm0LBKBf49bx0XVa9EuwaBP8DT12TS+fya5J+dM2P/YTJ/OULLxNifNtnv9/No/0FMm/ohcT4fo8eMY8WKNV6H5YlYrIvitHRFpB/QL2TTiOAvdYDawJaQfWlA3iv1cH7wOD8AccDzqvploZ8ZmDysyMDeLWS3quq9Be2MZPdCafP+U+d5HULUqPTY516HYKJQ9rH0U56re3uHax3nnOozvyvw80TkFqCLqvYNrv8fcLmqPhxSZgqQBfQEEoHZwMWqureg4zodvXCPozMwxhiPqT9sz1hIB+qErCdy4k1hacBPqpoFbBSRNQTmHl9Q0EGdTu14BnAf0JTAnWkAFNbCNcYYL4TrQhqBxNlYROoTSLa3A3fmKzMBuIPAfDRVCXQ3bCjsoE4vpI0FagKdge8IZHzPL6QZY0x+miOOl0KPo5oNPAxMB1YC41U1VUReFJFuwWLTgV0isoLAzWNPquqJQ6hCOL2Q1khVbxWR7sEbJT4E5jh8rzHGuCaMLV1UdRowLd+2Z0NeK/B4cHHEadLNCv5/r4g0I/DIntidDcUYU2qpRvdzc50m3RHBR7APAiYBFYBnIhaVMcaUUDhbupHgNOmOBX4H1CMwmTkEHstujDFRJSd8oxciwmnSnUhgeseFwNEiyhpjjGeKukDmNadJN1FVS/+ks8aYmBftSdfpkLG5InJxRCMxxpgwUHW+eKHQlq6IpBCYa6EMcI+IbCDQvSAERktcEvkQjTHGuWhv6RbVvdDVlSiMMSZMSvWQMVWNjhnIjTHGIX+MjF4wxphSoVS3dI0xprQp7X26xhhTqng1KsEpS7rGmJhiLV1jjHGRPye6H6xqSdcYE1Ose8EYY1yUY6MXjDHGPTZkzBhjXHTady9M2row0h9RalR6zOriuEMbvvQ6hKhR9YLuXocQU6x7wRhjXGSjF4wxxkVR3rtgSdcYE1use8EYY1xkoxeMMcZFUf4wYEu6xpjYolhL1xhjXJNt3QvGGOMea+kaY4yLrE/XGGNcZC1dY4xxkbV0jTHGRf7S3NIVkQOc/K46AVRVK0UkKmOMKaEof1pP4UlXVSu6FYgxxoRDTmlu6eYnItWBM46vq+rmsEdkjDGnINonvHE0B5qIdBORtcBG4DtgE/BFBOMyxpgSySnG4gWnE0/+FbgCWKOq9YEOwLyIRWWMMSWUI+J4KYqIdBGR1SKyTkQGFlLudyKiItKqqGM6TbpZqroL8ImIT1W/BYo8uDHGuM1fjKUwIhIHDAOuBy4C7hCRi05SriLwKPCTk/icJt29IlIBmA18ICJDgYMO32uMMa7JEedLEdoA61R1g6oeAz4CTvZspb8CfweOOInPadLtDhwCHgO+BNYDSQ7fa4wxrslBHC8i0k9EkkOWfiGHqg1sCVlPC27LJSKXAXVUdarT+IocvRBsYk9R1fYE+p7HOD24Mca4rTijF1R1BDCiJJ8jIj7gH0Cf4ryvyJauqvqBHBE5uySBGWOMm8LYvZAO1AlZTwxuO64i0AyYJSKbCAw2mFTUxTSn3Qu/ACki8l8Reev44vC9nurcqR2py2ezasX3PPXkQ16H46nTqS6+n7+YpLsf4Yb/e5iR//v8hP0Z23bQd8Dz3Nz3ce55/Fkyd+zK3bd12w76PfUi3e55lO739Cc9c7uboYfFdR1/w8LFM1iy7Bsee+KBE/aXLVuWd8e8xZJl3/DNrM8477zAr+aWLS/h+x+n8P2PU/hh3lS6JnXKfc+w4X9n/ab5zFsQ3aNFwzhkbAHQWETqi0hZ4HZg0vGdqrpPVauqaj1VrUdgRFc3VU0u7KBOb474LLiEivYxyPh8Pt4a+hJdbriDtLStzPtxGpOnfMXKlWu9Ds11p1Nd+P1+XnprJCNefZaa1Spz+x8G0v7KVjSs92uj5fX/jCGpYzu6d27HT4tTGDryA17+8yMAPP33f/L7O3/HVa2ac+jwYQK/IksPn8/HkH+8QPek3qSnZzJrzgSmTZ3B6lXrcsv0vrsne/fup8Ulv+V3t3Tlhb/+iXvufoQVK9Zwbdvu+P1+atSsxtx5U/li2kz8fj8fvP8JI95+j7ffed3DsyuaP0w3pKlqtog8DEwH4oBRqpoqIi8Cyao6qfAjnJzTb9M5qjomdAHOLckHuqlN60tZv34TGzduJisri/HjJ9ItqbPXYXnidKqLlFXrOK92Teok1CA+Pp7r21/Nt3MX5Cmz4ec0Lr+0GQBtWjTL3b9+0xb8/hyuatUcgPJnnsmZZ5Rz9wROUatWzdmw4Wc2bdpCVlYWn34yhRu7dsxT5sau1/G/Dz4FYMLnX9Cu3VUAHD58BL8/MJjqjHLl0JCm1dwfFrBn9153TuIUhPPmCFWdpqrnq2pDVX0puO3ZkyVcVW1XVCsXnCfdu0+yrY/D93omoXZNtqRl5K6npW8lIaGmhxF553Sqi+07d1OzWtXc9RrVqrBt5+48Zc5vWI8ZcwLDKmd+/xMHDx1m774DbErbSsWzytP/uVe59f4BDHn7vdwkVFrUSqhJWtrW3PWM9K0k1KqRr0yN3DJ+v5/9+w9QuUqgHdWqVXN+WvAlP87/gv6PDCp151+q70gTkTtEZDJQX0QmhSzfArsLeV/uMIycHBvOa6LPgPt7k7wslVvvH0Dy0hVUr1oZX5wPv9/PouWreOL+u/nfv/9O2tZtTJw+y+twXZWcvJTLW3eh3W9u4okBD1KuXFmvQyoWFeeLF4rq050LbAWqAkNCth8AlhX0ptBhGGXK1vas7zcjPZM6iQm564m1a5GRkelVOJ46neqietXKZO7Ymbu+bccualStfEKZN194CoBDhw/z9Zx5VKpwFjWqVeGChvWokxBoGf726jYsXbGGm+ng3gmcoq0ZmSQm1spdT6hdi4yt2/KV2UZiYuA7EBcXR6VKFdm9a0+eMmtWr+eXgwe56KILWLw4xZXYwyHaJzEvtKWrqj+r6ixVvVJVvwtZFqlqtltBltSC5CU0alSfevXqEB8fT8+e3Zk85Suvw/LE6VQXzZo04uf0raRt3UZWVhZffPsD7a5qnafMnn37yckJ/PMc+eHn9Ojy28B7L2jIgV8OsnvvPgB+WrychnUT3T2BU7Rw4TIaNKxH3bqJxMfH87tbujJt6ow8ZaZNnckdvX4HwE09rue7734EoG7dROLi4gCoUyeB889vyM+b09w9gVMUrtuAI8XR6IV8k5mXBeKBg9E+ibnf7+fR/oOYNvVD4nw+Ro8Zx4oVa7wOyxOnU12UiYvj6T/25YE/Dcafk0OP639Lo3p1+Ne7H9H0goa0v6o1C5akMvS/HyAILS+5iL880heAuLg4nri/N30HvIACFzVuwC03XuftCRWT3+/nySee5/OJY4iL8zH2vY9ZtXItfxnUn0WLUvhi2kzeGzOOESP/wZJl37Bnzz7uuTswcuPKq1rx2OMPkJWdTU5ODo/3fza3BTxq9FDaXnM5Vaqcy8o1P/C3wUMZ+954L0/1pKJ9EnNRLd6vfxERArcFX6GqBc66c5yX3Qsmeh3a8KXXIUSNqhec7Hb+09P+gxtOOWW+cd5djnPOY5vfdz1FF3sAogZMAGJzvJExplSL9tELTrsXbg5Z9RGY1tHRjDrGGOOmaP9p7fSOtNAZxbIJPDnCfhMZY6JOtPfpOkq6qnpPpAMxxphwiPZbOZw+I+18EZkpIsuD65eIyKDIhmaMMcWXgzpevOD0Qto7wJ+BLABVXUZgxh1jjIkqMXEhDSivqvMl74Pcov7mCGPM6SdWLqTtFJGGBM9HRG4hcHuwMcZElWi/Ddhp0n2IwFwKTUQkHdgI9IpYVMYYU0LZEt1tXadJNx14F/gWqAzsJzDd44sRissYY0okulOu86Q7EdgLLAIyiihrjDGeiZXuhURV7RLRSIwxJgy8GgrmlNMhY3NF5OKIRmKMMWGgxVi84LSl2xboIyIbgaOAEJj75pKIRWaMMSUQK90L10c0CmOMCRN/lHcvOJ174edIB2KMMeEQKy1dY4wpFTQWWrrGGFNaWEvXGGNcFO1DxizpGmNiSnSnXEu6xpgYkx3ladeSrjEmptiFNGNOolKjG70OIWocSJvldQgxxS6kGWOMi6yla4wxLrKWrjHGuMiv1tI1xhjX2DhdY4xxkfXpGmOMi6K9T9fpJObGGFMq5KCOl6KISBcRWS0i60Rk4En2Py4iK0RkmYjMFJG6RR3Tkq4xJqZoMf4rjIjEAcMIzCd+EXCHiFyUr9hioFXwgQ6fAK8WFZ8lXWNMTPGrOl6K0AZYp6obVPUY8BHQPbSAqn6rqoeCq/OAxKIOan26xpiYEsbRC7WBLSHracDlhZS/D/iiqINa0jXGxJTiXEgTkX5Av5BNI1R1RHE/U0TuAloB1xZV1pKuMSamFGfIWDDBFpRk04E6IeuJwW15iMh1wF+Aa1X1aFGfaUnXGBNTwti9sABoLCL1CSTb24E7QwuIyKXA20AXVd3u5KCWdI0xMUXDdBuwqmaLyMPAdCAOGKWqqSLyIpCsqpOA14AKwMciArBZVbsVdlxLusaYmBLOR7Cr6jRgWr5tz4a8vq64x7Ska4yJKTb3gjHGuChc3QuRYknXGBNTrKVrjDEuslnGjDHGRTaJuTHGuKhUdy+ISAoUfAbBmXWMMSZqRHvSLWqWsa5AEvBlcOkVXE4YuxatOndqR+ry2axa8T1PPfmQ1+F4KtbromPHa1m27FtSU2czYMAfTthftmxZxo4dRmrqbGbPnkjduoEJoSpXPofp0z9i586VvPHGi3ne07NnN5KTv2LBgulMmvQeVaqc68q5hNP385Lpentfru95LyPHjj9hf0bmNu57ZCA9ej9In4efInP7jtx9Q4b9l+697ifpzn787Y3hUT8yAAKjF5wuXig06arqz6r6M9BRVZ9S1ZTgMhDo5E6IJefz+Xhr6Et0TbqLi5u357bbbuLCCxt7HZYnYr0ufD4fQ4cOpnv3u2nRogM9e3ajSZO859enz23s3buPpk1/wz//OZLBg/8MwJEjR3nhhSEMHPhSnvJxcXG8/vrzdO58G61bdyYlZRUPPtjHrVMKC7/fz+Ahwxg+5K9M+uBtps2YxfqNP+cp8/q/RtKtSwc+f284D95zJ2/+ZzQAi1NWsDhlBZ+9928mjB1O6so1LFic4sFZFE84JzGPBKfz6YqIXB2yclUx3uuZNq0vZf36TWzcuJmsrCzGj59It6TOXofliVivi9atW+Q5v48/nkxSUt52QVJSJ95//xMAPvtsGu3bB77Shw4dZu7cBRw9eiRPeRFBRDjrrPIAVKpUga1bt7lwNuGTsnIN5yUmUKd2LeLj47m+w7V8M2denjLrN26mTcsWALS5rDnfzvkRCJz/sWPHyMrO5lhWFlnZfqpUPsf1cyiucE1iHilOE+d9wL9FZJOI/Az8G7g3cmGFR0LtmmxJy8hdT0vfSkJCTQ8j8k6s10VCQk3SQs4vPX0rCQk1Cizj9/vZv/9Aod0F2dnZPPLIX0hO/oqNG/flm4sAAAo0SURBVJO58MLGvPvuR5E5gQjZvmMnNatXy12vUb0q23fsylPmgsYNmPHdDwDM+G4uBw8dZu++/bRodiGtL7uE9t160b5bL66+/DIa1jvP1fhLwq85jhcvOEq6qrpQVZsDzYFLVLWFqi6KbGjGeKtMmTL06/d/XHHFDdSv34qUlJU89VTs9YUPeKgvyYtTuKXPQyQvSaFGtSr4fD42p2WwYdMWZn4+lm8mvM/8hUtZuGS51+EWKdr7dB0PGRORG4GmwBnB2XRQ1RcLKJs7MbDEnY3Pd9apR1oCGemZ1ElMyF1PrF2LjIxMT2LxWqzXRUZGJokh51e7di0yMradtEx6eiZxcXFUqlSRXbv2FHjM5s0Dj8PasCHQB/rpp1NOeoEumlWvVjXPhbFt23dSvVqVfGWqMPTlZ4BAV8uMWd9TqWIFPpn0Jc2bNqF8+TMBaHtFK5amrqRli2bunUAJlPbRCwCIyH+A24A/AgLcChT41EtVHaGqrVS1lVcJF2BB8hIaNapPvXp1iI+Pp2fP7kye8pVn8Xgp1usiOXlpnvO79dYkpkz5Ok+ZKVO+5q67bgHg5ptvYNasuYUeMyNjG02aNKZq1coAdOhwDatWrYvMCURIsybnszktg7SMTLKysvhi5ne0b3tFnjJ79u4jJyfwU/udsePocWOgL7xWjWokL0khO9tPVnY2yUtSaFC3zgmfEW2ivU/XaUv3KlW9RESWqeoLIjIEB88C8prf7+fR/oOYNvVD4nw+Ro8Zx4oVa7wOyxOxXhd+v5/+/Z9h8uSxxMXFMWbMOFauXMOzzz7OwoUpTJ36NaNHj2PUqDdJTZ3N7t176d374dz3r179AxUrVqRs2XiSkjrTtetdrFq1lpdeepMZMz4mKyubzZvT+f3vH/fwLIuvTJk4nn7sQe5/fBB+v58eXTvRqEFd/vXOezRtcj7tr7mCBYuX8eZ/RiMitGzejEFPBFrzndq3Zf6ipfTo/SAi0PbyVrTLl7CjUU6UD2sTJ/0aIjJfVduIyDzgZmA3sFxVGxX13jJla0d3DRhPlPHFeR1C1DiQNsvrEKJGfNUGcqrHaFrjcsc5J3XbT6f8ecXltKU7WUTOITBL+iICd6m9E7GojDGmhLwaleCU06S7CvCr6qcichFwGTAhcmEZY0zJRHv3gtNxus+o6gERaQv8FhgJDI9cWMYYUzLRfiHNadL1B/9/I/COqk4FykYmJGOMKbkcVceLF5wm3XQReZvAsLFpIlKuGO81xhjXRHtL12mfbk+gC/C6qu4VkVrAk5ELyxhjSsav/qILechR0lXVQ8BnIetbga2RCsoYY0oq2qeftCdHGGNiSrTfBmxJ1xgTU6yla4wxLor2cbqWdI0xMcUewW6MMS6KlduAjTGmVLA+XWOMcZH16RpjjIuspWuMMS6ycbrGGOMia+kaY4yLbPSCMca4yC6kGWOMi6K9e8HmxDXGxJRwzqcrIl1EZLWIrBORgSfZX05ExgX3/yQi9Yo6piVdY0xMUVXHS2FEJA4YBlwPXATcEXxGZKj7gD3BJ6O/Afy9qPgs6RpjYkoYH9fTBlinqhtU9RjwEdA9X5nuwJjg60+ADiJS6GPdI96nm30s3fXnyp+MiPRT1RFexxENrC5+ZXXxq1ipi+LkHBHpB/QL2TQipA5qA1tC9qUBl+c7RG4ZVc0WkX1AFWBnQZ95OrV0+xVd5LRhdfErq4tfnXZ1oaojVLVVyBLxPzqnU9I1xpjiSAfqhKwnBredtIyIlAHOBnYVdlBLusYYc3ILgMYiUl9EygK3A5PylZkE3B18fQvwjRZxhe50Gqdb6vuqwsjq4ldWF7+yuggR7KN9GJgOxAGjVDVVRF4EklV1EvBfYKyIrAN2E0jMhZJoH0hsjDGxxLoXjDHGRZZ0jTHGRZZ0SykRqSciy72OIxYE6/LOEr73l3DHE03sexZ+lnTJHephTl/1gJMmXftumHArlUlXRCaIyEIRSQ3eUYKI/CIiL4nIUhGZJyI1gtsbBtdTRGTw8ZaJiLQTkTkiMglYISIvikj/kM94SUQe9eQEnYsTkXeC9fCViJwpIr8XkQXBevhURMoDiMhoEfmPiCSLyBoR6Rrc3kdEJorILBFZKyLPBbdHfX0EW2ErT1IHDUXky+B3ZI6INAmWHy0it4S8/3gr9RXgGhFZIiKPBetkkoh8A8wUkQoiMlNEFgW/R/lvBY16InKWiEwNfi+Wi8htIvJs8LuyXERGHL99VURaBsstBR7yOPTYU5zJIaJlASoH/38msJzAbXcKJAW3vwoMCr6eAtwRfP0A8EvwdTvgIFA/uF4PWBR87QPWA1W8PtdC6qAekA20CK6PB+4KjRkYDPwx+Ho08GXw3BoTuKXxDKAPsDVYh8frs1VpqI9C6mAm0Di47XICYyeP18EtIe8P/S5MCdneJ1g/x79nZYBKwddVgXX8OvLnF6/rwWFd/Q54J2T97OPnF1wfG/LvZxnwm+Dr14DlXscfS0upbOkCjwT/Cs8jcDdIY+AYgQQLsJDAP0iAK4GPg68/zHec+aq6EUBVNwG7RORSoBOwWFULvbMkCmxU1SXB18fPuVmwdZcC9AKahpQfr6o5qroW2AA0CW7/WlV3qeph4DOgbSmqj5PVwVXAxyKyBHgbqFWC436tqruDrwX4m4gsA2YQuN++xilF7b4UoKOI/F1ErlHVfUD74HSEKcBvgaYicg5wjqrODr5vrFcBx6pS118lIu2A64ArVfWQiMwi0GLL0uCfZsCPs3M7mG99JIFWTk1gVDjijbCjIa/9BFqqo4GbVHWpiPQh0Io7Lv+gbC1ie2moj/x1UAPYq6otTlI2m2CXmoj4gLKFHDf0u9ELqAa0VNUsEdlE4DtXaqjqGhG5DLgBGCwiMwl0HbRS1S0i8jyl7JxKq9LY0j2bwPyVh4J9dVcUUX4egZ9WUPTdIp8DXYDWBO5CKY0qAltFJJ5Asgh1q4j4RKQh0ABYHdzeUUQqi8iZwE3AD8HtpbE+9gMbReRWAAloHty3CWgZfN0NiA++PkCg3gpyNrA9mHDbA3XDHnWEiUgCcEhV3yfQZXBZcNdOEalA4BZWVHUvsFdE2gb35/8OmVNU6lq6BPolHxCRlQSSxrwiyvcH3heRvwTfu6+ggqp6TES+JdBS8ocrYJc9A/wE7Aj+PzSZbAbmA5WAB1T1SPDayXzgUwITeryvqslQquujFzBcRAYRSKwfAUuBd4CJwa6pL/m1NbsM8Ae3jwb25DveB8Dk4M/wZGBVxM8g/C4GXhORHCALeJDAH9jlQCaBeQaOuwcYJSIKfOV2oLEu5m8DDl69P6yqKiK3E7iodtKrz8GfnIuAW4P9njFDREYTuFj0Sb7tfQj8xHz4JO+J2fowxiulsXuhuFoCS4IXQf4APHGyQhJ4DMc6YKYlGKsPYyIl5lu6xhgTTU6Hlq4xxkQNS7rGGOMiS7rGGOMiS7rGGOMiS7rGGOOi/wdG1dWPyasSHQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 3"
      ],
      "metadata": {
        "id": "AA9eS4SyLonp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "p3.load_weights('TESS//models//paper_3_loss_2.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "8iwti3mkLu59",
        "outputId": "99237856-beb7-426a-eab9-9e82ac71bc88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.9957550902942658\n",
            "Kappa: 0.9944161487780945\n",
            "Accuracy: 0.99581589958159\n",
            "Jaccard Score: 0.9915817770232032\n",
            "Precision: 0.9956140350877193\n",
            "Recall: 0.9959677419354839\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        62\n",
            "           1       0.98      1.00      0.99        56\n",
            "           2       1.00      1.00      1.00        57\n",
            "           3       1.00      1.00      1.00        64\n",
            "\n",
            "    accuracy                           1.00       239\n",
            "   macro avg       1.00      1.00      1.00       239\n",
            "weighted avg       1.00      1.00      1.00       239\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 4"
      ],
      "metadata": {
        "id": "M0hiA20fLrTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "p3.load_weights('TESS//models//paper_3_acc_2.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "1Z9zF7akL5yQ",
        "outputId": "bb9c3dd7-05be-46be-d4ab-e953bbe44435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.9829725829725829\n",
            "Kappa: 0.9776551982049364\n",
            "Accuracy: 0.9832635983263598\n",
            "Jaccard Score: 0.9670715249662618\n",
            "Precision: 0.9836516203703703\n",
            "Recall: 0.9825748847926268\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97        62\n",
            "           1       0.98      0.95      0.96        56\n",
            "           2       1.00      1.00      1.00        57\n",
            "           3       1.00      1.00      1.00        64\n",
            "\n",
            "    accuracy                           0.98       239\n",
            "   macro avg       0.98      0.98      0.98       239\n",
            "weighted avg       0.98      0.98      0.98       239\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECXrCd2uQEyG"
      },
      "source": [
        "# paper 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjTHJy74ATQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c50592e-d723-4db6-c1a5-1ada8f9a0e72"
      },
      "source": [
        "!pip install Signal_Analysis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Signal_Analysis\n",
            "  Downloading Signal_Analysis-0.1.26.tar.gz (378 kB)\n",
            "\u001b[K     || 378 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from Signal_Analysis) (1.21.5)\n",
            "Collecting peakutils\n",
            "  Downloading PeakUtils-1.3.3-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from peakutils->Signal_Analysis) (1.4.1)\n",
            "Building wheels for collected packages: Signal-Analysis\n",
            "  Building wheel for Signal-Analysis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Signal-Analysis: filename=Signal_Analysis-0.1.26-py3-none-any.whl size=14531 sha256=932f86e82c2d07d834f8a7a9e7fef9ba5bd1dc67623d550765dcf78179cf6f51\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/da/25/128af0db67fe61f8282e790d94387346357c063d72522661d6\n",
            "Successfully built Signal-Analysis\n",
            "Installing collected packages: peakutils, Signal-Analysis\n",
            "Successfully installed Signal-Analysis-0.1.26 peakutils-1.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bqtTSO4QgL7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import ast\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "# Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Sound Processing\n",
        "import librosa\n",
        "from Signal_Analysis.features.signal import get_F_0, get_HNR\n",
        "\n",
        "# Training Data Preparation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "#from kapre.utils import Normalization2D\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import IPython.display as ipd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqDv2Hg7QhFO"
      },
      "source": [
        "NUM_EMOTIONS = 4\n",
        "N_FFT = 4096\n",
        "HOP_LENGTH = 1024\n",
        "EMOTIONS = ['ang', 'hap', 'neu', 'sad']\n",
        "SR = 16000\n",
        "\n",
        "\n",
        "def extract_HSF(lld):\n",
        "    mean_val = lld.mean()\n",
        "    min_val = lld.min()\n",
        "    max_val = lld.max()\n",
        "    var_val = lld.var()\n",
        "    range_val = np.subtract(max_val, min_val)\n",
        "    q25_val = np.quantile(lld, 0.25)\n",
        "    q50_val = np.quantile(lld, 0.5)\n",
        "    q75_val = np.quantile(lld, 0.75)\n",
        "    return np.asarray([\n",
        "        mean_val,\n",
        "        min_val,\n",
        "        max_val,\n",
        "        var_val,\n",
        "        range_val,\n",
        "        q25_val,\n",
        "        q50_val,\n",
        "        q75_val,\n",
        "    ])\n",
        "\n",
        "def extract_LLD_from_subaudio(subaudio, fs):\n",
        "    # Frame-wise energy\n",
        "    energy_val = np.sum(np.square(subaudio)) / (subaudio.shape[0] / fs + 0.00000000000001)\n",
        "    \n",
        "    # Frame-wise Zero Crossing Rate\n",
        "    zcr_val = np.sum((subaudio[:-1] * subaudio[1:]) < 0)\n",
        "    \n",
        "    return np.asarray([\n",
        "        energy_val,\n",
        "        zcr_val,\n",
        "    ])\n",
        "\n",
        "def extract_LLD_from_audio(audio, fs):\n",
        "    # MFCC\n",
        "    mfcc = librosa.feature.mfcc(audio, fs, n_fft = N_FFT, hop_length = HOP_LENGTH, center = False).transpose()\n",
        "    mfcc_hsf = extract_HSF(mfcc)\n",
        "    \n",
        "    # LPC\n",
        "    lpc = librosa.lpc(audio, 16)\n",
        "    \n",
        "    # Mel-Spectrogram\n",
        "    spect = librosa.feature.melspectrogram(y = audio, sr = fs, n_fft = N_FFT, hop_length = HOP_LENGTH, center = False)\n",
        "    spect = librosa.power_to_db(spect, ref = np.max).transpose()\n",
        "    spect_hsf = extract_HSF(spect)\n",
        "    \n",
        "    # Other features\n",
        "    f0 = get_F_0(audio, fs)[0]\n",
        "    hnr = get_HNR(audio, fs)\n",
        "    \n",
        "    return np.asarray(mfcc), np.asarray(mfcc_hsf), np.asarray(lpc), np.asarray(spect), np.asarray(spect_hsf), np.asarray([f0, hnr])\n",
        "\n",
        "def extract_LLD(audio, fs):\n",
        "    #print(audio.shape)\n",
        "    #print(int((audio.shape[0] - N_FFT) // HOP_LENGTH) + 1)\n",
        "    num_windows = int((audio.shape[0] - N_FFT) // HOP_LENGTH) + 1\n",
        "    framewise_lld = np.zeros((num_windows, 2))\n",
        "    for idx in range(num_windows):\n",
        "        subaudio = audio[int(idx * HOP_LENGTH): int(idx * HOP_LENGTH + N_FFT)]\n",
        "        framewise_lld[idx, :] = extract_LLD_from_subaudio(subaudio, fs)\n",
        "    framewise_lld_hsf = extract_HSF(framewise_lld)\n",
        "    \n",
        "    mfcc, mfcc_hsf, lpc, spect, spect_hsf, others = extract_LLD_from_audio(audio, fs)\n",
        "    \n",
        "    assert(framewise_lld.shape[0] == mfcc.shape[0])\n",
        "    assert(mfcc.shape[0] == spect.shape[0])\n",
        "\n",
        "    rnn_feats = np.concatenate((framewise_lld, mfcc, spect), axis = 1)\n",
        "    dense_feats = np.concatenate((framewise_lld_hsf, mfcc_hsf, lpc, spect_hsf, others))\n",
        "    return rnn_feats, dense_feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25fb_afgQjgd",
        "outputId": "42b10104-ba59-4be9-e2b8-bf8eca78c02e"
      },
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "  X = []\n",
        "  Y = []\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "    y = librosa.load(row['path'], mono=True, duration = 30,sr = SR)[0]\n",
        "    y = librosa.util.fix_length(y,4*SR)\n",
        "    rnn_feats, dense_feats = extract_LLD(y, SR)\n",
        "    X.append(rnn_feats)\n",
        "    Y.append(label_to_onehot(row['labels']))\n",
        "    #print(rnn_feats.shape)\n",
        "\n",
        "  X = np.reshape(np.array(X),(len(Y),X[0].shape[0],X[0].shape[1]))\n",
        "  Y = np.reshape(np.array(Y),(X.shape[0],4))\n",
        "\n",
        "  return X,Y\n",
        "\n",
        "\n",
        "\n",
        "train_path = \"TESS//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"TESS//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"TESS//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Train Data (1114, 59, 150) (1114, 4)\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Test Data (239, 59, 150) (239, 4)\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Val Data (239, 59, 150) (239, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LovHtEvYQopA"
      },
      "source": [
        "X_train = np.expand_dims(X_train,axis = -1)\n",
        "X_test = np.expand_dims(X_test,axis = -1)\n",
        "X_val = np.expand_dims(X_val,axis = -1)\n",
        "\n",
        "X_train = (X_train - X_train.mean())/X_train.std()\n",
        "X_test = (X_test - X_test.mean())/X_test.std()\n",
        "X_val = (X_val - X_val.mean())/X_val.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRQrNwd4RL0q",
        "outputId": "df6b3c17-a538-4426-cb8f-04d9529b1c65"
      },
      "source": [
        "\n",
        "def RNNSpeechModel(no_of_classes, input_size):\n",
        "  \n",
        "  # x = tf.keras.layers.Input((input_len,))\n",
        "  # x = tf.keras.layers.Reshape((1,-1))(x)\n",
        "  # m = Melspectrogram(n_dft=1024, n_hop=128, input_shape=(1, input_len),\n",
        "  #                      padding='same', sr=sr, n_mels=80,\n",
        "  #                      fmin=40.0, fmax=sr / 2, power_melgram=1.0,\n",
        "  #                      return_decibel_melgram=True, trainable_fb=False,\n",
        "  #                      trainable_kernel=False,\n",
        "  #                      name='mel_stft')\n",
        "  # m.trainable = False\n",
        "  # x = m(x)\n",
        "  #x = Normalization2D(int_axis=0)(x)\n",
        "  #x = tf.keras.layers.Permute((2,1,3))(x)\n",
        "\n",
        "  input = tf.keras.layers.Input((input_size))\n",
        "  #Bidirectional RNN\n",
        "  x = tf.keras.layers.Conv2D(10,(5,1),activation='relu',padding = 'same')(input)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2D(1,(5,1),activation='relu', padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Lambda(lambda q: K.squeeze(q, -1))(x)\n",
        "  x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences = 'true'))(x)\n",
        "  #x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences = 'true'))(x)\n",
        "\n",
        "  #Attention unit\n",
        "  xFirst = tf.keras.layers.Lambda(lambda q: q[:,-1])(x)\n",
        "  query = tf.keras.layers.Dense(128)(xFirst)\n",
        "  att_score = tf.keras.layers.Dot(axes=[1,2])([query,x])\n",
        "  att_score = tf.keras.layers.Softmax()(att_score)\n",
        "\n",
        "  #weighted pooling\n",
        "  att_vector = tf.keras.layers.Dot(axes=[1,1])([att_score,x])\n",
        "  #x = tf.keras.layers.Dense(64,activation='relu')(att_vector)\n",
        "  #x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "  output = tf.keras.layers.Dense(no_of_classes,activation='softmax')(att_vector)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs = input,outputs = output)\n",
        "  return model\n",
        "  \n",
        "no_of_classes = 4\n",
        "input_size = X_train[0].shape\n",
        "p4 = RNNSpeechModel(no_of_classes,input_size)\n",
        "p4.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
        "p4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 59, 150, 1)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 59, 150, 10)  60          ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 59, 150, 10)  40         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 59, 150, 1)   51          ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 59, 150, 1)  4           ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 59, 150)      0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 59, 128)      110080      ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 128)          0           ['bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          16512       ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 59)           0           ['dense_2[0][0]',                \n",
            "                                                                  'bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " softmax (Softmax)              (None, 59)           0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 128)          0           ['softmax[0][0]',                \n",
            "                                                                  'bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 4)            516         ['dot_1[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 127,263\n",
            "Trainable params: 127,241\n",
            "Non-trainable params: 22\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 1"
      ],
      "metadata": {
        "id": "n8JD2MhJScvm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHO8pCqPWNAu",
        "outputId": "782d4bfe-4fa1-4e15-af13-c960d3abe6fe"
      },
      "source": [
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//paper_4_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//paper_4_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "p4.fit(X_train,Y_train, batch_size=8,validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "140/140 [==============================] - 5s 15ms/step - loss: 0.6427 - acc: 0.7217 - val_loss: 1.5144 - val_acc: 0.4226\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.51436, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 2/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.0120 - acc: 0.9996 - val_loss: 0.1837 - val_acc: 0.9331\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.51436 to 0.18367, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 3/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9874\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.18367 to 0.03190, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 4/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.03190 to 0.00395, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 5/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 7.0029e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00395 to 0.00141, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 6/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 5.0854e-04 - acc: 1.0000 - val_loss: 9.6763e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00141 to 0.00097, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 7/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 3.7252e-04 - acc: 1.0000 - val_loss: 8.1745e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00097 to 0.00082, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 8/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 2.7968e-04 - acc: 1.0000 - val_loss: 7.3918e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00082 to 0.00074, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 9/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 2.5770e-04 - acc: 1.0000 - val_loss: 5.2479e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00074 to 0.00052, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 10/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 1.6864e-04 - acc: 1.0000 - val_loss: 4.6461e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00052 to 0.00046, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 11/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 1.2794e-04 - acc: 1.0000 - val_loss: 4.6269e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00046 to 0.00046, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 12/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 1.4126e-04 - acc: 1.0000 - val_loss: 4.0429e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00046 to 0.00040, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 13/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 9.7183e-05 - acc: 1.0000 - val_loss: 3.4180e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00040 to 0.00034, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 14/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 9.0310e-05 - acc: 1.0000 - val_loss: 3.3052e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00034 to 0.00033, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 15/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 7.9116e-05 - acc: 1.0000 - val_loss: 3.0926e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00033 to 0.00031, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 16/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 6.4747e-05 - acc: 1.0000 - val_loss: 2.9954e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00031 to 0.00030, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 17/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 5.7901e-05 - acc: 1.0000 - val_loss: 2.5821e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00030 to 0.00026, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 18/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 4.7698e-05 - acc: 1.0000 - val_loss: 3.3674e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00026\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 19/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 4.9435e-05 - acc: 1.0000 - val_loss: 2.1692e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00026 to 0.00022, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 20/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 4.2919e-05 - acc: 1.0000 - val_loss: 2.1089e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00022 to 0.00021, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 21/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 4.0159e-05 - acc: 1.0000 - val_loss: 1.9885e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00021 to 0.00020, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 22/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 3.3751e-05 - acc: 1.0000 - val_loss: 1.9816e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00020 to 0.00020, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 23/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 3.2814e-05 - acc: 1.0000 - val_loss: 1.7510e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00020 to 0.00018, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 24/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 2.6540e-05 - acc: 1.0000 - val_loss: 1.5600e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00018 to 0.00016, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 25/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 2.4288e-05 - acc: 1.0000 - val_loss: 1.8113e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00016\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 26/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 2.4121e-05 - acc: 1.0000 - val_loss: 1.3700e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00016 to 0.00014, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 27/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 1.8669e-05 - acc: 1.0000 - val_loss: 1.3292e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.00014 to 0.00013, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 28/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 1.8040e-05 - acc: 1.0000 - val_loss: 1.4702e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00013\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 29/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 1.8587e-05 - acc: 1.0000 - val_loss: 1.3007e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00013 to 0.00013, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 30/30\n",
            "140/140 [==============================] - 1s 10ms/step - loss: 1.7099e-05 - acc: 1.0000 - val_loss: 1.1213e-04 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.00013 to 0.00011, saving model to TESS//models/paper_4_loss.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd5f23a5590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WgJotWJWnGY",
        "outputId": "a8888d53-cf69-49dc-a84c-6836f13eaf3a"
      },
      "source": [
        "p4.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 7ms/step - loss: 2.6789e-04 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0002678911841940135, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "8mofONLpWtv0",
        "outputId": "6727996e-e685-4d1a-ef12-28197ed9f0f2"
      },
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(p4.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(p4.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 SCORE: 1.0\n",
            "Kappa: 1.0\n",
            "Accuracy: 1.0\n",
            "Jaccard Score: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        62\n",
            "           1       1.00      1.00      1.00        56\n",
            "           2       1.00      1.00      1.00        57\n",
            "           3       1.00      1.00      1.00        64\n",
            "\n",
            "    accuracy                           1.00       239\n",
            "   macro avg       1.00      1.00      1.00       239\n",
            "weighted avg       1.00      1.00      1.00       239\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 2"
      ],
      "metadata": {
        "id": "7jkHHyotSf5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//paper_4_loss_2.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//paper_4_acc_2.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "p4.fit(X_train,Y_train, batch_size=8,validation_data=(X_val, Y_val),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmZ5Uii8ShLF",
        "outputId": "fc4f65a0-d9c6-4ec9-d191-356b5e0d69ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2579 - acc: 0.9237\n",
            "Epoch 1: val_loss improved from inf to 0.23782, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 17s 50ms/step - loss: 0.2579 - acc: 0.9237 - val_loss: 0.2378 - val_acc: 0.9665\n",
            "Epoch 2/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 1.0000\n",
            "Epoch 2: val_loss improved from 0.23782 to 0.03450, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 0.9916\n",
            "Epoch 3/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 3: val_loss improved from 0.03450 to 0.00586, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 36ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
            "Epoch 4/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 7.0453e-04 - acc: 1.0000\n",
            "Epoch 4: val_loss improved from 0.00586 to 0.00179, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 7.0453e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 5/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 4.9106e-04 - acc: 1.0000\n",
            "Epoch 5: val_loss improved from 0.00179 to 0.00111, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 6s 39ms/step - loss: 4.9092e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 6/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 3.5154e-04 - acc: 1.0000\n",
            "Epoch 6: val_loss improved from 0.00111 to 0.00095, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 3.5154e-04 - acc: 1.0000 - val_loss: 9.4990e-04 - val_acc: 1.0000\n",
            "Epoch 7/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 2.6995e-04 - acc: 1.0000\n",
            "Epoch 7: val_loss improved from 0.00095 to 0.00064, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 39ms/step - loss: 2.6960e-04 - acc: 1.0000 - val_loss: 6.4056e-04 - val_acc: 1.0000\n",
            "Epoch 8/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 2.0612e-04 - acc: 1.0000\n",
            "Epoch 8: val_loss improved from 0.00064 to 0.00054, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 6s 44ms/step - loss: 2.0612e-04 - acc: 1.0000 - val_loss: 5.3988e-04 - val_acc: 1.0000\n",
            "Epoch 9/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 1.7369e-04 - acc: 1.0000\n",
            "Epoch 9: val_loss improved from 0.00054 to 0.00040, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 1.7344e-04 - acc: 1.0000 - val_loss: 4.0153e-04 - val_acc: 1.0000\n",
            "Epoch 10/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 1.3977e-04 - acc: 1.0000\n",
            "Epoch 10: val_loss improved from 0.00040 to 0.00038, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 1.3969e-04 - acc: 1.0000 - val_loss: 3.8069e-04 - val_acc: 1.0000\n",
            "Epoch 11/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 1.1616e-04 - acc: 1.0000\n",
            "Epoch 11: val_loss improved from 0.00038 to 0.00034, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 6s 45ms/step - loss: 1.1604e-04 - acc: 1.0000 - val_loss: 3.4487e-04 - val_acc: 1.0000\n",
            "Epoch 12/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 1.0013e-04 - acc: 1.0000\n",
            "Epoch 12: val_loss improved from 0.00034 to 0.00031, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 39ms/step - loss: 1.0013e-04 - acc: 1.0000 - val_loss: 3.1219e-04 - val_acc: 1.0000\n",
            "Epoch 13/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 8.5085e-05 - acc: 1.0000\n",
            "Epoch 13: val_loss improved from 0.00031 to 0.00026, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 6s 40ms/step - loss: 8.5085e-05 - acc: 1.0000 - val_loss: 2.6471e-04 - val_acc: 1.0000\n",
            "Epoch 14/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 7.0403e-05 - acc: 1.0000\n",
            "Epoch 14: val_loss did not improve from 0.00026\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 7.0403e-05 - acc: 1.0000 - val_loss: 2.7469e-04 - val_acc: 1.0000\n",
            "Epoch 15/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 6.3756e-05 - acc: 1.0000\n",
            "Epoch 15: val_loss did not improve from 0.00026\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 6.3669e-05 - acc: 1.0000 - val_loss: 2.7117e-04 - val_acc: 1.0000\n",
            "Epoch 16/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 5.3973e-05 - acc: 1.0000\n",
            "Epoch 16: val_loss improved from 0.00026 to 0.00023, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 39ms/step - loss: 5.4153e-05 - acc: 1.0000 - val_loss: 2.3208e-04 - val_acc: 1.0000\n",
            "Epoch 17/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 4.7897e-05 - acc: 1.0000\n",
            "Epoch 17: val_loss improved from 0.00023 to 0.00023, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 38ms/step - loss: 4.7877e-05 - acc: 1.0000 - val_loss: 2.3175e-04 - val_acc: 1.0000\n",
            "Epoch 18/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 4.2854e-05 - acc: 1.0000\n",
            "Epoch 18: val_loss improved from 0.00023 to 0.00021, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 4.2804e-05 - acc: 1.0000 - val_loss: 2.1468e-04 - val_acc: 1.0000\n",
            "Epoch 19/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 3.8722e-05 - acc: 1.0000\n",
            "Epoch 19: val_loss improved from 0.00021 to 0.00019, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 3.8675e-05 - acc: 1.0000 - val_loss: 1.9205e-04 - val_acc: 1.0000\n",
            "Epoch 20/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 3.4438e-05 - acc: 1.0000\n",
            "Epoch 20: val_loss improved from 0.00019 to 0.00017, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 3.4403e-05 - acc: 1.0000 - val_loss: 1.7362e-04 - val_acc: 1.0000\n",
            "Epoch 21/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 3.1037e-05 - acc: 1.0000\n",
            "Epoch 21: val_loss did not improve from 0.00017\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 3.1098e-05 - acc: 1.0000 - val_loss: 1.7678e-04 - val_acc: 1.0000\n",
            "Epoch 22/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 2.7470e-05 - acc: 1.0000\n",
            "Epoch 22: val_loss did not improve from 0.00017\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 35ms/step - loss: 2.7470e-05 - acc: 1.0000 - val_loss: 1.9004e-04 - val_acc: 1.0000\n",
            "Epoch 23/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 2.4282e-05 - acc: 1.0000\n",
            "Epoch 23: val_loss did not improve from 0.00017\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 36ms/step - loss: 2.4344e-05 - acc: 1.0000 - val_loss: 1.8007e-04 - val_acc: 1.0000\n",
            "Epoch 24/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 2.2069e-05 - acc: 1.0000\n",
            "Epoch 24: val_loss improved from 0.00017 to 0.00016, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 38ms/step - loss: 2.2039e-05 - acc: 1.0000 - val_loss: 1.6499e-04 - val_acc: 1.0000\n",
            "Epoch 25/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 1.9645e-05 - acc: 1.0000\n",
            "Epoch 25: val_loss did not improve from 0.00016\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 36ms/step - loss: 1.9645e-05 - acc: 1.0000 - val_loss: 1.7502e-04 - val_acc: 1.0000\n",
            "Epoch 26/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 1.8157e-05 - acc: 1.0000\n",
            "Epoch 26: val_loss improved from 0.00016 to 0.00016, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 39ms/step - loss: 1.8150e-05 - acc: 1.0000 - val_loss: 1.6073e-04 - val_acc: 1.0000\n",
            "Epoch 27/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 1.6515e-05 - acc: 1.0000\n",
            "Epoch 27: val_loss improved from 0.00016 to 0.00016, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 1.6493e-05 - acc: 1.0000 - val_loss: 1.6017e-04 - val_acc: 1.0000\n",
            "Epoch 28/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 1.5747e-05 - acc: 1.0000\n",
            "Epoch 28: val_loss improved from 0.00016 to 0.00014, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 1.5727e-05 - acc: 1.0000 - val_loss: 1.3512e-04 - val_acc: 1.0000\n",
            "Epoch 29/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 1.3942e-05 - acc: 1.0000\n",
            "Epoch 29: val_loss improved from 0.00014 to 0.00013, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 1.3921e-05 - acc: 1.0000 - val_loss: 1.3372e-04 - val_acc: 1.0000\n",
            "Epoch 30/30\n",
            "139/140 [============================>.] - ETA: 0s - loss: 1.2575e-05 - acc: 1.0000\n",
            "Epoch 30: val_loss improved from 0.00013 to 0.00012, saving model to TESS//models/paper_4_loss_2.h5\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "140/140 [==============================] - 5s 37ms/step - loss: 1.2599e-05 - acc: 1.0000 - val_loss: 1.2296e-04 - val_acc: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faff7a7f0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p4.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPu37Jm6SyoT",
        "outputId": "41ae7d3a-0a0c-44af-c742-bebbafaeec11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 28ms/step - loss: 2.4576e-05 - acc: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.457626032992266e-05, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ0wyDP1E3NA"
      },
      "source": [
        "#Paper_5\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19gLVfE7kWwk",
        "outputId": "d71138a3-28ee-4a8a-f3d7-3fceaddd03c0"
      },
      "source": [
        "def findmaxsize(rslt_df):\n",
        "    sizes = []\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "      filename = row['path']\n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      \n",
        "      #print(y.shape)\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      \n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        "      #print(spect.shape)\n",
        "      \n",
        "      # Adding the size to the list\n",
        "      sizes.append(spect.shape)\n",
        "    print(f'The sizes of all the mel spectrograms in our data set are equal: {len(set(sizes)) == 1}')\n",
        "\n",
        "    # Checking the max size\n",
        "    print(f'The maximum size is: {max(sizes)}')\n",
        "\n",
        "\n",
        "    return max(sizes)\n",
        "\n",
        "\n",
        "X = pd.read_csv('TESS/TESS_details.csv',usecols=['labels','path'])\n",
        "options = ['angry', 'happy','neutral','sad'] \n",
        "\n",
        "time = 4\n",
        "rslt_df = X[X['labels'].isin(options)]\n",
        "\n",
        "max_x,max_y = findmaxsize(rslt_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sizes of all the mel spectrograms in our data set are equal: False\n",
            "The maximum size is: (64, 299)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObM4VpQHkZBE",
        "outputId": "45132807-38fc-42cc-863c-a3a536a13de3"
      },
      "source": [
        "max_x,max_y =(64, 299)\n",
        "T = 64\n",
        "print(max_y,T,(int(max_y/T)+1)*T,int(max_y/T)+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "299 64 320 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e6q33lHko3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a24739-104c-4d9c-fdc5-2ad9bf4f0a74"
      },
      "source": [
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  #l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "\n",
        "def extract_mel_spectrogram(df,max_x = max_x,max_y = max_y):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path'] \n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        " \n",
        "      if spect.shape[1] != max_y:\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        "\n",
        "      s=[]\n",
        "      for i in range(0,int((max_y-64)/30),1):\n",
        "        #print(spect[:,i*64:(i+1)*64].shape)\n",
        "        q=spect[:,i*30:64 +i*30]\n",
        "        #print(q.shape)\n",
        "        delta = librosa.feature.delta(q).reshape((max_x,64,1))\n",
        "        d_delta = librosa.feature.delta(q,order = 2).reshape((max_x,64,1))\n",
        "        #print(q.shape,delta.shape,d_delta.shape)\n",
        "        q = q.reshape((max_x,64,1))\n",
        "\n",
        "        z = np.concatenate((q,delta,d_delta),axis = -1)\n",
        "        #print(z.shape)\n",
        "        s.append(z)\n",
        "      mel_specs.append(np.asarray(s))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  #print(len(mel_specs),mel_specs[0].shape)\n",
        "  mel_specs = np.asarray(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        " \n",
        "train_path = \"TESS//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "#X_train_spec = np.expand_dims(X_train_spec,axis=-1)\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        " \n",
        " \n",
        "test_path = \"TESS//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "#X_test_spec = np.expand_dims(X_test_spec,axis=-1)\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        " \n",
        "val_path = \"TESS//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "#X_val_spec = np.expand_dims(X_val_spec,axis=-1)\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1114, 7, 64, 64, 3) (1114, 4)\n",
            "(239, 7, 64, 64, 3) (239, 4)\n",
            "(239, 7, 64, 64, 3) (239, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM-TKcc3E7rL",
        "outputId": "93929710-8dca-4d18-b895-a209f491104d"
      },
      "source": [
        "import keras\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "def div_L0(num):\n",
        "    [a, b] = div_L1(num)\n",
        "    [c, d, e, f] = div_L2(num)\n",
        "\n",
        "    return [a, b], [c, d, e, f]\n",
        "def div_L1(num):\n",
        "    a = num // 2\n",
        "    b = num - a\n",
        "\n",
        "    return [a, b]\n",
        "def div_L2(num):\n",
        "    [a, b] = div_L1(num)\n",
        "    [c, d] = div_L1(a)\n",
        "    [e, f] = div_L1(b)\n",
        "\n",
        "    return [c, d, e, f]\n",
        "\n",
        "def lpnorm_pooling(features_Ln):\n",
        "    '''\n",
        "    :param features_Ln:\n",
        "    :param var_p: 1-average pooling, np.inf-max pooling\n",
        "    :return:\n",
        "    '''\n",
        "    var_p = 2.14  # average pooling\n",
        "#   var_p = np.inf  # max pooling\n",
        "    lpnorm = tf.norm(features_Ln,ord=var_p,axis=1)\n",
        "    result = lpnorm * (1/features_Ln.shape[1])**(1/var_p)\n",
        "\n",
        "    #print(result)\n",
        "    result = tf.math.reduce_max(features_Ln,axis = 1)\n",
        "    #result = np.average(features_Ln,axis = 0)\n",
        "    #print(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "def subpart():\n",
        "    \n",
        "    input_layer = Input((227,227,3))\n",
        "\n",
        "    X = Resizing(227,227)(input_layer)\n",
        "    \n",
        "      \n",
        "    X = Conv2D(96,(11,11),strides = 4,name=\"conv0\")(X)\n",
        "    X = BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
        "    \n",
        "    X = Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3 ,name='bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D(2)(X)\n",
        "    \n",
        "    X = Flatten()(X)\n",
        "    \n",
        "    X = Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
        "    \n",
        "    X = Dense(4096, activation = 'relu', name = 'fc1')(X) \n",
        "\n",
        "    Y = Reshape((1,4096))(X)\n",
        "\n",
        "    return Model(inputs = input_layer,outputs = Y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def paper_2():\n",
        "    input_layer = Input((7,64,64,3))\n",
        "\n",
        "    sp = subpart()\n",
        "\n",
        "    for i in range(input_layer.shape[1]):\n",
        "      #print(input_layer[:,0,:,:,:].shape)\n",
        "      inp = Resizing(227,227)(input_layer[:,i,:,:,:])\n",
        "      output_layer = sp(inp)\n",
        "\n",
        "      if i == 0:\n",
        "        output_layers = output_layer\n",
        "      else:\n",
        "        output_layers = Concatenate(axis = 1)([output_layers,output_layer])\n",
        "    \n",
        "    print(output_layers.shape)\n",
        "    t,n, d = output_layers.shape\n",
        "    #rint(X.shape)\n",
        "\n",
        "    if n == 3:\n",
        "        features = np.row_stack((X, X[-1]))\n",
        "    if n == 2:\n",
        "        features = np.row_stack((X, X))\n",
        "    if n == 1:\n",
        "        print(n)\n",
        "        features = tf.stack((X, X, X, X),axis =1)\n",
        "\n",
        "    #print(features.shape)\n",
        "    t,n, d = output_layers.shape\n",
        "\n",
        "    [a, b], [c, d, e, f] = div_L0(n)\n",
        "\n",
        "    L0 = lpnorm_pooling(output_layers)\n",
        "    #print(a,b,c,d,e,f, features.shape)\n",
        "    L1_1 = lpnorm_pooling(output_layers[:,:a,:])\n",
        "    #print(features[:,:a,].shape)\n",
        "    L1_2 = lpnorm_pooling(output_layers[:,a:,:])\n",
        "\n",
        "    L2_1 = lpnorm_pooling(output_layers[:,:c,:])\n",
        "    L2_2 = lpnorm_pooling(output_layers[:,c:a,:])\n",
        "    L2_3 = lpnorm_pooling(output_layers[:,a:a+e,:])\n",
        "    L2_4 = lpnorm_pooling(output_layers[:,a+e:,:])\n",
        "\n",
        "    W_L0=1/4;\n",
        "    W_L1=1/4;\n",
        "    W_L2=1/2;\n",
        "\n",
        "    Weights_L = [[W_L0,0,0,0,0,0,0],\n",
        "                 [0,W_L1,0,0,0,0,0],\n",
        "                 [0,0,W_L1,0,0,0,0],\n",
        "                 [0,0,0,W_L2,0,0,0],\n",
        "                 [0,0,0,0,W_L2,0,0],\n",
        "                 [0,0,0,0,0,W_L2,0],\n",
        "                 [0,0,0,0,0,0,W_L2]]\n",
        "\n",
        "    features_Vp = Concatenate(axis =1)([W_L0*L0, W_L1*L1_1, W_L1*L1_2, W_L2*L2_1, W_L2*L2_2, W_L2*L2_3, W_L2*L2_4])\n",
        "\n",
        "    op = Dense(4,activation = 'softmax',kernel_regularizer=keras.regularizers.l2(0.01))(features_Vp)\n",
        "    #features_Up = np.matmul(Weights_L,features_Vp)\n",
        "\n",
        "    return Model(inputs=input_layer,outputs=op)\n",
        "\n",
        "p5 = paper_2()\n",
        "p5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 7, 4096)\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 7, 64, 64,   0           []                               \n",
            "                                3)]                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 64, 64, 3)   0           ['input_1[0][0]']                \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 64, 64, 3)   0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " resizing_1 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resizing_2 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2 (Sl  (None, 64, 64, 3)   0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " model (Functional)             (None, 1, 4096)      58286848    ['resizing_1[0][0]',             \n",
            "                                                                  'resizing_2[0][0]',             \n",
            "                                                                  'resizing_3[0][0]',             \n",
            "                                                                  'resizing_4[0][0]',             \n",
            "                                                                  'resizing_5[0][0]',             \n",
            "                                                                  'resizing_6[0][0]',             \n",
            "                                                                  'resizing_7[0][0]']             \n",
            "                                                                                                  \n",
            " resizing_3 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3 (Sl  (None, 64, 64, 3)   0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 2, 4096)      0           ['model[0][0]',                  \n",
            "                                                                  'model[1][0]']                  \n",
            "                                                                                                  \n",
            " resizing_4 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_4 (Sl  (None, 64, 64, 3)   0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 3, 4096)      0           ['concatenate[0][0]',            \n",
            "                                                                  'model[2][0]']                  \n",
            "                                                                                                  \n",
            " resizing_5 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_5 (Sl  (None, 64, 64, 3)   0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 4, 4096)      0           ['concatenate_1[0][0]',          \n",
            "                                                                  'model[3][0]']                  \n",
            "                                                                                                  \n",
            " resizing_6 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_5[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_6 (Sl  (None, 64, 64, 3)   0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 5, 4096)      0           ['concatenate_2[0][0]',          \n",
            "                                                                  'model[4][0]']                  \n",
            "                                                                                                  \n",
            " resizing_7 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_6[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 6, 4096)      0           ['concatenate_3[0][0]',          \n",
            "                                                                  'model[5][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 7, 4096)      0           ['concatenate_4[0][0]',          \n",
            "                                                                  'model[6][0]']                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_7 (Sl  (None, 3, 4096)     0           ['concatenate_5[0][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_8 (Sl  (None, 4, 4096)     0           ['concatenate_5[0][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_9 (Sl  (None, 1, 4096)     0           ['concatenate_5[0][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_10 (S  (None, 2, 4096)     0           ['concatenate_5[0][0]']          \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_11 (S  (None, 2, 4096)     0           ['concatenate_5[0][0]']          \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_12 (S  (None, 2, 4096)     0           ['concatenate_5[0][0]']          \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLambda  (None, 4096)        0           ['concatenate_5[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_7[0][0\n",
            " da)                                                             ]']                              \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_2 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_8[0][0\n",
            " da)                                                             ]']                              \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_9[0][0\n",
            " da)                                                             ]']                              \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_4 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_10[0][\n",
            " da)                                                             0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_5 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_11[0][\n",
            " da)                                                             0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_6 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_12[0][\n",
            " da)                                                             0]']                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_7 (TFOpLambda  (None, 4096)        0           ['tf.math.reduce_max[0][0]']     \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_8 (TFOpLambda  (None, 4096)        0           ['tf.math.reduce_max_1[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_9 (TFOpLambda  (None, 4096)        0           ['tf.math.reduce_max_2[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_10 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_3[0][0]']   \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_11 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_4[0][0]']   \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_12 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_5[0][0]']   \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_13 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_6[0][0]']   \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 28672)        0           ['tf.math.multiply_7[0][0]',     \n",
            "                                                                  'tf.math.multiply_8[0][0]',     \n",
            "                                                                  'tf.math.multiply_9[0][0]',     \n",
            "                                                                  'tf.math.multiply_10[0][0]',    \n",
            "                                                                  'tf.math.multiply_11[0][0]',    \n",
            "                                                                  'tf.math.multiply_12[0][0]',    \n",
            "                                                                  'tf.math.multiply_13[0][0]']    \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 4)            114692      ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 58,401,540\n",
            "Trainable params: 58,398,788\n",
            "Non-trainable params: 2,752\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 1"
      ],
      "metadata": {
        "id": "jFlSURpcZOAw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HhOdM5AHe4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a971b3-404e-406c-ade7-db138657cea4"
      },
      "source": [
        "p5.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//paper_5_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//paper_5_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = p5.fit(X_train_spec,Y_train_spec, batch_size=8,validation_data=(X_val_spec, Y_val_spec),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "140/140 [==============================] - 55s 141ms/step - loss: 4.8568 - accuracy: 0.5018 - val_loss: 1.2683 - val_accuracy: 0.5690\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.26830, saving model to TESS//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.56904, saving model to TESS//models/paper_5_acc.h5\n",
            "Epoch 2/30\n",
            "140/140 [==============================] - 19s 134ms/step - loss: 0.8033 - accuracy: 0.6921 - val_loss: 1.5148 - val_accuracy: 0.5607\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.26830\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.56904\n",
            "Epoch 3/30\n",
            "140/140 [==============================] - 19s 134ms/step - loss: 0.7112 - accuracy: 0.7481 - val_loss: 0.5899 - val_accuracy: 0.7992\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.26830 to 0.58992, saving model to TESS//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.56904 to 0.79916, saving model to TESS//models/paper_5_acc.h5\n",
            "Epoch 4/30\n",
            "140/140 [==============================] - 19s 137ms/step - loss: 0.4811 - accuracy: 0.8368 - val_loss: 0.6852 - val_accuracy: 0.7866\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.58992\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.79916\n",
            "Epoch 5/30\n",
            "140/140 [==============================] - 20s 140ms/step - loss: 0.4049 - accuracy: 0.8684 - val_loss: 0.3984 - val_accuracy: 0.8452\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.58992 to 0.39842, saving model to TESS//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.79916 to 0.84519, saving model to TESS//models/paper_5_acc.h5\n",
            "Epoch 6/30\n",
            "140/140 [==============================] - 20s 142ms/step - loss: 0.3400 - accuracy: 0.8883 - val_loss: 0.6051 - val_accuracy: 0.8159\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.39842\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.84519\n",
            "Epoch 7/30\n",
            "140/140 [==============================] - 20s 142ms/step - loss: 0.2083 - accuracy: 0.9347 - val_loss: 0.2352 - val_accuracy: 0.9163\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.39842 to 0.23523, saving model to TESS//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.84519 to 0.91632, saving model to TESS//models/paper_5_acc.h5\n",
            "Epoch 8/30\n",
            "140/140 [==============================] - 20s 139ms/step - loss: 0.2172 - accuracy: 0.9349 - val_loss: 0.2439 - val_accuracy: 0.9247\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.23523\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91632 to 0.92469, saving model to TESS//models/paper_5_acc.h5\n",
            "Epoch 9/30\n",
            "140/140 [==============================] - 20s 142ms/step - loss: 0.2017 - accuracy: 0.9382 - val_loss: 0.2508 - val_accuracy: 0.9079\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.23523\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.92469\n",
            "Epoch 10/30\n",
            "140/140 [==============================] - 20s 141ms/step - loss: 0.1157 - accuracy: 0.9651 - val_loss: 1.1126 - val_accuracy: 0.7615\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.23523\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.92469\n",
            "Epoch 11/30\n",
            "140/140 [==============================] - 20s 140ms/step - loss: 0.1016 - accuracy: 0.9681 - val_loss: 0.2362 - val_accuracy: 0.9331\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.23523\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.92469 to 0.93305, saving model to TESS//models/paper_5_acc.h5\n",
            "Epoch 12/30\n",
            "140/140 [==============================] - 20s 140ms/step - loss: 0.1050 - accuracy: 0.9640 - val_loss: 0.2653 - val_accuracy: 0.9205\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.23523\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.93305\n",
            "Epoch 13/30\n",
            "140/140 [==============================] - 20s 141ms/step - loss: 0.1204 - accuracy: 0.9686 - val_loss: 0.2080 - val_accuracy: 0.9331\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.23523 to 0.20805, saving model to TESS//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.93305\n",
            "Epoch 14/30\n",
            "140/140 [==============================] - 20s 140ms/step - loss: 0.1024 - accuracy: 0.9741 - val_loss: 0.5099 - val_accuracy: 0.7657\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.20805\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.93305\n",
            "Epoch 15/30\n",
            "140/140 [==============================] - 20s 140ms/step - loss: 0.1652 - accuracy: 0.9454 - val_loss: 0.1345 - val_accuracy: 0.9582\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.20805 to 0.13447, saving model to TESS//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.93305 to 0.95816, saving model to TESS//models/paper_5_acc.h5\n",
            "Epoch 16/30\n",
            "140/140 [==============================] - 20s 141ms/step - loss: 0.1205 - accuracy: 0.9610 - val_loss: 2.0174 - val_accuracy: 0.6067\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.13447\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.95816\n",
            "Epoch 17/30\n",
            "140/140 [==============================] - 20s 142ms/step - loss: 0.0895 - accuracy: 0.9777 - val_loss: 0.2064 - val_accuracy: 0.9456\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.13447\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.95816\n",
            "Epoch 18/30\n",
            "140/140 [==============================] - 20s 141ms/step - loss: 0.1151 - accuracy: 0.9693 - val_loss: 0.1711 - val_accuracy: 0.9456\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.13447\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.95816\n",
            "Epoch 19/30\n",
            "140/140 [==============================] - 20s 140ms/step - loss: 0.0916 - accuracy: 0.9740 - val_loss: 0.1038 - val_accuracy: 0.9791\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.13447 to 0.10384, saving model to TESS//models/paper_5_loss.h5\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.95816 to 0.97908, saving model to TESS//models/paper_5_acc.h5\n",
            "Epoch 20/30\n",
            "140/140 [==============================] - 20s 141ms/step - loss: 0.0595 - accuracy: 0.9864 - val_loss: 0.1837 - val_accuracy: 0.9498\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.10384\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.97908\n",
            "Epoch 21/30\n",
            "140/140 [==============================] - 20s 143ms/step - loss: 0.0561 - accuracy: 0.9860 - val_loss: 0.1811 - val_accuracy: 0.9414\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.10384\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.97908\n",
            "Epoch 22/30\n",
            "140/140 [==============================] - 20s 142ms/step - loss: 0.1624 - accuracy: 0.9572 - val_loss: 0.1327 - val_accuracy: 0.9623\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.10384\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.97908\n",
            "Epoch 23/30\n",
            "140/140 [==============================] - 20s 140ms/step - loss: 0.0610 - accuracy: 0.9844 - val_loss: 0.3757 - val_accuracy: 0.9038\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.10384\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.97908\n",
            "Epoch 24/30\n",
            "140/140 [==============================] - 20s 140ms/step - loss: 0.0500 - accuracy: 0.9876 - val_loss: 0.4972 - val_accuracy: 0.8577\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.10384\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.97908\n",
            "Epoch 25/30\n",
            "140/140 [==============================] - 20s 141ms/step - loss: 0.3641 - accuracy: 0.9177 - val_loss: 0.2533 - val_accuracy: 0.9331\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.10384\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.97908\n",
            "Epoch 26/30\n",
            "140/140 [==============================] - 20s 142ms/step - loss: 0.1527 - accuracy: 0.9585 - val_loss: 0.2559 - val_accuracy: 0.9414\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.10384\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.97908\n",
            "Epoch 27/30\n",
            "140/140 [==============================] - 20s 141ms/step - loss: 0.0623 - accuracy: 0.9803 - val_loss: 0.2651 - val_accuracy: 0.9540\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.10384\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.97908\n",
            "Epoch 28/30\n",
            "140/140 [==============================] - 20s 141ms/step - loss: 0.0600 - accuracy: 0.9870 - val_loss: 0.1745 - val_accuracy: 0.9623\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.10384\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.97908\n",
            "Epoch 29/30\n",
            "140/140 [==============================] - 20s 141ms/step - loss: 0.0786 - accuracy: 0.9841 - val_loss: 0.1766 - val_accuracy: 0.9540\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.10384\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.97908\n",
            "Epoch 30/30\n",
            "140/140 [==============================] - 20s 140ms/step - loss: 0.0450 - accuracy: 0.9884 - val_loss: 0.1853 - val_accuracy: 0.9707\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.10384\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.97908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlfQ0nPTtxby",
        "outputId": "f5e1e568-f288-4226-bdea-eb60331516ee"
      },
      "source": [
        "p5.load_weights('TESS//models//paper_5_acc.h5')\n",
        "print(p5.evaluate(X_test_spec,Y_test_spec))\n",
        "p5.load_weights('TESS//models//paper_5_loss.h5')\n",
        "p5.evaluate(X_test_spec,Y_test_spec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 2s 145ms/step - loss: 0.1123 - accuracy: 0.9791\n",
            "[0.11229915171861649, 0.9790794849395752]\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 0.1123 - accuracy: 0.9791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11229915171861649, 0.9790794849395752]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "shYi97oC0Tns",
        "outputId": "ae9037b2-d5db-4af8-9c41-a476aca52a16"
      },
      "source": [
        "#test set\n",
        "#p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 SCORE: 0.9787276631909804\n",
            "Kappa: 0.9720670391061452\n",
            "Accuracy: 0.9790794979079498\n",
            "Jaccard Score: 0.9583988052681338\n",
            "Precision: 0.9793822440999861\n",
            "Recall: 0.978267240682351\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        62\n",
            "           1       0.98      0.96      0.97        56\n",
            "           2       0.98      0.96      0.97        57\n",
            "           3       0.97      1.00      0.98        64\n",
            "\n",
            "    accuracy                           0.98       239\n",
            "   macro avg       0.98      0.98      0.98       239\n",
            "weighted avg       0.98      0.98      0.98       239\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 2"
      ],
      "metadata": {
        "id": "YkKgq7-6ZSpl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq-jMQbR0rCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a64a06-4755-4261-b8b8-633977a7a838"
      },
      "source": [
        "p5.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//paper_5_loss_2.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//paper_5_acc_2.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = p5.fit(X_train_spec,Y_train_spec, batch_size=8,validation_data=(X_val_spec, Y_val_spec),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 2.1071 - accuracy: 0.5718\n",
            "Epoch 1: val_loss improved from inf to 0.82401, saving model to TESS//models/paper_5_loss_2.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.66527, saving model to TESS//models/paper_5_acc_2.h5\n",
            "140/140 [==============================] - 40s 191ms/step - loss: 2.1071 - accuracy: 0.5718 - val_loss: 0.8240 - val_accuracy: 0.6653\n",
            "Epoch 2/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.9240 - accuracy: 0.6768\n",
            "Epoch 2: val_loss improved from 0.82401 to 0.77638, saving model to TESS//models/paper_5_loss_2.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.66527 to 0.72385, saving model to TESS//models/paper_5_acc_2.h5\n",
            "140/140 [==============================] - 29s 208ms/step - loss: 0.9240 - accuracy: 0.6768 - val_loss: 0.7764 - val_accuracy: 0.7238\n",
            "Epoch 3/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.6514 - accuracy: 0.7639\n",
            "Epoch 3: val_loss improved from 0.77638 to 0.60434, saving model to TESS//models/paper_5_loss_2.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.72385 to 0.75732, saving model to TESS//models/paper_5_acc_2.h5\n",
            "140/140 [==============================] - 28s 201ms/step - loss: 0.6514 - accuracy: 0.7639 - val_loss: 0.6043 - val_accuracy: 0.7573\n",
            "Epoch 4/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.7998\n",
            "Epoch 4: val_loss did not improve from 0.60434\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.75732\n",
            "140/140 [==============================] - 19s 134ms/step - loss: 0.5249 - accuracy: 0.7998 - val_loss: 0.6826 - val_accuracy: 0.6695\n",
            "Epoch 5/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4984 - accuracy: 0.8142\n",
            "Epoch 5: val_loss improved from 0.60434 to 0.44455, saving model to TESS//models/paper_5_loss_2.h5\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.75732 to 0.78661, saving model to TESS//models/paper_5_acc_2.h5\n",
            "140/140 [==============================] - 28s 199ms/step - loss: 0.4984 - accuracy: 0.8142 - val_loss: 0.4446 - val_accuracy: 0.7866\n",
            "Epoch 6/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4431 - accuracy: 0.8555\n",
            "Epoch 6: val_loss improved from 0.44455 to 0.39630, saving model to TESS//models/paper_5_loss_2.h5\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.78661 to 0.85774, saving model to TESS//models/paper_5_acc_2.h5\n",
            "140/140 [==============================] - 27s 191ms/step - loss: 0.4431 - accuracy: 0.8555 - val_loss: 0.3963 - val_accuracy: 0.8577\n",
            "Epoch 7/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3725 - accuracy: 0.8680\n",
            "Epoch 7: val_loss improved from 0.39630 to 0.35988, saving model to TESS//models/paper_5_loss_2.h5\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.85774 to 0.86192, saving model to TESS//models/paper_5_acc_2.h5\n",
            "140/140 [==============================] - 27s 194ms/step - loss: 0.3725 - accuracy: 0.8680 - val_loss: 0.3599 - val_accuracy: 0.8619\n",
            "Epoch 8/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 0.8860\n",
            "Epoch 8: val_loss improved from 0.35988 to 0.29652, saving model to TESS//models/paper_5_loss_2.h5\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.86192 to 0.90377, saving model to TESS//models/paper_5_acc_2.h5\n",
            "140/140 [==============================] - 27s 191ms/step - loss: 0.2965 - accuracy: 0.8860 - val_loss: 0.2965 - val_accuracy: 0.9038\n",
            "Epoch 9/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3495 - accuracy: 0.8869\n",
            "Epoch 9: val_loss did not improve from 0.29652\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.90377\n",
            "140/140 [==============================] - 19s 133ms/step - loss: 0.3495 - accuracy: 0.8869 - val_loss: 0.3060 - val_accuracy: 0.8828\n",
            "Epoch 10/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.9443\n",
            "Epoch 10: val_loss improved from 0.29652 to 0.17224, saving model to TESS//models/paper_5_loss_2.h5\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.90377 to 0.95397, saving model to TESS//models/paper_5_acc_2.h5\n",
            "140/140 [==============================] - 28s 198ms/step - loss: 0.1884 - accuracy: 0.9443 - val_loss: 0.1722 - val_accuracy: 0.9540\n",
            "Epoch 11/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1415 - accuracy: 0.9614\n",
            "Epoch 11: val_loss did not improve from 0.17224\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.95397\n",
            "140/140 [==============================] - 19s 134ms/step - loss: 0.1415 - accuracy: 0.9614 - val_loss: 0.3014 - val_accuracy: 0.8996\n",
            "Epoch 12/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2357 - accuracy: 0.9354\n",
            "Epoch 12: val_loss did not improve from 0.17224\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.95397\n",
            "140/140 [==============================] - 19s 135ms/step - loss: 0.2357 - accuracy: 0.9354 - val_loss: 0.1823 - val_accuracy: 0.9456\n",
            "Epoch 13/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1804 - accuracy: 0.9488\n",
            "Epoch 13: val_loss did not improve from 0.17224\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.95397\n",
            "140/140 [==============================] - 19s 134ms/step - loss: 0.1804 - accuracy: 0.9488 - val_loss: 0.4244 - val_accuracy: 0.8577\n",
            "Epoch 14/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9686\n",
            "Epoch 14: val_loss improved from 0.17224 to 0.15943, saving model to TESS//models/paper_5_loss_2.h5\n",
            "\n",
            "Epoch 14: val_accuracy improved from 0.95397 to 0.97071, saving model to TESS//models/paper_5_acc_2.h5\n",
            "140/140 [==============================] - 28s 202ms/step - loss: 0.1332 - accuracy: 0.9686 - val_loss: 0.1594 - val_accuracy: 0.9707\n",
            "Epoch 15/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9874\n",
            "Epoch 15: val_loss did not improve from 0.15943\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 136ms/step - loss: 0.0703 - accuracy: 0.9874 - val_loss: 0.2016 - val_accuracy: 0.9414\n",
            "Epoch 16/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1167 - accuracy: 0.9713\n",
            "Epoch 16: val_loss did not improve from 0.15943\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 135ms/step - loss: 0.1167 - accuracy: 0.9713 - val_loss: 0.2125 - val_accuracy: 0.9498\n",
            "Epoch 17/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9722\n",
            "Epoch 17: val_loss did not improve from 0.15943\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 135ms/step - loss: 0.0974 - accuracy: 0.9722 - val_loss: 0.2164 - val_accuracy: 0.9498\n",
            "Epoch 18/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9758\n",
            "Epoch 18: val_loss did not improve from 0.15943\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 135ms/step - loss: 0.0974 - accuracy: 0.9758 - val_loss: 0.1822 - val_accuracy: 0.9623\n",
            "Epoch 19/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9425\n",
            "Epoch 19: val_loss did not improve from 0.15943\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 135ms/step - loss: 0.2167 - accuracy: 0.9425 - val_loss: 0.1793 - val_accuracy: 0.9540\n",
            "Epoch 20/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9587\n",
            "Epoch 20: val_loss did not improve from 0.15943\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 136ms/step - loss: 0.1396 - accuracy: 0.9587 - val_loss: 0.3166 - val_accuracy: 0.9289\n",
            "Epoch 21/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.9488\n",
            "Epoch 21: val_loss did not improve from 0.15943\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 136ms/step - loss: 0.1912 - accuracy: 0.9488 - val_loss: 0.2058 - val_accuracy: 0.9582\n",
            "Epoch 22/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.9488\n",
            "Epoch 22: val_loss did not improve from 0.15943\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 136ms/step - loss: 0.1872 - accuracy: 0.9488 - val_loss: 0.2158 - val_accuracy: 0.9498\n",
            "Epoch 23/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.9811\n",
            "Epoch 23: val_loss did not improve from 0.15943\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 136ms/step - loss: 0.0816 - accuracy: 0.9811 - val_loss: 0.1823 - val_accuracy: 0.9665\n",
            "Epoch 24/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9820\n",
            "Epoch 24: val_loss did not improve from 0.15943\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 136ms/step - loss: 0.0731 - accuracy: 0.9820 - val_loss: 0.1900 - val_accuracy: 0.9456\n",
            "Epoch 25/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9677\n",
            "Epoch 25: val_loss improved from 0.15943 to 0.15719, saving model to TESS//models/paper_5_loss_2.h5\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 24s 168ms/step - loss: 0.1294 - accuracy: 0.9677 - val_loss: 0.1572 - val_accuracy: 0.9707\n",
            "Epoch 26/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9847\n",
            "Epoch 26: val_loss did not improve from 0.15719\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 137ms/step - loss: 0.0834 - accuracy: 0.9847 - val_loss: 0.1995 - val_accuracy: 0.9623\n",
            "Epoch 27/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9946\n",
            "Epoch 27: val_loss did not improve from 0.15719\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 136ms/step - loss: 0.0423 - accuracy: 0.9946 - val_loss: 0.3553 - val_accuracy: 0.9331\n",
            "Epoch 28/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9820\n",
            "Epoch 28: val_loss did not improve from 0.15719\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 137ms/step - loss: 0.0764 - accuracy: 0.9820 - val_loss: 0.2451 - val_accuracy: 0.9456\n",
            "Epoch 29/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9731\n",
            "Epoch 29: val_loss did not improve from 0.15719\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 19s 136ms/step - loss: 0.1058 - accuracy: 0.9731 - val_loss: 0.1770 - val_accuracy: 0.9498\n",
            "Epoch 30/30\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9919\n",
            "Epoch 30: val_loss improved from 0.15719 to 0.11651, saving model to TESS//models/paper_5_loss_2.h5\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.97071\n",
            "140/140 [==============================] - 23s 168ms/step - loss: 0.0447 - accuracy: 0.9919 - val_loss: 0.1165 - val_accuracy: 0.9707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p5.load_weights('TESS//models//paper_5_acc_2.h5')\n",
        "print(p5.evaluate(X_test_spec,Y_test_spec))\n",
        "p5.load_weights('TESS//models//paper_5_loss_2.h5')\n",
        "p5.evaluate(X_test_spec,Y_test_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0IHDYO0xykG",
        "outputId": "21eebafc-0501-40cd-a3c1-2bd6c5114a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 94ms/step - loss: 0.1792 - accuracy: 0.9623\n",
            "[0.17915083467960358, 0.9623430967330933]\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 0.2109 - accuracy: 0.9582\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21094420552253723, 0.9581589698791504]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "#p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "00v0jgjc6xEr",
        "outputId": "7648ad8b-ca82-49fb-bdae-af6b69ae2c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.9578580486321738\n",
            "Kappa: 0.9441458284645945\n",
            "Accuracy: 0.9581589958158996\n",
            "Jaccard Score: 0.9193410122669757\n",
            "Precision: 0.9590839905182988\n",
            "Recall: 0.9577288735952785\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98        62\n",
            "           1       0.93      0.98      0.96        56\n",
            "           2       0.98      0.91      0.95        57\n",
            "           3       0.94      0.97      0.95        64\n",
            "\n",
            "    accuracy                           0.96       239\n",
            "   macro avg       0.96      0.96      0.96       239\n",
            "weighted avg       0.96      0.96      0.96       239\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD4CAYAAABPLjVeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwUVbbA8d9JCIIKOOwkQUBAUVQQ2RQREWWTgAvihoobijoCijxGcR3xOS5PcRlHQARRR1FcWAXZDIsIYQ1h38nGHkARSTrn/dFN6EBIKtBd3WnPdz71savqVuXUnebk5tatW6KqGGOMcUdUqAMwxpi/Eku6xhjjIku6xhjjIku6xhjjIku6xhjjolLB/gHZGatteIRP5fpdQh1C2Pj9yOFQh2DCUM6RNDndc2Tv3uQ458RUPu+0f15xWUvXGGNcFPSWrjHGuCrXE+oICmVJ1xgTWTw5oY6gUJZ0jTERRTU31CEUypKuMSay5FrSNcYY91hL1xhjXGQ30owxxkXW0jXGGPeojV4wxhgX2Y00Y4xxkXUvGGOMi+xGmjHGuMhausYY4yK7kWaMMS4K8xtpjqZ2FJG/i8jfgh2MMcacLlWP4yUUnM6nWw1YJCJjRaSjiLg+8a8xxjiiuc6XEHCUdFV1MFAf+BjoBawXkVdFpG4QYzPGmOLLzXW+hIDjN0eoqgKZviUH+BvwjYi8HqTYjDGm+MK8pevoRpqI9AXuAXYDI4CnVTVbRKKA9cDA4IVojDHF4MkOdQSFcjp64W/Azaq61X+jquaKiL1t0RgTPkr66AURiQZuPz7hHqWqqwMelTHGnKow714oMumqd1zFWhE514V4im3ur0vocvejdLrzEUZ8Pu6E/emZO3ngyee46f6+9Or7LJk7dwOwcGkytzzQL29pcv2tzJizwO3wT1u7664maclPLF0+k/5PPnzC/tKlS/PJ6HdZunwmM2aN49xz4wBocvmlzJk/gTnzJzD3l4l0SWifd0yFCuX49LP3WbRkGgsXT6VZ88tcux63dGh/DSkrE1mzai4Dn34s1OGEVMTVRZjfSBPv/bEiCokkApcBC4Hfj25X1a5FHZudsdrxO+iLy+PxcMPdjzL8zZeoXqUStz3yNG889xR1a9fMK/PkC6/T5oqmdOt4Lb8uWcF3U2bw2rP9851n/4GDdLqrDzO+/piyZc4IVrhUrh/YnpioqCiWLJvOjV3vJS0tk1mJ3/HAff1Yu2ZDXpkHH7qLhhc3oH/f57ilexe6JLTnvnufoGzZMhw5ko3H46FatSrMWzCJC+pdgcfj4cOP3uCX+Yv4dPRYYmJiOPPMMuzffzCgsf9+5HBAz1ccUVFRrE6ZQ8fOd5CamsGCXybT8+5HWb16fchiCpVwq4ucI2mnPRz18JwxjnNOmdZ3uz781enoheeALsDLwFt+S0glr1nPuXE1qBlbnZiYGDpdexUz5/2ar8zGrdtp3uQSAJpfdgmz5i084TzTfp5P6xZNgppwg+Hypo3YtGkrW7ZsJzs7m2+/mcgNN1yXr0znG67ji8+/BeD776bQ5porAPjjj8N4PN7B4WXKnMHRX77ly59Nq1bN+HT0WACys7MDnnBDrXmzy9i4cQubN28jOzubsWN/oGtCh1CHFRKRWBfqyXa8hILTcbo/F7QEO7ii7Ny1l+pVKuetV6tSiZ279uYrc0Hd2kxP9HYbTJ+zgN8P/UHW/gP5ykyZOZdO17YOfsABFhtbjbTUjLz1tLRMasRWy1emRmz1vDIej4cD+w9SsZL34cLLmzZiwaIpzP91Mv37PofH46FWrZrs3r2Xf//ndebMG89777/KmWeWde+iXBAbV53tqel566lpGcTGVg9hRKETkXVR0vt0AUTkoIgcOG7ZLiLfich5wQ7ydAzocx9Jy1Po/mB/kpanUK1yJaKijl32rj17Wb9pK60isN+yKIuTltOyWSfatrmJJ596hDPOKE2pUqVo1LghH4/4nNatuvL7oT/o/9QjoQ7VGOfCvE/XaffCO8DTQBwQDwwAvgC+BEYeX1hEeotIkogkjfhsbKBiPUHVKhXJ3LU7b33Hrj1UrVIxf5nKFRn6z0F8M+Jt+j5wFwDly52dt//HWfNo17oFMaVK3tw/6ek7iIuvkbceF1edjPQd+cpkpGfmlYmOjqZ8hXLs3bMvX5l1azfy+++HuOiiC0hLyyAtLZPFScsB+OH7KTRq1DDIV+Ku9LRMasbH5q3Hx9UgPT0zhBGFTkTWRSS0dIGuqvqRqh5U1QOqOgzooKpf4R3Dm4+qDlPVpqra9MGePQIasL+LL6jPttQMUjN2kJ2dzZSZc2l7ZfN8ZfZlHSDX9xtt+BfjuKlzu3z7p8yYQ+d2VwctxmBasngFdevWplateGJiYri5excmT56Rr8zkyTO4866bAbjxpk4k/vwLALVqxRMdHQ1AzZqx1D//PLZuS2Xnzt2kpWVQr34dANpcc2W+G3ORYFHSMurVq0Pt2jWJiYmhR49uTJg4LdRhhURE1kWYt3SdNu8OiUgP4Bvfenfg6O3noI1OKEqpUtE80/chHn76JTy5Hm7qdB316pzL+yO/oOEF9WjbqjmLlq3kneFjEBEuv/QiBvc7NqwqLWMHmbt207SEtuQ8Hg8DnnqJb78fRXR0FJ+N+YY1q9fzzOB+LF2SzJTJMxgzeizDRrzF0uUz2bcvi/t79QWg5RVN6f/Uw2Rn56C5uTzV/4W8FvDAp15ixMdvE1M6hi2bt/NYn8h64NDj8dC332AmT/qC6KgoRo3+ilWr1oU6rJCIyLoI80nMnQ4ZOw8YClyBN8kuAPoDacDlqjr3ZMcGc8hYSRPoIWMlWSiHjJnwFYghY39Mesdxzil7Qz/Xh4w5aumq6iYg4SS7T5pwjTHGdWHe0nU64U0V4CGgtv8xqnp/cMIyxphTFOZzLzjt0/0BmANMB8L7VZvGmL+2SGjpAmeq6v8ENRJjjAmEMG/pOh0yNlFEOgc1EmOMCYQwH6frtKXbF3hGRP4EsgHB+zKJ8kGLzBhjTkVOBLyCXVXLiUhFvO9JKxPckIwx5jQ4GAbrlIh0xDtcNhoYoaqvHbf/XGA0cI6vzCBVnVzYOZ2OXngQb2s3HlgGtATmA+0KO84YY1wXoD5d3wscPgCuB1LxvhF9vKqu8is2GBirqh+KyEXAZLyjvE7KaZ9uX6AZsFVV2+KdW3d/8S7BGGNcELjHgJsDG1R1k6oewTvXTLfjyihwtJu1ApBOEZz26R5W1cMigoicoaprROQCh8caY4x7inGDTER6A739Ng3zzS0D3gm+tvvtSwVaHHeKF4FpIvJ34CzgOorgNOmmisg5wPfATyKyDyjwnWnGGBNSHuePEvgS7LAiC57cHcAoVX1LRK4AxojIxaonz/xOb6Td5Pv4oojMwtuM/vE0AjXGmOAI3DjdNKCm33q8b5u/B4COAKr6i4iUASoDO0920mJPIhsOb4wwxpiTClzSXQTUF5E6eJPt7cCdx5XZhndAwSgRuRDv6K5dhZ205M3cbYwxhQnQQw+qmiMijwNT8Q4HG6mqKSLyMpCkquOBp4DhItIf7021XlrE1I2WdI0xEUVzAzdO1zfmdvJx2573+7wKaFWcc1rSNcZEljCfe8GSrjEmshRj9EIoWNI1xkQWa+kaY4yLLOkaY4yLAjjhTTBY0jXGRBZr6RpjjIsCOGQsGIKedMvV6RDsH1FiHEydHeoQwkbZ2NahDsFEKhu9YIwx7lHrXjDGGBf91bsXjDHGVRHyCnZjjCkZrKVrjDEuyrEbacYY4x7rXjDGGBdZ94IxxrjHhowZY4ybrKVrjDEusqRrjDEusseAjTHGPYF8R1owWNI1xkQWS7rGGOOiMB+9EOWkkIj8XUT+FuxgjDHmtOWq8yUEHCVdoBqwSETGikhHEZFgBmWMMacsEpKuqg4G6gMfA72A9SLyqojUDWJsxhhTbOrJdbyEgtOWLqqqQKZvyQH+BnwjIq8HKTZjjCm+MG/pOrqRJiJ9gXuA3cAI4GlVzRaRKGA9MDB4IRpjjHORMmSsInCzqm7136iquSLSJfBhGWPMKYqEpKuqL4hIExHpBigwT1WX+PatDmaAxhhTLOE9YszxkLHngNFAJaAy8ImIDA5mYMYYcyo0J9fxEgpOuxd6Ao1U9TCAiLwGLANeCVZgxhhzSiKhpQukA2X81s8A0gIfjjPXX9+GFStmkZKSyIABj56wv3Tp0owZ8wEpKYkkJv5ArVrxAFSseA5Tp37J7t2refvtl/MdExMTwwcfvEZy8myWL5/JjTd2cuVaAmnugiS63P4gnXrcz4gxY0/Yn565gweeGMRN9/Sh1+MDydy5K2/fWx98TLe7Hibhzt68+vaHeAerRK4O7a8hZWUia1bNZeDTj4U6nJCKtLrQXHW8hILTpLsfSBGRUSLyCbASyBKRd0Xk3eCFd6KoqCiGDn2Fbt3upXHjdvTo0ZUGDernK9Or121kZe2nYcOree+9Ebzyyj8AOHz4T1566S0GDRpywnkHDfo7u3bt5pJLrqFx43bMmbPAlesJFI/HwytvfcCHb/2T8Z9/xOTps9m4Od99T958fwRdO7bju08/pM99d/LOf0YBsDR5FUuTV/Htp//m+zEfkrJ6HYuWJofgKtwRFRXFu0OH0CWhJ5c0asttt93IhRfWL/rACBSRdZFbjCUEnCbd74BngFnAbOBZ4AdgsW9xTbNmjdm4cQubN28jOzubr7+eQEJC+3xlEhLa89ln3wDw7beTadu2FQCHDv3B/PmL+PPPwyec9957e/D66x8AoKrs2bMvyFcSWMmr13FufCw142oQExNDp3ZtmHncL46Nm7fR/PLGADRv0ohZc34BQEQ4cuQI2Tk5HMnOJjvHQ6WK57h+DW5p3uyyfN+hsWN/oGtCh1CHFRKRWBcR0dJV1dHAf4GlwBLgv6o6+ugSzACPFxtbndTU9Lz1tLQMYmOrnbSMx+PhwIGDVKp08qkjKlQoD8ALLwzgl18m8fnnH1K1auUgRB88O3ftpnrVKnnr1apWZueuPfnKXFD/PKb/PA+A6T/P5/dDf5C1/wCNL76QZk0upW3Xu2jb9S5atWhC3drnuhq/m2LjqrPd7zuUmpZBbGz1EEYUOhFZF5HQ0hWRzsBG4F3gfWCDiJy001NEeotIkogkeTy/BSbSICpVKpr4+FgWLFjMFVfcwK+/Lua11yJvcMaAxx4kaWky3Xs9RtKyZKpVqURUVBTbUtPZtGU7M74bw8zvP2Ph4uUsXrYy1OEac0o0x/lSFN9cM2tFZIOIDDpJmR4iskpEUkTki6LO6XT0wv8BbVV1g++H1AUmAVMKKqyqw4BhAGXKnBvQNnx6eibx8bF563FxNUhP31FgmbS0TKKjoylfvlyh3QV79uzj998P8f333sv59ttJ9Op1eyDDDrqqVSrnuzG2Y+duqlapdFyZSgz93+cAb1fL9NlzKV/ubL4Z/yONGjbgzDPLAnBVy6YsT1nN5Y0vdu8CXJSelklNv+9QfFwN0tMzQxhR6ERiXQTqDewiEg18AFwPpOKd9Gu8qq7yK1Mf+AfQSlX3iUjVos7rtE/34NGE67MJOOg4+gBKSlpOvXp1qF27JjExMdx6awITJ/6Ur8zEiT/Rs2d3AG6+uTOzZ88v8ryTJk2nTZsrAGjbthWrV68PfPBBdHGD89mWmk5qeibZ2dlMmfEzba9qma/Mvqz95PrmGh0+5ituusHbF16jWhWSliWTk+MhOyeHpGXJnFerpuvX4JZFScvyfYd69OjGhInTQh1WSERkXQSue6E5sEFVN6nqEeBLoNtxZR4CPlDVfQCqurOokzpt6SaJyGRgLN4n0m7Fm/Vv9v2gbx2e57R5PB769XuOCRPGEB0dzejRX7F69Tqef/5JFi9OZtKknxg16itGjnyHlJRE9u7N4p57Hs87fu3aeZQrV47SpWNISOhAly49WbNmPYMH/y8jR77DG2+8wO7de+nd+ym3LikgSpWK5pn+fXj4ycF4PB5u6tKeeufV4v3hn9Kwwfm0bd2SRUtX8M5/RiEiXN7oYgY/5R1u177tVSxcspyb7umDCFzVoinXHJewI4nH46Fvv8FMnvQF0VFRjBr9FatWrQt1WCERiXVRnJauiPQGevttGub7Sx0gDtjuty8VaHHcKc73nWceEA28qKo/FvoznYzH9A0TOxlV1ftPtjPQ3Qsl2cHU2aEOIWyUjW0d6hBMGMo5knbac3XvbNfGcc6pOuPnk/48EekOdFTVB33rdwMtVPVxvzITgWygBxAPJAKXqGrWyc7rdO6F+xxdgTHGhJh6AvaOhTTAv58tnhMfCksFflXVbGCziKzDO/f4opOd1OnUjmWAB4CG+D2ZVlgL1xhjQiFQN9LwJs76IlIHb7K9HbjzuDLfA3fgnY+mMt7uhk2FndTpjbQxQHWgA/Az3owfkhtpxhhTGM0Vx0uh51HNAR4HpgKrgbGqmiIiL4tIV1+xqcAeEVmF9+Gxp1V1T8Fn9HLap7tUVS8TkRWqeqmIxABzVLXIuy3Wp3uM9ekeY326piCB6NNNv7Kt45wTO3+W6+97dDp6Idv33ywRuRjvK3uKHI9mjDFuUw3v9+Y6TbrDfK9gHwyMB84GngtaVMYYc4oC2KcbFE6T7hjgFqA23snMwftadmOMCSu5gRu9EBROk+4PeKd3XAz8GbxwjDHm9BR1gyzUnCbdeFXtGNRIjDEmAMI96TodMjZfRC4JaiTGGBMAqs6XUCi0pSsiyXjnWigF3Ccim/B2Lwjex38vDX6IxhjjXLi3dIvqXujiShTGGBMgJXrImKpuLWy/McaEG0+EjF4wxpgSoUS3dI0xpqQp6X26xhhTooRqVIJTlnSNMRHFWrrGGOMiT67Txw9Cw5KuMSaiWPeCMca4KNdGLxhjjHtsyJgxxrjoL9+9kJPrCfaPKDHKxV8T6hDCxm+Lhoc6hLBRp82AUIcQUax7wRhjXGSjF4wxxkVh3rtgSdcYE1mse8EYY1xkoxeMMcZFYf4yYEu6xpjIolhL1xhjXJNj3QvGGOMea+kaY4yLrE/XGGNcZC1dY4xxkbV0jTHGRZ6S3NIVkYMU/FSdAKqq5YMSlTHGnKIwf1tP4UlXVcu5FYgxxgRCbklu6R5PRKoCZY6uq+q2gEdkjDGnIdwnvHE0B5qIdBWR9cBm4GdgCzAliHEZY8wpyS3GEgpOJ578J9ASWKeqdYB2wIKgRWWMMacoV8TxUhQR6Sgia0Vkg4gMKqTcLSKiItK0qHM6TbrZqroHiBKRKFWdBRR5cmOMcZunGEthRCQa+ADoBFwE3CEiFxVQrhzQF/jVSXxOk26WiJwNJAKfi8hQ4HeHxxpjjGtyxflShObABlXdpKpHgC+BbgWU+yfwL+Cwk/icJt1uwCGgP/AjsBFIcHisMca4JhdxvIhIbxFJ8lt6+50qDtjut57q25ZHRJoANVV1ktP4ihy94GtiT1TVtnj7nkc7PbkxxritOKMXVHUYMOxUfo6IRAH/B/QqznFFtnRV1QPkikiFUwnMGGPcFMDuhTSgpt96vG/bUeWAi4HZIrIF72CD8UXdTHPavfAbkCwiH4vIu0cXh8eGVIf215CyMpE1q+Yy8OnHQh1OwF1/fRtWrJhFSkoiAwY8esL+0qVLM2bMB6SkJJKY+AO1asUDULHiOUyd+iW7d6/m7bdfzndMjx5dSUqaxqJFUxk//lMqVfqbK9cSSPOWraZr31fp8vchfPz99BP2p+/ay0Mv/5vuA17ngRffZ8eerLx9fYZ8xFW9/sHjr5Xc18S3bXcVcxZNYv6SH3m834Mn7C9dOob/jHyL+Ut+ZNL0L4k/NzZv34UNz2fCtC+Y/ct4Zs77njPOKE3ZsmUY89WHzFk4kdm/jOeZF/q7eTnFEsAhY4uA+iJSR0RKA7cD44/uVNX9qlpZVWuram28I7q6qmpSYSd1mnS/BZ7DeyNtsW8p9MThICoqineHDqFLQk8uadSW2267kQsvrB/qsAImKiqKoUNfoVu3e2ncuB09enSlQYP819er121kZe2nYcOree+9Ebzyyj8AOHz4T1566S0GDRqSr3x0dDRvvvkiHTrcRrNmHUhOXkOfPr3cuqSA8OTm8urH4/j3M7357u3/4cd5S9mYmpmvzP+NGU/C1U355s2B9O7egaFfTMzb16trW155/C63ww6YqKgoXn1zMHd1f5g2LRK4sXtnzr+gbr4yd9x9C/uzDnBlk44M+/doBr/4FOD9///9Yf/if558iWuu6MotXe4lOzsHgA/f/4TWzbtw/dW30LxFE669rrXr1+aER5wvhVHVHOBxYCqwGhirqiki8rKIdD3V+Jwm3XNUdbT/AoR986d5s8vYuHELmzdvIzs7m7Fjf6BrQodQhxUwzZo1znd9X389gYSE9vnKJCS057PPvgHg228n07ZtKwAOHfqD+fMX8eef+W+4iggiwllnnQlA+fJnk5Gxw4WrCZyVG7ZRs3pl4qtVJqZUKTpeeRmzF63MV2ZjaibNL/b+gmresB6zk47tb3HJ+ZxVtgwl1WWXX8KWTdvYtjWV7Oxsfhg3hQ6dr81XpmPnaxn73+8BmPjDNFq3aQlAm2tbsXrlOlatXAvAvn37yc3N5Y8/DjN/zkIAsrOzSV6xihqx1Vy8KucC+XCEqk5W1fNVta6qDvFte15VxxdQ9pqiWrngPOneW8C2Xg6PDZnYuOpsT03PW09NyyA2tnoIIwqs2NjqpPpdX1paBrHH/UPwL+PxeDhw4GCh3QU5OTk88cSzJCVNY/PmJC68sD6ffPJlcC4gSHbuzaJ6pXPy1qtWqsCOvfvzlbmgVhwzFq4AYMbCZH7/40+yDkbGKMjqNaqRlnasZZ+Rnkn1GlVPKJPuK3P0e1Gx4jnUrVcLRfnvuGFM+/kbHn3i/hPOX75COa7veA1zfg7P56NK9BNpInKHiEwA6ojIeL9lFrC3kOPyhmHk5kbGF/mvolSpUvTufTctW3amTp2mJCevZuDAyOsLf/LuriSt2kiPgW+yeNUGqlasQFSU0zZI5IqOLkXzlk147KGBdOvYk05druOqq1v67Y/mwxFv8vFHn7Fta2oIIz05FedLKBQ1ZGw+kAFUBt7y234QWHGyg/yHYZQqHRey+SfS0zKpGX/sBkF8XA3S0zMLOaJkSU/PJN7v+uLiapCevqPAMmlpmURHR1O+fDn27Nl30nM2auR94GbTpq0AjBs3scAbdOGsasVzyPS7MbZzz36qVaxwXJkKvD3A24o7dPhPpv+6gvJnlXU1zmDJzNhBXNyxv+hqxFYnM2PnCWVi46qTkb4j73uxd28WGemZLJifxN693vqb+VMilzS6iLmJ3lbtG0NfYtOmrQz/cIx7F1RM4T6JeaG/2lV1q6rOVtUrVPVnv2WJr5M5rC1KWka9enWoXbsmMTEx9OjRjQkTp4U6rIBJSlqe7/puvTWBiRN/yldm4sSf6NmzOwA339yZ2bPnF3rO9PQdNGhQn8qVKwLQrl1r1qzZEJwLCJKGdWuyLWMXqTv3kJ2Tw4/zl9KmacN8ZfYd+I3cXO8/z4+/m86NbVuEItSgWLZkJXXq1qJmrThiYmLodksnpk6Zla/M1Cmz6HHHjQB06daeuYneJ1hnz5jHhRedT9myZYiOjqZlq2asW+v9//9/nn2C8uXP5vlB/+vuBRVToB4DDhZHUzseN5l5aSAG+D3cJzH3eDz07TeYyZO+IDoqilGjv2LVqnWhDitgPB4P/fo9x4QJY4iOjmb06K9YvXodzz//JIsXJzNp0k+MGvUVI0e+Q0pKInv3ZnHPPY/nHb927TzKlStH6dIxJCR0oEuXnqxZs54hQ95h+vSvyc7OYdu2NB566MkQXmXxlYqO5h/330KfIR+Rm5vLjW1bUK9mDT74agoN69bkmqYXk7RqA+9+MQlEuPzC83jmge55x/d6/l22pO3k0OEjXP/Ii7z4yO20atwghFdUPB6Ph2eeHsJ/xw0nOjqKLz/7jnVrNvD0M4+zfGkK06bM4r9jxvHeR/9i/pIfydqXxSP3DwBg//4DfPTBaKbMHIuqMuOnRGZMS6RGbDX6Pf0I69duZFriOAA+GfY5X4wZF8pLLVC4T2IuqsX7619EBO9jwS1V9aSz7hwVyu6FcFMqKjrUIYSNrF//E+oQwkadNgNCHULYyMhaddop8+1zezrOOf23feZ6ii72nQP1+h6InLFXxpiIEe6jF5x2L9zstxqFd1pHRzPqGGOMm8L9T2unr+vxn1EsB++bIwqa4swYY0Iq3Pt0HSVdVb0v2IEYY0wghGpUglNO35F2vojMEJGVvvVLRWRwcEMzxpjiy0UdL6Hg9EbacOAfQDaAqq7AO+OOMcaElYi4kQacqaoLJf+L3ML+4QhjzF9PpNxI2y0idfFdj4h0x/t4sDHGhJVwfwzYadJ9DO9cCg1EJA3YDJTcCUeNMRErR8K7res06aYBnwCzgIrAAbzTPb5c2EHGGOO28E65zpPuD0AWsARIL6KsMcaETKR0L8SrasegRmKMMQEQqqFgTjkdMjZfRC4JaiTGGBMAWowlFJy2dK8CeonIZuBPQPDOfXNp0CIzxphTECndC52CGoUxxgSIJ8y7F5zOvbA12IEYY0wgREpL1xhjSgSNhJauMcaUFNbSNcYYF4X7kDFLusaYiBLeKdeSrjEmwuSEedq1pGuMiSh2I82YApzT4pFQhxA2Dm6eGuoQIordSDPGGBdZS9cYY1xkLV1jjHGRR62la4wxrrFxusYY4yLr0zXGGBeFe5+u00nMjTGmRMhFHS9FEZGOIrJWRDaIyKAC9j8pIqtEZIWIzBCRWkWd05KuMSaiaDH+VxgRiQY+wDuf+EXAHSJy0XHFlgJNfS90+AZ4vaj4LOkaYyKKR9XxUoTmwAZV3aSqR4AvgW7+BVR1lqoe8q0uAOKLOqn16RpjIkoARy/EAdv91lOBFoWUfwCYUtRJLekaYyJKcW6kiUhvoLffpmGqOqy4P1NEegJNgTZFlbWka4yJKMUZMuZLsCdLsmlATb/1eN+2fETkOuBZoI2q/lnUz7Ska4yJKAHsXlgE1BeROniT7W+2eoUAAA0WSURBVO3Anf4FROQy4COgo6rudHJSS7rGmIiiAXoMWFVzRORxYCoQDYxU1RQReRlIUtXxwBvA2cDXIgKwTVW7FnZeS7rGmIgSyFewq+pkYPJx2573+3xdcc9pSdcYE1Fs7gVjjHFRoLoXgsWSrjEmolhL1xhjXGSzjBljjItsEnNjjHFRie5eEJFkOPkV+GbWMcaYsBHuSbeoWca6AAnAj77lLt9ywti1cNWh/TWkrExkzaq5DHz6sVCHE3DXX9+GFStmkZKSyIABj56wv3Tp0owZ8wEpKYkkJv5ArVreSZAqVjyHqVO/ZPfu1bz99sv5junRoytJSdNYtGgq48d/SqVKf3PlWk6X1UXB5v66hC53P0qnOx9hxOfjTtifnrmTB558jpvu70uvvs+SuXM3AAuXJnPLA/3ylibX38qMOQvcDr/YVNXxEgqFJl1V3aqqW4HrVXWgqib7lkFAe3dCPHVRUVG8O3QIXRJ6ckmjttx2241ceGH9UIcVMFFRUQwd+grdut1L48bt6NGjKw0a5L++Xr1uIytrPw0bXs17743glVf+AcDhw3/y0ktvMWjQkHzlo6OjefPNF+nQ4TaaNetAcvIa+vTp5dYlnTKri4J5PB5eGfoRH/7recaPfo/JM+ewccv2fGXe/HAUXdu35buRQ+lz7228M3wMAM0vu4RxH7/DuI/fYeTb/6RMmTO4stllobiMYgnkJObB4HQ+XRGRVn4rVxbj2JBp3uwyNm7cwubN28jOzmbs2B/omtAh1GEFTLNmjfNd39dfTyAhIf/vwoSE9nz22TcAfPvtZNq29f7feOjQH8yfv4g//zycr7yIICKcddaZAJQvfzYZGTtcuJrTY3VRsOQ16zk3rgY1Y6sTExNDp2uvYua8X/OV2bh1O82bXAJ4E+2seQtPOM+0n+fTukUTypY5w5W4T0egJjEPFqeJ8wHg3yKyRUS2Av8G7g9eWIERG1ed7anpeeupaRnExlYPYUSBFRtbnVS/60tLyyA2ttpJy3g8Hg4cOFjon8g5OTk88cSzJCVNY/PmJC68sD6ffPJlcC4ggKwuCrZz116qV6mct16tSiV27tqbr8wFdWszPdHbbTB9zgJ+P/QHWfsP5CszZeZcOl3bOvgBB4BHcx0voeAo6arqYlVtBDQCLlXVxqq6JLihmVAoVaoUvXvfTcuWnalTpynJyasZODDy+sKd+KvUxYA+95G0PIXuD/YnaXkK1SpXIirqWGrYtWcv6zdtpVXz8O9agPDv03U8ZExEbgAaAmV8s+mgqi+fpGzexMASXYGoqLNOP9JTkJ6WSc342Lz1+LgapKdnhiSWYEhPzyTe7/ri4mqQnr6jwDJpaZlER0dTvnw59uzZd9JzNmrkfQXUpk1bARg3bmKBN6XCjdVFwapWqUjmrt156zt27aFqlYr5y1SuyNB/et+5eOjQH0z/+RfKlzs7b/+Ps+bRrnULYkqVjBGmJX30AgAi8h/gNuDvgAC3Aid966WqDlPVpqraNFQJF2BR0jLq1atD7do1iYmJoUePbkyYOC1k8QRaUtLyfNd3660JTJz4U74yEyf+RM+e3QG4+ebOzJ49v9BzpqfvoEGD+lSu7P2H2a5da9as2RCcCwggq4uCXXxBfbalZpCasYPs7GymzJxL2yub5yuzL+sAubneP7WHfzGOmzq3y7d/yow5dG53tWsxn65w79N1+qvrSlW9VERWqOpLIvIWDt4FFGoej4e+/QYzedIXREdFMWr0V6xatS7UYQWMx+OhX7/nmDBhDNHR0Ywe/RWrV6/j+eefZPHiZCZN+olRo75i5Mh3SElJZO/eLO655/G849eunUe5cuUoXTqGhIQOdOnSkzVr1jNkyDtMn/412dk5bNuWxkMPPRnCq3TG6qJgpUpF80zfh3j46Zfw5Hq4qdN11KtzLu+P/IKGF9SjbavmLFq2kneGj0FEuPzSixjc7+G849MydpC5azdNGzUM4VUUT26YP5EmTvo1RGShqjYXkQXAzcBeYKWq1ivq2FKl48K7BlxUKio61CGYMHRw89RQhxA2YmpcKKd7jobVWjjOOSk7fj3tn1dcTlu6E0TkHLyzpC/B+5Ta8KBFZYwxpyhUoxKccpp01wAeVR0nIhcBTYDvgxeWMcacmnDvXnA6Tvc5VT0oIlcB1wIjgA+DF5YxxpyacL+R5jTpenz/vQEYrqqTgNLBCckYY05drqrjJRScJt00EfkI77CxySJyRjGONcYY14R7S9dpn24PoCPwpqpmiUgN4OnghWWMMafGo56iC4WQo6SrqoeAb/3WM4CMYAVljDGnyl5MaYwxLgr3x4At6RpjIoq1dI0xxkXhPk7Xkq4xJqLYK9iNMcZFkfIYsDHGlAjWp2uMMS6yPl1jjHGRtXSNMcZFNk7XGGNcZC1dY4xxkY1eMMYYF9mNNGOMcVG4dy/YnLjGmIgSyPl0RaSjiKwVkQ0iMqiA/WeIyFe+/b+KSO2izmlJ1xgTUVTV8VIYEYkGPgA6ARcBd/jeEenvAWCf783obwP/Kio+S7rGmIgSwNf1NAc2qOomVT0CfAl0O65MN2C07/M3QDsRKfS17kHv0805kub6e+ULIiK9VXVYqOMIB1YXx1hdHBMpdVGcnCMivYHefpuG+dVBHLDdb18q0OK4U+SVUdUcEdkPVAJ2n+xn/pVaur2LLvKXYXVxjNXFMX+5ulDVYara1G8J+i+dv1LSNcaY4kgDavqtx/u2FVhGREoBFYA9hZ3Ukq4xxhRsEVBfROqISGngdmD8cWXGA/f6PncHZmoRd+j+SuN0S3xfVQBZXRxjdXGM1YUfXx/t48BUIBoYqaopIvIykKSq44GPgTEisgHYizcxF0rCfSCxMcZEEuteMMYYF1nSNcYYF1nSLaFEpLaIrAx1HJHAV5d3nuKxvwU6nnBi37PAs6RL3lAP89dVGygw6dp3wwRaiUy6IvK9iCwWkRTfEyWIyG8iMkRElovIAhGp5tte17eeLCKvHG2ZiMg1IjJHRMYDq0TkZRHp5/czhohI35BcoHPRIjLcVw/TRKSsiDwkIot89TBORM4EEJFRIvIfEUkSkXUi0sW3vZeI/CAis0VkvYi84Nse9vXha4WtLqAO6orIj77vyBwRaeArP0pEuvsdf7SV+hrQWkSWiUh/X52MF5GZwAwROVtEZojIEt/36PhHQcOeiJwlIpN834uVInKbiDzv+66sFJFhRx9fFZHLfeWWA4+FOPTIU5zJIcJlASr6/lsWWIn3sTsFEnzbXwcG+z5PBO7wfX4E+M33+Rrgd6COb702sMT3OQrYCFQK9bUWUge1gRygsW99LNDTP2bgFeDvvs+jgB9911Yf7yONZYBeQIavDo/WZ9OSUB+F1MEMoL5vWwu8YyeP1kF3v+P9vwsT/bb38tXP0e9ZKaC873NlYAPHRv78Fup6cFhXtwDD/dYrHL0+3/oYv38/K4CrfZ/fAFaGOv5IWkpkSxd4wvdbeAHep0HqA0fwJliAxXj/QQJcAXzt+/zFcedZqKqbAVR1C7BHRC4D2gNLVbXQJ0vCwGZVXeb7fPSaL/a17pKBu4CGfuXHqmquqq4HNgENfNt/UtU9qvoH8C1wVQmqj4Lq4ErgaxFZBnwE1DiF8/6kqnt9nwV4VURWANPxPm9f7bSidl8ycL2I/EtEWqvqfqCtbzrCZOBaoKGInAOco6qJvuPGhCrgSFXi+qtE5BrgOuAKVT0kIrPxttiy1ferGfDg7Np+P259BN5WTnVgZCDiDbI//T578LZURwE3qupyEemFtxV31PGDsrWI7SWhPo6vg2pAlqo2LqBsDr4uNRGJAkoXcl7/78ZdQBXgclXNFpEteL9zJYaqrhORJkBn4BURmYG366Cpqm4XkRcpYddUUpXElm4FvPNXHvL11bUsovwCvH9aQdFPi3wHdASa4X0KpSQqB2SISAzeZOHvVhGJEpG6wHnAWt/260WkooiUBW4E5vm2l8T6OABsFpFbAcSrkW/fFuBy3+euQIzv80G89XYyFYCdvoTbFqgV8KiDTERigUOq+hneLoMmvl27ReRsvI+woqpZQJaIXOXbf/x3yJymEtfSxdsv+YiIrMabNBYUUb4f8JmIPOs7dv/JCqrqERGZhbel5AlUwC57DvgV2OX7r38y2QYsBMoDj6jqYd+9k4XAOLwTenymqklQouvjLuBDERmMN7F+CSwHhgM/+LqmfuRYa3YF4PFtHwXsO+58nwMTfH+GJwFrgn4FgXcJ8IaI5ALZQB+8v2BXApl45xk46j5gpIgoMM3tQCNdxD8G7Lt7/4eqqojcjvemWoF3n31/ci4BbvX1e0YMERmF92bRN8dt74X3T8zHCzgmYuvDmFApid0LxXU5sMx3E+RR4KmCCon3NRwbgBmWYKw+jAmWiG/pGmNMOPkrtHSNMSZsWNI1xhgXWdI1xhgXWdI1xhgXWdI1xhgX/T8/R3QV8GuNvgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 3"
      ],
      "metadata": {
        "id": "WICDsY5X68cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "p5.load_weights('TESS//models//paper_5_acc_2.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "e8M5UezU62TR",
        "outputId": "2866c0b5-26da-465e-b273-f052ba1d321d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.9618742310321258\n",
            "Kappa: 0.949688917995977\n",
            "Accuracy: 0.9623430962343096\n",
            "Jaccard Score: 0.9267593793563745\n",
            "Precision: 0.9646009392728015\n",
            "Recall: 0.9606450602312232\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98        62\n",
            "           1       0.98      0.95      0.96        56\n",
            "           2       0.98      0.91      0.95        57\n",
            "           3       0.93      1.00      0.96        64\n",
            "\n",
            "    accuracy                           0.96       239\n",
            "   macro avg       0.96      0.96      0.96       239\n",
            "weighted avg       0.96      0.96      0.96       239\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3TYn_N1Ce2N"
      },
      "source": [
        "# Paper 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5qbqjJP6wOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31abc079-22bb-4f40-d835-62035bb62414"
      },
      "source": [
        "max_x = 96\n",
        "max_y = 299\n",
        "T = 64\n",
        "print(max_y,T,(int(max_y/T)+1)*T,int(max_y/T)+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "299 64 320 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDUSQ90Unoka",
        "outputId": "fe53a794-99f9-42aa-eca8-b25b960eeeb2"
      },
      "source": [
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  #l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "def extract_mel_spectrogram(df,max_x = max_x,max_y = (int(max_y/T)+1)*T):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path']\n",
        " \n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      #print(y.shape)\n",
        "      # Computing the mel spectrograms\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = max_x)\n",
        "      \n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        " \n",
        "            \n",
        "      \n",
        "      if spect.shape[1] != max_y:\n",
        "                #print('Sizes arent same')\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        "      s=[]\n",
        "      for i in range(int(max_y/T)):\n",
        "        #print(spect[:,i*64:(i+1)*64].shape)\n",
        "        q=spect[:,i*T:(i+1)*T]\n",
        "        delta = librosa.feature.delta(q).reshape((max_x,T,1))\n",
        "        d_delta = librosa.feature.delta(q,order = 2).reshape((max_x,T,1))\n",
        "        #print(q.shape,delta.shape,d_delta.shape)\n",
        "        q = q.reshape((max_x,T,1))\n",
        "\n",
        "        z = np.concatenate((q,delta,d_delta),axis = -1)\n",
        "        #print(z.shape)\n",
        "        s.append(z)\n",
        "      mel_specs.append(np.asarray(s))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  #print(len(mel_specs),mel_specs[0].shape)\n",
        "  mel_specs = np.asarray(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        " \n",
        "train_path = \"TESS//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "#X_train_spec = np.expand_dims(X_train_spec,axis=-1)\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        " \n",
        " \n",
        "test_path = \"TESS//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "#X_test_spec = np.expand_dims(X_test_spec,axis=-1)\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        " \n",
        "val_path = \"TESS//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "#X_val_spec = np.expand_dims(X_val_spec,axis=-1)\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1114, 5, 96, 64, 3) (1114, 4)\n",
            "(239, 5, 96, 64, 3) (239, 4)\n",
            "(239, 5, 96, 64, 3) (239, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1IXWkUmCu92",
        "outputId": "8f6c0763-dddb-434e-8b63-6001cc846e02"
      },
      "source": [
        "import keras\n",
        "\n",
        "def VGG_net():\n",
        "  input = Input((96,64,3))\n",
        "  t = Conv2D(64, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(input)\n",
        "  t = Conv2D(64, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = MaxPooling2D(2)(t)\n",
        "\n",
        "  t = Conv2D(128, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(128, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = MaxPooling2D(2)(t)\n",
        "\n",
        "  t = Conv2D(256, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(256, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(256, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(256, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = MaxPooling2D(2)(t)\n",
        "\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = MaxPooling2D(2)(t)\n",
        "\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = Conv2D(512, (3,3),padding = 'same', kernel_initializer = 'he_normal', activation = 'relu')(t)\n",
        "  t = MaxPooling2D(2)(t)\n",
        "\n",
        "  t = Flatten()(t)\n",
        "\n",
        "  t = Dense(4096, activation = 'relu')(t)\n",
        "  t = Dense(4096, activation = 'relu')(t)\n",
        "  t = Dense(128, activation = 'relu')(t)\n",
        "\n",
        "  t = Reshape((1,128))(t)\n",
        "\n",
        "  return Model(inputs = input, outputs = t)\n",
        "\n",
        "\n",
        "#change shape\n",
        "def paper_6():\n",
        "  ip = Input((5, 96,64,3))\n",
        "  vgg = VGG_net()\n",
        "\n",
        "  for i in range(ip.shape[1]):\n",
        "    op_layer = vgg(ip[:,i,:,:,:])\n",
        "    if i==0:\n",
        "      op_layers = op_layer\n",
        "    else:\n",
        "      op_layers = Concatenate(axis = 1)([op_layers,op_layer])\n",
        "\n",
        "  lstmb = Bidirectional(LSTM(256,return_sequences=True), merge_mode = 'sum')\n",
        "  t = lstmb(op_layers)  \n",
        "  lstmb2 = Bidirectional(LSTM(256,return_sequences=True), merge_mode = None)\n",
        "  t2 = lstmb2(t)  \n",
        "\n",
        "  h1 = t2[0]\n",
        "  h2 = t2[1]\n",
        "  print(h1.shape, h2.shape)\n",
        "  h1 = Softmax(axis = -1)(h1)\n",
        "  h2 = Softmax(axis =-1)(h2)\n",
        "  \n",
        "\n",
        "  sum1 = tf.keras.backend.sum(axis =1,x = h1)\n",
        "  sum2 = tf.keras.backend.sum(axis =1,x= h2)\n",
        "  sum = Concatenate()([sum1,sum2])\n",
        "  print(sum.shape)\n",
        "\n",
        "  mean1 = sum1/256.\n",
        "  mean2 = sum2/256.\n",
        "  mean = Concatenate()([mean1, mean2])\n",
        "\n",
        "  std1 = tf.keras.backend.std(axis =1, x= h1)\n",
        "  std2 =tf.keras.backend.std(axis =1, x =h2)\n",
        "  std = Concatenate()([std1, std2])\n",
        "\n",
        "  min1 = tf.keras.backend.min(axis =1,x=h1)\n",
        "  min2 = tf.keras.backend.min(axis =1, x=h2)\n",
        "  min = Concatenate()([min1, min2])\n",
        "\n",
        "  max1 = tf.keras.backend.max(axis =1, x=h1)\n",
        "  max2 = tf.keras.backend.max(axis=1, x =h2)\n",
        "  max = Concatenate()([max1,max2])\n",
        "\n",
        "  attention = Concatenate()([sum, mean, std, min, max])\n",
        "  print(attention.shape)\n",
        "\n",
        "  fc1 = Dense(512, activation = 'relu')(attention)\n",
        "  fc2 = Dense(4, activation = 'softmax')(fc1)  \n",
        "\n",
        "\n",
        "  return Model(inputs=ip,outputs=fc2)\n",
        "\n",
        "p6 = paper_6()\n",
        "p6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 5, 256) (None, 5, 256)\n",
            "(None, 512)\n",
            "(None, 2560)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 5, 96, 64, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_5 (Sli (None, 96, 64, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_6 (Sli (None, 96, 64, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Functional)            (None, 1, 128)       49917120    tf.__operators__.getitem_5[0][0] \n",
            "                                                                 tf.__operators__.getitem_6[0][0] \n",
            "                                                                 tf.__operators__.getitem_7[0][0] \n",
            "                                                                 tf.__operators__.getitem_8[0][0] \n",
            "                                                                 tf.__operators__.getitem_9[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_7 (Sli (None, 96, 64, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 2, 128)       0           model_2[0][0]                    \n",
            "                                                                 model_2[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_8 (Sli (None, 96, 64, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 3, 128)       0           concatenate_10[0][0]             \n",
            "                                                                 model_2[2][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_9 (Sli (None, 96, 64, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 4, 128)       0           concatenate_11[0][0]             \n",
            "                                                                 model_2[3][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 5, 128)       0           concatenate_12[0][0]             \n",
            "                                                                 model_2[4][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 5, 256)       788480      concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) [(None, 5, 256), (No 1050624     bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "softmax_2 (Softmax)             (None, 5, 256)       0           bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "softmax_3 (Softmax)             (None, 5, 256)       0           bidirectional_3[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_sum_2 (TFOpLambd (None, 256)          0           softmax_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_sum_3 (TFOpLambd (None, 256)          0           softmax_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.truediv_2 (TFOpLambda)  (None, 256)          0           tf.math.reduce_sum_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.truediv_3 (TFOpLambda)  (None, 256)          0           tf.math.reduce_sum_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_std_2 (TFOpLambd (None, 256)          0           softmax_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_std_3 (TFOpLambd (None, 256)          0           softmax_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_min_2 (TFOpLambd (None, 256)          0           softmax_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_min_3 (TFOpLambd (None, 256)          0           softmax_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_2 (TFOpLambd (None, 256)          0           softmax_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_3 (TFOpLambd (None, 256)          0           softmax_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 512)          0           tf.math.reduce_sum_2[0][0]       \n",
            "                                                                 tf.math.reduce_sum_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 512)          0           tf.math.truediv_2[0][0]          \n",
            "                                                                 tf.math.truediv_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 512)          0           tf.math.reduce_std_2[0][0]       \n",
            "                                                                 tf.math.reduce_std_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 512)          0           tf.math.reduce_min_2[0][0]       \n",
            "                                                                 tf.math.reduce_min_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 512)          0           tf.math.reduce_max_2[0][0]       \n",
            "                                                                 tf.math.reduce_max_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 2560)         0           concatenate_14[0][0]             \n",
            "                                                                 concatenate_15[0][0]             \n",
            "                                                                 concatenate_16[0][0]             \n",
            "                                                                 concatenate_17[0][0]             \n",
            "                                                                 concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 512)          1311232     concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 4)            2052        dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 53,069,508\n",
            "Trainable params: 53,069,508\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kro7ZckuM38w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66851edd-1988-463f-bfe1-1d0130efcc6e"
      },
      "source": [
        "p6.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//paper_6_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//paper_6_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "history = p6.fit(X_train_spec,Y_train_spec, batch_size=8,validation_data=(X_val_spec, Y_val_spec),\n",
        "                        epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "140/140 [==============================] - 37s 217ms/step - loss: 1.3935 - accuracy: 0.2234 - val_loss: 1.3940 - val_accuracy: 0.2050\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.39399, saving model to TESS//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.20502, saving model to TESS//models/paper_6_acc.h5\n",
            "Epoch 2/30\n",
            "140/140 [==============================] - 29s 208ms/step - loss: 1.3861 - accuracy: 0.2624 - val_loss: 1.3907 - val_accuracy: 0.2385\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.39399 to 1.39074, saving model to TESS//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.20502 to 0.23849, saving model to TESS//models/paper_6_acc.h5\n",
            "Epoch 3/30\n",
            "140/140 [==============================] - 29s 210ms/step - loss: 1.3872 - accuracy: 0.2550 - val_loss: 1.3963 - val_accuracy: 0.2050\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.39074\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.23849\n",
            "Epoch 4/30\n",
            "140/140 [==============================] - 30s 212ms/step - loss: 1.3891 - accuracy: 0.2368 - val_loss: 1.3959 - val_accuracy: 0.2050\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.39074\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.23849\n",
            "Epoch 5/30\n",
            "140/140 [==============================] - 30s 214ms/step - loss: 1.3868 - accuracy: 0.2501 - val_loss: 1.3943 - val_accuracy: 0.2050\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.39074\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.23849\n",
            "Epoch 6/30\n",
            "140/140 [==============================] - 30s 215ms/step - loss: 1.3810 - accuracy: 0.3034 - val_loss: 1.3904 - val_accuracy: 0.2050\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.39074 to 1.39035, saving model to TESS//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.23849\n",
            "Epoch 7/30\n",
            "140/140 [==============================] - 30s 216ms/step - loss: 1.3861 - accuracy: 0.2597 - val_loss: 1.3915 - val_accuracy: 0.2050\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.39035\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.23849\n",
            "Epoch 8/30\n",
            "140/140 [==============================] - 30s 217ms/step - loss: 1.3839 - accuracy: 0.2915 - val_loss: 1.3910 - val_accuracy: 0.2050\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.39035\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.23849\n",
            "Epoch 9/30\n",
            "140/140 [==============================] - 30s 217ms/step - loss: 1.3855 - accuracy: 0.2765 - val_loss: 1.3919 - val_accuracy: 0.2050\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.39035\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.23849\n",
            "Epoch 10/30\n",
            "140/140 [==============================] - 30s 217ms/step - loss: 1.3855 - accuracy: 0.2554 - val_loss: 1.3925 - val_accuracy: 0.2050\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.39035\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.23849\n",
            "Epoch 11/30\n",
            "140/140 [==============================] - 30s 218ms/step - loss: 1.3844 - accuracy: 0.2723 - val_loss: 1.3921 - val_accuracy: 0.2050\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.39035\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.23849\n",
            "Epoch 12/30\n",
            "140/140 [==============================] - 30s 218ms/step - loss: 1.3856 - accuracy: 0.2618 - val_loss: 1.3897 - val_accuracy: 0.2385\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.39035 to 1.38967, saving model to TESS//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.23849\n",
            "Epoch 13/30\n",
            "140/140 [==============================] - 30s 217ms/step - loss: 1.3789 - accuracy: 0.2815 - val_loss: 1.3984 - val_accuracy: 0.2050\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.38967\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.23849\n",
            "Epoch 14/30\n",
            "140/140 [==============================] - 30s 218ms/step - loss: 1.3905 - accuracy: 0.2579 - val_loss: 1.2784 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.38967 to 1.27837, saving model to TESS//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.23849 to 0.42678, saving model to TESS//models/paper_6_acc.h5\n",
            "Epoch 15/30\n",
            "140/140 [==============================] - 30s 217ms/step - loss: 1.2316 - accuracy: 0.4573 - val_loss: 1.1343 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.27837 to 1.13427, saving model to TESS//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.42678\n",
            "Epoch 16/30\n",
            "140/140 [==============================] - 30s 217ms/step - loss: 1.1511 - accuracy: 0.4623 - val_loss: 1.1317 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.13427 to 1.13169, saving model to TESS//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.42678\n",
            "Epoch 17/30\n",
            "140/140 [==============================] - 30s 217ms/step - loss: 1.1491 - accuracy: 0.4217 - val_loss: 1.1346 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.13169\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.42678\n",
            "Epoch 18/30\n",
            "140/140 [==============================] - 30s 218ms/step - loss: 1.1033 - accuracy: 0.4817 - val_loss: 1.1256 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.13169 to 1.12557, saving model to TESS//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.42678\n",
            "Epoch 19/30\n",
            "140/140 [==============================] - 31s 218ms/step - loss: 1.1102 - accuracy: 0.4536 - val_loss: 1.1125 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.12557 to 1.11255, saving model to TESS//models/paper_6_loss.h5\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.42678\n",
            "Epoch 20/30\n",
            "140/140 [==============================] - 30s 217ms/step - loss: 1.1088 - accuracy: 0.4788 - val_loss: 1.1325 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.11255\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.42678\n",
            "Epoch 21/30\n",
            "140/140 [==============================] - 30s 217ms/step - loss: 1.0936 - accuracy: 0.4785 - val_loss: 1.1192 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.11255\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.42678\n",
            "Epoch 22/30\n",
            "140/140 [==============================] - 31s 218ms/step - loss: 1.1073 - accuracy: 0.4523 - val_loss: 1.1225 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.11255\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.42678\n",
            "Epoch 23/30\n",
            "140/140 [==============================] - 31s 219ms/step - loss: 1.1301 - accuracy: 0.4539 - val_loss: 1.1178 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.11255\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.42678\n",
            "Epoch 24/30\n",
            "140/140 [==============================] - 31s 219ms/step - loss: 1.1264 - accuracy: 0.4659 - val_loss: 1.1270 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.11255\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.42678\n",
            "Epoch 25/30\n",
            "140/140 [==============================] - 31s 219ms/step - loss: 1.1286 - accuracy: 0.4496 - val_loss: 1.1475 - val_accuracy: 0.4435\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.11255\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.42678 to 0.44351, saving model to TESS//models/paper_6_acc.h5\n",
            "Epoch 26/30\n",
            "140/140 [==============================] - 30s 217ms/step - loss: 1.0902 - accuracy: 0.4696 - val_loss: 1.1233 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.11255\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.44351\n",
            "Epoch 27/30\n",
            "140/140 [==============================] - 30s 217ms/step - loss: 1.1388 - accuracy: 0.4729 - val_loss: 1.1431 - val_accuracy: 0.4435\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.11255\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.44351\n",
            "Epoch 28/30\n",
            "140/140 [==============================] - 30s 218ms/step - loss: 1.1430 - accuracy: 0.4479 - val_loss: 1.1211 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.11255\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.44351\n",
            "Epoch 29/30\n",
            "140/140 [==============================] - 30s 218ms/step - loss: 1.1115 - accuracy: 0.4726 - val_loss: 1.1173 - val_accuracy: 0.4268\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.11255\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.44351\n",
            "Epoch 30/30\n",
            "140/140 [==============================] - 31s 219ms/step - loss: 1.1051 - accuracy: 0.4627 - val_loss: 1.1281 - val_accuracy: 0.4435\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.11255\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.44351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoGhi4J7rl_S",
        "outputId": "71a01073-a1da-422c-a072-3ad4c40f912c"
      },
      "source": [
        "p6.load_weights('TESS//models//paper_6_acc.h5')\n",
        "print(p6.evaluate(X_test_spec,Y_test_spec))\n",
        "p6.load_weights('TESS//models//paper_6_loss.h5')\n",
        "p6.evaluate(X_test_spec,Y_test_spec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 1s 112ms/step - loss: 1.0972 - accuracy: 0.4812\n",
            "[1.0971777439117432, 0.48117154836654663]\n",
            "8/8 [==============================] - 1s 113ms/step - loss: 1.0748 - accuracy: 0.4686\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0748317241668701, 0.4686192572116852]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jan 2022"
      ],
      "metadata": {
        "id": "rnUUEFd1MSOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensembled"
      ],
      "metadata": {
        "id": "5jYowj2zJvs0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDszokaj2C7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d62e401-5943-4911-fb6c-6f6867600a95"
      },
      "source": [
        "time = 4\n",
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*time), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "  #out = Conv1D(4,1,activation='softmax')(out)\n",
        "  #out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (26))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  #out2 = Dense(4)(layer2)\n",
        "  #out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out,layer3])\n",
        "  output_layer = Flatten()(output_layer)\n",
        "  output_layer = Dense(4,activation='softmax')(output_layer)\n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled = Wavenet()\n",
        "ensembled.summary()\n",
        "\n",
        "ensembled.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 64000, 8)     48          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 64000, 8)     0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 64000, 8)     328         ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 64000, 8)     0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d (AveragePool  (None, 32000, 8)    0           ['leaky_re_lu_1[0][0]']          \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 32000, 16)    656         ['average_pooling1d[0][0]']      \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 32000, 16)    0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 32000, 16)    1296        ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 32000, 16)    0           ['conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d_1 (AveragePo  (None, 16000, 16)   0           ['leaky_re_lu_3[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 16000, 16)    1296        ['average_pooling1d_1[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 16000, 16)    0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 16000, 16)    1296        ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 16000, 16)    0           ['conv1d_5[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d_2 (AveragePo  (None, 8000, 16)    0           ['leaky_re_lu_5[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 8000, 32)     544         ['average_pooling1d_2[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 8000, 64)     4160        ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 8000, 64)     4160        ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 8000, 64)     0           ['conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 8000, 64)     0           ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 8000, 64)     0           ['activation[0][0]',             \n",
            "                                                                  'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 8000, 32)     2080        ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 8000, 32)     0           ['conv1d_6[0][0]',               \n",
            "                                                                  'conv1d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 8000, 32)     1056        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 8000, 64)     0           ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 8000, 64)     0           ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 8000, 64)     0           ['activation_2[0][0]',           \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 8000, 32)     2080        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 8000, 32)     0           ['conv1d_10[0][0]',              \n",
            "                                                                  'conv1d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 8000, 32)     1056        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 8000, 64)     0           ['conv1d_15[0][0]']              \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 8000, 64)     0           ['conv1d_16[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 8000, 64)     0           ['activation_4[0][0]',           \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 8000, 32)     2080        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 8000, 32)     0           ['conv1d_9[0][0]',               \n",
            "                                                                  'conv1d_13[0][0]',              \n",
            "                                                                  'conv1d_17[0][0]']              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 8000, 32)     0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling1d_3 (AveragePo  (None, 1, 32)       0           ['activation_6[0][0]']           \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 32, 1)        0           ['average_pooling1d_3[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 32)        0           ['conv1d_19[0][0]']              \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 32, 1)        0           ['conv1d_18[0][0]']              \n",
            "                                                                                                  \n",
            " permute_1 (Permute)            (None, 32, 1)        0           ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 32, 32)       0           ['reshape[0][0]',                \n",
            "                                                                  'permute_1[0][0]']              \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 32, 32)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " softmax (Softmax)              (None, 32, 32)       0           ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 32)        0           ['conv1d_20[0][0]']              \n",
            "                                                                                                  \n",
            " permute_2 (Permute)            (None, 32, 32)       0           ['softmax[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          3456        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 1, 32)        0           ['reshape_2[0][0]',              \n",
            "                                                                  'permute_2[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 32, 1)        0           ['dot_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 32, 1)        0           ['reshape_3[0][0]',              \n",
            "                                                                  'permute[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 32)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " permute_3 (Permute)            (None, 1, 32)        0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)            (None, 1, 32)        0           ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " average (Average)              (None, 1, 32)        0           ['permute_3[0][0]',              \n",
            "                                                                  'reshape_4[0][0]']              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 32)           0           ['average[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            132         ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 46,498\n",
            "Trainable params: 46,498\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on Emo-db"
      ],
      "metadata": {
        "id": "xYOasADGJ3Pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZEy6sjpJ2oN",
        "outputId": "3938fb53-ab57-430d-a3cf-5ff5eee650be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (237, 64000, 1) (237, 4)\n",
            "Test Data (50, 64000, 1) (50, 4)\n",
            "Val Data (51, 64000, 1) (51, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'EMO_DB/hand_engineered_features_EMODB_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB/hand_engineered_features_EMODB_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB/hand_engineered_features_EMODB_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7v9AgB4T0uG",
        "outputId": "44819219-e313-4f9c-870e-efe06a7b4aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 26) (237, 1)\n",
            "(50, 26) (50, 1)\n",
            "(51, 26) (51, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled.load_weights(\"TESS//models/ensembled_loss.h5\")\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "\n",
        "ensembled.load_weights(\"TESS//models/ensembled_acc.h5\")\n",
        "ensembled.evaluate([X_test,X_test_features],Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGurafxmKYst",
        "outputId": "74f66134-5446-42cf-a50b-6ca7c8cbc5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 10s 395ms/step - loss: 3.5288 - accuracy: 0.5600\n",
            "[3.528780937194824, 0.5600000023841858]\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 1.5731 - accuracy: 0.5800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5730894804000854, 0.5799999833106995]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "MEvkjQiHKcBa",
        "outputId": "3da19969-8edd-4df6-ff79-04e2037b1d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 117ms/step - loss: 1.5731 - accuracy: 0.5800\n",
            "[1.5730894804000854, 0.5799999833106995]\n",
            "F1 SCORE: 0.5308357893497212\n",
            "Kappa: 0.4274809160305344\n",
            "Accuracy: 0.58\n",
            "Jaccard Score: 0.37767516617631036\n",
            "Precision: 0.5444444444444445\n",
            "Recall: 0.548051948051948\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc380219750>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on Crema D"
      ],
      "metadata": {
        "id": "brxQSXfvKdsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = 4,sr = 16000)      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"CREMA//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"CREMA//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"CREMA//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UiFPsBjKf0n",
        "outputId": "0d190791-abd0-4b5b-af04-271df424595c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (3430, 64000, 1) (3430, 4)\n",
            "Test Data (735, 64000, 1) (735, 4)\n",
            "Val Data (735, 64000, 1) (735, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'CREMA/hand_engineered_features_CREMA_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'CREMA/hand_engineered_features_CREMA_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'CREMA/hand_engineered_features_CREMA_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZit0lhpKpEx",
        "outputId": "ecc677a9-5dff-4ca9-f3f8-dc651e9a16c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3430, 26) (3430, 1)\n",
            "(735, 26) (735, 1)\n",
            "(735, 26) (735, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled.load_weights(\"TESS//models/ensembled_loss.h5\")\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "\n",
        "ensembled.load_weights(\"TESS//models/ensembled_acc.h5\")\n",
        "ensembled.evaluate([X_test,X_test_features],Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v96I_8OfKr0g",
        "outputId": "7c5a3d04-26da-4aa3-a96f-de6dc582da18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 4s 161ms/step - loss: 4.0225 - accuracy: 0.4286\n",
            "[4.022480487823486, 0.4285714328289032]\n",
            "23/23 [==============================] - 4s 160ms/step - loss: 1.8934 - accuracy: 0.4422\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8933709859848022, 0.442176878452301]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "3xHu0LvyKz1v",
        "outputId": "a5139d7f-775e-42f5-dcc8-803819482370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 4s 162ms/step - loss: 1.8934 - accuracy: 0.4422\n",
            "[1.8933709859848022, 0.442176878452301]\n",
            "F1 SCORE: 0.43905951405951404\n",
            "Kappa: 0.2589997049277072\n",
            "Accuracy: 0.4421768707482993\n",
            "Jaccard Score: 0.28660721336256867\n",
            "Precision: 0.4403792299483251\n",
            "Recall: 0.4497897559226839\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc2a3c5a0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on Savee (manipulated)"
      ],
      "metadata": {
        "id": "i2Uje8ADKhh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"SAVEE//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"SAVEE//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"SAVEE//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV153WXVK9zO",
        "outputId": "1e8d06fa-7534-4ba4-c3a1-e36a004f2fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (207, 64000, 1) (207, 4)\n",
            "Test Data (45, 64000, 1) (45, 4)\n",
            "Val Data (44, 64000, 1) (44, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'SAVEE/hand_engineered_features_SAVEE_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'SAVEE/hand_engineered_features_SAVEE_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'SAVEE/hand_engineered_features_SAVEE_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThuELYB1K9gW",
        "outputId": "622d9f76-1ad0-4426-90dc-08360e7eba73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(207, 26) (207, 1)\n",
            "(45, 26) (45, 1)\n",
            "(44, 26) (44, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled.load_weights(\"TESS//models/ensembled_loss.h5\")\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "\n",
        "ensembled.load_weights(\"TESS//models/ensembled_acc.h5\")\n",
        "ensembled.evaluate([X_test,X_test_features],Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76vaOESgK8tw",
        "outputId": "451f39b4-c207-40f1-df0b-d37a8f31734d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 377ms/step - loss: 2.5565 - accuracy: 0.6000\n",
            "[2.5565497875213623, 0.6000000238418579]\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 1.2164 - accuracy: 0.6889\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.216365098953247, 0.6888889074325562]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "ATjRjxE_Kkxu",
        "outputId": "9f58e558-c793-4cdc-e188-42b5bd0a56cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 108ms/step - loss: 1.2164 - accuracy: 0.6889\n",
            "[1.216365098953247, 0.6888889074325562]\n",
            "F1 SCORE: 0.6375816993464052\n",
            "Kappa: 0.5625\n",
            "Accuracy: 0.6888888888888889\n",
            "Jaccard Score: 0.4829545454545454\n",
            "Precision: 0.7077497665732959\n",
            "Recall: 0.6408730158730158\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc2a3380f90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wavenet"
      ],
      "metadata": {
        "id": "OwmhLLpQQIku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameters\n",
        "n_filters = 32\n",
        "filter_width = 2\n",
        "dilation_rates = [2**i for i in range(4)] * 2 \n",
        "sr = 16000\n",
        "time = 4\n",
        "# define an input history series and pass it through a stack of dilated causal convolution blocks\n",
        "history_seq = Input(shape=(int(sr*time), 1))\n",
        "x = history_seq\n",
        "\n",
        "skips = []\n",
        "for dilation_rate in dilation_rates:\n",
        "    \n",
        "    # preprocessing - equivalent to time-distributed dense\n",
        "    x = Conv1D(16, 1, padding='same', activation='relu')(x) \n",
        "    \n",
        "    # filter\n",
        "    x_f = Conv1D(filters=n_filters,\n",
        "                 kernel_size=filter_width, \n",
        "                 padding='causal',\n",
        "                 dilation_rate=dilation_rate)(x)\n",
        "    \n",
        "    # gate\n",
        "    x_g = Conv1D(filters=n_filters,\n",
        "                 kernel_size=filter_width, \n",
        "                 padding='causal',\n",
        "                 dilation_rate=dilation_rate)(x)\n",
        "    \n",
        "    # combine filter and gating branches\n",
        "    z = Multiply()([Activation('tanh')(x_f),\n",
        "                    Activation('sigmoid')(x_g)])\n",
        "    \n",
        "    # postprocessing - equivalent to time-distributed dense\n",
        "    z = Conv1D(16, 1, padding='same', activation='relu')(z)\n",
        "    \n",
        "    # residual connection\n",
        "    x = Add()([x, z])    \n",
        "    \n",
        "    # collect skip connections\n",
        "    skips.append(z)\n",
        "\n",
        "# add all skip connection outputs \n",
        "out = Activation('relu')(Add()(skips))\n",
        "out = AveragePooling1D(sr*time)(out)\n",
        "out = Conv1D(8,1,activation='relu')(out)\n",
        "out = Conv1D(4,1,activation='softmax')(out)\n",
        "out = Reshape((4,1))(out)\n",
        "\n",
        "Wavenet_paper = Model(history_seq, out)\n",
        "Wavenet_paper.summary()"
      ],
      "metadata": {
        "id": "6qVi7a5sU_-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a012eca-af13-47dd-e4d4-17a94200f0c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 64000, 16)    32          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 64000, 32)    1056        ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 64000, 32)    1056        ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 64000, 32)    0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 64000, 32)    0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 64000, 32)    0           ['activation[0][0]',             \n",
            "                                                                  'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 64000, 16)    528         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 64000, 16)    0           ['conv1d[0][0]',                 \n",
            "                                                                  'conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 64000, 16)    272         ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 64000, 32)    1056        ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 64000, 32)    1056        ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 64000, 32)    0           ['conv1d_5[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 64000, 32)    0           ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 64000, 32)    0           ['activation_2[0][0]',           \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 64000, 16)    528         ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 64000, 16)    0           ['conv1d_4[0][0]',               \n",
            "                                                                  'conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 64000, 16)    272         ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 64000, 32)    1056        ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 64000, 32)    0           ['conv1d_9[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 64000, 32)    0           ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 64000, 32)    0           ['activation_4[0][0]',           \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 64000, 16)    528         ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 64000, 16)    0           ['conv1d_8[0][0]',               \n",
            "                                                                  'conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 64000, 16)    272         ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 64000, 32)    0           ['conv1d_13[0][0]']              \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 64000, 32)    0           ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 64000, 32)    0           ['activation_6[0][0]',           \n",
            "                                                                  'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 64000, 16)    528         ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 64000, 16)    0           ['conv1d_12[0][0]',              \n",
            "                                                                  'conv1d_15[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)             (None, 64000, 16)    272         ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_16[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_16[0][0]']              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 64000, 32)    0           ['conv1d_17[0][0]']              \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 64000, 32)    0           ['conv1d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 64000, 32)    0           ['activation_8[0][0]',           \n",
            "                                                                  'activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 64000, 16)    528         ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 64000, 16)    0           ['conv1d_16[0][0]',              \n",
            "                                                                  'conv1d_19[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)             (None, 64000, 16)    272         ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_21 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_20[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_22 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_20[0][0]']              \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 64000, 32)    0           ['conv1d_21[0][0]']              \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 64000, 32)    0           ['conv1d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 64000, 32)    0           ['activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_23 (Conv1D)             (None, 64000, 16)    528         ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 64000, 16)    0           ['conv1d_20[0][0]',              \n",
            "                                                                  'conv1d_23[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_24 (Conv1D)             (None, 64000, 16)    272         ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_25 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_24[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_26 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_24[0][0]']              \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 64000, 32)    0           ['conv1d_25[0][0]']              \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 64000, 32)    0           ['conv1d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 64000, 32)    0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_27 (Conv1D)             (None, 64000, 16)    528         ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 64000, 16)    0           ['conv1d_24[0][0]',              \n",
            "                                                                  'conv1d_27[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_28 (Conv1D)             (None, 64000, 16)    272         ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_29 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_28[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_30 (Conv1D)             (None, 64000, 32)    1056        ['conv1d_28[0][0]']              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 64000, 32)    0           ['conv1d_29[0][0]']              \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 64000, 32)    0           ['conv1d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 64000, 32)    0           ['activation_14[0][0]',          \n",
            "                                                                  'activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_31 (Conv1D)             (None, 64000, 16)    528         ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 64000, 16)    0           ['conv1d_3[0][0]',               \n",
            "                                                                  'conv1d_7[0][0]',               \n",
            "                                                                  'conv1d_11[0][0]',              \n",
            "                                                                  'conv1d_15[0][0]',              \n",
            "                                                                  'conv1d_19[0][0]',              \n",
            "                                                                  'conv1d_23[0][0]',              \n",
            "                                                                  'conv1d_27[0][0]',              \n",
            "                                                                  'conv1d_31[0][0]']              \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 64000, 16)    0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling1d (AveragePool  (None, 1, 16)       0           ['activation_16[0][0]']          \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " conv1d_32 (Conv1D)             (None, 1, 8)         136         ['average_pooling1d[0][0]']      \n",
            "                                                                                                  \n",
            " conv1d_33 (Conv1D)             (None, 1, 4)         36          ['conv1d_32[0][0]']              \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 4, 1)         0           ['conv1d_33[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,228\n",
            "Trainable params: 23,228\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Wavenet_paper.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "g3-1GY5hSKTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on emo db"
      ],
      "metadata": {
        "id": "AX6tUiYXRi8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gcGkwP0RlRg",
        "outputId": "992be1dc-ad19-46f5-e0bf-f39fe2a00ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (237, 64000, 1) (237, 4)\n",
            "Test Data (50, 64000, 1) (50, 4)\n",
            "Val Data (51, 64000, 1) (51, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'EMO_DB/hand_engineered_features_EMODB_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB/hand_engineered_features_EMODB_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'EMO_DB/hand_engineered_features_EMODB_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYA0eugcSUch",
        "outputId": "ae156e68-7333-482e-9247-2249c4efac1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 26) (237, 1)\n",
            "(50, 26) (50, 1)\n",
            "(51, 26) (51, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Wavenet_paper.load_weights('TESS//models//wavenet_paper_loss.h5')\n",
        "print(Wavenet_paper.evaluate(X_test,Y_test))\n",
        "Wavenet_paper.load_weights('TESS//models//wavenet_paper_acc.h5')\n",
        "Wavenet_paper.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97zD4twBSYkf",
        "outputId": "6d5f43a1-8320-47b5-b8a6-fd8b691340f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 12s 888ms/step - loss: 6.9970 - accuracy: 0.5900\n",
            "[6.9969587326049805, 0.5899999737739563]\n",
            "2/2 [==============================] - 2s 572ms/step - loss: 6.9970 - accuracy: 0.5900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.9969587326049805, 0.5899999737739563]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Wavenet_paper.evaluate(X_test,Y_test)\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(Wavenet_paper.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1)\n",
        "print(g.shape,p.shape)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))\n",
        "cf_matrix = confusion_matrix(Y_test_features,np.argmax(Wavenet_paper.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "I64DS-1hSX0a",
        "outputId": "3e0f5871-4829-4825-cb6b-54df1ba356c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 565ms/step - loss: 6.9970 - accuracy: 0.5900\n",
            "(50,) (50,)\n",
            "F1 SCORE: 0.11429608127721334\n",
            "Kappa: 0.019138755980861344\n",
            "Accuracy: 0.18\n",
            "Jaccard Score: 0.06452358926919519\n",
            "Precision: 0.22010869565217392\n",
            "Recall: 0.24837662337662336\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.14      0.23        22\n",
            "           1       0.13      0.86      0.23         7\n",
            "           2       0.00      0.00      0.00        11\n",
            "           3       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.18        50\n",
            "   macro avg       0.22      0.25      0.11        50\n",
            "weighted avg       0.35      0.18      0.13        50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f729954b590>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on Crema D"
      ],
      "metadata": {
        "id": "q4EmlnC9Rl4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = 4,sr = 16000)      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"CREMA//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"CREMA//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"CREMA//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3YNT4TlRnZB",
        "outputId": "a1434755-43c7-4d75-940c-cd3934409b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (3430, 64000, 1) (3430, 4)\n",
            "Test Data (735, 64000, 1) (735, 4)\n",
            "Val Data (735, 64000, 1) (735, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'CREMA/hand_engineered_features_CREMA_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'CREMA/hand_engineered_features_CREMA_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'CREMA/hand_engineered_features_CREMA_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P6JuFVaVRni",
        "outputId": "92a5eccb-edb8-4bac-9a0b-a8d5799001c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3430, 26) (3430, 1)\n",
            "(735, 26) (735, 1)\n",
            "(735, 26) (735, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Wavenet_paper.load_weights('TESS//models//wavenet_paper_loss.h5')\n",
        "print(Wavenet_paper.evaluate(X_test,Y_test))\n",
        "Wavenet_paper.load_weights('TESS//models//wavenet_paper_acc.h5')\n",
        "Wavenet_paper.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAV70vukVUeB",
        "outputId": "02737170-8bef-464c-f03e-24ec308311d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 21s 917ms/step - loss: 1.3119 - accuracy: 0.7129\n",
            "[1.311897873878479, 0.7129251956939697]\n",
            "23/23 [==============================] - 21s 891ms/step - loss: 1.3119 - accuracy: 0.7129\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.311897873878479, 0.7129251956939697]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Wavenet_paper.evaluate(X_test,Y_test)\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(Wavenet_paper.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1)\n",
        "print(g.shape,p.shape)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))\n",
        "cf_matrix = confusion_matrix(Y_test_features,np.argmax(Wavenet_paper.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "Lue6GzttVWos",
        "outputId": "fa53d06f-ef74-49d6-d819-f11c7202a384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 21s 889ms/step - loss: 1.3119 - accuracy: 0.7129\n",
            "(735,) (735,)\n",
            "F1 SCORE: 0.4035121315843354\n",
            "Kappa: 0.23986685663751606\n",
            "Accuracy: 0.4272108843537415\n",
            "Jaccard Score: 0.26954535030516813\n",
            "Precision: 0.39791484120991927\n",
            "Recall: 0.4376252564255768\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.47      0.40       176\n",
            "           1       0.23      0.12      0.16       204\n",
            "           2       0.44      0.34      0.38       176\n",
            "           3       0.56      0.83      0.67       179\n",
            "\n",
            "    accuracy                           0.43       735\n",
            "   macro avg       0.40      0.44      0.40       735\n",
            "weighted avg       0.39      0.43      0.40       735\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f722b357450>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on Savee"
      ],
      "metadata": {
        "id": "5SAomKQfRoPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"SAVEE//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"SAVEE//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"SAVEE//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfPoV_ZjRqX2",
        "outputId": "d46a6f0d-4bba-48cd-93b8-ad6c25809632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (207, 64000, 1) (207, 4)\n",
            "Test Data (45, 64000, 1) (45, 4)\n",
            "Val Data (44, 64000, 1) (44, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'SAVEE/hand_engineered_features_SAVEE_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'SAVEE/hand_engineered_features_SAVEE_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'SAVEE/hand_engineered_features_SAVEE_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYcBOACMbFCC",
        "outputId": "75b81772-8b54-4de8-dc29-787d8e177295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(207, 26) (207, 1)\n",
            "(45, 26) (45, 1)\n",
            "(44, 26) (44, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Wavenet_paper.load_weights('TESS//models//wavenet_paper_loss.h5')\n",
        "print(Wavenet_paper.evaluate(X_test,Y_test))\n",
        "Wavenet_paper.load_weights('TESS//models//wavenet_paper_acc.h5')\n",
        "Wavenet_paper.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR0OEdfsbH7Z",
        "outputId": "a9c43a34-590c-4465-9648-e4140bb978ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 717ms/step - loss: 7.3435 - accuracy: 0.6389\n",
            "[7.3435282707214355, 0.6388888955116272]\n",
            "2/2 [==============================] - 1s 437ms/step - loss: 7.3435 - accuracy: 0.6389\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7.3435282707214355, 0.6388888955116272]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Wavenet_paper.evaluate(X_test,Y_test)\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(Wavenet_paper.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1)\n",
        "print(g.shape,p.shape)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))\n",
        "cf_matrix = confusion_matrix(Y_test_features,np.argmax(Wavenet_paper.predict(X_test).reshape(Y_test_features.shape[0],4),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "RfLK6lzkbNa3",
        "outputId": "ff5f91a3-aad1-450d-bf32-f75fca4e3d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 449ms/step - loss: 7.3435 - accuracy: 0.6389\n",
            "(45,) (45,)\n",
            "F1 SCORE: 0.16173361522198731\n",
            "Kappa: 0.03591682419659736\n",
            "Accuracy: 0.24444444444444444\n",
            "Jaccard Score: 0.10075757575757577\n",
            "Precision: 0.13825757575757575\n",
            "Recall: 0.2857142857142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           1       0.30      1.00      0.47        10\n",
            "           2       0.00      0.00      0.00        18\n",
            "           3       0.25      0.14      0.18         7\n",
            "\n",
            "    accuracy                           0.24        45\n",
            "   macro avg       0.14      0.29      0.16        45\n",
            "weighted avg       0.11      0.24      0.13        45\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f722a77b210>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paper 1"
      ],
      "metadata": {
        "id": "SISsKEfKh-BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def paper_model():\n",
        "  inp = Input((352800,1))\n",
        "  l1 = BatchNormalization()(Conv1D(32,21,activation='relu',padding = 'same')(inp))\n",
        "  m1 = MaxPool1D(2)(l1)\n",
        "\n",
        "  l2 = BatchNormalization()(Conv1D(64,19,activation='relu',padding = 'same')(m1))\n",
        "  m2 = MaxPool1D(2)(l2)\n",
        "\n",
        "  l3 = BatchNormalization()(Conv1D(128,17,activation='relu',padding = 'same')(m2))\n",
        "  m3 = MaxPool1D(2)(l3)\n",
        "\n",
        "\n",
        "  l4 = BatchNormalization()(Conv1D(256,15,activation='relu',padding = 'same')(m3))\n",
        "  m4 = MaxPool1D(2)(l4)\n",
        "\n",
        "  l5 = BatchNormalization()(Conv1D(512,13,activation='relu',padding = 'same')(m4))\n",
        "  m5 = MaxPool1D(2)(l5)\n",
        "\n",
        "  l6 = BatchNormalization()(Conv1D(1024,11,activation='relu',padding = 'same')(m5))\n",
        "  m6 = MaxPool1D(2)(l6)\n",
        "\n",
        "  l7 = BatchNormalization()(Conv1D(1024,9,activation='relu',padding = 'same')(m6))\n",
        "  m7 = GlobalMaxPool1D()(l7)\n",
        "\n",
        "  fl = Flatten()(m7)\n",
        "  d1 = Dense(128,activation='relu')(fl)\n",
        "  out = Dense(4,activation='softmax')(d1)\n",
        "\n",
        "  return Model(inputs = inp,outputs = out)\n",
        "\n",
        "m = paper_model()\n",
        "m.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rDIUk9Eby8S",
        "outputId": "e1e1ff37-36f2-4ef4-f074-c7a18210e44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 352800, 1)]       0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 352800, 32)        704       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 352800, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 176400, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 176400, 64)        38976     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 176400, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 88200, 64)        0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 88200, 128)        139392    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 88200, 128)       512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 44100, 128)       0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 44100, 256)        491776    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 44100, 256)       1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 22050, 256)       0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 22050, 512)        1704448   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 22050, 512)       2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 11025, 512)       0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 11025, 1024)       5768192   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 11025, 1024)      4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 5512, 1024)       0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 5512, 1024)        9438208   \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 5512, 1024)       4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 1024)             0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               131200    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,725,572\n",
            "Trainable params: 17,719,492\n",
            "Non-trainable params: 6,080\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1Fd13XqfiMC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on emo db"
      ],
      "metadata": {
        "id": "VG6tnHKdiTI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 8\n",
        "srk = 44100\n",
        "def label_to_onehot(l):\n",
        "    l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = srk)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5vsMVqHiVFf",
        "outputId": "1374158c-a200-4013-c9e4-2b47ed994768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (237, 352800, 1) (237, 4)\n",
            "Test Data (50, 352800, 1) (50, 4)\n",
            "Val Data (51, 352800, 1) (51, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.load_weights('TESS//models//paper_1_acc.h5')\n",
        "print(m.evaluate(X_test,Y_test))\n",
        "m.load_weights('TESS//models//paper_1_loss.h5')\n",
        "m.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m9c-WHYih0h",
        "outputId": "4b99d6d5-e703-4441-8c90-fcc8bd7075f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 57s 17s/step - loss: 5.2522 - accuracy: 0.5000\n",
            "[5.252240180969238, 0.5]\n",
            "2/2 [==============================] - 9s 3s/step - loss: 5.2522 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.252240180969238, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(m.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(m.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "oK8evENQioZj",
        "outputId": "5e8d39c2-10f5-42ec-e2ee-2131bdf16df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.3557279111204277\n",
            "Kappa: 0.266001174398121\n",
            "Accuracy: 0.5\n",
            "Jaccard Score: 0.24855072463768113\n",
            "Precision: 0.32476190476190475\n",
            "Recall: 0.400974025974026\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.77      0.72        22\n",
            "           1       0.29      0.29      0.29         7\n",
            "           2       0.33      0.55      0.41        11\n",
            "           3       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.50        50\n",
            "   macro avg       0.32      0.40      0.36        50\n",
            "weighted avg       0.41      0.50      0.45        50\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD4CAYAAABPLjVeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3wUZf7A8c93Q2hSpEMICkoUpQhSBPQELICciO0QD09BBBse9h+eWA67nv2wYEM9G3qndAURFEUURBCkhU4SAiFUqcnu9/fHLmFDSSZhd2Z3+b7vNS93Zp6Z/e5zyzfPPvPMM6KqGGOMcYfP6wCMMeZYYknXGGNcZEnXGGNcZEnXGGNcZEnXGGNcVCbab7B77L9seETITwN/8jqEmPFsud1ehxAzJmX/6nUIMSN/X6Yc7TnyNq10nHOSa5501O9XUtbSNcYYF0W9pWuMMa4K+L2OoEiWdI0xicWf73UERbKka4xJKKoBr0MokiVdY0xiCVjSNcYY91hL1xhjXGQX0owxxkXW0jXGGPeojV4wxhgX2YU0Y4xxkXUvGGOMi+xCmjHGuMhausYY4yK7kGaMMS6K8QtpjqZ2FJHbRKRatIMxxpijpep3vHjB6Xy6dYDZIjJaRLqLiOsT/xpjjCMacL54wFHSVdVhQBrwFtAPSBeRx0Xk5CjGZowxJRcIOF884PjJEaqqQHZoyQeqAZ+JyNNRis0YY0ouxlu6ji6kicgQ4FpgE/AmcI+q5omID0gH7o1eiMYYUwL+PK8jKJLT0QvVgMtVdU34RlUNiMjFkQ/LGGNKKd5HL4hIEtDn4IS7n6oujnhUxhhTWvHevaCqfhFZKiInqOpaN4IqiR+WrOPpsT8SCCiXtTuV689rWWj/M2N/ZPbyLAD25OWz+Y89fP/IdcxensUzY38sKLc6ZxtP9j2P85o1dDP8iKrepSWNH+2PJPlY/8FU1r78xWHL1fzzWTR7+25+6fp/7Ji/ksqtGnPqv24M7hRY/cynbJr0s4uRR96Znc5k4MOD8CX5mPLxZD575bNC+5u2a8rAhwbS8LRGPD34aWZO/KFgX79/9KfteW0Q8THv+18Z+dBIt8N3VbeunXnuueEk+Xy8/c5HPP3MCK9DOjoRbOmKSHfgRSAJeFNVnzxo/wnAu8DxoTJDVXViUecsSffC7yLyM7Bz/0ZVvcR5+JHnDwR44vMfeG1QD+pUPY6+L31Bp6YncnKdA0OK77mkQ8Hrj75fyJKsXADaNk5h9J1XALBt1x56PjmaDqekuvsBIsnnI+3JAczv/Qh7szbT+qsn2PTVHHYtyyhULOm48qQO7MH2X5YVbNu5ZC2/dP0/1B+gbO3jaTPtX+ROnoP6Y/tn2pH4fD5uevRmHug7jNz1uTw37nl+mvIT69LXFZTJycrhhbte4LIbLy90bJPWTTitzWnc1vU2AJ7679M0a9+chbMWuPoZ3OLz+Xjpxcfo3uNqMjLWM+vHiYwbP5nFi9O9Dq30IpR0Q7/yRwAXAhkEh82OVdVFYcWGAaNV9VUROR2YCDQs6rxOk+4DJQ85+hauzaFBzSqk1qgCQLeWJzP99zWFkm64SfNWcHPX1odsn/LbKs5ukkqFsvF7g16VMxuze1U2e9ZsBGDjFz9Qs3sb1h6UdBsN7cPaf4/hhFsO/L0M7N5X8NpXviyouhN0lKS1PIX1q9ezYe0GAL4b9x1ndW1fKOluzAjWkx70D1QVypYrS5nkMogISclJbN20xb3gXdaubStWrFjNqlXBH7GjR4/hkp7d4jrpauQupLUDlqvqSgAR+RjoBYQnXQWqhF5XBbKKO6mjLKOq35YoVJds3L6TusdXKlivU/U4FqzdeNiyWVt2kLV5B+0apxyy76t5K/jbuc2jFqcbytWtzt5QKx5gb9ZmqpyZVqhMpeaNKJdSg81fzy2UdAEqn9mYJs/fQvkGtVh868tx28oFqFG3BpuycgrWc9dv4pSWpzo6duncJSyY+RvvznkPEWHCu+PJWJ5R/IFxKqV+XdZlHMgTGZnrade2lYcRRUAJ+mpFZBAwKGzTSFXd359UH1gXti8DOOugUzwMTBaR24DjgAuKe0+ntwHvEJHtBy3rRORzETnJyTm89tW8FVzQohFJvsIfOWf7LpZnb6HDqQ08iswlIjT+53WsePi9w+7eMXc5szvdyS/dhnLCkMvwlUt2OcDYUO/EeqQ2bkD/s/rRr911tOh4Bqe3a+p1WKYkSnBzhKqOVNU2YUtJO/CvBkapairQA3g/NJT2iJzeHPECcA/BzJ8K3A18CHwMvH1wYREZJCJzRGTOW1/NKkH8JVO7ynFkb/2jYH3Dtp3UrnrcYct+OW8l3Vs2PmT75Pkr6dKsIclJju8TiUl7szdTLqVGwXq5lOrszT7Q8k2qVIHjmjSg5f8epv3sEVRpnUaz9/6PymcU/pu5Kz0T/849HNckfv8I5WbnUjOlVsF6jXo1yd2QW8QRB7Tv3oGlvy5lz6497Nm1h1+mz6HJmU2iFarnsjKzaZB64Ndfav16ZGVlexhRBERu9EImEP4PITW0LdwAYDSAqv4IlAdqFnVSp5nmElV9XVV3qOr20F+Dbqr6CcGLbIWE//UY0K29w7couaYNarF203YyN28nL9/PV/NW0On0Ew4pt2rjVrbv3ssZJ9Y+ZN+X81ZwUcv4v5t5x6/LqXBSPcqfUBtJLkPtS89m01dzCvb7d+zih9MHMKvtrcxqeyvbf0ln4bVPsWP+yuAxoT865VJrUrFxCnvW5RzprWJe+vxlpDRKoU6DOpRJLsO5Pc/l5yk/OTo2JyuHZu2b4UvykVQmiWbtm7Nu+briD4xTs+fMo3HjRjRs2IDk5GR69+7FuPGTvQ7r6ETuNuDZQJqINBKRskAfYOxBZdYC5wOIyGkEk26R/3icXjnaJSK9gf3jbq4E9oRee3bVpUySj6GXduTmNyYRCCi92p1K47rVeeWrOZyeWovOTU8Egom1e8uTOXienszNO8je+getT6rnRfgRpf4A6fe9RYuP7w8OGftoGruWZtDw3qvYMX8FuWEJ+GBV2zXhhNsuRfP9aCBA+tA3ydu8w8XoIyvgD/DaA6/xz/eH40vy8fUnU1i7bC197+xL+oJ0fp7yM2kt0vjHG/dTqWol2l7Qjr53/pVbL7iVmRN+4IyOLfj35BEoytzpc5n9dXwPnyuK3+9nyO3DmDjhQ5J8Pka9+wmLFi0r/sBYFqHxt6qaLyKDga8IDgd7W1V/F5HhwBxVHQvcBbwhIncQzIX9QlMmHJEUsz9YKNhv+yLQIXTiWcAdBJvarVX1+yMdu3vsv+L7UngE/TTQWWvrWPBsud1ehxAzJmX/6nUIMSN/X+ZRz2C4e8ILjnNOhT/f7vqMiU5HL6wEeh5h9xETrjHGuC4RHtcjIrWAgQQH/RYco6rXRycsY4wppRife8Fpn+4YYAbwNRDbj9o0xhzbEqGlC1RU1f+LaiTGGBMJMd7SdTpkbLyI9IhqJMYYEwnxPstYyBDgHyKyF8gDhODDJKoUfZgxxrgsPwEewa6qlUWkOsHnpJWPbkjGGHMUYnzCJqejF24g2NpNBeYB7YGZhO7EMMaYmJEgfbpDgLbAGlXtArQCtkUtKmOMKa0Yfxqw0z7dPaq6R0QQkXKqukREnM2VZ4wxbkqQIWMZInI88AUwRUS2AId9ZpoxxnjKH9u3Eji9kHZZ6OXDIjKN4AzpX0YtKmOMKa0Y79Mt8fNpYvUpEsYYAyRe0jXGmJiWIH26xhgTFzSQAON0jTEmblj3gjHGuCgRRi8YY0zcsJauMca4yJKuMca4KBEmvDHGmLhhLV1jjHHRsT5k7Na/z4r2W8SNlAplvQ4hZkzKmul1CCZR2egFY4xxj1r3gjHGuOhY714wxhhX2dwLxhjjImvpGmOMi/LtQpoxxrjHuheMMcZF1r1gjDHusSFjxhjjJmvpGmOMiyzpGmOMi+w2YGOMcY89I80YY9xkSdcYY1wU46MXfE4KichtIlIt2sEYY8xRC6jzxQOOki5QB5gtIqNFpLuISDSDMsaYUkuEpKuqw4A04C2gH5AuIo+LyMlRjM0YY0pM/QHHS3FCjcylIrJcRIYeoUxvEVkkIr+LyIfFndNxn66qqohkA9lAPlAN+ExEpqjqvU7PY4wxURWhFqyIJAEjgAuBDIK/9seq6qKwMmnAfcDZqrpFRGoXd15HSVdEhgDXApuAN4F7VDVPRHxAOmBJ1xgTEyI4ZKwdsFxVVwKIyMdAL2BRWJmBwAhV3QKgqhuLO6nTlm514HJVXRO+UVUDInKxw3MYY0z0lSDpisggYFDYppGqOjL0uj6wLmxfBnDWQac4JXSeH4Ak4GFV/bKo93SUdFX1IRE5U0R6AQr8oKpzQ/sWOzmHMca4ogQjxkIJdmSxBY+sDMHrXZ2BVOA7EWmuqluPdIDTIWMPAO8CNYCawDsiMuwoAjXGmKjQ/IDjpRiZQIOw9dTQtnAZwFhVzVPVVcAygkn4iJwOGbsGaKuqD6nqQ0B74G8OjzXGGPcESrAUbTaQJiKNRKQs0AcYe1CZLwi2chGRmgS7G1YWdVKnfbpZQHlgT2i9HIdmfE8069SSvz7YH0nyMeOTqUx89YtC+7sOuJhz+5yPPz/Ajs3beefeEeRmbqJG/ZoMfv1exCcklSnD1HcnMf2DyR59ishI69SCHg9eiy/Jxy+fTOO7V8cV2t9xQA/a9OlMID/Azs3b+fzekWzN3ARA16F9OLVLKwCmvfw5C8fPcj1+N3Xr2pnnnhtOks/H2+98xNPPjPA6JM8kWl1E6kKaquaLyGDgK4L9tW+r6u8iMhyYo6pjQ/u6isgiwE9wkEFuUecV1eIDFJEvgLbAFIJ9uhcCPxNsWqOqfz/Ssdc3vDJqI5DF5+OJaS/x7DXD2Zy9mQfHPsnrt71A1vKMgjJNOjRl5a/p7Nuzj87XdKVJ+6a8Nvh5kpLLIAL5+/IpV7E8j0x+jscvv5+tG7dEK1xSKBu1c4tPuGPac7xzzRNsz87lprGPMvq2f5Oz/MDfxkYdTifj1+Xk7dlHu2suoFH70/hk8Muc0qUlHa+/iPf6PUVS2WQGfDyMd/o+zt4/dkct3iezvo3auYvj8/lY/PsMuve4moyM9cz6cSLX/O0WFi9O9ywmr8RaXeTvyzzqG6+2XNHZcc6p9t/prt/o5bR74XPgH8A0YDpwPzAG+CW0eOKklo3ZuCabnHUb8efl89O4H2jZtW2hMkt+/J19e/YBsPLXdKrVrQGAPy+f/H35AJQpW4Z4v8kutWVjctdsYMu6jfjz/CwY9yOndW1dqMyqHxeRF6qLdb+mU6VudQBqp6Wy+uclBPwB8nbvZcOStaR1auH6Z3BLu7atWLFiNatWrSUvL4/Ro8dwSc9uXofliUSsCw2o48ULTkcvvBvq02hCsKW7VFX3RTUyB46vU53NWZsK1resz+Wklkfuw/5T7/NYMP3XgvVq9Wpw+9v/oHbDunz6+PtRbeVGW5U61diWdeBXzfb1m0lt2fiI5Vv37kL69PkAZC9eQ5chl/PDGxNIrlCORh2asjE9JnqPoiKlfl3WZWQVrGdkrqdd21YeRuSdhKyL2J7vxvHNET2A14EVgACNRORGVZ10hPIFY986Vm/FqZVPilC4pdf+0j/RsMXJPHXVgwXbtqzP5aGL7uL42tUYPPJe5kz6ke2btnkYpTvOuPRs6rdoxJtXPQLA8hkLqN/iJAb972F25u5g3dx0AjE+U5MxR6L5XkdQNKfdC88BXVS1s6p2AroAzx+psKqOVNU2qtommgl364bNVE+pWbBerV4NtmzYfEi5089uzsWDr+ClG54s6FIodJ6NW8hcto60tqdFLdZo275hC1VTahSsV6lXne2HqYuTz25Gp8GX8p8bnsUfVhffjhjDiB7/YNTfngCB3JXZrsTthazMbBqkphSsp9avR1ZW4n7eoiRiXWjA+eIFp0l3h6ouD1tfCeyIQjwlsmr+cuo0rEfN1NokJZfhrJ5nM2/K7EJlTmjaiGsfv5GXbniSHbnbC7ZXq1ud5HLBC1sVqxxHWpsmZK/MIl5lzl9BjYZ1qZZai6TkJJr37MCSKYW72+s1PZFejw/ggxueZWdYXYhPqHB8JQDqNGlA3SYnsHzGb67G76bZc+bRuHEjGjZsQHJyMr1792Lc+PgeuVJaCVkXkRsyFhVOh4zNEZGJwGiCfbp/ITj5w+UAqvq/KMVXpIA/wH8efJM73xuGL8nH96O/ISs9g0vvuIrVC1Yw7+s59L7vb5SrWJ5bXrkLgNzMTbw88CnqNU7lqvuvC30c4as3xpK5dK0XHyMiAv4A4x8cxXXvDQ0OGRs9nY3pmZx/x5VkLljJkq/n0v2+vpStWJ4+rwQHm2zNzOWDgc+SlFyGgZ8Gu132/rGbT+94hYCDGZjild/vZ8jtw5g44UOSfD5GvfsJixYt8zosTyRiXXjVgnXK6ZCxd4rYrap6/ZF2RnPIWLyJ5pCxeOPlkDETuyIxZGzj+Z0c55zaU791fdiS09EL/aMdiDHGRIL6Y3v4p9PRC+WBAUBTgnemAVBUC9cYY7wQ690LTi+kvQ/UBboB3xKc+MHzC2nGGHMwDYjjxQtOk25jVX0A2Kmq7wJ/5tB5JY0xxnOxPmTM6eiFvNB/t4pIM4KP7Cn2sRTGGOM21QTo0wVGhh7BPozg1GaVgAeiFpUxxpRSrPfpOk267wNXAA0JTmYOwceyG2NMTAkkwugFgjOKbSM4o9je6IVjjDFHx6sLZE45Tbqpqto9qpEYY0wExHrSdTp6YaaINI9qJMYYEwGqzhcvFNnSFZEFBCcnKAP0F5GVBLsXhODtv4k707UxJi7Feku3uO6Fi12JwhhjIiSuh4yp6hq3AjHGmEjwJ8joBWOMiQtx3dI1xph4E+99usYYE1e8GpXglCVdY0xCsZauMca4yB9wevuBNyzpGmMSinUvGGOMiwI2esEYY9xjQ8aMMcZFx3z3wuK83Gi/RdxISa7ndQgxI7NjmtchxIz6M9O9DiGhWPeCMca4yEYvGGOMi2K8d8GSrjEmsVj3gjHGuMhGLxhjjIti/GHAlnSNMYlFsZauMca4Jt+6F4wxxj3W0jXGGBfFep9ubI8iNsaYElLE8VIcEekuIktFZLmIDC2i3BUioiLSprhzWtI1xiSUQAmWoohIEjACuAg4HbhaRE4/TLnKwBDgJyfxWdI1xiQUP+J4KUY7YLmqrlTVfcDHQK/DlHsEeArY4yS+IpOuiOwQke2HWXaIyHYnb2CMMW4KiPNFRAaJyJywZVDYqeoD68LWM0LbCojImUADVZ3gNL4iL6SpamWnJzLGmFgQKMHoBVUdCYwszfuIiA94DuhXkuNKNHpBRGoD5fevq+rakhxvjDHRFsEJbzKBBmHrqaFt+1UGmgHTRQSgLjBWRC5R1TlHOqmjPl0RuURE0oFVwLfAamBSSaI3xhg3ROpCGjAbSBORRiJSFugDjN2/U1W3qWpNVW2oqg2BWUCRCRecX0h7BGgPLFPVRsD5oTcwxpiYEhBxvBRFVfOBwcBXwGJgtKr+LiLDReSS0sbntHshT1VzRcQnIj5VnSYiL5T2TY0xJlr8ETyXqk4EJh607cEjlO3s5JxOk+5WEakEfAd8ICIbgZ0OjzXGGNcEYvsuYMfdC72AXcAdwJfACqBntIIyxpjSCiCOFy8U29IN3ZUxXlW7EOx7fjfqURljTCnF/eN6VNUvIgERqaqq29wIyhhjSivWuxec9un+ASwQkSmE9eWq6t+jElUJtO/cltuHDybJl8TYjybw/oiPCu1veVYLbv/nrZx82sk8eMtwpk34rtD+ipUq8tH0UXz35fc8O+wlN0OPuLROLejx4LX4knz88sk0vnt1XKH9HQf0oE2fzgTyA+zcvJ3P7x3J1sxNAHQd2odTu7QCYNrLn7NwfHwPTinbrh2VBw+GpCR2T5jArg8/LLS/fPfuVL7pJvybgp9/9+efs3tC8Kai2lOnkr9qFQCBDRvYev/97gbvsm5dO/Pcc8NJ8vl4+52PePqZEV6HdFRifZYxp0n3f6ElnOeteJ/Px12PDWHI1fewcX0Ob098jRmTZ7I6fU1BmezMDTxyx1P0vemqw55j0D3XM2/Wb26FHDXiE3oO78871zzB9uxcbhr7KIunzCVn+YGx3OsXrebVnsPI27OPdtdcQLf7ruaTwS9zSpeWpDRtxIge95FUNpkBHw8jffp89v6x28NPdBR8PioPGcLWu+/Gn5ND9ddeY+8PP+Bfs6ZQsT3TprHjxRcPOVz37WPzDTe4Fa2nfD4fL734GN17XE1Gxnpm/TiRceMns3hxutehlZo/xlu6Ti+kHa+q74YvQLVoBubE6a2akLE6i6y168nPy+frMd9wbrezC5XJztjAisUrCQQO/ft3avNTqF6rGj99N9utkKMmtWVjctdsYMu6jfjz/CwY9yOndW1dqMyqHxeRt2cfAOt+TadK3eoA1E5LZfXPSwj4A+Tt3suGJWtJ69TC9c8QKclNmuDPzMS/fj3k57Pnm28od/bZxR94DGrXthUrVqxm1aq15OXlMXr0GC7p2c3rsI5KBG+OiAqnSfe6w2zrF8E4SqVW3ZpszNpYsL5xfQ616tZ0dKyI8PcHb+blR16NVniuqlKnGtuycgvWt6/fTJU61Y9YvnXvLqRPnw9A9uI1pHVqQXL5slSsVplGHZpStV6NqMccLb5atQjk5BSsB3JySKpV65By5c49l+pvvUXVf/4TX9h+KVuW6q+/TrVXXqHcOee4ErNXUurXZV1GVsF6RuZ6UlLqehjR0Yv1pFtk94KIXA38FWgkImPDdlUGNhdx3CBgEECjqqdQ57iUCIQaWVdc14uZ3/xEzvpNXofiujMuPZv6LRrx5lWPALB8xgLqtziJQf97mJ25O1g3N/2wvwwSyd6ZM9kzdSrk5VGhZ0+q3ncfW+68E4BNV11FYNMmkurVo9rzz5O/ciX+rKxizmhiRYw/Iq3YPt2ZwHqgJvBs2PYdwBE7QsNn7ulQv0vU+n5zsjdRO6V2wXrterXIyXaWRJu1bsoZZzXniut6UeG4CiQnl2HXzt28+sQb0Qo3qrZv2ELVlAOt0yr1qrN9w6F/F08+uxmdBl/KW1c9gn9ffsH2b0eM4dsRYwD4y4u3krsyO/pBR0kgJ6dQy9VXqxb+sJYvgG4/MDPp7gkTqHTjjQeOD11c869fz7558yiTlpawSTcrM5sGqQcaRan165GVFb//30PsX0grsntBVdeo6nRV7aCq34Ytc0P3JXtq8bwlNGhUn3oN6lImuQwX9DqPGZNnOjr24dse47J2fbi8/dW8/MirTPpsctwmXIDM+Suo0bAu1VJrkZScRPOeHVgy5ZdCZeo1PZFejw/ggxueZWfugaQjPqHC8ZUAqNOkAXWbnMDyGfF7cTFv6VKSUlPx1a0LZcpQ/rzz2Duz8PfCV/1A10u5jh3JXxucME8qVYLk5ODrqlVJbtaM/NWrXYvdbbPnzKNx40Y0bNiA5ORkevfuxbjxk70O66j4S7B4wdHoBRHZwYHRCmWBZGCnqlaJVmBO+P0Bnh32Ei98+DQ+n4/xn0xi1bLVDLy7P4vnL+X7KTM57YxTefKtR6hctRLnXNiBG+7qT9/z+nsZdlQE/AHGPziK694bGhwyNno6G9MzOf+OK8lcsJIlX8+l+319KVuxPH1eCY7025qZywcDnyUpuQwDPw3eTr73j918escrBPyx3l4ogt/PjhdfpNozz4DPx55Jk/CvXs1x/fuTv3Qpe2fOpOIVV1CuY0fU70d37GD7k08CUObEE6l8110QCIDPx84PPzxk1EMi8fv9DLl9GBMnfEiSz8eodz9h0aJlXod1VGJ9nK6oluzXvwQnjuwFtFfVIz6obb9odi/Em/OT63kdQsy4rWFi/lwvjfoz43d4VqTl78s86pT5/AnXOM45d6z9j+spusTPSNOgL4D4HldijElIcT16YT8RuTxs1Qe0weFD2Iwxxk2x/tPa6R1p4TOK5RN8csThnoppjDGeivU+XUdJV1UT78qTMSYheTUqwSmnz0g7RUSmisjC0HoLERkW3dCMMabkAqjjxQtOL6S9AdwH5AGo6m8EH9JmjDExJSEupAEVVfVnKfwgN89vjjDGmIMlyoW0TSJyMqHPIyJXErw92BhjYkqs39bjNOneSnAuhSYikgmsAvpGLSpjjCmlfInttq7TpJsJvANMA6oD2wlO9zg8SnEZY0ypxHbKdZ50xwBbgbmA3b9pjIlZidK9kKqq3aMaiTHGRIBXQ8GccjpkbKaINI9qJMYYEwFagsULTlu65wD9RGQVsBcQgnPfxO+DtIwxCSlRuhcuimoUxhgTIf4Y715wOvdC4s7ibIxJKInS0jXGmLigidDSNcaYeGEtXWOMcVGsDxmzpGuMSSixnXIt6RpjEkx+jKddS7rGmIRyzF9Im52zLNpvETdmY3Wx30NzZngdQuxI+ZPXESQUu5BmjDEuOuZbusYY4yZr6RpjjIv8GtstXaezjBljTFyI5NOARaS7iCwVkeUiMvQw++8UkUUi8lvoieknFndOS7rGmISiJfhfUUQkCRhBcMKv04GrReT0g4r9CrQJzbj4GfB0cfFZ0jXGJJQIPoK9HbBcVVeq6j7gY6BXeAFVnaaqu0Krs4DU4k5qSdcYk1BK0r0gIoNEZE7YMijsVPWBdWHrGaFtRzIAmFRcfHYhzRiTUEoyZExVRxJ80vlREZFrgDZAp+LKWtI1xiSUCI5eyAQahK2nhrYVIiIXAPcDnVR1b3EntaRrjEkoEZxlbDaQJiKNCCbbPsBfwwuISCvgdaC7qm50clJLusaYhBKpmyNUNV9EBgNfAUnA26r6u4gMB+ao6ljgGaAS8KmIAKxV1UuKOq8lXWNMQonkbcCqOhGYeNC2B8NeX1DSc1rSNcYkFJvE3BhjXKQxfhuwJV1jTEJJiEewG2NMvLDuBWOMcZF1LxhjjIuspWuMMS6yJ0cYY4yLYn0Sc0u6xpiEEtfdCyKyAI78CUIT9xpjTMyI9aRb3Hy6FwM9gS9DS9/QcsitcbGqW9fO/L7wO9lPnwEAAApRSURBVJYs+p5777nV63A8dSzVxfez5nBxnxu4qPf1vPn+6EP2Z2VvYMDfh3LZtTfTb/C9ZG/MKdh3453D6NDtSm655yE3Q/ZMon0vVNXx4oUik66qrlHVNcCFqnqvqi4ILUOBru6EWHo+n4+XXnyMi3teQ/MzunDVVZdy2mlpXofliWOpLvx+P48+O4JXn32EsR+8zsSvp7Ni1ZpCZf717ze5pPv5fP7eq9zc/6+88Nqogn39/3oFTzxwt8tReyMRvxeRfEZaNDh9coSIyNlhKx1LcKxn2rVtxYoVq1m1ai15eXmMHj2GS3p28zosTxxLdbFg8TJOSE2hQf16JCcnc9H5nfhmxqxCZVasWku71i0BaHfmGUyb8WPBvvZtWlGxYkVXY/ZKIn4vIvWMtGhxmjgHAK+IyGoRWQO8AlwfvbAiI6V+XdZlZBWsZ2SuJyWlrocReedYqouNOZuoW7tWwXqd2jXZmJNbqMypaSfx9bc/APD1tzPZuWs3W7dtdzXOWJCI3wu/BhwvXnA0ekFVfwHOEJGqofVtUY3KmCi7+9YbeOy5VxgzcQqtWzanTq0a+Hwx/+PNOJAwd6SJyJ+BpkD50GS9qOrwI5QdBAwCkKSq+HzHHX2kpZCVmU2D1JSC9dT69cjKyvYkFq8dS3VRu1bNQhfGNmzcRO1aNQ4qU4MXn3gAgF27dvP19O+pUrmSq3HGgkT8XsT76AUAROQ14CrgNkCAvwAnHqm8qo5U1Taq2sarhAswe848GjduRMOGDUhOTqZ3716MGz/Zs3i8dCzVRbMmp7A2I4uMrGzy8vKYNPVbupzTvlCZLVu3EQgEf16+8f4nXPbnmL8uHBWJ+L2I9T5dpy3djqraQkR+U9V/isizOHjUsNf8fj9Dbh/GxAkfkuTzMerdT1i0aJnXYXniWKqLMmWS+McdN3PjncPw+/1cdnFXGp90Iv9+4z2aNjmFLn9qz+xff+OF10YhIrQ+oxnD7rql4Phrb76bVWvXsWvXHs6/9BqG33cHZ5/V2sNPFD2J+L0IxHj3gjjp/xCRn1W1nYjMAi4HNgMLVbVxcceWKVs/tmvAeGJ31gyvQ4gZFVL+5HUIMSN/X6Yc7Tma1jnLcc75fcNPR/1+JeW0pTtORI4n+BC2uQTvUnsjalEZY0wpeTUqwSmnSXcJ4FfV/4rI6cCZwBfRC8sYY0on1rsXnI6ReUBVd4jIOcB5wJvAq9ELyxhjSifWL6Q5Tbr+0H//DLyhqhOAstEJyRhjSi+g6njxgtOkmykirxMcNjZRRMqV4FhjjHFNrLd0nfbp9ga6A/9S1a0iUg+4J3phGWNM6fjVX3whDzm9DXgX8L+w9fXA+mgFZYwxpZUwtwEbY0w8iPXbgC3pGmMSirV0jTHGRbE+TteSrjEmodgj2I0xxkWJchuwMcbEBevTNcYYF1mfrjHGuMhausYY4yIbp2uMMS6ylq4xxrjIRi8YY4yL7EKaMca4KNa7F2xOXGNMQonkfLoi0l1ElorIchEZepj95UTkk9D+n0SkYXHntKRrjEkoqup4KYqIJAEjgIuA04GrQ8+IDDcA2BJ6MvrzwFPFxWdJ1xiTUCL4uJ52wHJVXamq+4CPgV4HlekFvBt6/RlwvogU+Vj3qPfpRuI59pEgIoNUdaTXccQCq4sDYqEu8vdlevn2BWKhLiKhJDlHRAYBg8I2jQyrg/rAurB9GcBZB52ioIyq5ovINqAGsOlI73kstXQHFV/kmGF1cYDVxQHHXF2o6khVbRO2RP2PzrGUdI0xpiQygQZh66mhbYctIyJlgKpAblEntaRrjDGHNxtIE5FGIlIW6AOMPajMWOC60OsrgW+0mCt0x9I43bjvq4ogq4sDrC4OsLoIE+qjHQx8BSQBb6vq7yIyHJijqmOBt4D3RWQ5sJlgYi6SxPpAYmOMSSTWvWCMMS6ypGuMMS6ypBunRKShiCz0Oo5EEKrLv5by2D8iHU8sse9Z5FnSpWCohzl2NQQOm3Ttu2EiLS6Troh8ISK/iMjvoTtKEJE/ROQxEZkvIrNEpE5o+8mh9QUi8uj+lomIdBaRGSIyFlgkIsNF5Paw93hMRIZ48gGdSxKRN0L1MFlEKojIQBGZHaqH/4pIRQARGSUir4nIHBFZJiIXh7b3E5ExIjJdRNJF5KHQ9pivj1ArbPFh6uBkEfky9B2ZISJNQuVHiciVYcfvb6U+CfxJROaJyB2hOhkrIt8AU0WkkohMFZG5oe/RwbeCxjwROU5EJoS+FwtF5CoReTD0XVkoIiP3374qIq1D5eYDt3oceuIpyeQQsbIA1UP/rQAsJHjbnQI9Q9ufBoaFXo8Hrg69vgn4I/S6M7ATaBRabwjMDb32ASuAGl5/1iLqoCGQD7QMrY8GrgmPGXgUuC30ehTwZeizpRG8pbE80A9YH6rD/fXZJh7qo4g6mAqkhbadRXDs5P46uDLs+PDvwviw7f1C9bP/e1YGqBJ6XRNYzoGRP394XQ8O6+oK4I2w9ar7P19o/f2wfz+/AeeGXj8DLPQ6/kRa4rKlC/w99Fd4FsG7QdKAfQQTLMAvBP9BAnQAPg29/vCg8/ysqqsAVHU1kCsirYCuwK+qWuSdJTFglarOC73e/5mbhVp3C4C+QNOw8qNVNaCq6cBKoElo+xRVzVXV3cD/gHPiqD4OVwcdgU9FZB7wOlCvFOedoqqbQ68FeFxEfgO+Jni/fZ2jitp9C4ALReQpEfmTqm4DuoSmI1wAnAc0FZHjgeNV9bvQce97FXCiirv+KhHpDFwAdFDVXSIynWCLLU9Df5oBP84+286D1t8k2MqpC7wdiXijbG/Yaz/Bluoo4FJVnS8i/Qi24vY7eFC2FrM9Hurj4DqoA2xV1ZaHKZtPqEtNRHxA2SLOG/7d6AvUAlqrap6IrCb4nYsbqrpMRM4EegCPishUgl0HbVR1nYg8TJx9pngVjy3dqgTnr9wV6qtrX0z5WQR/WkHxd4t8DnQH2hK8CyUeVQbWi0gywWQR7i8i4hORk4GTgKWh7ReKSHURqQBcCvwQ2h6P9bEdWCUifwGQoDNC+1YDrUOvLwGSQ693EKy3I6kKbAwl3C7AiRGPOspEJAXYpar/IdhlcGZo1yYRqUTwFlZUdSuwVUTOCe0/+DtkjlLctXQJ9kveJCKLCSaNWcWUvx34j4jcHzp225EKquo+EZlGsKXkj1TALnsA+AnICf03PJmsBX4GqgA3qeqe0LWTn4H/EpzQ4z+qOgfiuj76Aq+KyDCCifVjYD7wBjAm1DX1JQdas78B/tD2UcCWg873ATAu9DN8DrAk6p8g8poDz4hIAMgDbib4B3YhkE1wnoH9+gNvi4gCk90ONNEl/G3Aoav3u1VVRaQPwYtqh736HPrJORf4S6jfM2GIyCiCF4s+O2h7P4I/MQcf5piErQ9jvBKP3Qsl1RqYF7oIcgtw1+EKSfAxHMuBqZZgrD6MiZaEb+kaY0wsORZausYYEzMs6RpjjIss6RpjjIss6RpjjIss6RpjjIv+HxfH4AHCSGZ5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on Crema D"
      ],
      "metadata": {
        "id": "zbMKcUF6kFHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 8\n",
        "srk = 44100\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = srk)      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"CREMA//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"CREMA//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"CREMA//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdCXkt-_jNZr",
        "outputId": "d310e31b-680f-49d4-e8b5-0396fda51d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (3430, 352800, 1) (3430, 4)\n",
            "Test Data (735, 352800, 1) (735, 4)\n",
            "Val Data (735, 352800, 1) (735, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.load_weights('TESS//models//paper_1_acc.h5')\n",
        "print(m.evaluate(X_test,Y_test))\n",
        "m.load_weights('TESS//models//paper_1_loss.h5')\n",
        "m.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkmoDskakOgZ",
        "outputId": "cdd09c22-b83a-4073-b121-e1d1104e93bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 184s 6s/step - loss: 3.7487 - accuracy: 0.4381\n",
            "[3.748687982559204, 0.43809524178504944]\n",
            "23/23 [==============================] - 119s 5s/step - loss: 3.7487 - accuracy: 0.4381\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.748687982559204, 0.43809524178504944]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(m.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(m.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "T5_hDwADkUaJ",
        "outputId": "87e04a70-405e-403f-92d2-76b9e76e13eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.41706556974951264\n",
            "Kappa: 0.25798408682579843\n",
            "Accuracy: 0.4380952380952381\n",
            "Jaccard Score: 0.27489420512035523\n",
            "Precision: 0.459530120713349\n",
            "Recall: 0.4513444915802786\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.60      0.56       176\n",
            "           1       0.44      0.10      0.16       204\n",
            "           2       0.33      0.61      0.43       176\n",
            "           3       0.53      0.50      0.52       179\n",
            "\n",
            "    accuracy                           0.44       735\n",
            "   macro avg       0.46      0.45      0.42       735\n",
            "weighted avg       0.46      0.44      0.41       735\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on SAVEE"
      ],
      "metadata": {
        "id": "f6QhzeOalzw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 8\n",
        "srk = 44100\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = srk)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"SAVEE//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"SAVEE//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"SAVEE//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDfp2ZdLl2V1",
        "outputId": "e06c86e0-3031-4b3f-a2ed-43d1954fa7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (207, 352800, 1) (207, 4)\n",
            "Test Data (45, 352800, 1) (45, 4)\n",
            "Val Data (44, 352800, 1) (44, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.load_weights('TESS//models//paper_1_acc.h5')\n",
        "print(m.evaluate(X_test,Y_test))\n",
        "m.load_weights('TESS//models//paper_1_loss.h5')\n",
        "m.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHkYYBFOv9ss",
        "outputId": "a9bf21ad-8e57-43ea-85e3-ec68b8421bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 22s 17s/step - loss: 2.4457 - accuracy: 0.6000\n",
            "[2.445659637451172, 0.6000000238418579]\n",
            "2/2 [==============================] - 8s 3s/step - loss: 2.4457 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.445659637451172, 0.6000000238418579]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(m.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(m.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "gVfGDyrqwA0u",
        "outputId": "90c83ce1-49a2-4be3-c34c-915770928c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.48542510121457483\n",
            "Kappa: 0.44060773480662985\n",
            "Accuracy: 0.6\n",
            "Jaccard Score: 0.3670634920634921\n",
            "Precision: 0.46977124183006536\n",
            "Recall: 0.5194444444444445\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.50      0.53        10\n",
            "           1       0.50      0.80      0.62        10\n",
            "           2       0.82      0.78      0.80        18\n",
            "           3       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.60        45\n",
            "   macro avg       0.47      0.52      0.49        45\n",
            "weighted avg       0.56      0.60      0.57        45\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paper 2"
      ],
      "metadata": {
        "id": "lNt6VRSta7uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def findmaxsize(rslt_df):\n",
        "\n",
        "    sizes = []\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "      filename = row['path']\n",
        "\n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      #print(y.shape)\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      \n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        "      #print(spect.shape)\n",
        "      \n",
        "      # Adding the size to the list\n",
        "      sizes.append(spect.shape)\n",
        "    print(f'The sizes of all the mel spectrograms in our data set are equal: {len(set(sizes)) == 1}')\n",
        "\n",
        "    # Checking the max size\n",
        "    print(f'The maximum size is: {max(sizes)}')\n",
        "\n",
        "\n",
        "    return max(sizes)\n",
        "\n",
        "\n",
        "X = pd.read_csv('TESS/TESS_details.csv',usecols=['labels','path'])\n",
        "options = ['angry', 'happy','neutral','sad'] \n",
        "\n",
        "time = 4\n",
        "rslt_df = X[X['labels'].isin(options)]\n",
        "\n",
        "max_x,max_y = findmaxsize(rslt_df)"
      ],
      "metadata": {
        "id": "uCEifEYpwO8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd937031-16ac-49e6-bd3b-add440025173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sizes of all the mel spectrograms in our data set are equal: False\n",
            "The maximum size is: (64, 299)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T=80\n",
        "max_x = 64\n",
        "max_y = 299\n",
        "import keras\n",
        "def AlexNet(input_shape):\n",
        "    \n",
        "    X_input = Input(input_shape)\n",
        "    \n",
        "    X = Conv2D(96,(11,11),strides = 4,name=\"conv0\")(X_input)\n",
        "    X = BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
        "    \n",
        "    X = Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3 ,name='bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max2')(X)\n",
        "    \n",
        "    X = Reshape((36,256))(X)\n",
        "\n",
        "    X= LSTM(256,return_sequences=True)(X)\n",
        "    X= LSTM(256)(X)\n",
        "\n",
        "    \n",
        "    #X = Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
        "    \n",
        "    #X = Dense(4096, activation = 'relu', name = 'fc1')(X) \n",
        "    \n",
        "    \n",
        "\n",
        "    model = Model(inputs = X_input, outputs = X, name='AlexNet')\n",
        "\n",
        "    return model\n",
        "\n",
        "def paper_2():\n",
        "    input_layer = Input((int(max_y/T)+1,max_x,T,3))\n",
        "    alex = AlexNet((227,227,3))\n",
        "    \n",
        "    for i in range(int(max_y/T)+1):\n",
        "      #print(input_layer[:,0,:,:,:].shape)\n",
        "      inp = keras.layers.Resizing(227,227)(input_layer[:,i,:,:,:])\n",
        "      \n",
        "      cnn = alex(inp)\n",
        "\n",
        "      #cnn = Reshape((1,4096))(cnn)\n",
        "\n",
        "      if i == 0:\n",
        "        output_layers = cnn\n",
        "      else:\n",
        "        output_layers = Concatenate(axis = 1)([output_layers,cnn])\n",
        "      \n",
        "    \n",
        "    #print(len(output_layers))\n",
        "    #lstm = LSTM(256,return_sequences=True)(output_layers)\n",
        "    #lstm = LSTM(256,return_sequences=True)(lstm)\n",
        "    #lstm = LSTM(256)(lstm)\n",
        "    \n",
        "    out = Dense(4,activation='softmax')(output_layers)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return Model(inputs=input_layer,outputs=out)\n",
        "p2 = paper_2()\n",
        "p2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl6jknbobiNW",
        "outputId": "2e3b9d41-cd94-4d05-d5b2-a20e7c58afad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 4, 64, 80,   0           []                               \n",
            "                                3)]                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 64, 80, 3)   0           ['input_1[0][0]']                \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 64, 80, 3)   0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " resizing (Resizing)            (None, 227, 227, 3)  0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resizing_1 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2 (Sl  (None, 64, 80, 3)   0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " AlexNet (Functional)           (None, 256)          4803328     ['resizing[0][0]',               \n",
            "                                                                  'resizing_1[0][0]',             \n",
            "                                                                  'resizing_2[0][0]',             \n",
            "                                                                  'resizing_3[0][0]']             \n",
            "                                                                                                  \n",
            " resizing_2 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3 (Sl  (None, 64, 80, 3)   0           ['input_1[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 512)          0           ['AlexNet[0][0]',                \n",
            "                                                                  'AlexNet[1][0]']                \n",
            "                                                                                                  \n",
            " resizing_3 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 768)          0           ['concatenate[0][0]',            \n",
            "                                                                  'AlexNet[2][0]']                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 1024)         0           ['concatenate_1[0][0]',          \n",
            "                                                                  'AlexNet[3][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 4)            4100        ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,807,428\n",
            "Trainable params: 4,804,676\n",
            "Non-trainable params: 2,752\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p2.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8FyOwI8ZbnWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing  on Emo db"
      ],
      "metadata": {
        "id": "cyk-PI0-boI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "def extract_mel_spectrogram(df,max_x = max_x,max_y = (int(max_y/T)+1)*T):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path']\n",
        " \n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      #print(y.shape)\n",
        "      # Computing the mel spectrograms\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      \n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        " \n",
        "            \n",
        "      \n",
        "      if spect.shape[1] != max_y:\n",
        "                #print('Sizes arent same')\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        "      s=[]\n",
        "      for i in range(int(max_y/T)):\n",
        "        #print(spect[:,i*64:(i+1)*64].shape)\n",
        "        q=spect[:,i*T:(i+1)*T]\n",
        "        delta = librosa.feature.delta(q).reshape((max_x,T,1))\n",
        "        d_delta = librosa.feature.delta(q,order = 2).reshape((max_x,T,1))\n",
        "        #print(q.shape,delta.shape,d_delta.shape)\n",
        "        q = q.reshape((max_x,T,1))\n",
        "\n",
        "        z = np.concatenate((q,delta,d_delta),axis = -1)\n",
        "        #print(z.shape)\n",
        "        s.append(z)\n",
        "      mel_specs.append(np.asarray(s))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  #print(len(mel_specs),mel_specs[0].shape)\n",
        "  mel_specs = np.asarray(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        " \n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "#X_train_spec = np.expand_dims(X_train_spec,axis=-1)\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        " \n",
        " \n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "#X_test_spec = np.expand_dims(X_test_spec,axis=-1)\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        " \n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "#X_val_spec = np.expand_dims(X_val_spec,axis=-1)\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z46dmZDtbvxG",
        "outputId": "2d01484a-6720-4840-ad35-15ed685a241a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 4, 64, 80, 3) (237, 4)\n",
            "(50, 4, 64, 80, 3) (50, 4)\n",
            "(51, 4, 64, 80, 3) (51, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "print(p2.evaluate(X_test_spec,Y_test_spec))\n",
        "p2.load_weights('TESS//models//paper_2_loss.h5')\n",
        "p2.evaluate(X_test_spec,Y_test_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm-rbrtScjNV",
        "outputId": "81d88d15-d279-4b96-d71b-b8b528dbbc9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 15s 755ms/step - loss: 3.3971 - accuracy: 0.3000\n",
            "[3.3970611095428467, 0.30000001192092896]\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 3.0904 - accuracy: 0.4000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.0904080867767334, 0.4000000059604645]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "U17mhY2Rcp2i",
        "outputId": "db1e98ce-fb71-4975-ad85-7de3e42895ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.2151359504300681\n",
            "Kappa: 0.02343749999999989\n",
            "Accuracy: 0.3\n",
            "Jaccard Score: 0.1327468487394958\n",
            "Precision: 0.23035714285714287\n",
            "Recall: 0.2409090909090909\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.41      0.49        22\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.18      0.45      0.26        11\n",
            "           3       0.14      0.10      0.12        10\n",
            "\n",
            "    accuracy                           0.30        50\n",
            "   macro avg       0.23      0.24      0.22        50\n",
            "weighted avg       0.33      0.30      0.29        50\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on  Crema D"
      ],
      "metadata": {
        "id": "dcPhzd7xbwai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  #l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "def extract_mel_spectrogram(df,max_x = max_x,max_y = (int(max_y/T)+1)*T):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path']\n",
        " \n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      #print(y.shape)\n",
        "      # Computing the mel spectrograms\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      \n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        " \n",
        "            \n",
        "      \n",
        "      if spect.shape[1] != max_y:\n",
        "                #print('Sizes arent same')\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        "      s=[]\n",
        "      for i in range(int(max_y/T)):\n",
        "        #print(spect[:,i*64:(i+1)*64].shape)\n",
        "        q=spect[:,i*T:(i+1)*T]\n",
        "        delta = librosa.feature.delta(q).reshape((max_x,T,1))\n",
        "        d_delta = librosa.feature.delta(q,order = 2).reshape((max_x,T,1))\n",
        "        #print(q.shape,delta.shape,d_delta.shape)\n",
        "        q = q.reshape((max_x,T,1))\n",
        "\n",
        "        z = np.concatenate((q,delta,d_delta),axis = -1)\n",
        "        #print(z.shape)\n",
        "        s.append(z)\n",
        "      mel_specs.append(np.asarray(s))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  #print(len(mel_specs),mel_specs[0].shape)\n",
        "  mel_specs = np.asarray(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        " \n",
        "train_path = \"CREMA//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "#X_train_spec = np.expand_dims(X_train_spec,axis=-1)\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        " \n",
        " \n",
        "test_path = \"CREMA//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "#X_test_spec = np.expand_dims(X_test_spec,axis=-1)\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        " \n",
        "val_path = \"CREMA//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "#X_val_spec = np.expand_dims(X_val_spec,axis=-1)\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu5GkH8Nb7hl",
        "outputId": "83e18e4f-ed9d-4676-908d-af70d83ab2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3430, 4, 64, 80, 3) (3430, 4)\n",
            "(735, 4, 64, 80, 3) (735, 4)\n",
            "(735, 4, 64, 80, 3) (735, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "print(p2.evaluate(X_test_spec,Y_test_spec))\n",
        "p2.load_weights('TESS//models//paper_2_loss.h5')\n",
        "p2.evaluate(X_test_spec,Y_test_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTBE8vTjgG2K",
        "outputId": "93391235-0591-43c6-d391-7fc638b75349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 19s 161ms/step - loss: 4.6277 - accuracy: 0.2735\n",
            "[4.627744197845459, 0.27346938848495483]\n",
            "23/23 [==============================] - 4s 153ms/step - loss: 4.7039 - accuracy: 0.2830\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.703924655914307, 0.2829931974411011]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "i-RdNsiWgfqI",
        "outputId": "83e83ffa-12ad-48d7-abb1-5fed401b10d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.19961506418693392\n",
            "Kappa: 0.042772688694430516\n",
            "Accuracy: 0.27346938775510204\n",
            "Jaccard Score: 0.12209327315710294\n",
            "Precision: 0.21715168787283695\n",
            "Recall: 0.28317832656170644\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.03      0.05       176\n",
            "           1       0.00      0.00      0.00       204\n",
            "           2       0.22      0.56      0.32       176\n",
            "           3       0.35      0.55      0.43       179\n",
            "\n",
            "    accuracy                           0.27       735\n",
            "   macro avg       0.22      0.28      0.20       735\n",
            "weighted avg       0.21      0.27      0.19       735\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD4CAYAAABPLjVeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVdrA8d8zkwQC0jsk0hVBRRSwYMFGUQHXwqKyK67KWlDsa8HGqqu4a9sXV1ER1wq6KEizo1gQEOk19DQCCaFDMjPP+8cMYRIguUmmZXi+fu6HOfeee+e51/Bwcu6554qqYowxJjJc0Q7AGGOOJpZ0jTEmgizpGmNMBFnSNcaYCLKka4wxEZQQ7i+oc0xbGx4RsLtgX7RDiBl7M2dFO4SYMazr36IdQsx4ff3HUtljFG5d6zjnJDZsU+nvKy9r6RpjTASFvaVrjDER5fNGO4JSWdI1xsQXryfaEZTKkq4xJq6o+qIdQqks6Rpj4ovPkq4xxkSOtXSNMSaC7EaaMcZEkLV0jTEmctRGLxhjTATZjTRjjIkg614wxpgIshtpxhgTQdbSNcaYCLIbacYYE0ExfiPN0dSOInKHiNQLdzDGGFNZql7HS1lEpI+IrBSRNBF58DDbXxSRBYFllYjkl3VMpy3dJsBcEZkPjAW+UHt3uzEmFoWoT1dE3MBo4GIgHX8OnKyqy4q+SvXuoPp3AF3KOq6jlq6qjgDaA28BQ4DVIvKMiLQtz0kYY0zY+XzOl9J1B9JUda2qFgAfAQNKqX8N8GFZB3X85ohAyzY7sHiAesAnIjLK6TGMMSbs1Od4EZGhIjIvaBkadKQWwKagcnpg3SFEpCXQGvi2rPAcdS+IyHDgz8BW4E3gflUtFBEXsBp4wMlxjDEm7LyFjquq6hhgTAi+dRDwiTroKHbap1sPuEJVNwSvVFWfiFxWgQCNMSY8Qjd6IQNIDSqnBNYdziDgdicHLbN7IdCZPKhkwj1AVZc7+SJjjImIcnQvlGEu0F5EWotIEv7EOrlkJRHpgL9h+ouT8Mps6aqqNzBk4lhV3ejkoOF24UXn8tyoR3G73fz3nfG8+MLrxbYnJSXx+hv/5JRTTiQvbxs3XH8nGzdmcP75PXhi5AMkJiVSWFDIoyOe5Yfv/dfpyqv7ce99t6KqZGflcPNN95CXuy0apxc2vXv15IUXRuJ2uRj79oeMen50tEMKmx9nz+PZl17D6/NxZb8+3PSngcW2P/fy68yZvwiAffv3k7ctn1+++IQ5vy3kuVcO/ra5buMmnn/yQS4896yIxh8unc47hYGP3YDL7eLH8d/wxX8+K7b9ohsvo8egC/F5vOzK28E7D7xKXsbWKEVbQSFq6aqqR0SGAV8AbmCsqi4VkZHAPFU9kIAHAR85HdElTuqJyA/4h0LMAXYHBdW/rH3rHNM2pEPLXC4X8xd8zeX9rycjI5vvfviUG2+4i5Ur0orq3HTzdXQ6sQN3D3+UK6+6jMv69eKG6+/k5JM7kpOzlezsHE7oeBwTP3ubE47rgdvtZmXaL3Tv2pu83G2M/Pvf2LN3L88+80ooQ2d3wb6QHq88XC4Xy5fOos8l15CensXsX6Yx+E+3sXz56qjEszdzVtiO7fV6uXTQTbzx0jM0bdyQP940nOef+BttW7c8bP33P57E8tVreOrhe4qt375jJ30H/oVvPnuX5OrVwxbvsK5/C9uxg4nLxd+/e5mXBv+dbdl5PDT5H7x1x8tkpaUX1TnuzE6s+301hfsKOHdwL44/oxNvDHsxIvEBvL7+Y6nsMfbNetdxzql+zp8q/X3l5XT0wqPAZcBI4F9BS8Sd1rUza9duYP36TRQWFjLxkylceulFxepcculFfPD+RAA++3Q65/U8E4BFi5aRnZ0DwPJlq0iuXp2kpCREBBGoWSMZgFq1jyE7KyeCZxV+3bt1Yc2a9axbt5HCwkImTJhE/369ox1WWCxevopjU5qT2qIZiYmJ9L3wPL6dNfuI9ad9/T2XXNTzkPVffjeLc87oGtaEG0mtT2lHzoZstm7KwVvoYd7nP9G5V9didVb9spTCfQUArPt9FXWb1o9GqJWi3kLHSzQ4upGmqt+HOxCnmjdvQkZ6VlE5IyObrt06F6vTrHnTojper5cd23dSv0G9Yt0FAy7vw8KFSyko8P+A3XPXY/z86zT27NnLmjXruffuxyNwNpHTvEVTNqVnFpXTM7Lo3q3McdxVUs6WrTRt3Kio3KRxQxYvXXnYupnZm8nIyub00zofsm361z/w50F/CFuckVa3SX22ZeYWlbdl5dH6lPZHrN9j4IUsnfl7JEILrRif8MbpY8A7RWRHiWWTiHwqIm3CHWSodTihPU+OfIC77hwBQEJCAjfedB3n9ujP8e3OZOmSFdxz361RjtJEwvSvv6dXz7Nxu93F1m/ZmsfqtevocfppUYosuk6//BxantyGL8ccct8o9oXu4YiwcNq98BJwP/6BwSnAfcAH+J/QGFuycvCA44LCHaGKFYDMzM20SGlWVG7RoilZmZuL1cnKzC6q43a7qV2nVlErt3nzprz/wX/469D7WbfOf1/w5JNPACgqfzpxGqeffmpI4462zIxsUlOaF5VTWjQjMzM7ihGFT+NGDcnO2VJU3pyzlcaNGhy27vSvv6fvxT0PWT/j2x+48NyzSEyInzmh8jfnUa/5wetQr1l98jfnHlKvQ4+T6DvsCl696Tk8BbE9Y9dhhW70Qlg4Tbr9VfV1Vd2pqjsCA4p7q+p4/EMlilHVMaraVVW7JiXWDmnA839bRNu2rWjZMoXExESuuOoypk37plidadO+4drrrgDg8j/0LRqhUKdOLSb8702eeHwUv87+rah+ZuZmju/QjgYN/f1X519wNitXphFP5s5bQLt2rWnVKpXExEQGDhzA51O+jHZYYXFih+PYmJ5JemY2hYWFTP/me84/+4xD6q3dsIkdO3dxyoknHLJt+lczD9vPW5WtX5hG41bNaJDSGHdiAl379WDhV/OK1Unt1IrBzwzl1ZueY2duaBtMERPjLV2n/4zvEZGBwCeB8lXAgVvxEZ34xuv1ct+9TzLxs3G43S7ee/cTVixfzcMj7uL3+YuZPu0b3n1nAmPe/Be/L/yWbdvy+cuQ4QDc/Nc/06ZNSx548A4eePAOAP4wYAjZ2Tk8949XmP7FhxQWeti0MYNbb4mvh+y8Xi/D7xrBtKkf4Ha5GPfOeJYtWxXtsMIiIcHNw3ffyl/vGYHX6+UPl/WiXZuW/N8b/6VTh+M4/xx/Ap7+9ff0veg8RIrfwM7I2kx2zla6djkpGuGHjc/r46PH3mL4fx/B5Xbx04TvyFqdTr+7/8iGxWtY9PU8rnzoT1SrUZ2hr94LQF7GVl69+bkoR15OMd6n63TIWBvgZeBM/El2NnA3/qczTlPVH4+0b6iHjFVl0RwyFmvCOWSsqonUkLGqIBRDxvZOfclxzkm+9K6IDxlzOnphLdDvCJuPmHCNMSbiYryl63TCm0bAzUCr4H1U9S/hCcsYYyooxt8c4bRPdxIwC/gaiO1XbRpjjm7x0NIFaqiqdTwZY2JfjLd0nQ4ZmyIil4Q1EmOMCYUYH6frtKU7HHhYRPYDhYDgf5lEaAfhGmNMZXli+4EOp6MXaolIffzvSYuP2T+MMfEpxt+Z63T0wk34W7spwALgDOBn4MLwhWaMMRUQJ326w4FuwAZVPR//3LrbwxaVMcZUVJw8BrxPVff5552Vaqq6QkSOD2tkxhhTEXEyZCxdROoCnwFficg24LDvTDPGmKjyxvajBE5vpB2YyfkJEfkOqAPMCFtUxhhTUTHep1vuyUJj6S0SxhhziBhPuk5vpBljTNUQwocjRKRP4G3oaSLy4BHqDBSRZSKyVEQ+KOuY8TMtvjHGAOoLzThdEXEDo4GLgXRgrohMVtVlQXXaAw8BPVR1m4g0Luu4lnSNMfEldN0L3YG0wNS2iMhHwABgWVCdm4HRqroNQFXLfI24dS8YY+KL1+t4CX6fY2AZGnSkFsCmoHJ6YF2w44DjROQnEZktIn3KCs9ausaY+FKOlm7gfY9jKvFtCfinR+iJ/4ndH0TkJFXNL20HY4yJH6HrXsgAUoPKKYF1wdKBX1W1EFgnIqvwJ+G5RzqodS8YY+KLqvOldHOB9iLSWkSSgEHA5BJ1PsPfykVEGuLvblhb2kGtpWuMiS8haumqqkdEhgFfAG5grKouFZGRwDxVnRzY1ktEluF/q879qppb2nEt6Rpj4kuIhowBqOo0YFqJdY8FfVbgnsDiSNiTbq2k5HB/RZVhr2A/yJuxItohxIybPYXRDiG+xMPcC8YYU1VojD8GbEnXGBNfQti9EA6WdI0x8SVO5tM1xpiqwVq6xhgTQR67kWaMMZFj3QvGGBNB1r1gjDGRY0PGjDEmkqyla4wxEWRJ1xhjIsgeAzbGmMgJ1TvSwsWSrjEmvljSNcaYCIrx0QuO3hwhIneISL1wB2OMMZXmU+dLFDh9XU8T/O98nyAifUREwhmUMcZUWDwkXVUdgf9la28BQ4DVIvKMiLQNY2zGGFNu6vU5XqLB8YspA6+lyA4sHqAe8ImIjApTbMYYU37x0NIVkeEi8hswCvgJOElVbwVOA64MY3zGGFMu6lPHS1kC3akrRSRNRB48zPYhIrJFRBYElpvKOqbT0Qv1gStUdUOxk1P1ichlDo9hjDHhF6IWrIi4gdHAxUA6/vtak1V1WYmq41V1mNPjOkq6qvq4iJwqIgMABX5S1fmBbcudfpkxxoRd6LpquwNpqroWQEQ+AgYAJZNuuTjtXngUeAdoADQE3haREZX5YmOMCQf1+BwvIjJUROYFLUODDtUC2BRUTg+sK+lKEVkkIp+ISGpZ8TntXhgMdFbVfQAi8iywAHjK4f7GGBMZ5WjpquoYYEwlvu1z4ENV3S8if8XfOL2gtB2cJt1MoDqwL1CuBmRUNMrK6nlhD5585kHcbjcfvvs/Rr/8VrHtSUmJvPSff3By545s25bPrX+5j/RNmaSkNmfm7MmsSVsPwPx5i3jo3pHUPKYGE6f+t2j/Zs2bMPHjKTzx8HORPK2w692rJy+8MBK3y8XYtz9k1POjox1S2Py0YDnPvf0pPp/yhwtP58bLLyq2/flxnzJ3aRoAewsK2bZ9Jz+O+wcAtz79OotXr+eUDm34vwdvjnjsoVa7ZxeOffImcLvY+uFXZI+eWGx7o8G9aTTkEvD68O7ey4a/vcq+1elIYgItn72VGp3bgc/HpsffYucvS6J0Fs6FcO6FDCC45ZpCibynqrlBxTfxDzYoldOkux1YKiJf4e/TvRiYIyKvBL74TofHqTSXy8VTo0Zw7RU3k5WZzdRvxvPljO9YvXJtUZ1Bg69ge/4Ozu56Cf2v6MvDT9zDbTfeB8D69Zvofd5VxY65e9eeYuumfTue6Z9/HZkTihCXy8UrLz9Nn0uuIT09i9m/TOPzKV+yfPnqaIcWcl6fj2fe+h+vj7iFJg3qcu1DL9Kz64m0TWlaVOf+IX8o+vzB9B9Yse7g36Uh/c9n7/4CPvn6l4jGHRYuF8c+9VdWXfs4hVm5nDD1efK/nMO+1elFVXI/+4Et730BQJ2Lu5H6+F9YPXgkDa+9GIBlFw0noUEd2r/7GMsvvQ80tuc2CGGf7lygvYi0xp9sBwHXBlcQkWaqmhUo9gfKvMfldJzup8DDwHfATOARYBLwW2CJmFNOO4n16zaycUM6hYUeJk2cTq++xVvzvS65gI8/mgTA1Elfcva5pzs+fuu2LWnYqAG//hLR0wq77t26sGbNetat20hhYSETJkyif7/e0Q4rLJakbSS1aUNSmjQkMSGBPmd1YebcI7fQZvz0O33PPrWofPpJx1EzuXokQg27mqe0Z//6LAo2bkYLPeRN+pG6vYr/ffDt2lv02V2jelFSTW6fyo6fFwPgyd2Od8duanZuF7ngKyhUQ8ZU1QMMA77An0wnqOpSERkpIv0D1e4UkaUishC4E//DY6VyOnrhHRFJAjrgb+muVNUCJ/uGWrNmjcnKyC4qZ2dupstpJxWr0zSojtfrZceOXdSrXxeAY49twYyZH7Nr5y5GPf1v5syeX2zfAVf0ZfKnM8J8FpHXvEVTNqVnFpXTM7Lo3q1LFCMKn5y8fJo2qFtUbtygDotXbzxs3cwteWTk5NL9xPaRCi+ikprVpyBra1G5IDuXY7oceq6Nru9Lk5sH4EpKYOUfHwVgz/L11L24G3mf/UBS84bUOKktic0bwoIY/+0ohA+aqeo0YFqJdY8FfX4IeKg8x3SUdEXkEuB1YA0gQGsR+auqTj9C/aHAUIC6NZpRs1r98sQUNjmbt9D95IvJ37adkzp35K33XuGCswawa+fuojr9r+jL8FvKdQ1NFTbjp9+56IzOuF2OH86MS1vemc6Wd6ZT//JzaXbn1ay/+xW2fvQ1ye1S6DjtX+xPz2H3bysgSo/Olod6oh1B6Zz+pL0AnK+qPVX1POB84MUjVVbVMaraVVW7hjrhZmXl0KzFwb65ps2bkJWVU6xOdlAdt9tN7drHsC0vn4KCQvK3bQdg8cJlbFi3iTZtWxXtd0Kn40lwu1m8sFLD8GJSZkY2qSnNi8opLZqRmZldyh5VV+P6dcnOzS8q5+Rup0n9OoetO+Pn3+nb49TDbosHBVl5JDVrWFROatqAgqy8I9bPmzSLur0D3Q9eH5ueHMuy3nez5sZ/4K5dk31ro3b/3DH1OV+iwWnS3amqaUHltcDOMMRTpoXzl9C6zbGkHtuCxMQEBlzRl69mfFeszlfTv+PqQQMAuHRAL36a9SsA9RvUwxVo0RzbMoXWbY5l4/qDw/Auv7IvkyYetvFe5c2dt4B27VrTqlUqiYmJDBw4gM+nfBntsMKiU9tUNmZtIT0nl0KPhxk//855XTsdUm9dxmZ27t5D5+NaRT7ICNm9cDXVWzcjKbUxkphA/QFnk//VnGJ1qrVuVvS5zoVd2b/Of1/IVT0JV3I1AGqf0xn1eIvdgItZvnIsUeB09MI8EZkGTMDfp3s1/kfirgBQ1Yml7RxKXq+XRx94hvc/eR2X28349z9l1Yo13PfQ7Sz8fSlfzZjJR+9N5OXX/sGP86aRv207t910PwBnnHUa9z40DE+hB5/Px4P3jiQ/f0fRsS+7vDd//uNtkTqViPJ6vQy/awTTpn6A2+Vi3DvjWbZsVbTDCosEt5uH/nIltz79Oj6fj8vPP512qc0YPX46ndqm0rPriYC/a6H3WV0oOVPpkMdeYX1GDnv2FXDxLU/wxC2D6HFKh2icSuV5fWx89A2Oe/9xcLnJHf81+1Ztovl917B7YRrbv5pL4yGXUPtsf1L1bN/FurtfBiChYV2Oe/9x1OejMDuPdcNfivLJOBOtFqxTog6Gf4jI26VsVlX9y5E2ptQ/McbHl0RO9q5t0Q4hZuya+0a0Q4gZSy6tzNj8+NI1/bNKz9Wdc+F5jnNO42++j/jc4E5HL9wQ7kCMMSYU1Bvb71hwOnqhOnAj0An/k2kAlNbCNcaYaIj17gWnN9LeBZoCvYHv8T8OF5UbacYYUxr1ieMlGpwm3Xaq+iiwW1XfAS4FnD/mZYwxERLrQ8acjl4oDPyZLyIn4n9lT+PwhGSMMRWnGgd9usCYwCvYRwCTgWOAR8MWlTHGVFCs9+k6Tbrv4n8XWiv880WC/7XsxhgTU3zxMHoB/4xi2/HPKLY/fOEYY0zlROsGmVNOk26KqvYJayTGGBMCsZ50nY5e+FlETiq7mjHGRJeq8yUaSm3pishi/HMtJAA3iMha/N0Lgv/x35PDH6IxxjgX6y3dsroXLotIFMYYEyJVesiYqm6IVCDGGBMK3jgZvWCMMVVCrLd0j+53lBhj4k4o514QkT4islJE0kTkwVLqXSkiKiJdyzqmJV1jTFwJ1egFEXEDo4G+QEfgGhHpeJh6tYDhwK9O4rOka4yJKyFs6XYH0lR1beDt5x8BAw5T7+/Ac8A+J/FZ0jXGxBWvz+V4EZGhIjIvaBkadKgWwKagcnpgXRERORVIVdWpTuOzG2nGmLhSnoceVHUMUKH3JYmIC/+b0oeUZz9LusaYuOIL3eiFDCA1qJwSWHdALeBEYGbg5aZNgcki0l9V5x3poJZ0jTFxJYRDxuYC7UWkNf5kOwi49uD36Hag4YGyiMwE7ist4YL16Rpj4kyoRi+oqgcYBnwBLAcmqOpSERkpIv0rGl/YW7pb9mwP91eYKsj7ybhohxAz6tXdG+0Q4koIuxdQ1WnAtBLrHjtC3Z5OjmndC8aYuOL1xfYv8JZ0jTFxJUozNjpmSdcYE1dC2b0QDpZ0jTFxJdYnvLGka4yJKzH+MmBLusaY+KJYS9cYYyLGY90LxhgTOdbSNcaYCLI+XWOMiSBr6RpjTARZS9cYYyLIW5VbuiKyk8M/VSeAqmrtsERljDEV5OB9k1FVatJV1VqRCsQYY0LBV5VbuiWJSGOg+oGyqm4MeUTGGFMJsT7hjaM50ESkv4isBtYB3wPrgelhjMsYYyrEV44lGpxOPPl34Axglaq2Bi4EZoctKmOMqSCfiOMlGpwm3UJVzQVcIuJS1e+ArmGMyxhjKsRbjiUanPbp5ovIMcAPwPsikgPsDl9YxhhTMbE+esFpS3cAsAe4G5gBrAH6hSsoY4ypKB/ieImGMpOuiLiBKarqU1WPqr6jqq8EuhuMMSamaDmWsohIHxFZKSJpIvLgYbbfIiKLRWSBiPwoIh3LOmaZSVdVvYBPROo4iNEYY6LKJ86X0gQanKOBvkBH4JrDJNUPVPUkVT0FGAW8UFZ8TrsXdgGLReQtEXnlwOJw35DrdXFPFi+aybKls7jvvtsO2Z6UlMR7777KsqWzmPXDZFq2TAGgfv26fPHFeHK3ruClF/9ebJ8nn3yAtLRfyd26IiLnEA29e/Vk6ZIfWLHsRx64//ZohxNW7nadSR7+Esl3vULiOQMO2Z7Q5TxqPPgm1W8bRfXbRpFw2gVF26ROA6pf/wjJd75A8h0vIHUbRTL0kEvu0ZXUz9/k2GlvU/fGgUesV/Ois2m75AuqdWrv3+/MU0kZ/3+kTHyNlPH/R3L3zpEKuVJCOGSsO5CmqmtVtQD4CH9XaxFV3RFUrImDBrTTG2kTA0ux73O4b0i5XC5efvkpLrn0WtLTs/j5pylMmfIVK1asLqpzw5BB5Ofn07HTOVx9dX+efuphBv/pNvbt28+TT/6TTh2Pp1On44sdd+rUr/jPf8axdMkPkT6liHC5XLzy8tP0ueQa0tOzmP3LND6f8iXLl68ue+eqRoSkfjeyb9xT6I5cqt/yDzwr5qFbMopV8yz+mYKpYw/ZvdqVwyj4fiK+NYshqRporA+3L4XLRaMRt5N580N4sreSMv7f7P5uNoVriz/XJDWSqTP4cvYtXF60zrttO1nDHsO7JY+kdi1p9vozbLjwukifQbl5y9FVKyJDgaFBq8ao6pjA5xbApqBt6cDphznG7cA9QBJwQcntJTlt6dYN9OUWLUA9h/uGVLdup7BmzXrWrdtIYWEhEz6eTL9+vYrV6devF+++9wkAEydO5fzzewCwZ89efv55Lvv27z/kuHPm/E52dk74TyBKunfrUvy6TZhE/369ox1WWLhS2uHLzUa35YDXi3fxzySc0M3RvtKoBbjc/oQLULAfCgvCGG14VTvpeAo3ZuJJzwaPh13TZ1LzgjMPqVf/juvJHzsBLTh4rgUr1uDdkuf/nLYBqV4NEhMjFntFlaelq6pjVLVr0DLmCIc9IlUdraptgb8BI8qq7zTpXn+YdUPKEVfING/elE3pmUXljIwsWjRvekid9EAdr9fLjh07adAgKv9GxIzmLYpft/SMLJqXuG7xQmrXR7cfvM+r23ORWvUPqefudDrJtz9PtUH3ILUbAOBq2Bzdt5tq19xL9dueI7H3YIjSIPpQSGjcAE/2lqKyZ/NWEho3LFYn6YR2JDRtxJ4f5hzxODUvPpv9y9KgsDBssYZKCLsXMoDUoHJKYN2RfARcXtZBy5pl7BrgWqC1iEwO2lQLyCtlv6ImuzuhLm73MWXFYUxEeVb8hmfRT+D1kND1IqpdeTv73h4JLhfuliew99UH0O1bqTbwbhK69MQz/7tohxweIjR8YCg5j/zriFUS27akwT03kjn04QgGVnEhfEXaXKC9iLTGn2wH4c+HRUSkvaoe6KO7FCizv66sPt2fgSygIRD8f2UnsOhIOwWa6GMAqlVPDWmHWGZmNqkpzYvKLVo0IyMz+5A6KSnNycjIxu12U7t2LXJzt4UyjConM6P4dUtp0YzMEtctXuiOPKROg6Ky1GmA7izRRti7q+ij57dvSOo92L/v9jx8Wev9XROAd/kcXKnHQRVNup6cXBKaHrwRmNCkIZ6crUVlV81kktq1ovnbowBwN6xP038/SfYdj7N/6WrcTRrS9OXHyHn4eTybsiIef0WEak4FVfWIyDDgC8ANjFXVpSIyEpinqpOBYSJyEVAIbOPwvQLFlDW14wZgA3BoJ1CUzJu3kHbtWtGqVSoZGdkMvLo/f77+jmJ1pkz5ij8Nvopff53PFVdcysyZP0Up2tgxd94C2rVrffC6DRzAn/4cnyMYfBlrcDVohtRthO7Mw33SWez/uPhgGzmmLrorHwB3h674tqQH9k2D5BpQoxbs2YmrzYn4MtZG/BxCZf+SlSQe24KEFk3wbM7lmL492fzAs0Xbfbv2sP6cgyMamr89itx/vsH+patx1apJs1f/Tt5LY9n3+7JohF8hoXy8V1WnAdNKrHss6PPw8h7T0eiFEpOZJwGJwO5oTGLu9Xq5665HmfL5e7jdbsa9M57ly1fx2GP3Mv+3RUyZ+hVvj/uIt8e+xLKls8jLyy+WXFau/JnatWqRlJRIv369ufSy61ixYjXPPP0wf/zj5dSokcyatDm8Pe5DnnrqxUifXth4vV6G3zWCaVM/wO1yMe6d8SxbtiraYYWHz0fBlLFUv/4RcLnwzP8OzUkn8YKB+DLX4F3xGwln9iWhQ1fU54U9u9g/8VX/vqoUzHiX5BseAxG8GWvx/PZ1dM+nMrw+tj4zmmavP4O4Xez49EsK16MMzS0AABAqSURBVGyg3u1/Zv/SVeyZeeR5q2pf05/E1ObUu+U66t3iH7WQNfQhvHnbIxV9hcT6Y8Ci5RwOIyKCf6zaGap6yBMaJYW6e6Eq8/pi/e1NkbP9bz2iHULMyP40tpNYJLVd8kWlU+aLxw52nHPu3vhexFO009ELRdTvMyA+xxsZY6q0WJ9P12n3whVBRRf+aR33hSUiY4yphFj/1drpE2nBM4p58L854tBnK40xJspivU/XUdJV1RvCHYgxxoRCtCYnd8rpO9KOE5FvRGRJoHyyiJT5uJsxxkSaD3W8RIPTG2lvAA/hHwCMqi7C/3SGMcbElLi4kQbUUNU5UvwZdE8Y4jHGmEqJlxtpW0WkLYHzEZGr8D8ebIwxMSXWR8M7Tbq3459LoYOIZADrgNifWNMYc9TxSGy3dZ0m3QzgbeA7oD6wA//EDiPDFJcxxlRIbKdc50l3EpAPzAcyy6hrjDFREy/dCymq2ieskRhjTAhEayiYU06HjP0sIieFNRJjjAmBUL6CPRyctnTPBoaIyDpgPyD45745OWyRGWNMBcRL90LfsEZhjDEh4o3x7gWncy9sCHcgxhgTCvHS0jXGmCpBY7ylW+5JzI0xJpaFcu4FEekjIitFJE1EDnlTjojcIyLLRGRRYFKwlmUd05KuMSauhGqWMRFxA6Px39PqCFwjIh1LVPsd6BoYVPAJMKqs+CzpGmPiSgiHjHUH0lR1raoWAB9R4uUNqvqdqu4JFGcDKWUd1JKuMSaueFDHi4gMFZF5QcvQoEO1ADYFldMD647kRmB6WfHZjTRjTFwpz400VR2DfzKvShGRwfjfHXleWXXDnnTttePmcHbNyol2CDGjyaX1ox1CXAlhxskAUoPKKYF1xYjIRcAjwHmqur+sg1r3gjEmrmg5/ivDXKC9iLQWkST8b8uZHFxBRLoArwP9VdVRS8K6F4wxcSVULV1V9YjIMOALwA2MVdWlIjISmKeqk4HngWOAjwNv1tmoqv1LO64lXWNMXPFq6B6OUNVpwLQS6x4L+nxReY9pSdcYE1difWpHS7rGmLgS648BW9I1xsSVWB8vZUnXGBNXrHvBGGMiyLoXjDEmgkI5eiEcLOkaY+KKdS8YY0wE2Y00Y4yJIOvTNcaYCLLuBWOMiSC1G2nGGBM5cfEKdmOMqSqse8EYYyLIuheMMSaCrKVrjDERZEPGjDEmguwxYGOMiaAq3b0gIovhyGegqieHPCJjjKmEWE+6Zb0N+DKgHzAjsFwXWA55b1Cs6t2rJ0uX/MCKZT/ywP23RzucqDqarkVS9+40+O9/afD++9S49toj1qt27rk0mTmThOOPL1qX0KYN9UaPpsHbb1N/7FhISopEyGHjPq4LNe77NzXuH01izz8csj3htPOp+ejbJA//F8nD/0VCt4Ov/ar5j4+L1le//qFIhl1hqup4KYuI9BGRlSKSJiIPHmb7uSIyX0Q8InKVk/hKbemq6obAgS9W1S5Bmx4UkfnAIUHEEpfLxSsvP02fS64hPT2L2b9M4/MpX7J8+epohxZxR9W1cLmoNXw4+ffdh3fLFuq/9hr7f/oJ74YNxapJcjI1rrySgmXLDq50u6n9yCPseOYZPGvWILVrg8cT4RMIIXFR7fKb2fvmk+j2XJKHjcKzbC6ak16sWuGinyiY9Oah+xcWsPfleyMUbGiEqqUrIm5gNHAxkA7MFZHJqhr0A8NGYAhwn9PjltXSDfp+6RFUOKsc+0ZN925dWLNmPevWbaSwsJAJEybRv1/vaIcVFUfTtUjs0AFvRgberCzweNj37bdU69HjkHo1b7yR3R9+CAUFReuSunbFs3YtnjVrANAdO8AX6/NWHZkrtR2+3Cw0bzN4PXgW/khCx+7RDiustBz/laE7kKaqa1W1APgIGFDsu1TXq+oiyjG5mdPEeSPwqoisF5ENwKvAX5x+SbQ0b9GUTemZReX0jCyaN28axYii52i6Fq5GjfBt2VJU9m3ZgrtRo2J1Etq3x92oEQWzZxdfn5oKqtQdNYr6Y8ZQY9CgiMQcLlKnAZqfW1TW7blInfqH1Es48UyS73qB6oPvR+o0CNqQRPIdo0i+/VncVSRZe9XneBGRoSIyL2gZGnSoFsCmoHJ6YF2lOBq9oKq/AZ1FpE6gvL2yX2xM1IhQ6/bb2f7ss4duc7tJOukkcm+5Bd23j3ovvIBn1SoK5s+PfJwR4lk+F8+CWeD1kHB6L6oNvJN9bzwOwJ5n/4ruyEPqNyH55ifZm73B32qOYeV5Ik1VxwBjwhfNoRwPGRORS4FOQHURAUBVRx6h7lBgKIC46+By1ax8pBWQmZFNakrzonJKi2ZkZmZHJZZoO5quhW/LFlxBLVtXo0Z4g1q+UqMGCa1bU/+ll/zb69en7tNPk//II3i3bKFg4UJ0u79dUTB7Ngnt21fZpKvbc5G6B1uuUqcBuj2veKU9u4o+euZ8TbVL/nRw/x3+upq3Ge/aJbhatMEb40k3hKMXMoDUoHJKYF2lOOpeEJHXgD8CdwACXA20PFJ9VR2jql1VtWu0Ei7A3HkLaNeuNa1apZKYmMjAgQP4fMqXUYsnmo6ma1G4ciXulBRcTZtCQgLVL7iA/T//XLRdd+9my4ABbB00iK2DBlG4bBn5jzyCZ+VKCubMIaFNG6hWDdxuEk85BU+JG3BViS89DVeDZki9xuBOIKHz2XiXzy1WR2rVK/rs7tgNX04gryTXBHegXVajFu5WHfBt3kSsC2Gf7lygvYi0FpEkYBAwubLxOW3pnqWqJ4vIIlV9UkT+BUyv7JeHm9frZfhdI5g29QPcLhfj3hnPsmWroh1WVBxV18LrZefLL1Pv+efB5WLf9Ol416+n5g034Fm5slgCLkl37WLPxx/T4LXXANg/e/Yh/b5Vis/H/klvknzjY+ByUTj3G3ybN5F08SC86WvwLp9LYo9LcHfsBl4funcn+yb8GwBX4xSq/eEWUAURCmZ+esioh1jkC9ETaarqEZFhwBeAGxirqktFZCQwT1Uni0g34FOgHtBPRJ5U1U6lHVccjlWbo6rdRWQ2cAWQByxR1XZl7ZuQ1CK2RyqbqMg4q320Q4gZNU8/9MbW0eqY5yZKZY/RqcnpjnPO0s2/Vvr7ystpS/dzEakLPA/Mx/+U2hthi8oYYyrIq7E9xM9p0l0BeFX1fyLSETgV+Cx8YRljTMWEqnshXJyO031UVXeKyNnABcCbwH/CF5YxxlRMCG+khYXTpOsN/Hkp8IaqTgWq9gPpxpi45FN1vESD06SbISKv4x82Nk1EqpVjX2OMiZhYb+k67dMdCPQB/qmq+SLSDLg/fGEZY0zFeNVbdqUocvoY8B5gYlA5C8gKV1DGGFNR9mJKY4yJoFifxNySrjEmrlhL1xhjIijWx+la0jXGxBV7BbsxxkRQvDwGbIwxVYL16RpjTARZn64xxkSQtXSNMSaCbJyuMcZEkLV0jTEmgmz0gjHGRJDdSDPGmAiK9e4FmxPXGBNXQjmfroj0EZGVIpImIg8eZns1ERkf2P6riLQq65iWdI0xcUVVHS+lERE3MBroC3QErgm8IzLYjcC2wJvRXwSeKys+S7rGmLgSwtf1dAfSVHWtqhYAHwEDStQZALwT+PwJcKGIlPpa97D36XoKMiL+XvnDEZGhqjom2nHEArsWB9m1OCherkV5co6IDAWGBq0aE3QNWgCbgralA6eXOERRHVX1iMh2oAGw9UjfeTS1dIeWXeWoYdfiILsWBx1110JVx6hq16Al7P/oHE1J1xhjyiMDSA0qpwTWHbaOiCQAdYDc0g5qSdcYYw5vLtBeRFqLSBIwCJhcos5k4PrA56uAb7WMO3RH0zjdKt9XFUJ2LQ6ya3GQXYsggT7aYcAXgBsYq6pLRWQkME9VJwNvAe+KSBqQhz8xl0pifSCxMcbEE+teMMaYCLKka4wxEWRJt4oSkVYisiTaccSDwLW8toL77gp1PLHEfs5Cz5IuRUM9zNGrFXDYpGs/GybUqmTSFZHPROQ3EVkaeKIEEdklIk+LyEIRmS0iTQLr2wbKi0XkqQMtExHpKSKzRGQysExERorIXUHf8bSIDI/KCTrnFpE3AtfhSxFJFpGbRWRu4Dr8T0RqAIjIOBF5TUTmicgqEbkssH6IiEwSkZkislpEHg+sj/nrEWiFLT/MNWgrIjMCPyOzRKRDoP44EbkqaP8DrdRngXNEZIGI3B24JpNF5FvgGxE5RkS+EZH5gZ+jko+CxjwRqSkiUwM/F0tE5I8i8ljgZ2WJiIw58PiqiJwWqLcQuD3Kocef8kwOESsLUD/wZzKwBP9jdwr0C6wfBYwIfJ4CXBP4fAuwK/C5J7AbaB0otwLmBz67gDVAg2ifaynXoBXgAU4JlCcAg4NjBp4C7gh8HgfMCJxbe/yPNFYHhgBZgWt44Hp2rQrXo5Rr8A3QPrDudPxjJw9cg6uC9g/+WZgStH5I4Poc+DlLAGoHPjcE0jg48mdXtK+Dw2t1JfBGULnOgfMLlN8N+vuzCDg38Pl5YEm044+npUq2dIE7A/8Kz8b/NEh7oAB/ggX4Df9fSIAzgY8Dnz8ocZw5qroOQFXXA7ki0gXoBfyuqqU+WRID1qnqgsDnA+d8YqB1txi4DugUVH+CqvpUdTWwFugQWP+Vquaq6l5gInB2Fboeh7sGZwEfi8gC4HWgWQWO+5Wq5gU+C/CMiCwCvsb/vH2TSkUdeYuBi0XkORE5R1W3A+cHpiNcDFwAdBKRukBdVf0hsN+70Qo4XlW5/ioR6QlcBJypqntEZCb+FluhBv5pBrw4O7fdJcpv4m/lNAXGhiLeMNsf9NmLv6U6DrhcVReKyBD8rbgDSg7K1jLWV4XrUfIaNAHyVfWUw9T1EOhSExEXkFTKcYN/Nq4DGgGnqWqhiKzH/zNXZajqKhE5FbgEeEpEvsHfddBVVTeJyBNUsXOqqqpiS7cO/vkr9wT66s4oo/5s/L9aQdlPi3wK9AG64X8KpSqqBWSJSCL+ZBHsahFxiUhboA2wMrD+YhGpLyLJwOXAT4H1VfF67ADWicjVAOLXObBtPXBa4HN/IDHweSf+63YkdYCcQMI9H2gZ8qjDTESaA3tU9T38XQanBjZtFZFj8D/CiqrmA/kicnZge8mfIVNJVa6li79f8hYRWY4/acwuo/5dwHsi8khg3+1HqqiqBSLyHf6WkjdUAUfYo8CvwJbAn8HJZCMwB6gN3KKq+wL3TuYA/8M/ocd7qjoPqvT1uA74j4iMwJ9YPwIWAm8AkwJdUzM42JpdBHgD68cB20oc733g88Cv4fOAFWE/g9A7CXheRHxAIXAr/n9glwDZ+OcZOOAGYKyIKPBlpAONd3H/GHDg7v1eVVURGYT/ptph7z4HfuWcD1wd6PeMGyIyDv/Nok9KrB+C/1fMYYfZJ26vhzHRUhW7F8rrNGBB4CbIbcC9h6sk/tdwpAHfWIKx62FMuMR9S9cYY2LJ0dDSNcaYmGFJ1xhjIsiSrjHGRJAlXWOMiSBLusYYE0H/Dz54jcSNy+YPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on SAVEE"
      ],
      "metadata": {
        "id": "C7ZmoGmIb8Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "def extract_mel_spectrogram(df,max_x = max_x,max_y = (int(max_y/T)+1)*T):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path']\n",
        " \n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      #print(y.shape)\n",
        "      # Computing the mel spectrograms\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      \n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        " \n",
        "            \n",
        "      \n",
        "      if spect.shape[1] != max_y:\n",
        "                #print('Sizes arent same')\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        "      s=[]\n",
        "      for i in range(int(max_y/T)):\n",
        "        #print(spect[:,i*64:(i+1)*64].shape)\n",
        "        q=spect[:,i*T:(i+1)*T]\n",
        "        delta = librosa.feature.delta(q).reshape((max_x,T,1))\n",
        "        d_delta = librosa.feature.delta(q,order = 2).reshape((max_x,T,1))\n",
        "        #print(q.shape,delta.shape,d_delta.shape)\n",
        "        q = q.reshape((max_x,T,1))\n",
        "\n",
        "        z = np.concatenate((q,delta,d_delta),axis = -1)\n",
        "        #print(z.shape)\n",
        "        s.append(z)\n",
        "      mel_specs.append(np.asarray(s))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  #print(len(mel_specs),mel_specs[0].shape)\n",
        "  mel_specs = np.asarray(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        "train_path = \"SAVEE//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "#X_train_spec = np.expand_dims(X_train_spec,axis=-1)\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        " \n",
        " \n",
        "test_path = \"SAVEE//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "#X_test_spec = np.expand_dims(X_test_spec,axis=-1)\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        " \n",
        "val_path = \"SAVEE//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "#X_val_spec = np.expand_dims(X_val_spec,axis=-1)\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOdBDcGTcBXx",
        "outputId": "95da8c1d-9184-4aa4-c99e-830b53dd2a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(207, 4, 64, 80, 3) (207, 4)\n",
            "(45, 4, 64, 80, 3) (45, 4)\n",
            "(44, 4, 64, 80, 3) (44, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "print(p2.evaluate(X_test_spec,Y_test_spec))\n",
        "p2.load_weights('TESS//models//paper_2_loss.h5')\n",
        "p2.evaluate(X_test_spec,Y_test_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_CXIisLpAk_",
        "outputId": "b32e507e-237a-4118-b053-226ab9cf9249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 775ms/step - loss: 4.0863 - accuracy: 0.4000\n",
            "[4.086273670196533, 0.4000000059604645]\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 3.5226 - accuracy: 0.4000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.5226175785064697, 0.4000000059604645]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p2.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "Wm1BQUmipFHo",
        "outputId": "22aafde9-e20a-41fc-d154-bf1580c77a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.14285714285714288\n",
            "Kappa: 0.0\n",
            "Accuracy: 0.4\n",
            "Jaccard Score: 0.1\n",
            "Precision: 0.1\n",
            "Recall: 0.25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           1       0.00      0.00      0.00        10\n",
            "           2       0.40      1.00      0.57        18\n",
            "           3       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.40        45\n",
            "   macro avg       0.10      0.25      0.14        45\n",
            "weighted avg       0.16      0.40      0.23        45\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paper 3"
      ],
      "metadata": {
        "id": "0fpvFT_5pzNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time = 4\n",
        "def paper_3():\n",
        "  inp =  Input((time*16000,1))\n",
        "  l1 = Conv1D(64,80,strides = 4,padding = 'same')(inp)\n",
        "  m1 = MaxPooling1D(4)(l1)\n",
        "\n",
        "  l2 = Conv1D(128,3,strides = 1,padding = 'same')(m1)\n",
        "  l2 = Conv1D(128,3,strides = 1,padding = 'same')(l2)\n",
        "  m2 = MaxPooling1D(4)(l2)\n",
        "\n",
        "  l3 = Conv1D(256,3,strides = 1,padding = 'same')(m2)\n",
        "  l3 = Conv1D(256,3,strides = 1,padding = 'same')(l3)\n",
        "  m3 = MaxPooling1D(4)(l3)\n",
        "\n",
        "  l4 = Conv1D(512,3,strides = 1,padding = 'same')(m3)\n",
        "  l4 = Conv1D(512,3,strides = 1,padding = 'same')(l4)\n",
        "  m4 = GlobalAveragePooling1D()(l4)\n",
        "\n",
        "  f1 = Dense(1024)(m4)\n",
        "  f2 = Dense(4, activation='softmax')(f1)\n",
        "\n",
        "  return Model(inputs= inp,outputs=f2)\n",
        "\n",
        "p3 = paper_3()\n",
        "p3.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIy2xtG9pqVy",
        "outputId": "de403ccd-0023-476e-ed90-6a7960d5a388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 64000, 1)]        0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 16000, 64)         5184      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 4000, 64)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 4000, 128)         24704     \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 4000, 128)         49280     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1000, 128)        0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 1000, 256)         98560     \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 1000, 256)         196864    \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 250, 256)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 250, 512)          393728    \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 250, 512)          786944    \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 512)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 4100      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,084,676\n",
            "Trainable params: 2,084,676\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p3.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0-8GOyx_qN2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on Emo db"
      ],
      "metadata": {
        "id": "YJlEfq0iqc9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wpBj53AqbRh",
        "outputId": "cfd03dd3-d9af-4669-ef6b-57d8e7feb20c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (237, 64000, 1) (237, 4)\n",
            "Test Data (50, 64000, 1) (50, 4)\n",
            "Val Data (51, 64000, 1) (51, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p3.save_weights('TESS//models//paper_3_acc.h5')\n",
        "#p3.load_weights('TESS//models//paper_3_acc.h5')\n",
        "#print(p3.evaluate(X_test,Y_test))\n",
        "#p3.load_weights('TESS//models//paper_3_loss.h5')\n",
        "p3.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c4EzTBqqroY",
        "outputId": "a75d16de-9c21-477c-955d-839cec5fb493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 330ms/step - loss: 1.3900 - accuracy: 0.2200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3899999856948853, 0.2199999988079071]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "EFzAKD1PrEIY",
        "outputId": "f3a9bdd6-523e-4f6d-bfa7-14defec146e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.09016393442622951\n",
            "Kappa: 0.0\n",
            "Accuracy: 0.22\n",
            "Jaccard Score: 0.055\n",
            "Precision: 0.055\n",
            "Recall: 0.25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        22\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.22      1.00      0.36        11\n",
            "           3       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.22        50\n",
            "   macro avg       0.06      0.25      0.09        50\n",
            "weighted avg       0.05      0.22      0.08        50\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on Crema D"
      ],
      "metadata": {
        "id": "WaLVlkvBrMTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = 4,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"CREMA//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"CREMA//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"CREMA//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21uJHNkErImt",
        "outputId": "27357d50-9357-4f0b-9fb7-ad314f0a2a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (3430, 64000, 1) (3430, 4)\n",
            "Test Data (735, 64000, 1) (735, 4)\n",
            "Val Data (735, 64000, 1) (735, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p3.save_weights('TESS//models//paper_3_acc.h5')\n",
        "#p3.load_weights('TESS//models//paper_3_acc.h5')\n",
        "#print(p3.evaluate(X_test,Y_test))\n",
        "#p3.load_weights('TESS//models//paper_3_loss.h5')\n",
        "p3.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06jWiecprbww",
        "outputId": "8a5501ea-fe6a-4dda-81e7-cbba1d4046a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 2s 100ms/step - loss: 1.3880 - accuracy: 0.2395\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3879621028900146, 0.23945578932762146]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "5sJ0klz7rgoP",
        "outputId": "00f5d4e9-8b4e-4268-ba08-f23c8003acf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.09659714599341383\n",
            "Kappa: 0.0\n",
            "Accuracy: 0.23945578231292516\n",
            "Jaccard Score: 0.05986394557823129\n",
            "Precision: 0.05986394557823129\n",
            "Recall: 0.25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       176\n",
            "           1       0.00      0.00      0.00       204\n",
            "           2       0.24      1.00      0.39       176\n",
            "           3       0.00      0.00      0.00       179\n",
            "\n",
            "    accuracy                           0.24       735\n",
            "   macro avg       0.06      0.25      0.10       735\n",
            "weighted avg       0.06      0.24      0.09       735\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on SAVEE"
      ],
      "metadata": {
        "id": "HEEDoE1QrilN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = time,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"SAVEE//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"SAVEE//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"SAVEE//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVW0q5AJrh0J",
        "outputId": "f40da75a-eb41-4b47-8080-980dce2a8ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (207, 64000, 1) (207, 4)\n",
            "Test Data (45, 64000, 1) (45, 4)\n",
            "Val Data (44, 64000, 1) (44, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p3.save_weights('TESS//models//paper_3_acc.h5')\n",
        "#p3.load_weights('TESS//models//paper_3_acc.h5')\n",
        "#print(p3.evaluate(X_test,Y_test))\n",
        "#p3.load_weights('TESS//models//paper_3_loss.h5')\n",
        "p3.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvLPK29_rw4n",
        "outputId": "369a22ad-0fe3-4af2-f7da-c66a57324284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 311ms/step - loss: 1.3893 - accuracy: 0.4000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3893481492996216, 0.4000000059604645]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(p3.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "6Xogs1Byr59U",
        "outputId": "2dd9be3d-8054-4224-f1ae-8d2f2459f340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.14285714285714288\n",
            "Kappa: 0.0\n",
            "Accuracy: 0.4\n",
            "Jaccard Score: 0.1\n",
            "Precision: 0.1\n",
            "Recall: 0.25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           1       0.00      0.00      0.00        10\n",
            "           2       0.40      1.00      0.57        18\n",
            "           3       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.40        45\n",
            "   macro avg       0.10      0.25      0.14        45\n",
            "weighted avg       0.16      0.40      0.23        45\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paper 4"
      ],
      "metadata": {
        "id": "ldkYFYODsI6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install Signal_Analysis kapre\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import ast\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "# Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Sound Processing\n",
        "import librosa\n",
        "from Signal_Analysis.features.signal import get_F_0, get_HNR\n",
        "\n",
        "# Training Data Preparation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "#from kapre.utils import Normalization2D\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import IPython.display as ipd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FigLhHdmsKQB",
        "outputId": "3a2d758b-d547-4e7c-e8b8-75575bd61ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Signal_Analysis\n",
            "  Downloading Signal_Analysis-0.1.26.tar.gz (378 kB)\n",
            "\u001b[?25l\r\u001b[K     |                               | 10 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |                              | 20 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |                             | 30 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |                            | 40 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |                           | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |                          | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |                          | 71 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |                         | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |                        | 92 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |                       | 102 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |                      | 112 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |                     | 122 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |                    | 133 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |                    | 143 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |                   | 153 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |                  | 163 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |                 | 174 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |                | 184 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |               | 194 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |              | 204 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |             | 215 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |             | 225 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |            | 235 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |           | 245 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |          | 256 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |         | 266 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |        | 276 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |       | 286 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |       | 296 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |      | 307 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |     | 317 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |    | 327 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |   | 337 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |  | 348 kB 4.5 MB/s eta 0:00:01\r\u001b[K     | | 358 kB 4.5 MB/s eta 0:00:01\r\u001b[K     || 368 kB 4.5 MB/s eta 0:00:01\r\u001b[K     || 378 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kapre in /usr/local/lib/python3.7/dist-packages (0.3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from Signal_Analysis) (1.19.5)\n",
            "Collecting peakutils\n",
            "  Downloading PeakUtils-1.3.3-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from kapre) (2.7.0)\n",
            "Requirement already satisfied: librosa>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from kapre) (0.8.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.2->kapre) (1.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.2->kapre) (21.3)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.2->kapre) (0.51.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.2->kapre) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.2->kapre) (1.1.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.2->kapre) (0.2.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.2->kapre) (2.1.9)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.2->kapre) (1.6.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.2->kapre) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.2->kapre) (0.10.3.post1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.7.2->kapre) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.7.2->kapre) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa>=0.7.2->kapre) (3.0.7)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.7.2->kapre) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.7.2->kapre) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa>=0.7.2->kapre) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.7.2->kapre) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa>=0.7.2->kapre) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.7.2->kapre) (2.21)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (0.37.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (0.23.1)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (3.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (2.7.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (13.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (3.10.0.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (1.43.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (1.13.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (3.17.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->kapre) (1.0.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.0.0->kapre) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0.0->kapre) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0.0->kapre) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0.0->kapre) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0.0->kapre) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0.0->kapre) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0.0->kapre) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0.0->kapre) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0.0->kapre) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0.0->kapre) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.0.0->kapre) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.0.0->kapre) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.0.0->kapre) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0.0->kapre) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.0.0->kapre) (3.1.1)\n",
            "Building wheels for collected packages: Signal-Analysis\n",
            "  Building wheel for Signal-Analysis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Signal-Analysis: filename=Signal_Analysis-0.1.26-py3-none-any.whl size=14531 sha256=67e84a67a5df5da7779a1648bf9a0bbcf26d38e1d5b2e564483b3240723ad72b\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/da/25/128af0db67fe61f8282e790d94387346357c063d72522661d6\n",
            "Successfully built Signal-Analysis\n",
            "Installing collected packages: peakutils, Signal-Analysis\n",
            "Successfully installed Signal-Analysis-0.1.26 peakutils-1.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EMOTIONS = 4\n",
        "N_FFT = 4096\n",
        "HOP_LENGTH = 1024\n",
        "EMOTIONS = ['ang', 'hap', 'neu', 'sad']\n",
        "SR = 16000\n",
        "\n",
        "\n",
        "def extract_HSF(lld):\n",
        "    mean_val = lld.mean()\n",
        "    min_val = lld.min()\n",
        "    max_val = lld.max()\n",
        "    var_val = lld.var()\n",
        "    range_val = np.subtract(max_val, min_val)\n",
        "    q25_val = np.quantile(lld, 0.25)\n",
        "    q50_val = np.quantile(lld, 0.5)\n",
        "    q75_val = np.quantile(lld, 0.75)\n",
        "    return np.asarray([\n",
        "        mean_val,\n",
        "        min_val,\n",
        "        max_val,\n",
        "        var_val,\n",
        "        range_val,\n",
        "        q25_val,\n",
        "        q50_val,\n",
        "        q75_val,\n",
        "    ])\n",
        "\n",
        "def extract_LLD_from_subaudio(subaudio, fs):\n",
        "    # Frame-wise energy\n",
        "    energy_val = np.sum(np.square(subaudio)) / (subaudio.shape[0] / fs + 0.00000000000001)\n",
        "    \n",
        "    # Frame-wise Zero Crossing Rate\n",
        "    zcr_val = np.sum((subaudio[:-1] * subaudio[1:]) < 0)\n",
        "    \n",
        "    return np.asarray([\n",
        "        energy_val,\n",
        "        zcr_val,\n",
        "    ])\n",
        "\n",
        "def extract_LLD_from_audio(audio, fs):\n",
        "    # MFCC\n",
        "    mfcc = librosa.feature.mfcc(audio, fs, n_fft = N_FFT, hop_length = HOP_LENGTH, center = False).transpose()\n",
        "    mfcc_hsf = extract_HSF(mfcc)\n",
        "    \n",
        "    # LPC\n",
        "    lpc = librosa.lpc(audio, 16)\n",
        "    \n",
        "    # Mel-Spectrogram\n",
        "    spect = librosa.feature.melspectrogram(y = audio, sr = fs, n_fft = N_FFT, hop_length = HOP_LENGTH, center = False)\n",
        "    spect = librosa.power_to_db(spect, ref = np.max).transpose()\n",
        "    spect_hsf = extract_HSF(spect)\n",
        "    \n",
        "    # Other features\n",
        "    f0 = get_F_0(audio, fs)[0]\n",
        "    hnr = get_HNR(audio, fs)\n",
        "    \n",
        "    return np.asarray(mfcc), np.asarray(mfcc_hsf), np.asarray(lpc), np.asarray(spect), np.asarray(spect_hsf), np.asarray([f0, hnr])\n",
        "\n",
        "def extract_LLD(audio, fs):\n",
        "    #print(audio.shape)\n",
        "    #print(int((audio.shape[0] - N_FFT) // HOP_LENGTH) + 1)\n",
        "    num_windows = int((audio.shape[0] - N_FFT) // HOP_LENGTH) + 1\n",
        "    framewise_lld = np.zeros((num_windows, 2))\n",
        "    for idx in range(num_windows):\n",
        "        subaudio = audio[int(idx * HOP_LENGTH): int(idx * HOP_LENGTH + N_FFT)]\n",
        "        framewise_lld[idx, :] = extract_LLD_from_subaudio(subaudio, fs)\n",
        "    framewise_lld_hsf = extract_HSF(framewise_lld)\n",
        "    \n",
        "    mfcc, mfcc_hsf, lpc, spect, spect_hsf, others = extract_LLD_from_audio(audio, fs)\n",
        "    \n",
        "    assert(framewise_lld.shape[0] == mfcc.shape[0])\n",
        "    assert(mfcc.shape[0] == spect.shape[0])\n",
        "\n",
        "    rnn_feats = np.concatenate((framewise_lld, mfcc, spect), axis = 1)\n",
        "    dense_feats = np.concatenate((framewise_lld_hsf, mfcc_hsf, lpc, spect_hsf, others))\n",
        "    return rnn_feats, dense_feats"
      ],
      "metadata": {
        "id": "iFQqFsxRsTLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "  X = []\n",
        "  Y = []\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "    y = librosa.load(row['path'], mono=True, duration = 30,sr = SR)[0]\n",
        "    y = librosa.util.fix_length(y,4*SR)\n",
        "    rnn_feats, dense_feats = extract_LLD(y, SR)\n",
        "    X.append(rnn_feats)\n",
        "    Y.append(label_to_onehot(row['labels']))\n",
        "    #print(rnn_feats.shape)\n",
        "\n",
        "  X = np.reshape(np.array(X),(len(Y),X[0].shape[0],X[0].shape[1]))\n",
        "  Y = np.reshape(np.array(Y),(X.shape[0],4))\n",
        "\n",
        "  return X,Y\n",
        "\n",
        "\n",
        "\n",
        "train_path = \"TESS//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"TESS//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"TESS//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm8LSg5SsaSm",
        "outputId": "e383f97c-a453-4a0d-fb1e-187613fb8882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Train Data (1114, 59, 150) (1114, 4)\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Test Data (239, 59, 150) (239, 4)\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Val Data (239, 59, 150) (239, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.expand_dims(X_train,axis = -1)\n",
        "X_test = np.expand_dims(X_test,axis = -1)\n",
        "X_val = np.expand_dims(X_val,axis = -1)\n",
        "\n",
        "X_train = (X_train - X_train.mean())/X_train.std()\n",
        "X_test = (X_test - X_test.mean())/X_test.std()\n",
        "X_val = (X_val - X_val.mean())/X_val.std()"
      ],
      "metadata": {
        "id": "bAblnuHKsuly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def RNNSpeechModel(no_of_classes, input_size):\n",
        "  \n",
        "  # x = tf.keras.layers.Input((input_len,))\n",
        "  # x = tf.keras.layers.Reshape((1,-1))(x)\n",
        "  # m = Melspectrogram(n_dft=1024, n_hop=128, input_shape=(1, input_len),\n",
        "  #                      padding='same', sr=sr, n_mels=80,\n",
        "  #                      fmin=40.0, fmax=sr / 2, power_melgram=1.0,\n",
        "  #                      return_decibel_melgram=True, trainable_fb=False,\n",
        "  #                      trainable_kernel=False,\n",
        "  #                      name='mel_stft')\n",
        "  # m.trainable = False\n",
        "  # x = m(x)\n",
        "  #x = Normalization2D(int_axis=0)(x)\n",
        "  #x = tf.keras.layers.Permute((2,1,3))(x)\n",
        "\n",
        "  input = tf.keras.layers.Input((input_size))\n",
        "  #Bidirectional RNN\n",
        "  x = tf.keras.layers.Conv2D(10,(5,1),activation='relu',padding = 'same')(input)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2D(1,(5,1),activation='relu', padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Lambda(lambda q: K.squeeze(q, -1))(x)\n",
        "  x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences = 'true'))(x)\n",
        "  #x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences = 'true'))(x)\n",
        "\n",
        "  #Attention unit\n",
        "  xFirst = tf.keras.layers.Lambda(lambda q: q[:,-1])(x)\n",
        "  query = tf.keras.layers.Dense(128)(xFirst)\n",
        "  att_score = tf.keras.layers.Dot(axes=[1,2])([query,x])\n",
        "  att_score = tf.keras.layers.Softmax()(att_score)\n",
        "\n",
        "  #weighted pooling\n",
        "  att_vector = tf.keras.layers.Dot(axes=[1,1])([att_score,x])\n",
        "  #x = tf.keras.layers.Dense(64,activation='relu')(att_vector)\n",
        "  #x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
        "  output = tf.keras.layers.Dense(no_of_classes,activation='softmax')(att_vector)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs = input,outputs = output)\n",
        "  return model\n",
        "  \n",
        "no_of_classes = 4\n",
        "input_size = X_train[0].shape\n",
        "p4 = RNNSpeechModel(no_of_classes,input_size)\n",
        "p4.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
        "p4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9degwOmKsw0m",
        "outputId": "0e73425d-23f2-4deb-9864-cde1103875ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 59, 150, 1)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 59, 150, 10)  60          ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 59, 150, 10)  40         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 59, 150, 1)   51          ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 59, 150, 1)  4           ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 59, 150)      0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 59, 128)      110080      ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 128)          0           ['bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          16512       ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 59)           0           ['dense_3[0][0]',                \n",
            "                                                                  'bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " softmax (Softmax)              (None, 59)           0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 128)          0           ['softmax[0][0]',                \n",
            "                                                                  'bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 4)            516         ['dot_1[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 127,263\n",
            "Trainable params: 127,241\n",
            "Non-trainable params: 22\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on Emo db"
      ],
      "metadata": {
        "id": "fKJPqiBwsiQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "  X = []\n",
        "  Y = []\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "    y = librosa.load(row['path'], mono=True, duration = 30,sr = SR)[0]\n",
        "    y = librosa.util.fix_length(y,4*SR)\n",
        "    rnn_feats, dense_feats = extract_LLD(y, SR)\n",
        "    X.append(rnn_feats)\n",
        "    Y.append(label_to_onehot(row['labels']))\n",
        "    #print(rnn_feats.shape)\n",
        "\n",
        "  X = np.reshape(np.array(X),(len(Y),X[0].shape[0],X[0].shape[1]))\n",
        "  Y = np.reshape(np.array(Y),(X.shape[0],4))\n",
        "\n",
        "  return X,Y\n",
        "\n",
        "\n",
        "\n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGPz642mshJL",
        "outputId": "59f28867-056b-414f-b22f-8b6cba43cb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Train Data (237, 59, 150) (237, 4)\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Test Data (50, 59, 150) (50, 4)\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Val Data (51, 59, 150) (51, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.expand_dims(X_train,axis = -1)\n",
        "X_test = np.expand_dims(X_test,axis = -1)\n",
        "X_val = np.expand_dims(X_val,axis = -1)\n",
        "\n",
        "X_train = (X_train - X_train.mean())/X_train.std()\n",
        "X_test = (X_test - X_test.mean())/X_test.std()\n",
        "X_val = (X_val - X_val.mean())/X_val.std()"
      ],
      "metadata": {
        "id": "NVBkmx3ju7yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p4.load_weights('TESS//models//paper_4_loss.h5')\n",
        "p4.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7UzwJMqvJk1",
        "outputId": "d196adab-e510-42a3-d5dd-d65a65f2a6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 66ms/step - loss: 2.8070 - acc: 0.3600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.8069710731506348, 0.36000001430511475]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(p4.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(p4.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "xNsgtkBevR6G",
        "outputId": "128b6e8f-0a65-45d0-d500-d4c0add242f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.2853067765567766\n",
            "Kappa: 0.08045977011494243\n",
            "Accuracy: 0.36\n",
            "Jaccard Score: 0.17709627329192545\n",
            "Precision: 0.4027777777777778\n",
            "Recall: 0.2918831168831169\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.59      0.54        22\n",
            "           1       0.11      0.29      0.16         7\n",
            "           2       0.50      0.09      0.15        11\n",
            "           3       0.50      0.20      0.29        10\n",
            "\n",
            "    accuracy                           0.36        50\n",
            "   macro avg       0.40      0.29      0.29        50\n",
            "weighted avg       0.45      0.36      0.35        50\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on CREMA"
      ],
      "metadata": {
        "id": "vn41LHpq1wWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "  X = []\n",
        "  Y = []\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "    y = librosa.load(row['path'], mono=True, duration = 30,sr = SR)[0]\n",
        "    y = librosa.util.fix_length(y,4*SR)\n",
        "    try :\n",
        "      rnn_feats, dense_feats = extract_LLD(y, SR)\n",
        "      X.append(rnn_feats)\n",
        "      Y.append(label_to_onehot(row['labels']))\n",
        "    except:\n",
        "      print(\"Error\",row['path'])\n",
        "    #print(rnn_feats.shape)\n",
        "\n",
        "  X = np.reshape(np.array(X),(len(Y),X[0].shape[0],X[0].shape[1]))\n",
        "  Y = np.reshape(np.array(Y),(X.shape[0],4))\n",
        "\n",
        "  return X,Y\n",
        "\n",
        "\n",
        "\n",
        "train_path = \"CREMA//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"CREMA//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"CREMA//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzvLF2nO1ot1",
        "outputId": "9c94ed14-6e0e-48ef-8450-e394a442db80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Train Data (3429, 59, 150) (3429, 4)\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Test Data (735, 59, 150) (735, 4)\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Val Data (735, 59, 150) (735, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.expand_dims(X_train,axis = -1)\n",
        "X_test = np.expand_dims(X_test,axis = -1)\n",
        "X_val = np.expand_dims(X_val,axis = -1)\n",
        "\n",
        "X_train = (X_train - X_train.mean())/X_train.std()\n",
        "X_test = (X_test - X_test.mean())/X_test.std()\n",
        "X_val = (X_val - X_val.mean())/X_val.std()"
      ],
      "metadata": {
        "id": "DmT0jGMa1vnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p4.load_weights('TESS//models//paper_4_loss.h5')\n",
        "p4.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55Vflje57Moq",
        "outputId": "cb2d6f8d-f14d-4bd7-a5a2-95209427262a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 19ms/step - loss: 3.2281 - acc: 0.3143\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.2281222343444824, 0.3142857253551483]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(p4.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(p4.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "UqmYrfx9-EQ5",
        "outputId": "d544a7aa-5802-4fba-8a15-db36b7a36df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.2997925251603066\n",
            "Kappa: 0.09029738955330169\n",
            "Accuracy: 0.3142857142857143\n",
            "Jaccard Score: 0.17817345656917458\n",
            "Precision: 0.32301245396128636\n",
            "Recall: 0.31935813939593105\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.36      0.32       176\n",
            "           1       0.34      0.16      0.22       204\n",
            "           2       0.35      0.21      0.26       176\n",
            "           3       0.31      0.55      0.40       179\n",
            "\n",
            "    accuracy                           0.31       735\n",
            "   macro avg       0.32      0.32      0.30       735\n",
            "weighted avg       0.32      0.31      0.30       735\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on SAVEE"
      ],
      "metadata": {
        "id": "ZiE7me6fIaay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "  X = []\n",
        "  Y = []\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "    y = librosa.load(row['path'], mono=True, duration = 30,sr = SR)[0]\n",
        "    y = librosa.util.fix_length(y,4*SR)\n",
        "    rnn_feats, dense_feats = extract_LLD(y, SR)\n",
        "    X.append(rnn_feats)\n",
        "    Y.append(label_to_onehot(row['labels']))\n",
        "    #print(rnn_feats.shape)\n",
        "\n",
        "  X = np.reshape(np.array(X),(len(Y),X[0].shape[0],X[0].shape[1]))\n",
        "  Y = np.reshape(np.array(Y),(X.shape[0],4))\n",
        "\n",
        "  return X,Y\n",
        "\n",
        "\n",
        "\n",
        "train_path = \"SAVEE//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"SAVEE//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"SAVEE//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WmYUU_GITLQ",
        "outputId": "54bdd86c-da48-4c2f-e9f0-f72c9be94a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Train Data (207, 59, 150) (207, 4)\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Test Data (45, 59, 150) (45, 4)\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "<class 'numpy.float64'> \n",
            "\n",
            "Val Data (44, 59, 150) (44, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.expand_dims(X_train,axis = -1)\n",
        "X_test = np.expand_dims(X_test,axis = -1)\n",
        "X_val = np.expand_dims(X_val,axis = -1)\n",
        "\n",
        "X_train = (X_train - X_train.mean())/X_train.std()\n",
        "X_test = (X_test - X_test.mean())/X_test.std()\n",
        "X_val = (X_val - X_val.mean())/X_val.std()"
      ],
      "metadata": {
        "id": "zvxQxTioI-m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p4.load_weights('TESS//models//paper_4_loss.h5')\n",
        "p4.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkiheNr4JCeD",
        "outputId": "bd9ae388-8edd-409f-a75e-568d4f2fd450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 61ms/step - loss: 3.6440 - acc: 0.3111\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.643960952758789, 0.31111112236976624]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(p4.predict(X_test).reshape(Y_test.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(p4.predict(X_test).reshape(Y_test.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "3kuoD9ukJIbt",
        "outputId": "90a655cf-7e26-48c1-d5c9-840066f84da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.2806962685011465\n",
            "Kappa: 0.13246268656716442\n",
            "Accuracy: 0.3111111111111111\n",
            "Jaccard Score: 0.1765625\n",
            "Precision: 0.3680351906158358\n",
            "Recall: 0.37142857142857144\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.30      0.46        10\n",
            "           1       0.29      0.90      0.44        10\n",
            "           2       0.00      0.00      0.00        18\n",
            "           3       0.18      0.29      0.22         7\n",
            "\n",
            "    accuracy                           0.31        45\n",
            "   macro avg       0.37      0.37      0.28        45\n",
            "weighted avg       0.32      0.31      0.23        45\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paper 5"
      ],
      "metadata": {
        "id": "xzxTHfx4yEw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_x,max_y=(64,299)"
      ],
      "metadata": {
        "id": "nRxLLpiByU42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "def div_L0(num):\n",
        "    [a, b] = div_L1(num)\n",
        "    [c, d, e, f] = div_L2(num)\n",
        "\n",
        "    return [a, b], [c, d, e, f]\n",
        "def div_L1(num):\n",
        "    a = num // 2\n",
        "    b = num - a\n",
        "\n",
        "    return [a, b]\n",
        "def div_L2(num):\n",
        "    [a, b] = div_L1(num)\n",
        "    [c, d] = div_L1(a)\n",
        "    [e, f] = div_L1(b)\n",
        "\n",
        "    return [c, d, e, f]\n",
        "\n",
        "def lpnorm_pooling(features_Ln):\n",
        "    '''\n",
        "    :param features_Ln:\n",
        "    :param var_p: 1-average pooling, np.inf-max pooling\n",
        "    :return:\n",
        "    '''\n",
        "    var_p = 2.14  # average pooling\n",
        "#   var_p = np.inf  # max pooling\n",
        "    lpnorm = tf.norm(features_Ln,ord=var_p,axis=1)\n",
        "    result = lpnorm * (1/features_Ln.shape[1])**(1/var_p)\n",
        "\n",
        "    #print(result)\n",
        "    result = tf.math.reduce_max(features_Ln,axis = 1)\n",
        "    #result = np.average(features_Ln,axis = 0)\n",
        "    #print(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "def subpart():\n",
        "    \n",
        "    input_layer = Input((227,227,3))\n",
        "\n",
        "    X = keras.layers.Resizing(227,227)(input_layer)\n",
        "    \n",
        "      \n",
        "    X = Conv2D(96,(11,11),strides = 4,name=\"conv0\")(X)\n",
        "    X = BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
        "    \n",
        "    X = Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3 ,name='bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D(2)(X)\n",
        "    \n",
        "    X = Flatten()(X)\n",
        "    \n",
        "    X = Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
        "    \n",
        "    X = Dense(4096, activation = 'relu', name = 'fc1')(X) \n",
        "\n",
        "    Y = Reshape((1,4096))(X)\n",
        "\n",
        "    return Model(inputs = input_layer,outputs = Y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def paper_2():\n",
        "    input_layer = Input((27,64,64,3))\n",
        "\n",
        "    sp = subpart()\n",
        "\n",
        "    for i in range(input_layer.shape[1]):\n",
        "      #print(input_layer[:,0,:,:,:].shape)\n",
        "      inp = keras.layers.Resizing(227,227)(input_layer[:,i,:,:,:])\n",
        "      output_layer = sp(inp)\n",
        "\n",
        "      if i == 0:\n",
        "        output_layers = output_layer\n",
        "      else:\n",
        "        output_layers = Concatenate(axis = 1)([output_layers,output_layer])\n",
        "    \n",
        "    print(output_layers.shape)\n",
        "    t,n, d = output_layers.shape\n",
        "    #rint(X.shape)\n",
        "\n",
        "    if n == 3:\n",
        "        features = np.row_stack((X, X[-1]))\n",
        "    if n == 2:\n",
        "        features = np.row_stack((X, X))\n",
        "    if n == 1:\n",
        "        print(n)\n",
        "        features = tf.stack((X, X, X, X),axis =1)\n",
        "\n",
        "    #print(features.shape)\n",
        "    t,n, d = output_layers.shape\n",
        "\n",
        "    [a, b], [c, d, e, f] = div_L0(n)\n",
        "\n",
        "    L0 = lpnorm_pooling(output_layers)\n",
        "    #print(a,b,c,d,e,f, features.shape)\n",
        "    L1_1 = lpnorm_pooling(output_layers[:,:a,:])\n",
        "    #print(features[:,:a,].shape)\n",
        "    L1_2 = lpnorm_pooling(output_layers[:,a:,:])\n",
        "\n",
        "    L2_1 = lpnorm_pooling(output_layers[:,:c,:])\n",
        "    L2_2 = lpnorm_pooling(output_layers[:,c:a,:])\n",
        "    L2_3 = lpnorm_pooling(output_layers[:,a:a+e,:])\n",
        "    L2_4 = lpnorm_pooling(output_layers[:,a+e:,:])\n",
        "\n",
        "    W_L0=1/4;\n",
        "    W_L1=1/4;\n",
        "    W_L2=1/2;\n",
        "\n",
        "    Weights_L = [[W_L0,0,0,0,0,0,0],\n",
        "                 [0,W_L1,0,0,0,0,0],\n",
        "                 [0,0,W_L1,0,0,0,0],\n",
        "                 [0,0,0,W_L2,0,0,0],\n",
        "                 [0,0,0,0,W_L2,0,0],\n",
        "                 [0,0,0,0,0,W_L2,0],\n",
        "                 [0,0,0,0,0,0,W_L2]]\n",
        "\n",
        "    features_Vp = Concatenate(axis =1)([W_L0*L0, W_L1*L1_1, W_L1*L1_2, W_L2*L2_1, W_L2*L2_2, W_L2*L2_3, W_L2*L2_4])\n",
        "\n",
        "    op = Dense(4,activation = 'softmax',kernel_regularizer=keras.regularizers.l2(0.01))(features_Vp)\n",
        "    #features_Up = np.matmul(Weights_L,features_Vp)\n",
        "\n",
        "    return Model(inputs=input_layer,outputs=op)\n",
        "\n",
        "p5 = paper_2()\n",
        "p5.summary()\n",
        "p5.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yoHZej3FJJsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95c30bf-5f28-4448-dabc-0c0bc5ebdcc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 27, 4096)\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 27, 64, 64,  0           []                               \n",
            "                                 3)]                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " resizing_1 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " resizing_2 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2 (Sl  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " model (Functional)             (None, 1, 4096)      58286848    ['resizing_1[0][0]',             \n",
            "                                                                  'resizing_2[0][0]',             \n",
            "                                                                  'resizing_3[0][0]',             \n",
            "                                                                  'resizing_4[0][0]',             \n",
            "                                                                  'resizing_5[0][0]',             \n",
            "                                                                  'resizing_6[0][0]',             \n",
            "                                                                  'resizing_7[0][0]',             \n",
            "                                                                  'resizing_8[0][0]',             \n",
            "                                                                  'resizing_9[0][0]',             \n",
            "                                                                  'resizing_10[0][0]',            \n",
            "                                                                  'resizing_11[0][0]',            \n",
            "                                                                  'resizing_12[0][0]',            \n",
            "                                                                  'resizing_13[0][0]',            \n",
            "                                                                  'resizing_14[0][0]',            \n",
            "                                                                  'resizing_15[0][0]',            \n",
            "                                                                  'resizing_16[0][0]',            \n",
            "                                                                  'resizing_17[0][0]',            \n",
            "                                                                  'resizing_18[0][0]',            \n",
            "                                                                  'resizing_19[0][0]',            \n",
            "                                                                  'resizing_20[0][0]',            \n",
            "                                                                  'resizing_21[0][0]',            \n",
            "                                                                  'resizing_22[0][0]',            \n",
            "                                                                  'resizing_23[0][0]',            \n",
            "                                                                  'resizing_24[0][0]',            \n",
            "                                                                  'resizing_25[0][0]',            \n",
            "                                                                  'resizing_26[0][0]',            \n",
            "                                                                  'resizing_27[0][0]']            \n",
            "                                                                                                  \n",
            " resizing_3 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3 (Sl  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 2, 4096)      0           ['model[0][0]',                  \n",
            "                                                                  'model[1][0]']                  \n",
            "                                                                                                  \n",
            " resizing_4 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_4 (Sl  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 3, 4096)      0           ['concatenate[0][0]',            \n",
            "                                                                  'model[2][0]']                  \n",
            "                                                                                                  \n",
            " resizing_5 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_5 (Sl  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 4, 4096)      0           ['concatenate_1[0][0]',          \n",
            "                                                                  'model[3][0]']                  \n",
            "                                                                                                  \n",
            " resizing_6 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_5[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_6 (Sl  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 5, 4096)      0           ['concatenate_2[0][0]',          \n",
            "                                                                  'model[4][0]']                  \n",
            "                                                                                                  \n",
            " resizing_7 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_6[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_7 (Sl  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 6, 4096)      0           ['concatenate_3[0][0]',          \n",
            "                                                                  'model[5][0]']                  \n",
            "                                                                                                  \n",
            " resizing_8 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_7[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_8 (Sl  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 7, 4096)      0           ['concatenate_4[0][0]',          \n",
            "                                                                  'model[6][0]']                  \n",
            "                                                                                                  \n",
            " resizing_9 (Resizing)          (None, 227, 227, 3)  0           ['tf.__operators__.getitem_8[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_9 (Sl  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 8, 4096)      0           ['concatenate_5[0][0]',          \n",
            "                                                                  'model[7][0]']                  \n",
            "                                                                                                  \n",
            " resizing_10 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_9[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_10 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 9, 4096)      0           ['concatenate_6[0][0]',          \n",
            "                                                                  'model[8][0]']                  \n",
            "                                                                                                  \n",
            " resizing_11 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_10[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_11 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 10, 4096)     0           ['concatenate_7[0][0]',          \n",
            "                                                                  'model[9][0]']                  \n",
            "                                                                                                  \n",
            " resizing_12 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_11[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_12 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 11, 4096)     0           ['concatenate_8[0][0]',          \n",
            "                                                                  'model[10][0]']                 \n",
            "                                                                                                  \n",
            " resizing_13 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_12[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_13 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 12, 4096)     0           ['concatenate_9[0][0]',          \n",
            "                                                                  'model[11][0]']                 \n",
            "                                                                                                  \n",
            " resizing_14 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_13[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_14 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 13, 4096)     0           ['concatenate_10[0][0]',         \n",
            "                                                                  'model[12][0]']                 \n",
            "                                                                                                  \n",
            " resizing_15 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_14[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_15 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 14, 4096)     0           ['concatenate_11[0][0]',         \n",
            "                                                                  'model[13][0]']                 \n",
            "                                                                                                  \n",
            " resizing_16 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_15[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_16 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 15, 4096)     0           ['concatenate_12[0][0]',         \n",
            "                                                                  'model[14][0]']                 \n",
            "                                                                                                  \n",
            " resizing_17 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_16[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_17 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 16, 4096)     0           ['concatenate_13[0][0]',         \n",
            "                                                                  'model[15][0]']                 \n",
            "                                                                                                  \n",
            " resizing_18 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_17[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_18 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 17, 4096)     0           ['concatenate_14[0][0]',         \n",
            "                                                                  'model[16][0]']                 \n",
            "                                                                                                  \n",
            " resizing_19 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_18[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_19 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenate)   (None, 18, 4096)     0           ['concatenate_15[0][0]',         \n",
            "                                                                  'model[17][0]']                 \n",
            "                                                                                                  \n",
            " resizing_20 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_19[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_20 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_17 (Concatenate)   (None, 19, 4096)     0           ['concatenate_16[0][0]',         \n",
            "                                                                  'model[18][0]']                 \n",
            "                                                                                                  \n",
            " resizing_21 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_20[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_21 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_18 (Concatenate)   (None, 20, 4096)     0           ['concatenate_17[0][0]',         \n",
            "                                                                  'model[19][0]']                 \n",
            "                                                                                                  \n",
            " resizing_22 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_21[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_22 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_19 (Concatenate)   (None, 21, 4096)     0           ['concatenate_18[0][0]',         \n",
            "                                                                  'model[20][0]']                 \n",
            "                                                                                                  \n",
            " resizing_23 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_22[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_23 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_20 (Concatenate)   (None, 22, 4096)     0           ['concatenate_19[0][0]',         \n",
            "                                                                  'model[21][0]']                 \n",
            "                                                                                                  \n",
            " resizing_24 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_23[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_24 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_21 (Concatenate)   (None, 23, 4096)     0           ['concatenate_20[0][0]',         \n",
            "                                                                  'model[22][0]']                 \n",
            "                                                                                                  \n",
            " resizing_25 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_24[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_25 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_22 (Concatenate)   (None, 24, 4096)     0           ['concatenate_21[0][0]',         \n",
            "                                                                  'model[23][0]']                 \n",
            "                                                                                                  \n",
            " resizing_26 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_25[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_26 (S  (None, 64, 64, 3)   0           ['input_3[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_23 (Concatenate)   (None, 25, 4096)     0           ['concatenate_22[0][0]',         \n",
            "                                                                  'model[24][0]']                 \n",
            "                                                                                                  \n",
            " resizing_27 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_26[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " concatenate_24 (Concatenate)   (None, 26, 4096)     0           ['concatenate_23[0][0]',         \n",
            "                                                                  'model[25][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_25 (Concatenate)   (None, 27, 4096)     0           ['concatenate_24[0][0]',         \n",
            "                                                                  'model[26][0]']                 \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_27 (S  (None, 13, 4096)    0           ['concatenate_25[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_28 (S  (None, 14, 4096)    0           ['concatenate_25[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_29 (S  (None, 6, 4096)     0           ['concatenate_25[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_30 (S  (None, 7, 4096)     0           ['concatenate_25[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_31 (S  (None, 7, 4096)     0           ['concatenate_25[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_32 (S  (None, 7, 4096)     0           ['concatenate_25[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLambda  (None, 4096)        0           ['concatenate_25[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_27[0][\n",
            " da)                                                             0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_2 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_28[0][\n",
            " da)                                                             0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_29[0][\n",
            " da)                                                             0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_4 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_30[0][\n",
            " da)                                                             0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_5 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_31[0][\n",
            " da)                                                             0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_6 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_32[0][\n",
            " da)                                                             0]']                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_7 (TFOpLambda  (None, 4096)        0           ['tf.math.reduce_max[0][0]']     \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_8 (TFOpLambda  (None, 4096)        0           ['tf.math.reduce_max_1[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_9 (TFOpLambda  (None, 4096)        0           ['tf.math.reduce_max_2[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_10 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_3[0][0]']   \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_11 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_4[0][0]']   \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_12 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_5[0][0]']   \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_13 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_6[0][0]']   \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate_26 (Concatenate)   (None, 28672)        0           ['tf.math.multiply_7[0][0]',     \n",
            "                                                                  'tf.math.multiply_8[0][0]',     \n",
            "                                                                  'tf.math.multiply_9[0][0]',     \n",
            "                                                                  'tf.math.multiply_10[0][0]',    \n",
            "                                                                  'tf.math.multiply_11[0][0]',    \n",
            "                                                                  'tf.math.multiply_12[0][0]',    \n",
            "                                                                  'tf.math.multiply_13[0][0]']    \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 4)            114692      ['concatenate_26[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 58,401,540\n",
            "Trainable params: 58,398,788\n",
            "Non-trainable params: 2,752\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "def extract_mel_spectrogram(df,max_x = 64,max_y = 898):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path']\n",
        " \n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      #print(y.shape)\n",
        "      # Computing the mel spectrograms\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      \n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        " \n",
        "            \n",
        "      \n",
        "      if spect.shape[1] != max_y:\n",
        "                #print('Sizes arent same')\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        "      s=[]\n",
        "      for i in range(0,int((max_y-64)/30),1):\n",
        "        #print(spect[:,i*64:(i+1)*64].shape)\n",
        "        q=spect[:,i*30:64 +i*30]\n",
        "        delta = librosa.feature.delta(q).reshape((max_x,64,1))\n",
        "        d_delta = librosa.feature.delta(q,order = 2).reshape((max_x,64,1))\n",
        "        #print(q.shape,delta.shape,d_delta.shape)\n",
        "        q = q.reshape((max_x,64,1))\n",
        "        z = np.concatenate((q,delta,d_delta),axis = -1)\n",
        "        s.append(z)\n",
        "\n",
        "      mel_specs.append(np.asarray(s))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  #print(len(mel_specs),mel_specs[0].shape)\n",
        "  mel_specs = np.asarray(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        " \n",
        "train_path = \"EMO_DB//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        " \n",
        " \n",
        "test_path = \"EMO_DB//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        " \n",
        "val_path = \"EMO_DB//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqJUtMxiyboG",
        "outputId": "dc5416ba-fb13-454f-d188-c468f19c1afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 27, 64, 64, 3) (237, 4)\n",
            "(50, 27, 64, 64, 3) (50, 4)\n",
            "(51, 27, 64, 64, 3) (51, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p5.load_weights('TESS//models//paper_5_acc.h5')\n",
        "print(p5.evaluate(X_test_spec,Y_test_spec))\n",
        "p5.load_weights('TESS//models//paper_5_loss.h5')\n",
        "p5.evaluate(X_test_spec,Y_test_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M59xwTZTy7Xs",
        "outputId": "880960ec-92b2-48b1-d404-afbdaa687c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 16s 1s/step - loss: 29.5725 - accuracy: 0.4400\n",
            "[29.572500228881836, 0.4399999976158142]\n",
            "2/2 [==============================] - 2s 675ms/step - loss: 29.5725 - accuracy: 0.4400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[29.5725040435791, 0.4399999976158142]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "#p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "Z6yvhVXmzJkV",
        "outputId": "f096add0-36d5-43f6-ebbe-2d0fc0ca099b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.1527777777777778\n",
            "Kappa: 0.0\n",
            "Accuracy: 0.44\n",
            "Jaccard Score: 0.11\n",
            "Precision: 0.11\n",
            "Recall: 0.25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      1.00      0.61        22\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.00      0.00      0.00        11\n",
            "           3       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.44        50\n",
            "   macro avg       0.11      0.25      0.15        50\n",
            "weighted avg       0.19      0.44      0.27        50\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on CREMA"
      ],
      "metadata": {
        "id": "rENYXUU7z4uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  #l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "\n",
        "def extract_mel_spectrogram(df,max_x = 64,max_y = 501):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path'] \n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        " \n",
        "      if spect.shape[1] != max_y:\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        "\n",
        "      s=[]\n",
        "      for i in range(0,int((max_y-64)/30),1):\n",
        "        #print(spect[:,i*64:(i+1)*64].shape)\n",
        "        q=spect[:,i*30:64 +i*30]\n",
        "        #print(q.shape)\n",
        "        delta = librosa.feature.delta(q).reshape((max_x,64,1))\n",
        "        d_delta = librosa.feature.delta(q,order = 2).reshape((max_x,64,1))\n",
        "        #print(q.shape,delta.shape,d_delta.shape)\n",
        "        q = q.reshape((max_x,64,1))\n",
        "\n",
        "        z = np.concatenate((q,delta,d_delta),axis = -1)\n",
        "        #print(z.shape)\n",
        "        s.append(z)\n",
        "      mel_specs.append(np.asarray(s))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  #print(len(mel_specs),mel_specs[0].shape)\n",
        "  mel_specs = np.asarray(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        " \n",
        "train_path = \"CREMA//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "#X_train_spec = np.expand_dims(X_train_spec,axis=-1)\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        " \n",
        " \n",
        "test_path = \"CREMA//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "#X_test_spec = np.expand_dims(X_test_spec,axis=-1)\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        " \n",
        "val_path = \"CREMA//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "#X_val_spec = np.expand_dims(X_val_spec,axis=-1)\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT3_iNO1zs4j",
        "outputId": "c36a8347-a4d0-4104-a59d-a1232ebf91c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3430, 14, 64, 64, 3) (3430, 4)\n",
            "(735, 14, 64, 64, 3) (735, 4)\n",
            "(735, 14, 64, 64, 3) (735, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "def div_L0(num):\n",
        "    [a, b] = div_L1(num)\n",
        "    [c, d, e, f] = div_L2(num)\n",
        "\n",
        "    return [a, b], [c, d, e, f]\n",
        "def div_L1(num):\n",
        "    a = num // 2\n",
        "    b = num - a\n",
        "\n",
        "    return [a, b]\n",
        "def div_L2(num):\n",
        "    [a, b] = div_L1(num)\n",
        "    [c, d] = div_L1(a)\n",
        "    [e, f] = div_L1(b)\n",
        "\n",
        "    return [c, d, e, f]\n",
        "\n",
        "def lpnorm_pooling(features_Ln):\n",
        "    '''\n",
        "    :param features_Ln:\n",
        "    :param var_p: 1-average pooling, np.inf-max pooling\n",
        "    :return:\n",
        "    '''\n",
        "    var_p = 2.14  # average pooling\n",
        "#   var_p = np.inf  # max pooling\n",
        "    lpnorm = tf.norm(features_Ln,ord=var_p,axis=1)\n",
        "    result = lpnorm * (1/features_Ln.shape[1])**(1/var_p)\n",
        "\n",
        "    #print(result)\n",
        "    result = tf.math.reduce_max(features_Ln,axis = 1)\n",
        "    #result = np.average(features_Ln,axis = 0)\n",
        "    #print(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "def subpart():\n",
        "    \n",
        "    input_layer = Input((227,227,3))\n",
        "\n",
        "    X = keras.layers.Resizing(227,227)(input_layer)\n",
        "    \n",
        "      \n",
        "    X = Conv2D(96,(11,11),strides = 4,name=\"conv0\")(X)\n",
        "    X = BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
        "    \n",
        "    X = Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3 ,name='bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D(2)(X)\n",
        "    \n",
        "    X = Flatten()(X)\n",
        "    \n",
        "    X = Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
        "    \n",
        "    X = Dense(4096, activation = 'relu', name = 'fc1')(X) \n",
        "\n",
        "    Y = Reshape((1,4096))(X)\n",
        "\n",
        "    return Model(inputs = input_layer,outputs = Y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def paper_2():\n",
        "    input_layer = Input((14,64,64,3))\n",
        "\n",
        "    sp = subpart()\n",
        "\n",
        "    for i in range(input_layer.shape[1]):\n",
        "      #print(input_layer[:,0,:,:,:].shape)\n",
        "      inp = keras.layers.Resizing(227,227)(input_layer[:,i,:,:,:])\n",
        "      output_layer = sp(inp)\n",
        "\n",
        "      if i == 0:\n",
        "        output_layers = output_layer\n",
        "      else:\n",
        "        output_layers = Concatenate(axis = 1)([output_layers,output_layer])\n",
        "    \n",
        "    print(output_layers.shape)\n",
        "    t,n, d = output_layers.shape\n",
        "    #rint(X.shape)\n",
        "\n",
        "    if n == 3:\n",
        "        features = np.row_stack((X, X[-1]))\n",
        "    if n == 2:\n",
        "        features = np.row_stack((X, X))\n",
        "    if n == 1:\n",
        "        print(n)\n",
        "        features = tf.stack((X, X, X, X),axis =1)\n",
        "\n",
        "    #print(features.shape)\n",
        "    t,n, d = output_layers.shape\n",
        "\n",
        "    [a, b], [c, d, e, f] = div_L0(n)\n",
        "\n",
        "    L0 = lpnorm_pooling(output_layers)\n",
        "    #print(a,b,c,d,e,f, features.shape)\n",
        "    L1_1 = lpnorm_pooling(output_layers[:,:a,:])\n",
        "    #print(features[:,:a,].shape)\n",
        "    L1_2 = lpnorm_pooling(output_layers[:,a:,:])\n",
        "\n",
        "    L2_1 = lpnorm_pooling(output_layers[:,:c,:])\n",
        "    L2_2 = lpnorm_pooling(output_layers[:,c:a,:])\n",
        "    L2_3 = lpnorm_pooling(output_layers[:,a:a+e,:])\n",
        "    L2_4 = lpnorm_pooling(output_layers[:,a+e:,:])\n",
        "\n",
        "    W_L0=1/4;\n",
        "    W_L1=1/4;\n",
        "    W_L2=1/2;\n",
        "\n",
        "    Weights_L = [[W_L0,0,0,0,0,0,0],\n",
        "                 [0,W_L1,0,0,0,0,0],\n",
        "                 [0,0,W_L1,0,0,0,0],\n",
        "                 [0,0,0,W_L2,0,0,0],\n",
        "                 [0,0,0,0,W_L2,0,0],\n",
        "                 [0,0,0,0,0,W_L2,0],\n",
        "                 [0,0,0,0,0,0,W_L2]]\n",
        "\n",
        "    features_Vp = Concatenate(axis =1)([W_L0*L0, W_L1*L1_1, W_L1*L1_2, W_L2*L2_1, W_L2*L2_2, W_L2*L2_3, W_L2*L2_4])\n",
        "\n",
        "    op = Dense(4,activation = 'softmax',kernel_regularizer=keras.regularizers.l2(0.01))(features_Vp)\n",
        "    #features_Up = np.matmul(Weights_L,features_Vp)\n",
        "\n",
        "    return Model(inputs=input_layer,outputs=op)\n",
        "\n",
        "p5 = paper_2()\n",
        "p5.summary()\n",
        "p5.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqwL7m3o0DyX",
        "outputId": "e3211f86-74e4-49bc-d389-ff0ba1f22290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 14, 4096)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 14, 64, 64,  0           []                               \n",
            "                                 3)]                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_33 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_34 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " resizing_29 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_33[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " resizing_30 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_34[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_35 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " model_2 (Functional)           (None, 1, 4096)      58286848    ['resizing_29[0][0]',            \n",
            "                                                                  'resizing_30[0][0]',            \n",
            "                                                                  'resizing_31[0][0]',            \n",
            "                                                                  'resizing_32[0][0]',            \n",
            "                                                                  'resizing_33[0][0]',            \n",
            "                                                                  'resizing_34[0][0]',            \n",
            "                                                                  'resizing_35[0][0]',            \n",
            "                                                                  'resizing_36[0][0]',            \n",
            "                                                                  'resizing_37[0][0]',            \n",
            "                                                                  'resizing_38[0][0]',            \n",
            "                                                                  'resizing_39[0][0]',            \n",
            "                                                                  'resizing_40[0][0]',            \n",
            "                                                                  'resizing_41[0][0]',            \n",
            "                                                                  'resizing_42[0][0]']            \n",
            "                                                                                                  \n",
            " resizing_31 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_35[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_36 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_27 (Concatenate)   (None, 2, 4096)      0           ['model_2[0][0]',                \n",
            "                                                                  'model_2[1][0]']                \n",
            "                                                                                                  \n",
            " resizing_32 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_36[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_37 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_28 (Concatenate)   (None, 3, 4096)      0           ['concatenate_27[0][0]',         \n",
            "                                                                  'model_2[2][0]']                \n",
            "                                                                                                  \n",
            " resizing_33 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_37[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_38 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_29 (Concatenate)   (None, 4, 4096)      0           ['concatenate_28[0][0]',         \n",
            "                                                                  'model_2[3][0]']                \n",
            "                                                                                                  \n",
            " resizing_34 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_38[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_39 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_30 (Concatenate)   (None, 5, 4096)      0           ['concatenate_29[0][0]',         \n",
            "                                                                  'model_2[4][0]']                \n",
            "                                                                                                  \n",
            " resizing_35 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_39[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_40 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_31 (Concatenate)   (None, 6, 4096)      0           ['concatenate_30[0][0]',         \n",
            "                                                                  'model_2[5][0]']                \n",
            "                                                                                                  \n",
            " resizing_36 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_40[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_41 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_32 (Concatenate)   (None, 7, 4096)      0           ['concatenate_31[0][0]',         \n",
            "                                                                  'model_2[6][0]']                \n",
            "                                                                                                  \n",
            " resizing_37 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_41[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_42 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenate)   (None, 8, 4096)      0           ['concatenate_32[0][0]',         \n",
            "                                                                  'model_2[7][0]']                \n",
            "                                                                                                  \n",
            " resizing_38 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_42[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_43 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_34 (Concatenate)   (None, 9, 4096)      0           ['concatenate_33[0][0]',         \n",
            "                                                                  'model_2[8][0]']                \n",
            "                                                                                                  \n",
            " resizing_39 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_43[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_44 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_35 (Concatenate)   (None, 10, 4096)     0           ['concatenate_34[0][0]',         \n",
            "                                                                  'model_2[9][0]']                \n",
            "                                                                                                  \n",
            " resizing_40 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_44[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_45 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_36 (Concatenate)   (None, 11, 4096)     0           ['concatenate_35[0][0]',         \n",
            "                                                                  'model_2[10][0]']               \n",
            "                                                                                                  \n",
            " resizing_41 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_45[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_46 (S  (None, 64, 64, 3)   0           ['input_7[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_37 (Concatenate)   (None, 12, 4096)     0           ['concatenate_36[0][0]',         \n",
            "                                                                  'model_2[11][0]']               \n",
            "                                                                                                  \n",
            " resizing_42 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_46[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " concatenate_38 (Concatenate)   (None, 13, 4096)     0           ['concatenate_37[0][0]',         \n",
            "                                                                  'model_2[12][0]']               \n",
            "                                                                                                  \n",
            " concatenate_39 (Concatenate)   (None, 14, 4096)     0           ['concatenate_38[0][0]',         \n",
            "                                                                  'model_2[13][0]']               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_47 (S  (None, 7, 4096)     0           ['concatenate_39[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_48 (S  (None, 7, 4096)     0           ['concatenate_39[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_49 (S  (None, 3, 4096)     0           ['concatenate_39[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_50 (S  (None, 4, 4096)     0           ['concatenate_39[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_51 (S  (None, 3, 4096)     0           ['concatenate_39[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_52 (S  (None, 4, 4096)     0           ['concatenate_39[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_7 (TFOpLamb  (None, 4096)        0           ['concatenate_39[0][0]']         \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_8 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_47[0][\n",
            " da)                                                             0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_9 (TFOpLamb  (None, 4096)        0           ['tf.__operators__.getitem_48[0][\n",
            " da)                                                             0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_10 (TFOpLam  (None, 4096)        0           ['tf.__operators__.getitem_49[0][\n",
            " bda)                                                            0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_11 (TFOpLam  (None, 4096)        0           ['tf.__operators__.getitem_50[0][\n",
            " bda)                                                            0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_12 (TFOpLam  (None, 4096)        0           ['tf.__operators__.getitem_51[0][\n",
            " bda)                                                            0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_13 (TFOpLam  (None, 4096)        0           ['tf.__operators__.getitem_52[0][\n",
            " bda)                                                            0]']                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_21 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_7[0][0]']   \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_22 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_8[0][0]']   \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_23 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_9[0][0]']   \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_24 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_10[0][0]']  \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_25 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_11[0][0]']  \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_26 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_12[0][0]']  \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_27 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_13[0][0]']  \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate_40 (Concatenate)   (None, 28672)        0           ['tf.math.multiply_21[0][0]',    \n",
            "                                                                  'tf.math.multiply_22[0][0]',    \n",
            "                                                                  'tf.math.multiply_23[0][0]',    \n",
            "                                                                  'tf.math.multiply_24[0][0]',    \n",
            "                                                                  'tf.math.multiply_25[0][0]',    \n",
            "                                                                  'tf.math.multiply_26[0][0]',    \n",
            "                                                                  'tf.math.multiply_27[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 4)            114692      ['concatenate_40[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 58,401,540\n",
            "Trainable params: 58,398,788\n",
            "Non-trainable params: 2,752\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p5.load_weights('TESS//models//paper_5_acc.h5')\n",
        "print(p5.evaluate(X_test_spec,Y_test_spec))\n",
        "p5.load_weights('TESS//models//paper_5_loss.h5')\n",
        "p5.evaluate(X_test_spec,Y_test_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZL-qu8c59ky",
        "outputId": "569f47d9-ff7e-4a74-b54c-23cd96e84fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 17s 477ms/step - loss: 23.2334 - accuracy: 0.2748\n",
            "[23.233396530151367, 0.2748299241065979]\n",
            "23/23 [==============================] - 11s 465ms/step - loss: 23.2334 - accuracy: 0.2748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[23.233396530151367, 0.2748299241065979]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "#p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "ihf7zmCc6Hie",
        "outputId": "b7286270-4893-42fd-8f5b-3b7ab175a0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.1619248895562287\n",
            "Kappa: 0.04194128220491322\n",
            "Accuracy: 0.2748299319727891\n",
            "Jaccard Score: 0.09782379891035166\n",
            "Precision: 0.18458646616541352\n",
            "Recall: 0.28030303030303033\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.95      0.40       176\n",
            "           1       0.49      0.17      0.25       204\n",
            "           2       0.00      0.00      0.00       176\n",
            "           3       0.00      0.00      0.00       179\n",
            "\n",
            "    accuracy                           0.27       735\n",
            "   macro avg       0.18      0.28      0.16       735\n",
            "weighted avg       0.20      0.27      0.16       735\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on SAVEE"
      ],
      "metadata": {
        "id": "mtSQnKGD6WMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "    'angry':(1,0,0,0),\n",
        "    'happy':(0,1,0,0),\n",
        "    'neutral':(0,0,1,0),\n",
        "    'sad':(0,0,0,1)\n",
        "}\n",
        "\n",
        "\n",
        "def label_to_onehot(l):\n",
        "  #l=l[2:]\n",
        "  onehot = label_dict[l]\n",
        "  return onehot\n",
        "\n",
        "\n",
        "def extract_mel_spectrogram(df,max_x = 64,max_y = 714):\n",
        "  labels = []\n",
        "  mel_specs= []\n",
        "  for index, row in df.iterrows():\n",
        "      filename = row['path'] \n",
        "      y, sr = librosa.core.load(filename,sr = 16000)\n",
        "      spect = librosa.feature.melspectrogram(y=y, sr=sr, window=\"hamming\", win_length = int(0.025*sr),hop_length=int(0.010*sr),n_mels = 64)\n",
        "      spect = librosa.power_to_db(spect, ref=np.max)\n",
        " \n",
        "      if spect.shape[1] != max_y:\n",
        "              spect.resize(max_x,max_y, refcheck=False)\n",
        "\n",
        "      s=[]\n",
        "      for i in range(0,int((max_y-64)/30),1):\n",
        "        #print(spect[:,i*64:(i+1)*64].shape)\n",
        "        q=spect[:,i*30:64 +i*30]\n",
        "        #print(q.shape)\n",
        "        delta = librosa.feature.delta(q).reshape((max_x,64,1))\n",
        "        d_delta = librosa.feature.delta(q,order = 2).reshape((max_x,64,1))\n",
        "        #print(q.shape,delta.shape,d_delta.shape)\n",
        "        q = q.reshape((max_x,64,1))\n",
        "\n",
        "        z = np.concatenate((q,delta,d_delta),axis = -1)\n",
        "        #print(z.shape)\n",
        "        s.append(z)\n",
        "      mel_specs.append(np.asarray(s))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "  #print(len(mel_specs),mel_specs[0].shape)\n",
        "  mel_specs = np.asarray(mel_specs)\n",
        "  labels = np.array(labels).reshape(len(labels),4)\n",
        "  return mel_specs, labels\n",
        " \n",
        "train_path = \"SAVEE//train.csv\"\n",
        "train_csv = pd.read_csv(train_path,usecols=['labels','path'])\n",
        "X_train_spec,Y_train_spec = extract_mel_spectrogram(train_csv)\n",
        "X_train_spec = (X_train_spec - X_train_spec.mean())/ X_train_spec.std()\n",
        "#X_train_spec = np.expand_dims(X_train_spec,axis=-1)\n",
        "print(X_train_spec.shape,Y_train_spec.shape)\n",
        " \n",
        " \n",
        "test_path = \"SAVEE//test.csv\"\n",
        "test_csv = pd.read_csv(test_path,usecols=['labels','path'])\n",
        "X_test_spec,Y_test_spec = extract_mel_spectrogram(test_csv)\n",
        "X_test_spec = (X_test_spec - X_test_spec.mean())/ X_test_spec.std()\n",
        "#X_test_spec = np.expand_dims(X_test_spec,axis=-1)\n",
        "print(X_test_spec.shape,Y_test_spec.shape)\n",
        " \n",
        "val_path = \"SAVEE//val.csv\"\n",
        "val_csv = pd.read_csv(val_path,usecols=['labels','path'])\n",
        "X_val_spec,Y_val_spec = extract_mel_spectrogram(val_csv)\n",
        "X_val_spec = (X_val_spec - X_val_spec.mean())/ X_val_spec.std()\n",
        "#X_val_spec = np.expand_dims(X_val_spec,axis=-1)\n",
        "print(X_val_spec.shape,Y_val_spec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVGSIoI-6Utt",
        "outputId": "57a6d559-eadb-425d-d006-63d4b2053987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(207, 21, 64, 64, 3) (207, 4)\n",
            "(45, 21, 64, 64, 3) (45, 4)\n",
            "(44, 21, 64, 64, 3) (44, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "def div_L0(num):\n",
        "    [a, b] = div_L1(num)\n",
        "    [c, d, e, f] = div_L2(num)\n",
        "\n",
        "    return [a, b], [c, d, e, f]\n",
        "def div_L1(num):\n",
        "    a = num // 2\n",
        "    b = num - a\n",
        "\n",
        "    return [a, b]\n",
        "def div_L2(num):\n",
        "    [a, b] = div_L1(num)\n",
        "    [c, d] = div_L1(a)\n",
        "    [e, f] = div_L1(b)\n",
        "\n",
        "    return [c, d, e, f]\n",
        "\n",
        "def lpnorm_pooling(features_Ln):\n",
        "    '''\n",
        "    :param features_Ln:\n",
        "    :param var_p: 1-average pooling, np.inf-max pooling\n",
        "    :return:\n",
        "    '''\n",
        "    var_p = 2.14  # average pooling\n",
        "#   var_p = np.inf  # max pooling\n",
        "    lpnorm = tf.norm(features_Ln,ord=var_p,axis=1)\n",
        "    result = lpnorm * (1/features_Ln.shape[1])**(1/var_p)\n",
        "\n",
        "    #print(result)\n",
        "    result = tf.math.reduce_max(features_Ln,axis = 1)\n",
        "    #result = np.average(features_Ln,axis = 0)\n",
        "    #print(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "def subpart():\n",
        "    \n",
        "    input_layer = Input((227,227,3))\n",
        "\n",
        "    X = keras.layers.Resizing(227,227)(input_layer)\n",
        "    \n",
        "      \n",
        "    X = Conv2D(96,(11,11),strides = 4,name=\"conv0\")(X)\n",
        "    X = BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
        "    \n",
        "    X = Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3 ,name='bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = MaxPooling2D(2)(X)\n",
        "    \n",
        "    X = Flatten()(X)\n",
        "    \n",
        "    X = Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
        "    \n",
        "    X = Dense(4096, activation = 'relu', name = 'fc1')(X) \n",
        "\n",
        "    Y = Reshape((1,4096))(X)\n",
        "\n",
        "    return Model(inputs = input_layer,outputs = Y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def paper_2():\n",
        "    input_layer = Input((21,64,64,3))\n",
        "\n",
        "    sp = subpart()\n",
        "\n",
        "    for i in range(input_layer.shape[1]):\n",
        "      #print(input_layer[:,0,:,:,:].shape)\n",
        "      inp = keras.layers.Resizing(227,227)(input_layer[:,i,:,:,:])\n",
        "      output_layer = sp(inp)\n",
        "\n",
        "      if i == 0:\n",
        "        output_layers = output_layer\n",
        "      else:\n",
        "        output_layers = Concatenate(axis = 1)([output_layers,output_layer])\n",
        "    \n",
        "    print(output_layers.shape)\n",
        "    t,n, d = output_layers.shape\n",
        "    #rint(X.shape)\n",
        "\n",
        "    if n == 3:\n",
        "        features = np.row_stack((X, X[-1]))\n",
        "    if n == 2:\n",
        "        features = np.row_stack((X, X))\n",
        "    if n == 1:\n",
        "        print(n)\n",
        "        features = tf.stack((X, X, X, X),axis =1)\n",
        "\n",
        "    #print(features.shape)\n",
        "    t,n, d = output_layers.shape\n",
        "\n",
        "    [a, b], [c, d, e, f] = div_L0(n)\n",
        "\n",
        "    L0 = lpnorm_pooling(output_layers)\n",
        "    #print(a,b,c,d,e,f, features.shape)\n",
        "    L1_1 = lpnorm_pooling(output_layers[:,:a,:])\n",
        "    #print(features[:,:a,].shape)\n",
        "    L1_2 = lpnorm_pooling(output_layers[:,a:,:])\n",
        "\n",
        "    L2_1 = lpnorm_pooling(output_layers[:,:c,:])\n",
        "    L2_2 = lpnorm_pooling(output_layers[:,c:a,:])\n",
        "    L2_3 = lpnorm_pooling(output_layers[:,a:a+e,:])\n",
        "    L2_4 = lpnorm_pooling(output_layers[:,a+e:,:])\n",
        "\n",
        "    W_L0=1/4;\n",
        "    W_L1=1/4;\n",
        "    W_L2=1/2;\n",
        "\n",
        "    Weights_L = [[W_L0,0,0,0,0,0,0],\n",
        "                 [0,W_L1,0,0,0,0,0],\n",
        "                 [0,0,W_L1,0,0,0,0],\n",
        "                 [0,0,0,W_L2,0,0,0],\n",
        "                 [0,0,0,0,W_L2,0,0],\n",
        "                 [0,0,0,0,0,W_L2,0],\n",
        "                 [0,0,0,0,0,0,W_L2]]\n",
        "\n",
        "    features_Vp = Concatenate(axis =1)([W_L0*L0, W_L1*L1_1, W_L1*L1_2, W_L2*L2_1, W_L2*L2_2, W_L2*L2_3, W_L2*L2_4])\n",
        "\n",
        "    op = Dense(4,activation = 'softmax',kernel_regularizer=keras.regularizers.l2(0.01))(features_Vp)\n",
        "    #features_Up = np.matmul(Weights_L,features_Vp)\n",
        "\n",
        "    return Model(inputs=input_layer,outputs=op)\n",
        "\n",
        "p5 = paper_2()\n",
        "p5.summary()\n",
        "p5.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTeHP1jf6cU1",
        "outputId": "62d1123c-815d-4a2c-8484-5ac0aeca56fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 21, 4096)\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None, 21, 64, 64,  0           []                               \n",
            "                                 3)]                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_53 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_54 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " resizing_44 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_53[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " resizing_45 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_54[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_55 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " model_4 (Functional)           (None, 1, 4096)      58286848    ['resizing_44[0][0]',            \n",
            "                                                                  'resizing_45[0][0]',            \n",
            "                                                                  'resizing_46[0][0]',            \n",
            "                                                                  'resizing_47[0][0]',            \n",
            "                                                                  'resizing_48[0][0]',            \n",
            "                                                                  'resizing_49[0][0]',            \n",
            "                                                                  'resizing_50[0][0]',            \n",
            "                                                                  'resizing_51[0][0]',            \n",
            "                                                                  'resizing_52[0][0]',            \n",
            "                                                                  'resizing_53[0][0]',            \n",
            "                                                                  'resizing_54[0][0]',            \n",
            "                                                                  'resizing_55[0][0]',            \n",
            "                                                                  'resizing_56[0][0]',            \n",
            "                                                                  'resizing_57[0][0]',            \n",
            "                                                                  'resizing_58[0][0]',            \n",
            "                                                                  'resizing_59[0][0]',            \n",
            "                                                                  'resizing_60[0][0]',            \n",
            "                                                                  'resizing_61[0][0]',            \n",
            "                                                                  'resizing_62[0][0]',            \n",
            "                                                                  'resizing_63[0][0]',            \n",
            "                                                                  'resizing_64[0][0]']            \n",
            "                                                                                                  \n",
            " resizing_46 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_55[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_56 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_41 (Concatenate)   (None, 2, 4096)      0           ['model_4[0][0]',                \n",
            "                                                                  'model_4[1][0]']                \n",
            "                                                                                                  \n",
            " resizing_47 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_56[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_57 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_42 (Concatenate)   (None, 3, 4096)      0           ['concatenate_41[0][0]',         \n",
            "                                                                  'model_4[2][0]']                \n",
            "                                                                                                  \n",
            " resizing_48 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_57[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_58 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_43 (Concatenate)   (None, 4, 4096)      0           ['concatenate_42[0][0]',         \n",
            "                                                                  'model_4[3][0]']                \n",
            "                                                                                                  \n",
            " resizing_49 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_58[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_59 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_44 (Concatenate)   (None, 5, 4096)      0           ['concatenate_43[0][0]',         \n",
            "                                                                  'model_4[4][0]']                \n",
            "                                                                                                  \n",
            " resizing_50 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_59[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_60 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_45 (Concatenate)   (None, 6, 4096)      0           ['concatenate_44[0][0]',         \n",
            "                                                                  'model_4[5][0]']                \n",
            "                                                                                                  \n",
            " resizing_51 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_60[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_61 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_46 (Concatenate)   (None, 7, 4096)      0           ['concatenate_45[0][0]',         \n",
            "                                                                  'model_4[6][0]']                \n",
            "                                                                                                  \n",
            " resizing_52 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_61[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_62 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_47 (Concatenate)   (None, 8, 4096)      0           ['concatenate_46[0][0]',         \n",
            "                                                                  'model_4[7][0]']                \n",
            "                                                                                                  \n",
            " resizing_53 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_62[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_63 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_48 (Concatenate)   (None, 9, 4096)      0           ['concatenate_47[0][0]',         \n",
            "                                                                  'model_4[8][0]']                \n",
            "                                                                                                  \n",
            " resizing_54 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_63[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_64 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_49 (Concatenate)   (None, 10, 4096)     0           ['concatenate_48[0][0]',         \n",
            "                                                                  'model_4[9][0]']                \n",
            "                                                                                                  \n",
            " resizing_55 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_64[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_65 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_50 (Concatenate)   (None, 11, 4096)     0           ['concatenate_49[0][0]',         \n",
            "                                                                  'model_4[10][0]']               \n",
            "                                                                                                  \n",
            " resizing_56 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_65[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_66 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_51 (Concatenate)   (None, 12, 4096)     0           ['concatenate_50[0][0]',         \n",
            "                                                                  'model_4[11][0]']               \n",
            "                                                                                                  \n",
            " resizing_57 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_66[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_67 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_52 (Concatenate)   (None, 13, 4096)     0           ['concatenate_51[0][0]',         \n",
            "                                                                  'model_4[12][0]']               \n",
            "                                                                                                  \n",
            " resizing_58 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_67[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_68 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_53 (Concatenate)   (None, 14, 4096)     0           ['concatenate_52[0][0]',         \n",
            "                                                                  'model_4[13][0]']               \n",
            "                                                                                                  \n",
            " resizing_59 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_68[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_69 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_54 (Concatenate)   (None, 15, 4096)     0           ['concatenate_53[0][0]',         \n",
            "                                                                  'model_4[14][0]']               \n",
            "                                                                                                  \n",
            " resizing_60 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_69[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_70 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_55 (Concatenate)   (None, 16, 4096)     0           ['concatenate_54[0][0]',         \n",
            "                                                                  'model_4[15][0]']               \n",
            "                                                                                                  \n",
            " resizing_61 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_70[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_71 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_56 (Concatenate)   (None, 17, 4096)     0           ['concatenate_55[0][0]',         \n",
            "                                                                  'model_4[16][0]']               \n",
            "                                                                                                  \n",
            " resizing_62 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_71[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_72 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_57 (Concatenate)   (None, 18, 4096)     0           ['concatenate_56[0][0]',         \n",
            "                                                                  'model_4[17][0]']               \n",
            "                                                                                                  \n",
            " resizing_63 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_72[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_73 (S  (None, 64, 64, 3)   0           ['input_9[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate_58 (Concatenate)   (None, 19, 4096)     0           ['concatenate_57[0][0]',         \n",
            "                                                                  'model_4[18][0]']               \n",
            "                                                                                                  \n",
            " resizing_64 (Resizing)         (None, 227, 227, 3)  0           ['tf.__operators__.getitem_73[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " concatenate_59 (Concatenate)   (None, 20, 4096)     0           ['concatenate_58[0][0]',         \n",
            "                                                                  'model_4[19][0]']               \n",
            "                                                                                                  \n",
            " concatenate_60 (Concatenate)   (None, 21, 4096)     0           ['concatenate_59[0][0]',         \n",
            "                                                                  'model_4[20][0]']               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_74 (S  (None, 10, 4096)    0           ['concatenate_60[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_75 (S  (None, 11, 4096)    0           ['concatenate_60[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_76 (S  (None, 5, 4096)     0           ['concatenate_60[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_77 (S  (None, 5, 4096)     0           ['concatenate_60[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_78 (S  (None, 5, 4096)     0           ['concatenate_60[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_79 (S  (None, 6, 4096)     0           ['concatenate_60[0][0]']         \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_14 (TFOpLam  (None, 4096)        0           ['concatenate_60[0][0]']         \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_15 (TFOpLam  (None, 4096)        0           ['tf.__operators__.getitem_74[0][\n",
            " bda)                                                            0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_16 (TFOpLam  (None, 4096)        0           ['tf.__operators__.getitem_75[0][\n",
            " bda)                                                            0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_17 (TFOpLam  (None, 4096)        0           ['tf.__operators__.getitem_76[0][\n",
            " bda)                                                            0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_18 (TFOpLam  (None, 4096)        0           ['tf.__operators__.getitem_77[0][\n",
            " bda)                                                            0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_19 (TFOpLam  (None, 4096)        0           ['tf.__operators__.getitem_78[0][\n",
            " bda)                                                            0]']                             \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_20 (TFOpLam  (None, 4096)        0           ['tf.__operators__.getitem_79[0][\n",
            " bda)                                                            0]']                             \n",
            "                                                                                                  \n",
            " tf.math.multiply_35 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_14[0][0]']  \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_36 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_15[0][0]']  \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_37 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_16[0][0]']  \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_38 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_17[0][0]']  \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_39 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_18[0][0]']  \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_40 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_19[0][0]']  \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_41 (TFOpLambd  (None, 4096)        0           ['tf.math.reduce_max_20[0][0]']  \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate_61 (Concatenate)   (None, 28672)        0           ['tf.math.multiply_35[0][0]',    \n",
            "                                                                  'tf.math.multiply_36[0][0]',    \n",
            "                                                                  'tf.math.multiply_37[0][0]',    \n",
            "                                                                  'tf.math.multiply_38[0][0]',    \n",
            "                                                                  'tf.math.multiply_39[0][0]',    \n",
            "                                                                  'tf.math.multiply_40[0][0]',    \n",
            "                                                                  'tf.math.multiply_41[0][0]']    \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            114692      ['concatenate_61[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 58,401,540\n",
            "Trainable params: 58,398,788\n",
            "Non-trainable params: 2,752\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p5.load_weights('TESS//models//paper_5_acc.h5')\n",
        "print(p5.evaluate(X_test_spec,Y_test_spec))\n",
        "p5.load_weights('TESS//models//paper_5_loss.h5')\n",
        "p5.evaluate(X_test_spec,Y_test_spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp0XOanY6ecX",
        "outputId": "19aab893-3a87-4783-f71a-df007ac6616f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 6s 997ms/step - loss: 18.2215 - accuracy: 0.2667\n",
            "[18.221452713012695, 0.2666666805744171]\n",
            "2/2 [==============================] - 1s 382ms/step - loss: 18.2215 - accuracy: 0.2667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[18.221452713012695, 0.2666666805744171]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test set\n",
        "#p2.load_weights('TESS//models//paper_2_acc.h5')\n",
        "from sklearn.metrics import *\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test_spec,axis = -1),np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())\n",
        "g = np.argmax(Y_test_spec,axis = -1)\n",
        "p = np.argmax(p5.predict(X_test_spec).reshape(Y_test_spec.shape),axis = 1)\n",
        "g = g.ravel()\n",
        "p = p.ravel()\n",
        "f1 = f1_score(g,p,average= 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average='macro')\n",
        "precision = precision_score(g,p,average='macro') \n",
        "recall = recall_score(g,p,average='macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "print(classification_report(g,p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "IQ3ayHxa6hIU",
        "outputId": "92b8f6fa-d6d7-4482-faa0-98229b9f4add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE: 0.17283298097251584\n",
            "Kappa: 0.05714285714285716\n",
            "Accuracy: 0.26666666666666666\n",
            "Jaccard Score: 0.10565015479876161\n",
            "Precision: 0.13068181818181818\n",
            "Recall: 0.3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.90      0.42        10\n",
            "           1       0.25      0.30      0.27        10\n",
            "           2       0.00      0.00      0.00        18\n",
            "           3       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.27        45\n",
            "   macro avg       0.13      0.30      0.17        45\n",
            "weighted avg       0.12      0.27      0.15        45\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feb 2022"
      ],
      "metadata": {
        "id": "vtgfgGNCwWAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hamming Window"
      ],
      "metadata": {
        "id": "aom9EiT6wX--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(csvpath,path):\n",
        "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
        "    for i in range(1, 21):\n",
        "        header += f' mfcc{i}'\n",
        "    header += ' label'\n",
        "    header = header.split()\n",
        "    file = open(csvpath, 'w', newline='')\n",
        "    with file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow(header)\n",
        "    rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "    for index, row in rslt_df.iterrows(): \n",
        "        filename = row['path']\n",
        "        y, sr = librosa.load(row['path'], mono=True, duration=30)\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr,window=\"hamming\")\n",
        "        rmse = librosa.feature.rms(y=y)\n",
        "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr,window=\"hamming\")\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr,window=\"hamming\")\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr,window=\"hamming\")\n",
        "        zcr = librosa.feature.zero_crossing_rate(y)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr,window=\"hamming\")\n",
        "        to_append = f' {filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
        "        for e in mfcc:\n",
        "                    to_append += f' {np.mean(e)}'\n",
        "        onehot_label = label_to_onehot(row['labels'])\n",
        "        to_append += f' {np.argmax(onehot_label)}'\n",
        "        file = open(csvpath, 'a', newline='')\n",
        "        with file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow(to_append.split())\n",
        "\n",
        "train_csv = \"TESS//train.csv\"\n",
        "test_csv = \"TESS//test.csv\"\n",
        "val_csv = \"TESS//val.csv\"\n",
        "csvpath = 'TESS//hamming_hand_engineered_features_EMODB_train.csv'\n",
        "extract_features(csvpath,train_csv)\n",
        "csvpath = 'TESS//hamming_hand_engineered_features_EMODB_test.csv'\n",
        "extract_features(csvpath,test_csv)\n",
        "csvpath = 'TESS//hamming_hand_engineered_features_EMODB_val.csv'\n",
        "extract_features(csvpath,val_csv)"
      ],
      "metadata": {
        "id": "F34ZUJYB6lhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "      'angry':(1,0,0,0),\n",
        "      'happy':(0,1,0,0),\n",
        "      'neutral':(0,0,1,0),\n",
        "      'sad':(0,0,0,1)\n",
        "  }\n",
        "time = 4\n",
        "def label_to_onehot(l):\n",
        "    #l=l[2:]\n",
        "    onehot = label_dict[l]\n",
        "    return onehot\n",
        "def load_csv(path):\n",
        "  audio_files=[]\n",
        "  labels=[]\n",
        "\n",
        "  rslt_df = pd.read_csv(path,usecols=['labels','path'])\n",
        "\n",
        "  for index, row in rslt_df.iterrows(): \n",
        "      \n",
        "      y, sr = librosa.load(row['path'], mono=True, duration = 4,sr = 16000)\n",
        "      \n",
        "      audio_files.append(librosa.util.fix_length(y,int(sr*time)))\n",
        "      labels.append(label_to_onehot(row['labels']))\n",
        "\n",
        "  audio_files = np.reshape(np.array(audio_files),(len(labels),int(sr*time),1))\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  return audio_files,labels\n",
        "\n",
        "train_path = \"TESS//train.csv\"\n",
        "X_train,Y_train = load_csv(train_path)\n",
        "print(\"Train Data\",X_train.shape,Y_train.shape)\n",
        "\n",
        "test_path = \"TESS//test.csv\"\n",
        "X_test,Y_test = load_csv(test_path)\n",
        "print(\"Test Data\",X_test.shape,Y_test.shape)\n",
        "\n",
        "val_path = \"TESS//val.csv\"\n",
        "X_val,Y_val = load_csv(val_path)\n",
        "print(\"Val Data\",X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "id": "NTFYfMyjwnjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4139dc2-a62f-4814-dca9-f7db8a8688e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data (1114, 64000, 1) (1114, 4)\n",
            "Test Data (239, 64000, 1) (239, 4)\n",
            "Val Data (239, 64000, 1) (239, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csvpath = 'TESS/hamming_hand_engineered_features_EMODB_train.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(np.array(data.iloc[:, :-1], dtype = float))\n",
        "X_train_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_train_features = np.array(data.iloc[:, -1]).reshape(X_train_features.shape[0],1)\n",
        "\n",
        "csvpath = 'TESS/hamming_hand_engineered_features_EMODB_test.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_test_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_test_features = np.array(data.iloc[:, -1]).reshape(X_test_features.shape[0],1)\n",
        "\n",
        "csvpath = 'TESS/hamming_hand_engineered_features_EMODB_val.csv'\n",
        "data = pd.read_csv(csvpath)\n",
        "data = data.drop(['filename'],axis=1)\n",
        "X_val_features = scaler.transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "Y_val_features = np.array(data.iloc[:, -1]).reshape(X_val_features.shape[0],1)\n",
        "\n",
        "\n",
        "\n",
        "print(X_train_features.shape,Y_train_features.shape)\n",
        "print(X_test_features.shape,Y_test_features.shape)\n",
        "print(X_val_features.shape,Y_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAla4PlhxrP7",
        "outputId": "ca2f619d-6458-4e62-edc5-2ea250edb2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1114, 26) (1114, 1)\n",
            "(239, 26) (239, 1)\n",
            "(239, 26) (239, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time = 4\n",
        "def self_attention(b5):\n",
        "    b5 = Permute(dims = (2,1))(b5)\n",
        "    w,x,z = b5.shape\n",
        "    z1=int(z)\n",
        "    query = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)            #can change the factor to divide \n",
        "    key = Conv1D(z1, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "    value = Conv1D(z, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(b5)\n",
        "\n",
        "    query = Reshape([x, z1])(query)\n",
        "    key = Reshape([z1, x])(key)\n",
        "    value = Reshape([z, x])(value)\n",
        "\n",
        "    prod = Dot(axes = 2)([query,Permute(dims = (2,1))(key)])\n",
        "\n",
        "    w = z1**-2\n",
        "    prod = Lambda(lambda x: x * w)(prod)\n",
        "    prod = Softmax()(prod)\n",
        "    \n",
        "    attention = Dot(axes = 2)([value,Permute(dims = (2,1))(prod)])\n",
        "    attention = Reshape([x,z])(attention)\n",
        "    attention = Add()([attention,b5])\n",
        "    attention = Permute(dims = (2,1))(attention)\n",
        "    return attention\n",
        "\n",
        "\n",
        "def Wavenet():\n",
        "  n_filters = 64\n",
        "  filter_width = 2\n",
        "  dilation_rates = [2**i for i in range(3)]  \n",
        "  sr = 16000\n",
        "\n",
        "  ip1 = Input(shape=(int(sr*time), 1))\n",
        "  \n",
        "\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(ip1))\n",
        "  x = LeakyReLU()(Conv1D(8,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = LeakyReLU()(Conv1D(16,5,padding='same')(x))\n",
        "  x = AveragePooling1D()(x)\n",
        "  skips = []\n",
        "  for dilation_rate in dilation_rates:\n",
        "      \n",
        "      \n",
        "      x = Conv1D(32, 1, padding='same', activation='relu')(x) \n",
        "      \n",
        "      # filter\n",
        "      x_f = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # gate\n",
        "      x_g = Conv1D(filters=n_filters,\n",
        "                  kernel_size=filter_width, \n",
        "                  padding='causal',\n",
        "                  dilation_rate=dilation_rate)(x)\n",
        "      \n",
        "      # combine filter and gating branches\n",
        "      z = Multiply()([Activation('tanh')(x_f),\n",
        "                      Activation('sigmoid')(x_g)])\n",
        "      \n",
        "      # postprocessing - equivalent to time-distributed dense\n",
        "      z = Conv1D(32, 1, padding='same', activation='relu')(z)\n",
        "      \n",
        "      # residual connection\n",
        "      x = Add()([x, z])    \n",
        "      \n",
        "      \n",
        "      skips.append(z)\n",
        "\n",
        "\n",
        "  out = Activation('relu')(Add()(skips))\n",
        "\n",
        "  out = AveragePooling1D(8000)(out)\n",
        "  out = self_attention(out)\n",
        "\n",
        "  #out = Conv1D(4,1,activation='softmax')(out)\n",
        "  #out1 = Reshape((4,1))(out)\n",
        " \n",
        "  inp1 = Input(shape = (26))\n",
        "  layer1 = LeakyReLU()(Dense(128)(inp1))\n",
        "  layer3 = LeakyReLU()(Dense(32)(layer1))\n",
        "  layer3 = Reshape((1,32))(layer3)\n",
        "  #out2 = Dense(4)(layer2)\n",
        "  #out2 = Reshape((4,1))(out2)\n",
        "\n",
        "  output_layer = Average()([out,layer3])\n",
        "  output_layer = Flatten()(output_layer)\n",
        "  output_layer = Dense(4,activation='softmax')(output_layer)\n",
        "  \n",
        "  model = Model(inputs = [ip1,inp1],outputs = [output_layer])\n",
        "  return model\n",
        "\n",
        "#layer2 = Flatten()(model2.output)\n",
        "\n",
        "ensembled = Wavenet()\n",
        "ensembled.summary()\n",
        "\n",
        "ensembled.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZTw0J7N1cnm",
        "outputId": "55352a83-0fe5-4020-d32b-76c19ac429fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64000, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 64000, 8)     48          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 64000, 8)     0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 64000, 8)     328         ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 64000, 8)     0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d (AveragePool  (None, 32000, 8)    0           ['leaky_re_lu_1[0][0]']          \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 32000, 16)    656         ['average_pooling1d[0][0]']      \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 32000, 16)    0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 32000, 16)    1296        ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 32000, 16)    0           ['conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d_1 (AveragePo  (None, 16000, 16)   0           ['leaky_re_lu_3[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 16000, 16)    1296        ['average_pooling1d_1[0][0]']    \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 16000, 16)    0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 16000, 16)    1296        ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 16000, 16)    0           ['conv1d_5[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d_2 (AveragePo  (None, 8000, 16)    0           ['leaky_re_lu_5[0][0]']          \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 8000, 32)     544         ['average_pooling1d_2[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 8000, 64)     4160        ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 8000, 64)     4160        ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 8000, 64)     0           ['conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 8000, 64)     0           ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 8000, 64)     0           ['activation[0][0]',             \n",
            "                                                                  'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 8000, 32)     2080        ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 8000, 32)     0           ['conv1d_6[0][0]',               \n",
            "                                                                  'conv1d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 8000, 32)     1056        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 8000, 64)     0           ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 8000, 64)     0           ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 8000, 64)     0           ['activation_2[0][0]',           \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 8000, 32)     2080        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 8000, 32)     0           ['conv1d_10[0][0]',              \n",
            "                                                                  'conv1d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 8000, 32)     1056        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)             (None, 8000, 64)     4160        ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 8000, 64)     0           ['conv1d_15[0][0]']              \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 8000, 64)     0           ['conv1d_16[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 8000, 64)     0           ['activation_4[0][0]',           \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 8000, 32)     2080        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 8000, 32)     0           ['conv1d_9[0][0]',               \n",
            "                                                                  'conv1d_13[0][0]',              \n",
            "                                                                  'conv1d_17[0][0]']              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 8000, 32)     0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling1d_3 (AveragePo  (None, 1, 32)       0           ['activation_6[0][0]']           \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 32, 1)        0           ['average_pooling1d_3[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 32)        0           ['conv1d_19[0][0]']              \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 32, 1)        0           ['conv1d_18[0][0]']              \n",
            "                                                                                                  \n",
            " permute_1 (Permute)            (None, 32, 1)        0           ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 32, 32)       0           ['reshape[0][0]',                \n",
            "                                                                  'permute_1[0][0]']              \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 32, 32)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)             (None, 32, 1)        2           ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " softmax (Softmax)              (None, 32, 32)       0           ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 32)        0           ['conv1d_20[0][0]']              \n",
            "                                                                                                  \n",
            " permute_2 (Permute)            (None, 32, 32)       0           ['softmax[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          3456        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 1, 32)        0           ['reshape_2[0][0]',              \n",
            "                                                                  'permute_2[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 32, 1)        0           ['dot_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 32, 1)        0           ['reshape_3[0][0]',              \n",
            "                                                                  'permute[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 32)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " permute_3 (Permute)            (None, 1, 32)        0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)            (None, 1, 32)        0           ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " average (Average)              (None, 1, 32)        0           ['permute_3[0][0]',              \n",
            "                                                                  'reshape_4[0][0]']              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 32)           0           ['average[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            132         ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 46,498\n",
            "Trainable params: 46,498\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Fitting our neural network\n",
        "model_checkpoint1 = ModelCheckpoint('TESS//models//ensembled_hamming_loss.h5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model_checkpoint2 = ModelCheckpoint('TESS//models//ensembled_hamming_acc.h5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
        "ensembled.fit([X_train,X_train_features],Y_train, batch_size=16,validation_data=([X_val,X_val_features], Y_val),epochs=30,callbacks = [model_checkpoint1,model_checkpoint2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f91iLYjN1x82",
        "outputId": "f094a633-386f-4bf8-90e2-9cbb40410d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.7459 - accuracy: 0.8106\n",
            "Epoch 00001: val_loss improved from inf to 0.28772, saving model to TESS//models/ensembled_hamming_loss.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.95816, saving model to TESS//models/ensembled_hamming_acc.h5\n",
            "70/70 [==============================] - 36s 265ms/step - loss: 0.7459 - accuracy: 0.8106 - val_loss: 0.2877 - val_accuracy: 0.9582\n",
            "Epoch 2/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.1529 - accuracy: 0.9803\n",
            "Epoch 00002: val_loss improved from 0.28772 to 0.11334, saving model to TESS//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.95816 to 0.97071, saving model to TESS//models/ensembled_hamming_acc.h5\n",
            "70/70 [==============================] - 17s 246ms/step - loss: 0.1529 - accuracy: 0.9803 - val_loss: 0.1133 - val_accuracy: 0.9707\n",
            "Epoch 3/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9892\n",
            "Epoch 00003: val_loss improved from 0.11334 to 0.08232, saving model to TESS//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.97071\n",
            "70/70 [==============================] - 16s 233ms/step - loss: 0.0615 - accuracy: 0.9892 - val_loss: 0.0823 - val_accuracy: 0.9707\n",
            "Epoch 4/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9955\n",
            "Epoch 00004: val_loss improved from 0.08232 to 0.05914, saving model to TESS//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.97071 to 0.98745, saving model to TESS//models/ensembled_hamming_acc.h5\n",
            "70/70 [==============================] - 17s 241ms/step - loss: 0.0355 - accuracy: 0.9955 - val_loss: 0.0591 - val_accuracy: 0.9874\n",
            "Epoch 5/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9964\n",
            "Epoch 00005: val_loss improved from 0.05914 to 0.05256, saving model to TESS//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.98745\n",
            "70/70 [==============================] - 16s 233ms/step - loss: 0.0231 - accuracy: 0.9964 - val_loss: 0.0526 - val_accuracy: 0.9874\n",
            "Epoch 6/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9973\n",
            "Epoch 00006: val_loss improved from 0.05256 to 0.04541, saving model to TESS//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.98745 to 0.99163, saving model to TESS//models/ensembled_hamming_acc.h5\n",
            "70/70 [==============================] - 18s 254ms/step - loss: 0.0170 - accuracy: 0.9973 - val_loss: 0.0454 - val_accuracy: 0.9916\n",
            "Epoch 7/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9982\n",
            "Epoch 00007: val_loss improved from 0.04541 to 0.03966, saving model to TESS//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 16s 233ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.0397 - val_accuracy: 0.9916\n",
            "Epoch 8/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9982\n",
            "Epoch 00008: val_loss improved from 0.03966 to 0.03646, saving model to TESS//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 16s 232ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.0365 - val_accuracy: 0.9916\n",
            "Epoch 9/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9991\n",
            "Epoch 00009: val_loss did not improve from 0.03646\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 16s 222ms/step - loss: 0.0081 - accuracy: 0.9991 - val_loss: 0.0384 - val_accuracy: 0.9916\n",
            "Epoch 10/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 00010: val_loss improved from 0.03646 to 0.03293, saving model to TESS//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 16s 225ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9916\n",
            "Epoch 11/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9991\n",
            "Epoch 00011: val_loss did not improve from 0.03293\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 216ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.0331 - val_accuracy: 0.9916\n",
            "Epoch 12/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9991\n",
            "Epoch 00012: val_loss improved from 0.03293 to 0.03038, saving model to TESS//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 16s 224ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0304 - val_accuracy: 0.9916\n",
            "Epoch 13/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 00013: val_loss did not improve from 0.03038\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 216ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9916\n",
            "Epoch 14/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 00014: val_loss improved from 0.03038 to 0.02910, saving model to TESS//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 16s 225ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9916\n",
            "Epoch 15/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 00015: val_loss did not improve from 0.02910\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 216ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9916\n",
            "Epoch 16/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 00016: val_loss did not improve from 0.02910\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 215ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 0.9916\n",
            "Epoch 17/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 00017: val_loss did not improve from 0.02910\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 215ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9916\n",
            "Epoch 18/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 00018: val_loss did not improve from 0.02910\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 215ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9916\n",
            "Epoch 19/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 00019: val_loss did not improve from 0.02910\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 216ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.9916\n",
            "Epoch 20/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 00020: val_loss improved from 0.02910 to 0.02730, saving model to TESS//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 16s 224ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9916\n",
            "Epoch 21/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 00021: val_loss did not improve from 0.02730\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 215ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9916\n",
            "Epoch 22/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 00022: val_loss improved from 0.02730 to 0.02652, saving model to TESS//models/ensembled_hamming_loss.h5\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 16s 224ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9916\n",
            "Epoch 23/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 8.2893e-04 - accuracy: 1.0000\n",
            "Epoch 00023: val_loss did not improve from 0.02652\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 216ms/step - loss: 8.2893e-04 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9916\n",
            "Epoch 24/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 7.7658e-04 - accuracy: 1.0000\n",
            "Epoch 00024: val_loss did not improve from 0.02652\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 216ms/step - loss: 7.7658e-04 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9916\n",
            "Epoch 25/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 7.5754e-04 - accuracy: 1.0000\n",
            "Epoch 00025: val_loss did not improve from 0.02652\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 216ms/step - loss: 7.5754e-04 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9916\n",
            "Epoch 26/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 6.0859e-04 - accuracy: 1.0000\n",
            "Epoch 00026: val_loss did not improve from 0.02652\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 216ms/step - loss: 6.0859e-04 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9916\n",
            "Epoch 27/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 5.7552e-04 - accuracy: 1.0000\n",
            "Epoch 00027: val_loss did not improve from 0.02652\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 216ms/step - loss: 5.7552e-04 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9916\n",
            "Epoch 28/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 5.5580e-04 - accuracy: 1.0000\n",
            "Epoch 00028: val_loss did not improve from 0.02652\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 216ms/step - loss: 5.5580e-04 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9916\n",
            "Epoch 29/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 4.9616e-04 - accuracy: 1.0000\n",
            "Epoch 00029: val_loss did not improve from 0.02652\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 215ms/step - loss: 4.9616e-04 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 0.9916\n",
            "Epoch 30/30\n",
            "70/70 [==============================] - ETA: 0s - loss: 4.4225e-04 - accuracy: 1.0000\n",
            "Epoch 00030: val_loss did not improve from 0.02652\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.99163\n",
            "70/70 [==============================] - 15s 216ms/step - loss: 4.4225e-04 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9916\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7d547d4190>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled.load_weights('TESS//models//ensembled_hamming_loss.h5')\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "\n",
        "ensembled.load_weights('TESS//models//ensembled_hamming_acc.h5')\n",
        "ensembled.evaluate([X_test,X_test_features],Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ugKTuG2DVP",
        "outputId": "412e46dc-ef5a-4875-a639-526b5ef5420e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 2s 144ms/step - loss: 0.0189 - accuracy: 0.9958\n",
            "[0.01888386905193329, 0.9958158731460571]\n",
            "8/8 [==============================] - 1s 155ms/step - loss: 0.0223 - accuracy: 0.9874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.022274935618042946, 0.9874476790428162]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensembled.load_weights('TESS//models//ensembled_hamming_acc.h5')\n",
        "print(ensembled.evaluate([X_test,X_test_features],Y_test))\n",
        "g = np.argmax(Y_test,axis = -1)\n",
        "p = np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1)\n",
        "g.ravel()\n",
        "p.ravel()\n",
        "from sklearn.metrics import *\n",
        "\n",
        "f1 = f1_score(g,p,average = 'macro')\n",
        "kappa = cohen_kappa_score(g,p)\n",
        "accuracy = accuracy_score(g,p) \n",
        "jaccard = jaccard_score(g,p,average = 'macro')\n",
        "precision = precision_score(g,p,average = 'macro') \n",
        "recall = recall_score(g,p,average = 'macro')\n",
        "#print(np.unique(gt),np.unique(pd))\n",
        "print(\"F1 SCORE:\", f1)\n",
        "print(\"Kappa:\",kappa)\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Jaccard Score:\",jaccard)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\",recall)\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(np.argmax(Y_test,axis = -1),np.argmax(ensembled.predict([X_test,X_test_features]),axis = -1))\n",
        "sns.heatmap(cf_matrix/cf_matrix.astype(np.float).sum(axis=1), annot=True, xticklabels =label_dict.keys(),yticklabels =label_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "DcHFr08J2lGk",
        "outputId": "cba11104-01ac-4ba8-858a-2d85fc517325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 157ms/step - loss: 0.0223 - accuracy: 0.9874\n",
            "[0.022274935618042946, 0.9874476790428162]\n",
            "F1 SCORE: 0.987548878370035\n",
            "Kappa: 0.9832433569375307\n",
            "Accuracy: 0.9874476987447699\n",
            "Jaccard Score: 0.975705329153605\n",
            "Precision: 0.9878434065934066\n",
            "Recall: 0.9873218201754386\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7cdb4f5710>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "awPEl1Yv4nUk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}